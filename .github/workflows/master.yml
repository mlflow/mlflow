name: MLflow tests

on:
  pull_request:
  push:
    branches:
      - master
      - branch-[0-9]+.[0-9]+
  workflow_dispatch:
    inputs:
      repository:
        description: >
          [Optional] Repository name with owner. For example, mlflow/mlflow.
           Defaults to the repository that triggered a workflow.
        required: false
        default: ""
      ref:
        description: >
          [Optional] The branch, tag or SHA to checkout. When checking out the repository that
           triggered a workflow, this defaults to the reference or SHA for that event. Otherwise,
           uses the default branch.
        required: false
        default: ""

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

# Use `bash --noprofile --norc -exo pipefail` by default for all `run` steps in this workflow:
# https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions#defaultsrun
defaults:
  run:
    shell: bash --noprofile --norc -exo pipefail {0}

env:
  # Note miniconda is pre-installed in the virtual environments for GitHub Actions:
  # https://github.com/actions/virtual-environments/blob/main/images/linux/scripts/installers/miniconda.sh
  MLFLOW_CONDA_HOME: /usr/share/miniconda
  SPARK_LOCAL_IP: localhost

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
      with:
        repository: ${{ github.event.inputs.repository }}
        ref: ${{ github.event.inputs.ref }}
    - uses: ./.github/actions/setup-python
    - uses: ./.github/actions/cache-pip
    - name: Add problem matchers
      run: |
        echo "::add-matcher::.github/workflows/matchers/pylint.json"
        echo "::add-matcher::.github/workflows/matchers/black.json"
    - name: Install dependencies
      run: |
        source ./dev/install-common-deps.sh --ml
        pip install -r requirements/lint-requirements.txt
    - name: Test custom pylint-plugins
      run : |
        pytest pylint_plugins/tests
    - name: Install pre-commit hooks
      run: |
        pre-commit install -t pre-commit -t prepare-commit-msg
    - name: Run pre-commit
      run: |
        pre-commit run --all-files --color=always

  # python-skinny tests cover a subset of mlflow functionality
  # that is meant to be supported with a smaller dependency footprint.
  # The python skinny tests cover the subset of mlflow functionality
  # while also verifying certain dependencies are omitted.
  python-skinny:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
      with:
        submodules: recursive
        repository: ${{ github.event.inputs.repository }}
        ref: ${{ github.event.inputs.ref }}
    - uses: ./.github/actions/setup-python
    - name: Install dependencies
      run: |
        source ./dev/install-common-deps.sh --skinny
    - name: Run tests
      run: |
        ./dev/run-python-skinny-tests.sh

  python:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
      with:
        repository: ${{ github.event.inputs.repository }}
        ref: ${{ github.event.inputs.ref }}
        submodules: recursive
    - name: Increase available disk space
      run: |
        # Increase available disk space by removing unnecessary tool chains:
        # https://github.com/actions/virtual-environments/issues/709#issuecomment-612569242
        rm -rf "$AGENT_TOOLSDIRECTORY"
    - uses: ./.github/actions/setup-python
    - uses: ./.github/actions/setup-pyenv
    - uses: ./.github/actions/setup-java
      with:
        java-version: 11
        distribution: 'adopt'
    - uses: ./.github/actions/cache-pip
    - name: Install dependencies
      run: |
        source ./dev/install-common-deps.sh --ml
    - name: Run tests
      run: |
        source dev/setup-ssh.sh
        ./dev/run-python-tests.sh

  database:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
      with:
        repository: ${{ github.event.inputs.repository }}
        ref: ${{ github.event.inputs.ref }}
        submodules: recursive
    - name: Build
      run: |
        ./tests/db/compose.sh pull -q postgresql mysql mssql
        ./tests/db/compose.sh build --build-arg DEPENDENCIES="$(python setup.py -q dependencies)"
    - name: Run tests
      run: |
        set +e
        err=0
        trap 'err=1' ERR

        for service in $(./tests/db/compose.sh config --services | grep '^mlflow-')
        do
          # Set `--no-TTY` to show container logs on GitHub Actions:
          # https://github.com/actions/virtual-environments/issues/5022
          ./tests/db/compose.sh run --rm --no-TTY $service pytest \
            tests/store/tracking/test_sqlalchemy_store.py \
            tests/store/model_registry/test_sqlalchemy_store.py \
            tests/db
        done

        test $err = 0

    - name: Run migration check
      run: |
        set +e
        err=0
        trap 'err=1' ERR

        ./tests/db/compose.sh down --volumes --remove-orphans
        for service in $(./tests/db/compose.sh config --services | grep '^migration-')
        do
          ./tests/db/compose.sh run --rm --no-TTY $service
        done

        test $err = 0

    - name: Rebuild images with SQLAlchemy 2.x
      run: |
        sed -i 's/sqlalchemy.*/sqlalchemy>=2.0.0b2/g' requirements/core-requirements.txt
        git diff
        ./tests/db/compose.sh build --build-arg DEPENDENCIES="$(python setup.py -q dependencies)"
    - name: Run tests
      run: |
        set +e
        err=0
        trap 'err=1' ERR

        for service in $(./tests/db/compose.sh config --services | grep '^mlflow-')
        do
          # Set `--no-TTY` to show container logs on GitHub Actions:
          ./tests/db/compose.sh run --rm --no-TTY $service pytest \
            tests/store/tracking/test_sqlalchemy_store.py \
            tests/store/model_registry/test_sqlalchemy_store.py \
            tests/db
        done

        test $err = 0
    - name: Clean up
      run: |
        ./tests/db/compose.sh down --volumes --remove-orphans --rmi all

  java:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
      with:
        submodules: recursive
        repository: ${{ github.event.inputs.repository }}
        ref: ${{ github.event.inputs.ref }}
    - uses: ./.github/actions/setup-python
    - uses: ./.github/actions/setup-java
    - name: Install dependencies
      run: |
        source ./dev/install-common-deps.sh
    - name: Run tests
      run: |
        cd mlflow/java
        mvn clean package -q

  flavors:
    # TODO: Change this to 'ubuntu-latest' once https://github.com/mlflow/mlflow/issues/7222 is fixed
    runs-on: ubuntu-20.04
    steps:
      - uses: actions/checkout@v3
        with:
          repository: ${{ github.event.inputs.repository }}
          ref: ${{ github.event.inputs.ref }}
          submodules: recursive
      - name: Increase available disk space
        run: |
          # Increase available disk space by removing unnecessary tool chains:
          # https://github.com/actions/virtual-environments/issues/709#issuecomment-612569242
          rm -rf "$AGENT_TOOLSDIRECTORY"
      - uses: ./.github/actions/setup-python
      - uses: ./.github/actions/setup-pyenv
      - uses: ./.github/actions/setup-java
      - uses: ./.github/actions/cache-pip
      - name: Install dependencies
        run: |
          source ./dev/install-common-deps.sh --ml
      - name: Run tests
        run: |
          ./dev/run-python-flavor-tests.sh;

  # It takes 9 ~ 10 minutes to run tests in `tests/models`. To make CI finish faster,
  # run these tests in a separate job.
  models:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          submodules: recursive
          repository: ${{ github.event.inputs.repository }}
          ref: ${{ github.event.inputs.ref }}
      - uses: ./.github/actions/setup-python
      - uses: ./.github/actions/setup-pyenv
      - uses: ./.github/actions/setup-java
      - name: Install dependencies
        run: |
          source ./dev/install-common-deps.sh
          pip install pyspark
      - name: Run tests
        run: |
          export MLFLOW_HOME=$(pwd)
          pytest tests/models

  pyfunc:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          repository: ${{ github.event.inputs.repository }}
          ref: ${{ github.event.inputs.ref }}
          submodules: recursive
      - uses: ./.github/actions/setup-python
      - uses: ./.github/actions/setup-pyenv
      - uses: ./.github/actions/setup-java
      - name: Install dependencies
        run: |
          source ./dev/install-common-deps.sh
          pip install tensorflow pyspark
      - name: Run tests
        run: |
          export MLFLOW_HOME=$(pwd)
          pytest --durations=30 tests/pyfunc

  sagemaker:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          submodules: recursive
          repository: ${{ github.event.inputs.repository }}
          ref: ${{ github.event.inputs.ref }}
      - uses: ./.github/actions/setup-python
      - uses: ./.github/actions/setup-java
      - name: Install dependencies
        run: |
          source ./dev/install-common-deps.sh --ml
      - name: Run tests
        run: |
          ./dev/run-python-sagemaker-tests.sh;

  windows:
    runs-on: windows-latest
    steps:
      - uses: actions/checkout@v3
        with:
          submodules: recursive
          repository: ${{ github.event.inputs.repository }}
          ref: ${{ github.event.inputs.ref }}
      - uses: ./.github/actions/setup-python
      - uses: ./.github/actions/setup-pyenv
      - uses: ./.github/actions/setup-java
      - name: Install python dependencies
        run: |
          pip install -r requirements/test-requirements.txt
          pip install --no-dependencies tests/resources/mlflow-test-plugin
          pip install -e .[extras]
          pip install pyspark
      - name: Download Hadoop winutils for Spark
        run: |
          git clone https://github.com/cdarlint/winutils
      - name: Run python tests
        run: |
          # Set Hadoop environment variables required for testing Spark integrations on Windows
          export HADOOP_HOME=`realpath winutils/hadoop-3.2.2`
          export PATH=$PATH:$HADOOP_HOME/bin
          # Run Windows tests
          pytest --ignore-flavors --ignore=tests/projects --ignore=tests/examples tests --ignore=tests/recipes

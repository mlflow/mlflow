name: codex

on:
  pull_request:

jobs:
  codex:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      models: read
      pull-requests: write
    timeout-minutes: 10
    steps:
      - name: Install codex
        run: |
          npm install -g @openai/codex

      - name: Set up config
        run: |
          # https://github.com/openai/codex/blob/main/codex-rs/config.md
          mkdir -p ~/.codex
          cat <<EOF > ~/.codex/config.toml
          model = "openai/gpt-4.1"
          model_provider = "github-models"

          [model_providers.github-models]
          name = "GitHub Models"
          base_url = "https://models.github.ai/inference"
          env_key = "GITHUB_TOKEN"
          wire_api = "chat"

          [mcp_servers.github]
          command = "docker"
          args = [
            "run",
            "-i",
            "--rm",
            "-e",
            "GITHUB_PERSONAL_ACCESS_TOKEN",
            "ghcr.io/github/github-mcp-server",
          ]
          env = { "GITHUB_PERSONAL_ACCESS_TOKEN" = "${{ secrets.GITHUB_TOKEN }}" }
          EOF

      - name: Run codex
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          codex --full-auto --skip-git-repo-check exec "Can you review https://github.com/mlflow/mlflow/pull/17335 and leave comments?"

syntax = "proto2";

package mlflow;

import "scalapb/scalapb.proto";

option java_package = "org.mlflow.api.proto";
option py_generic_services = true;
option (scalapb.options) = {flat_package: true};

// Status of an optimization job.
enum OptimizationJobStatus {
  OPTIMIZATION_JOB_STATUS_UNSPECIFIED = 0;

  OPTIMIZATION_JOB_STATUS_PENDING = 1;

  OPTIMIZATION_JOB_STATUS_IN_PROGRESS = 2;

  OPTIMIZATION_JOB_STATUS_COMPLETED = 3;

  OPTIMIZATION_JOB_STATUS_FAILED = 4;

  OPTIMIZATION_JOB_STATUS_CANCELED = 5;
}

// Type of optimizer algorithm to use.
enum OptimizerType {
  OPTIMIZER_TYPE_UNSPECIFIED = 0;

  // GEPA (Guided Evolution of Prompt Attributes) optimizer.
  OPTIMIZER_TYPE_GEPA = 1;

  // MetaPrompt optimizer - uses metaprompting with LLMs to improve prompts in a single pass.
  OPTIMIZER_TYPE_METAPROMPT = 2;
}

// Tag for an optimization job.
message OptimizationJobTag {
  optional string key = 1;

  optional string value = 2;
}

// Configuration for a prompt optimization job.
// Stored as run parameters in the underlying MLflow run.
message OptimizationJobConfig {
  // URI of the target prompt to optimize (e.g., "prompts:/my-prompt/1").
  optional string target_prompt_uri = 1;

  // The optimizer type to use.
  optional OptimizerType optimizer_type = 2;

  // JSON-serialized optimizer-specific configuration.
  // Different optimizers accept different parameters:
  // - GEPA: {"reflection_model": "openai:/gpt-5", "max_metric_calls": 300}
  // - MetaPrompt: {"reflection_model": "openai:/gpt-5", "guidelines": "...", "lm_kwargs": {...}}
  optional string optimizer_config_json = 3;
}

// Represents a prompt optimization job entity.
message OptimizationJob {
  // Unique identifier for the optimization job.
  // Used to poll job execution status (pending/running/completed/failed).
  optional string job_id = 1;

  // MLflow run ID where optimization metrics and results are stored.
  // Use this to view results in MLflow UI. Only available after job starts running.
  optional string run_id = 2;

  // Current status of the job.
  optional OptimizationJobStatus status = 3;

  // ID of the MLflow experiment where this optimization job is tracked.
  optional string experiment_id = 4;

  // URI of the source prompt that optimization started from (e.g., "prompts:/my-prompt/1").
  optional string source_prompt_uri = 5;

  // URI of the optimized prompt (e.g., "prompts:/my-prompt/2").
  // Only set if optimization completed successfully.
  optional string optimized_prompt_uri = 6;

  // Configuration for the optimization job.
  optional OptimizationJobConfig config = 7;

  // Timestamp when the job was created (milliseconds since epoch).
  optional int64 creation_timestamp_ms = 8;

  // Timestamp when the job completed (milliseconds since epoch).
  // Only set if status is COMPLETED, FAILED, or CANCELED.
  optional int64 completion_timestamp_ms = 9;

  // Error message if the job failed.
  optional string error_message = 10;

  // Tags associated with this job.
  repeated OptimizationJobTag tags = 11;

  // Initial evaluation score before optimization (from MLflow run metrics).
  optional double initial_eval_score = 12;

  // Final evaluation score after optimization (from MLflow run metrics).
  optional double final_eval_score = 13;
}

syntax = "proto2";

package mlflow;

import "assessments.proto";
import "databricks.proto";
import "datasets.proto";
import "google/protobuf/duration.proto";
import "google/protobuf/field_mask.proto";
import "google/protobuf/timestamp.proto";
import "opentelemetry/proto/trace/v1/trace.proto";
import "prompt_optimization.proto";
import "scalapb/scalapb.proto";

option java_package = "org.mlflow.api.proto";
option py_generic_services = true;
option (scalapb.options) = {flat_package: true};

service MlflowService {
  // Get metadata for an experiment.
  //
  // This endpoint will return deleted experiments, but prefers the active experiment
  // if an active and deleted experiment share the same name. If multiple deleted
  // experiments share the same name, the API will return one of them.
  //
  // Throws ``RESOURCE_DOES_NOT_EXIST`` if no experiment with the specified name exists.
  //
  rpc getExperimentByName(GetExperimentByName) returns (GetExperimentByName.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/experiments/get-by-name"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Get Experiment By Name"
    };
  }

  // Create an experiment with a name. Returns the ID of the newly created experiment.
  // Validates that another experiment with the same name does not already exist and fails
  // if another experiment with the same name already exists.
  //
  //
  // Throws ``RESOURCE_ALREADY_EXISTS`` if a experiment with the given name exists.
  //
  rpc createExperiment(CreateExperiment) returns (CreateExperiment.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/experiments/create"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Create Experiment"
    };
  }

  rpc searchExperiments(SearchExperiments) returns (SearchExperiments.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/experiments/search"
          since: {
            major: 2
            minor: 0
          }
        },
        {
          method: "GET"
          path: "/mlflow/experiments/search"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Search Experiments"
    };
  }

  // Get metadata for an experiment. This method works on deleted experiments.
  rpc getExperiment(GetExperiment) returns (GetExperiment.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/experiments/get"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Get Experiment"
    };
    option (graphql) = {};
  }

  // Mark an experiment and associated metadata, runs, metrics, params, and tags for deletion.
  // If the experiment uses FileStore, artifacts associated with experiment are also deleted.
  //
  rpc deleteExperiment(DeleteExperiment) returns (DeleteExperiment.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/experiments/delete"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Delete Experiment"
    };
  }

  // Restore an experiment marked for deletion. This also restores
  // associated metadata, runs, metrics, params, and tags. If experiment uses FileStore, underlying
  // artifacts associated with experiment are also restored.
  //
  // Throws ``RESOURCE_DOES_NOT_EXIST`` if experiment was never created or was permanently deleted.
  //
  rpc restoreExperiment(RestoreExperiment) returns (RestoreExperiment.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/experiments/restore"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Restore Experiment"
    };
  }

  // Update experiment metadata.
  //
  rpc updateExperiment(UpdateExperiment) returns (UpdateExperiment.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/experiments/update"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Update Experiment"
    };
  }

  // Create a new run within an experiment. A run is usually a single execution of a
  // machine learning or data ETL pipeline. MLflow uses runs to track :ref:`mlflowParam`,
  // :ref:`mlflowMetric`, and :ref:`mlflowRunTag` associated with a single execution.
  //
  rpc createRun(CreateRun) returns (CreateRun.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/runs/create"
          since: {
            major: 2
            minor: 0
          }
        }
      ]

      visibility: PUBLIC
      rpc_doc_title: "Create Run"
    };
  }

  // Update run metadata.
  //
  rpc updateRun(UpdateRun) returns (UpdateRun.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/runs/update"
          since: {
            major: 2
            minor: 0
          }
        }
      ]

      visibility: PUBLIC
      rpc_doc_title: "Update Run"
    };
  }

  // Mark a run for deletion.
  rpc deleteRun(DeleteRun) returns (DeleteRun.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/runs/delete"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Delete Run"
    };
  }

  // Restore a deleted run.
  rpc restoreRun(RestoreRun) returns (RestoreRun.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/runs/restore"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Restore Run"
    };
  }

  // Log a metric for a run. A metric is a key-value pair (string key, float value) with an
  // associated timestamp. Examples include the various metrics that represent ML model accuracy.
  // A metric can be logged multiple times.
  //
  rpc logMetric(LogMetric) returns (LogMetric.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/runs/log-metric"
          since: {
            major: 2
            minor: 0
          }
        }
      ]

      visibility: PUBLIC
      rpc_doc_title: "Log Metric"
    };
  }

  // Log a param used for a run. A param is a key-value pair (string key,
  // string value). Examples include hyperparameters used for ML model training and
  // constant dates and values used in an ETL pipeline. A param can be logged only once for a run.
  //
  rpc logParam(LogParam) returns (LogParam.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/runs/log-parameter"
          since: {
            major: 2
            minor: 0
          }
        }
      ]

      visibility: PUBLIC
      rpc_doc_title: "Log Param"
    };
  }

  // Set a tag on an experiment. Experiment tags are metadata that can be updated.
  //
  rpc setExperimentTag(SetExperimentTag) returns (SetExperimentTag.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/experiments/set-experiment-tag"
          since: {
            major: 2
            minor: 0
          }
        }
      ]

      visibility: PUBLIC
      rpc_doc_title: "Set Experiment Tag"
    };
  }

  // Delete a tag on an experiment.
  //
  rpc deleteExperimentTag(DeleteExperimentTag) returns (DeleteExperimentTag.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/experiments/delete-experiment-tag"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Delete Experiment Tag"
    };
  }

  // Set a tag on a run. Tags are run metadata that can be updated during a run and after
  // a run completes.
  //
  rpc setTag(SetTag) returns (SetTag.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/runs/set-tag"
          since: {
            major: 2
            minor: 0
          }
        }
      ]

      visibility: PUBLIC
      rpc_doc_title: "Set Tag"
    };
  }

  // DEPRECATED. Use setTraceTagV3 instead.
  rpc setTraceTag(SetTraceTag) returns (SetTraceTag.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "PATCH"
          path: "/mlflow/traces/{request_id}/tags"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Set Trace Tag"
    };
  }

  // Set a tag on a trace. Tags are mutable and can be updated as desired.
  rpc setTraceTagV3(SetTraceTagV3) returns (SetTraceTagV3.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "PATCH"
          path: "/mlflow/traces/{trace_id}/tags"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Set Trace Tag V3"
    };
  }

  // DEPRECATED. Use deleteTraceTagV3 instead.
  rpc deleteTraceTag(DeleteTraceTag) returns (DeleteTraceTag.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "DELETE"
          path: "/mlflow/traces/{request_id}/tags"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Delete Trace Tag"
    };
  }

  // Delete a tag from a trace.
  rpc deleteTraceTagV3(DeleteTraceTagV3) returns (DeleteTraceTagV3.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "DELETE"
          path: "/mlflow/traces/{trace_id}/tags"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Delete Trace Tag V3"
    };
  }

  // Delete a tag on a run. Tags are run metadata that can be updated during a run and after
  // a run completes.
  //
  rpc deleteTag(DeleteTag) returns (DeleteTag.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/runs/delete-tag"
          since: {
            major: 2
            minor: 0
          }
        }
      ]

      visibility: PUBLIC
      rpc_doc_title: "Delete Tag"
    };
  }

  // Get metadata, metrics, params, and tags for a run. In the case where multiple metrics
  // with the same key are logged for a run, return only the value with the latest timestamp.
  // If there are multiple values with the latest timestamp, return the maximum of these values.
  rpc getRun(GetRun) returns (GetRun.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/runs/get"
          since: {
            major: 2
            minor: 0
          }
        }
      ]

      visibility: PUBLIC
      rpc_doc_title: "Get Run"
    };
    option (graphql) = {};
  }

  // Search for runs that satisfy expressions. Search expressions can use :ref:`mlflowMetric` and
  // :ref:`mlflowParam` keys.
  //
  rpc searchRuns(SearchRuns) returns (SearchRuns.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/runs/search"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Search Runs"
    };
    option (graphql) = {};
  }

  // List artifacts for a run. Takes an optional ``artifact_path`` prefix which if specified,
  // the response contains only artifacts with the specified prefix.
  //
  rpc listArtifacts(ListArtifacts) returns (ListArtifacts.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/artifacts/list"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "List Artifacts"
    };
    option (graphql) = {};
  }

  // Get a list of all values for the specified metric for a given run.
  //
  rpc getMetricHistory(GetMetricHistory) returns (GetMetricHistory.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/metrics/get-history"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Get Metric History"
    };
  }

  // Retrieves the value history for a specified metric across one or more specified runs.
  rpc getMetricHistoryBulkInterval(GetMetricHistoryBulkInterval) returns (GetMetricHistoryBulkInterval.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/metrics/get-history-bulk-interval"
          since: {
            major: 2
            minor: 11
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
    };
    option (graphql) = {};
  }

  // Log a batch of metrics, params, and tags for a run.
  // If any data failed to be persisted, the server will respond with an error (non-200 status code).
  // In case of error (due to internal server error or an invalid request), partial data may
  // be written.
  //
  // You can write metrics, params, and tags in interleaving fashion, but within a given entity
  // type are guaranteed to follow the order specified in the request body. That is, for an API
  // request like
  //
  // .. code-block:: json
  //
  //   {
  //      "run_id": "2a14ed5c6a87499199e0106c3501eab8",
  //      "metrics": [
  //        {"key": "mae", "value": 2.5, "timestamp": 1552550804},
  //        {"key": "rmse", "value": 2.7, "timestamp": 1552550804},
  //      ],
  //      "params": [
  //        {"key": "model_class", "value": "LogisticRegression"},
  //      ]
  //   }
  //
  // the server is guaranteed to write metric "rmse" after "mae", though it may write param
  // "model_class" before both metrics, after "mae", or after both metrics.
  //
  // The overwrite behavior for metrics, params, and tags is as follows:
  //
  // - Metrics: metric values are never overwritten. Logging a metric (key, value, timestamp) appends to the set of values for the metric with the provided key.
  //
  // - Tags: tag values can be overwritten by successive writes to the same tag key. That is, if multiple tag values with the same key are provided in the same API request, the last-provided tag value is written. Logging the same tag (key, value) is permitted - that is, logging a tag is idempotent.
  //
  // - Params: once written, param values cannot be changed (attempting to overwrite a param value will result in an error). However, logging the same param (key, value) is permitted - that is, logging a param is idempotent.
  //
  // Request Limits
  // --------------
  // A single JSON-serialized API request may be up to 1 MB in size and contain:
  //
  // - No more than 1000 metrics, params, and tags in total
  // - Up to 1000 metrics
  // - Up to 100 params
  // - Up to 100 tags
  //
  // For example, a valid request might contain 900 metrics, 50 params, and 50 tags, but logging
  // 900 metrics, 50 params, and 51 tags is invalid. The following limits also apply
  // to metric, param, and tag keys and values:
  //
  // - Metric, param, and tag keys can be up to 250 characters in length
  // - Param and tag values can be up to 250 characters in length
  //
  rpc logBatch(LogBatch) returns (LogBatch.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/runs/log-batch"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Log Batch"
    };
  }

  // .. note::
  //     Experimental: This API may change or be removed in a future release without warning.
  rpc logModel(LogModel) returns (LogModel.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/runs/log-model"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Log Model"
    };
  }

  rpc logInputs(LogInputs) returns (LogInputs.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/runs/log-inputs"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Log Inputs"
    };
  }

  // Logs outputs, such as datasets and models, from an MLflow Run.
  //
  // .. note::
  //     Experimental: This API may change or be removed in a future release without warning.
  rpc logOutputs(LogOutputs) returns (LogOutputs.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/runs/outputs"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Log Outputs"
    };
  }

  rpc searchDatasets(SearchDatasets) returns (SearchDatasets.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "mlflow/experiments/search-datasets"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
    };
    option (graphql) = {};
  }

  // Start a new trace within an experiment.
  rpc startTrace(StartTrace) returns (StartTrace.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/traces"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Start Trace"
    };
  }

  // End a trace within an experiment.
  rpc endTrace(EndTrace) returns (EndTrace.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "PATCH"
          path: "/mlflow/traces/{request_id}"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "End Trace"
    };
  }

  // DEPRECATED. Use getTraceInfoV3 instead.
  rpc getTraceInfo(GetTraceInfo) returns (GetTraceInfo.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/traces/{request_id}/info"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Get TraceInfo"
    };
  }

  // Get Trace (returning a TraceInfoV3). Differences between TraceV3 and Trace
  // are assessments and semantics of TraceLocation, which describes where the Trace is stored.
  rpc getTraceInfoV3(GetTraceInfoV3) returns (GetTraceInfoV3.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/traces/{trace_id}"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Get TraceInfo v3"
    };
  }

  // Get trace with spans for given trace id.
  // This API is for OSS MLflow only for traces in v3.
  rpc getTrace(GetTrace) returns (GetTrace.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/traces/get"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Get Trace v3"
    };
  }

  // Get complete traces with spans for given trace identifiers.
  // This API is for OSS MLflow only for traces in v3.
  rpc batchGetTraces(BatchGetTraces) returns (BatchGetTraces.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/traces/batchGet"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Get Traces"
    };
  }

  // DEPRECATED. Use searchTracesV3 instead.
  rpc searchTraces(SearchTraces) returns (SearchTraces.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/traces"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Search Traces"
    };
  }

  // Search for traces that satisfy specified filters
  // (e.g. ``trace.status = 'OK' and trace.timestamp_ms > 1711089570679``), and retrieve the traces
  // in a specified ordering (e.g. ``["timestamp_ms DESC"]``).
  rpc searchTracesV3(SearchTracesV3) returns (SearchTracesV3.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/traces/search"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Search Traces V3"
    };
  }

  // Create a trace using the V3 API format
  rpc startTraceV3(StartTraceV3) returns (StartTraceV3.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/traces"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
    };
  }

  // Links traces to a run by creating internal trace input relationships.
  // This API allows associating multiple traces with runs for evaluation and labeling workflows.
  rpc linkTracesToRun(LinkTracesToRun) returns (LinkTracesToRun.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/traces/link-to-run"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Link Traces to Run"
    };
  }

  // Links prompt versions to a trace.
  rpc linkPromptsToTrace(LinkPromptsToTrace) returns (LinkPromptsToTrace.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/traces/link-prompts"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Link Prompts to Trace"
    };
  }

  // Edge endpoint used to search for online traces from an inference table.
  rpc searchUnifiedTraceHandler(SearchUnifiedTraces) returns (SearchUnifiedTraces.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/unified-traces"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Search Unified Traces"
    };
  }

  // Edge endpoint used to retrieve for online trace from an inference table.
  rpc getOnlineTraceDetails(GetOnlineTraceDetails) returns (GetOnlineTraceDetails.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/get-online-trace-details"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Get Online Trace Details"
    };
  }

  // DEPRECATED. Use deleteTracesV3 instead.
  rpc deleteTraces(DeleteTraces) returns (DeleteTraces.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/traces/delete-traces"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Delete Traces"
    };
  }

  // Delete traces. There are two supported ways to do this:
  // Case 1: ``max_timestamp_millis`` and ``max_traces`` may both be specified for time-based deletion.
  // Case 2: ``trace_ids`` may be specified for trace ID-based deletion.
  rpc deleteTracesV3(DeleteTracesV3) returns (DeleteTracesV3.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/traces/delete-traces"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Delete Traces V3"
    };
  }

  // Calculate the correlation (NPMI) between two trace filter conditions.
  rpc calculateTraceFilterCorrelation(CalculateTraceFilterCorrelation) returns (CalculateTraceFilterCorrelation.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/traces/calculate-filter-correlation"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Calculate Trace Filter Correlation"
    };
  }

  // Query aggregated metrics for traces, spans, or assessments.
  // Supports grouping by dimensions and time-based aggregation.
  rpc queryTraceMetrics(QueryTraceMetrics) returns (QueryTraceMetrics.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/traces/metrics"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Query Trace Metrics"
    };
  }

  rpc createLoggedModel(CreateLoggedModel) returns (CreateLoggedModel.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/logged-models"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Create Logged Model"
    };
  }

  rpc finalizeLoggedModel(FinalizeLoggedModel) returns (FinalizeLoggedModel.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "PATCH"
          path: "/mlflow/logged-models/{model_id}"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Finalize Logged Model"
    };
  }

  rpc getLoggedModel(GetLoggedModel) returns (GetLoggedModel.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/logged-models/{model_id}"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Get Logged Model"
    };
  }

  rpc deleteLoggedModel(DeleteLoggedModel) returns (DeleteLoggedModel.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "DELETE"
          path: "/mlflow/logged-models/{model_id}"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Delete a Logged Model"
    };
  }

  // Search for Logged Models that satisfy specified search criteria.
  rpc searchLoggedModels(SearchLoggedModels) returns (SearchLoggedModels.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/logged-models/search"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Search LoggedModels"
    };
  }

  rpc setLoggedModelTags(SetLoggedModelTags) returns (SetLoggedModelTags.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "PATCH"
          path: "/mlflow/logged-models/{model_id}/tags"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Set Logged Model Tag"
    };
  }

  rpc deleteLoggedModelTag(DeleteLoggedModelTag) returns (DeleteLoggedModelTag.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "DELETE"
          path: "/mlflow/logged-models/{model_id}/tags/{tag_key}"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Delete Logged Model Tag"
    };
  }

  // List artifacts for a LoggedModel. Takes an optional ``artifact_path`` prefix which if specified,
  // the response contains only artifacts with the specified prefix.
  rpc listLoggedModelArtifacts(ListLoggedModelArtifacts) returns (ListLoggedModelArtifacts.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/logged-models/{model_id}/artifacts/directories"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "List Artifacts for Logged Models"
    };
  }

  rpc LogLoggedModelParams(LogLoggedModelParamsRequest) returns (LogLoggedModelParamsRequest.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/logged-models/{model_id}/params"
          since: {
            major: 2
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Log Logged Model Params"
    };
  }

  rpc GetAssessment(GetAssessmentRequest) returns (GetAssessmentRequest.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/traces/{trace_id}/assessments/{assessment_id}"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Get Assessment"
    };
  }

  // Create an assessment associated with a trace.
  rpc createAssessment(CreateAssessment) returns (CreateAssessment.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/traces/{assessment.trace_id}/assessments"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        CUSTOMER_UNAUTHORIZED,
        ALREADY_EXISTS,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Create an assessment of a trace or a span within the trace"
    };
  }

  // Update an assessment associated with a trace.
  rpc updateAssessment(UpdateAssessment) returns (UpdateAssessment.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "PATCH"
          path: "/mlflow/traces/{trace_id}/assessments/{assessment_id}"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        CUSTOMER_UNAUTHORIZED,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Update an existing assessment on a trace."
    };
  }

  // Delete an assessment.
  rpc deleteAssessment(DeleteAssessment) returns (DeleteAssessment.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "DELETE"
          path: "/mlflow/traces/{trace_id}/assessments/{assessment_id}"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Delete Assessment"
    };
  }

  // Evaluation Dataset RPCs

  // Create an evaluation dataset
  rpc createDataset(CreateDataset) returns (CreateDataset.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/datasets/create"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        CUSTOMER_UNAUTHORIZED,
        ALREADY_EXISTS,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Create Evaluation Dataset"
    };
  }

  // Get an evaluation dataset by ID
  rpc getDataset(GetDataset) returns (GetDataset.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/datasets/{dataset_id}"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        RESOURCE_DOES_NOT_EXIST,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Get Evaluation Dataset"
    };
  }

  // Delete an evaluation dataset
  rpc deleteDataset(DeleteDataset) returns (DeleteDataset.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "DELETE"
          path: "/mlflow/datasets/{dataset_id}"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        RESOURCE_DOES_NOT_EXIST,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Delete Evaluation Dataset"
    };
  }

  // Search evaluation datasets
  rpc searchEvaluationDatasets(SearchEvaluationDatasets) returns (SearchEvaluationDatasets.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/datasets/search"
          since: {
            major: 3
            minor: 0
          }
        },
        {
          method: "GET"
          path: "/mlflow/datasets/search"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Search Evaluation Datasets"
    };
  }

  // Update evaluation dataset tags
  rpc setDatasetTags(SetDatasetTags) returns (SetDatasetTags.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "PATCH"
          path: "/mlflow/datasets/{dataset_id}/tags"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        RESOURCE_DOES_NOT_EXIST,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Set Evaluation Dataset Tags"
    };
  }

  // Delete an evaluation dataset tag
  rpc deleteDatasetTag(DeleteDatasetTag) returns (DeleteDatasetTag.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "DELETE"
          path: "/mlflow/datasets/{dataset_id}/tags/{key}"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        RESOURCE_DOES_NOT_EXIST,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Delete Evaluation Dataset Tag"
    };
  }

  // Upsert evaluation dataset records
  rpc upsertDatasetRecords(UpsertDatasetRecords) returns (UpsertDatasetRecords.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/datasets/{dataset_id}/records"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        RESOURCE_DOES_NOT_EXIST,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Upsert Evaluation Dataset Records"
    };
  }

  // Get experiment IDs associated with an evaluation dataset
  rpc getDatasetExperimentIds(GetDatasetExperimentIds) returns (GetDatasetExperimentIds.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/datasets/{dataset_id}/experiment-ids"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        RESOURCE_DOES_NOT_EXIST,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Get Evaluation Dataset Experiment IDs"
    };
  }

  // =============================================================================
  // Scorer Management RPCs
  // =============================================================================

  // Register a scorer for an experiment.
  rpc registerScorer(RegisterScorer) returns (RegisterScorer.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/scorers/register"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Register Scorer"
    };
  }

  // List all scorers for an experiment.
  rpc listScorers(ListScorers) returns (ListScorers.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/scorers/list"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "List Scorers"
    };
  }

  // List all versions of a specific scorer for an experiment.
  rpc listScorerVersions(ListScorerVersions) returns (ListScorerVersions.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/scorers/versions"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "List Scorer Versions"
    };
  }

  // Get a specific scorer for an experiment.
  rpc getScorer(GetScorer) returns (GetScorer.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/scorers/get"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Get Scorer"
    };
  }

  // Delete a scorer for an experiment.
  rpc deleteScorer(DeleteScorer) returns (DeleteScorer.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "DELETE"
          path: "/mlflow/scorers/delete"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Delete Scorer"
    };
  }

  // Get records for an evaluation dataset
  rpc getDatasetRecords(GetDatasetRecords) returns (GetDatasetRecords.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/datasets/{dataset_id}/records"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        RESOURCE_DOES_NOT_EXIST,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Get Evaluation Dataset Records"
    };
  }

  // Add a dataset to additional experiments
  rpc addDatasetToExperiments(AddDatasetToExperiments) returns (AddDatasetToExperiments.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/datasets/{dataset_id}/add-experiments"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        RESOURCE_DOES_NOT_EXIST,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Add Dataset to Experiments"
    };
  }

  // Remove a dataset from experiments
  rpc removeDatasetFromExperiments(RemoveDatasetFromExperiments) returns (RemoveDatasetFromExperiments.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/datasets/{dataset_id}/remove-experiments"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        RESOURCE_DOES_NOT_EXIST,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC_UNDOCUMENTED
      rpc_doc_title: "Remove Dataset from Experiments"
    };
  }

  // ========== Secrets Management APIs ==========

  // Create a new encrypted secret for LLM provider authentication
  rpc createGatewaySecret(CreateGatewaySecret) returns (CreateGatewaySecret.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/gateway/secrets/create"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Create Gateway Secret"
    };
  }

  // Get metadata about a secret (does not include the encrypted value)
  rpc getGatewaySecretInfo(GetGatewaySecretInfo) returns (GetGatewaySecretInfo.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/gateway/secrets/get"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Get Gateway Secret Info"
    };
  }

  // Update an existing secret's value or auth configuration
  rpc updateGatewaySecret(UpdateGatewaySecret) returns (UpdateGatewaySecret.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/gateway/secrets/update"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Update Gateway Secret"
    };
  }

  // Delete a secret
  rpc deleteGatewaySecret(DeleteGatewaySecret) returns (DeleteGatewaySecret.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "DELETE"
          path: "/mlflow/gateway/secrets/delete"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Delete Gateway Secret"
    };
  }

  // List all secrets with optional filtering by provider
  rpc listGatewaySecretInfos(ListGatewaySecretInfos) returns (ListGatewaySecretInfos.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/gateway/secrets/list"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "List Gateway Secrets"
    };
  }

  // ========== Endpoints Management APIs ==========

  // Create a new endpoint with model configurations
  rpc createGatewayEndpoint(CreateGatewayEndpoint) returns (CreateGatewayEndpoint.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/gateway/endpoints/create"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Create Gateway Endpoint"
    };
  }

  // Get endpoint details including all model configurations
  rpc getGatewayEndpoint(GetGatewayEndpoint) returns (GetGatewayEndpoint.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/gateway/endpoints/get"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Get Gateway Endpoint"
    };
  }

  // Update an endpoint's name
  rpc updateGatewayEndpoint(UpdateGatewayEndpoint) returns (UpdateGatewayEndpoint.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/gateway/endpoints/update"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Update Gateway Endpoint"
    };
  }

  // Delete an endpoint and all its model configurations
  rpc deleteGatewayEndpoint(DeleteGatewayEndpoint) returns (DeleteGatewayEndpoint.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "DELETE"
          path: "/mlflow/gateway/endpoints/delete"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Delete Gateway Endpoint"
    };
  }

  // List endpoints with optional filtering by provider or secret
  rpc listGatewayEndpoints(ListGatewayEndpoints) returns (ListGatewayEndpoints.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/gateway/endpoints/list"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "List Gateway Endpoints"
    };
  }

  // ========== Model Definitions Management APIs ==========

  // Create a reusable model definition
  rpc createGatewayModelDefinition(CreateGatewayModelDefinition) returns (CreateGatewayModelDefinition.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/gateway/model-definitions/create"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Create Gateway Model Definition"
    };
  }

  // Get a model definition by ID
  rpc getGatewayModelDefinition(GetGatewayModelDefinition) returns (GetGatewayModelDefinition.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/gateway/model-definitions/get"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Get Gateway Model Definition"
    };
  }

  // List all model definitions with optional filters
  rpc listGatewayModelDefinitions(ListGatewayModelDefinitions) returns (ListGatewayModelDefinitions.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/gateway/model-definitions/list"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "List Gateway Model Definitions"
    };
  }

  // Update a model definition
  rpc updateGatewayModelDefinition(UpdateGatewayModelDefinition) returns (UpdateGatewayModelDefinition.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/gateway/model-definitions/update"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Update Gateway Model Definition"
    };
  }

  // Delete a model definition (fails if in use by any endpoint)
  rpc deleteGatewayModelDefinition(DeleteGatewayModelDefinition) returns (DeleteGatewayModelDefinition.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "DELETE"
          path: "/mlflow/gateway/model-definitions/delete"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Delete Gateway Model Definition"
    };
  }

  // ========== Endpoint Model Mappings Management APIs ==========

  // Attach an existing model definition to an endpoint
  rpc attachModelToEndpoint(AttachModelToGatewayEndpoint) returns (AttachModelToGatewayEndpoint.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/gateway/endpoints/models/attach"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Attach Model to Endpoint"
    };
  }

  // Detach a model definition from an endpoint (does not delete the model definition)
  rpc detachModelFromEndpoint(DetachModelFromGatewayEndpoint) returns (DetachModelFromGatewayEndpoint.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/gateway/endpoints/models/detach"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Detach Model from Endpoint"
    };
  }

  // ========== Endpoint Bindings Management APIs ==========

  // Create a binding between an endpoint and an MLflow resource
  rpc createEndpointBinding(CreateGatewayEndpointBinding) returns (CreateGatewayEndpointBinding.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/gateway/endpoints/bindings/create"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Create Endpoint Binding"
    };
  }

  // Delete a binding between an endpoint and a resource
  rpc deleteEndpointBinding(DeleteGatewayEndpointBinding) returns (DeleteGatewayEndpointBinding.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "DELETE"
          path: "/mlflow/gateway/endpoints/bindings/delete"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Delete Endpoint Binding"
    };
  }

  // List all bindings for an endpoint
  rpc listEndpointBindings(ListGatewayEndpointBindings) returns (ListGatewayEndpointBindings.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/gateway/endpoints/bindings/list"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "List Endpoint Bindings"
    };
  }

  // Set a tag on an endpoint
  rpc setGatewayEndpointTag(SetGatewayEndpointTag) returns (SetGatewayEndpointTag.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/gateway/endpoints/set-tag"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Gateway Set Endpoint Tag"
    };
  }

  // Delete a tag from an endpoint
  rpc deleteGatewayEndpointTag(DeleteGatewayEndpointTag) returns (DeleteGatewayEndpointTag.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "DELETE"
          path: "/mlflow/gateway/endpoints/delete-tag"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      visibility: PUBLIC
      rpc_doc_title: "Gateway Delete Endpoint Tag"
    };
  }

  // Create a new prompt optimization job.
  // This endpoint initiates an optimization run with the specified configuration.
  // The optimization process runs asynchronously and can be monitored via getPromptOptimizationJob.
  rpc createPromptOptimizationJob(CreatePromptOptimizationJob) returns (CreatePromptOptimizationJob.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/prompt-optimization/jobs"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        RESOURCE_DOES_NOT_EXIST,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC
      rpc_doc_title: "Create Prompt Optimization Job"
    };
  }

  // Get the details and status of a prompt optimization job.
  // Returns the job configuration, current status, progress statistics,
  // and the best prompt if the optimization has completed.
  rpc getPromptOptimizationJob(GetPromptOptimizationJob) returns (GetPromptOptimizationJob.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "GET"
          path: "/mlflow/prompt-optimization/jobs/{job_id}"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        RESOURCE_DOES_NOT_EXIST,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC
      rpc_doc_title: "Get Prompt Optimization Job"
    };
  }

  // Search for prompt optimization jobs.
  // Returns a list of optimization jobs matching the specified filters.
  rpc searchPromptOptimizationJobs(SearchPromptOptimizationJobs) returns (SearchPromptOptimizationJobs.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/prompt-optimization/jobs/search"
          since: {
            major: 3
            minor: 0
          }
        },
        {
          method: "GET"
          path: "/mlflow/prompt-optimization/jobs/search"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC
      rpc_doc_title: "Search Prompt Optimization Jobs"
    };
  }

  // Cancel an in-progress prompt optimization job.
  // If the job is already completed or cancelled, this operation has no effect.
  rpc cancelPromptOptimizationJob(CancelPromptOptimizationJob) returns (CancelPromptOptimizationJob.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "POST"
          path: "/mlflow/prompt-optimization/jobs/{job_id}/cancel"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        RESOURCE_DOES_NOT_EXIST,
        INVALID_STATE,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC
      rpc_doc_title: "Cancel Prompt Optimization Job"
    };
  }

  // Delete a prompt optimization job and its associated data.
  // This permanently removes the job and all related information.
  rpc deletePromptOptimizationJob(DeletePromptOptimizationJob) returns (DeletePromptOptimizationJob.Response) {
    option (rpc) = {
      endpoints: [
        {
          method: "DELETE"
          path: "/mlflow/prompt-optimization/jobs/{job_id}"
          since: {
            major: 3
            minor: 0
          }
        }
      ]
      error_codes: [
        INVALID_PARAMETER_VALUE,
        RESOURCE_DOES_NOT_EXIST,
        INTERNAL_ERROR
      ]
      visibility: PUBLIC
      rpc_doc_title: "Delete Prompt Optimization Job"
    };
  }
}

// View type for ListExperiments query.
enum ViewType {
  // Default. Return only active experiments.
  ACTIVE_ONLY = 1;

  // Return only deleted experiments.
  DELETED_ONLY = 2;

  // Get all experiments.
  ALL = 3;
}

// Source that generated a run.
enum SourceType {
  // Databricks notebook environment.
  NOTEBOOK = 1;

  // Scheduled or Run Now job.
  JOB = 2;

  // As a prepackaged project: either a Docker image or GitHub source, etc.
  PROJECT = 3;

  // Local run: Using CLI, IDE, or local notebook.
  LOCAL = 4;

  // Unknown source type.
  UNKNOWN = 1000;
}

// Status of a run.
enum RunStatus {
  // Run has been initiated.
  RUNNING = 1;

  // Run is scheduled to run at a later time.
  SCHEDULED = 2;

  // Run has completed.
  FINISHED = 3;

  // Run execution failed.
  FAILED = 4;

  // Run killed by user.
  KILLED = 5;
}

// Metric associated with a run, represented as a key-value pair.
message Metric {
  // Key identifying this metric.
  optional string key = 1;

  // Value associated with this metric.
  optional double value = 2;

  // The timestamp at which this metric was recorded.
  optional int64 timestamp = 3;

  // Step at which to log the metric.
  optional int64 step = 4 [default = 0];

  // The name of the dataset associated with the metric.
  // E.g. "my.uc.table@2" "nyc-taxi-dataset", "fantastic-elk-3"
  optional string dataset_name = 5 [(visibility) = PUBLIC_UNDOCUMENTED];

  // Dataset digest of the dataset associated with the metric,
  // e.g. an md5 hash of the dataset that uniquely identifies it
  // within datasets of the same name.
  optional string dataset_digest = 6 [(visibility) = PUBLIC_UNDOCUMENTED];

  // The ID of the LoggedModel or Registered Model Version associated with
  // the metric, if applicable.
  optional string model_id = 7 [(visibility) = PUBLIC_UNDOCUMENTED];

  // The ID of the run containing the metric.
  optional string run_id = 8 [(visibility) = PUBLIC_UNDOCUMENTED];
}

// Param associated with a run.
message Param {
  // Key identifying this param.
  optional string key = 1;

  // Value associated with this param.
  optional string value = 2;
}

// A single run.
message Run {
  // Run metadata.
  optional RunInfo info = 1;
  // Run data.
  optional RunData data = 2;
  // Run inputs.
  optional RunInputs inputs = 3;
  // Run outputs.
  optional RunOutputs outputs = 4;
}

// Run data (metrics, params, and tags).
message RunData {
  // Run metrics.
  repeated Metric metrics = 1;
  // Run parameters.
  repeated Param params = 2;

  // Additional metadata key-value pairs.
  repeated RunTag tags = 3;
}

// Run inputs.
message RunInputs {
  // Dataset inputs to the Run.
  repeated DatasetInput dataset_inputs = 1;
  // Model inputs to the Run.
  repeated ModelInput model_inputs = 2;
}

// Outputs of a Run.
message RunOutputs {
  // Model outputs of the Run.
  repeated ModelOutput model_outputs = 1;
}

// Tag for a run.
message RunTag {
  // The tag key.
  optional string key = 1;
  // The tag value.
  optional string value = 2;
}

// Tag for an experiment.
message ExperimentTag {
  // The tag key.
  optional string key = 1;
  // The tag value.
  optional string value = 2;
}

// Metadata of a single run.
message RunInfo {
  // Unique identifier for the run.
  optional string run_id = 15;

  // [Deprecated, use run_id instead] Unique identifier for the run. This field will
  // be removed in a future MLflow version.
  optional string run_uuid = 1;

  // The name of the run.
  optional string run_name = 3;

  // The experiment ID.
  optional string experiment_id = 2;

  // User who initiated the run.
  // This field is deprecated as of MLflow 1.0, and will be removed in a future
  // MLflow release. Use 'mlflow.user' tag instead.
  optional string user_id = 6;

  // Current status of the run.
  optional RunStatus status = 7;

  // Unix timestamp of when the run started in milliseconds.
  optional int64 start_time = 8;

  // Unix timestamp of when the run ended in milliseconds.
  optional int64 end_time = 9;

  // URI of the directory where artifacts should be uploaded.
  // This can be a local path (starting with "/"), or a distributed file system (DFS)
  // path, like ``s3://bucket/directory`` or ``dbfs:/my/directory``.
  // If not set, the local ``./mlruns`` directory is  chosen.
  optional string artifact_uri = 13;

  // Current life cycle stage of the experiment : OneOf("active", "deleted")
  optional string lifecycle_stage = 14;
}

// Experiment
message Experiment {
  // Unique identifier for the experiment.
  optional string experiment_id = 1;

  // Human readable name that identifies the experiment.
  optional string name = 2;

  // Location where artifacts for the experiment are stored.
  optional string artifact_location = 3;

  // Current life cycle stage of the experiment: "active" or "deleted".
  // Deleted experiments are not returned by APIs.
  optional string lifecycle_stage = 4;

  // Last update time
  optional int64 last_update_time = 5;

  // Creation time
  optional int64 creation_time = 6;

  // Tags: Additional metadata key-value pairs.
  repeated ExperimentTag tags = 7;
}

// DatasetInput. Represents a dataset and input tags.
message DatasetInput {
  // A list of tags for the dataset input, e.g. a "context" tag with value "training"
  repeated InputTag tags = 1;

  // The dataset being used as a Run input.
  optional Dataset dataset = 2 [(validate_required) = true];
}

// Represents a LoggedModel or Registered Model Version input to a Run.
message ModelInput {
  // The unique identifier of the model.
  optional string model_id = 1 [(validate_required) = true];
}

// Tag for an input.
message InputTag {
  // The tag key.
  optional string key = 1 [(validate_required) = true];
  // The tag value.
  optional string value = 2 [(validate_required) = true];
}

// Dataset. Represents a reference to data used for training, testing, or evaluation during
// the model development process.
message Dataset {
  // The name of the dataset. E.g. "my.uc.table@2" "nyc-taxi-dataset", "fantastic-elk-3"
  optional string name = 1 [(validate_required) = true];

  // Dataset digest, e.g. an md5 hash of the dataset that uniquely identifies it
  // within datasets of the same name.
  optional string digest = 2 [(validate_required) = true];

  // The type of the dataset source, e.g. 'databricks-uc-table', 'DBFS', 'S3', ...
  optional string source_type = 3 [(validate_required) = true];

  // Source information for the dataset. Note that the source may not exactly reproduce the
  // dataset if it was transformed / modified before use with MLflow.
  optional string source = 4 [(validate_required) = true];

  // The schema of the dataset. E.g., MLflow ColSpec JSON for a dataframe, MLflow TensorSpec JSON
  // for an ndarray, or another schema format.
  optional string schema = 5;

  // The profile of the dataset. Summary statistics for the dataset, such as the number of rows
  // in a table, the mean / std / mode of each column in a table, or the number of elements
  // in an array.
  optional string profile = 6;
}

// Represents a LoggedModel output of a Run.
message ModelOutput {
  // The unique identifier of the model.
  optional string model_id = 1 [(validate_required) = true];

  // Step at which the model was produced.
  optional int64 step = 2 [(validate_required) = true];
}

message CreateExperiment {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Experiment name.
  optional string name = 1 [(validate_required) = true];

  // Location where all artifacts for the experiment are stored.
  // If not provided, the remote server will select an appropriate default.
  optional string artifact_location = 2;

  // A collection of tags to set on the experiment. Maximum tag size and number of tags per request
  // depends on the storage backend. All storage backends are guaranteed to support tag keys up
  // to 250 bytes in size and tag values up to 5000 bytes in size. All storage backends are also
  // guaranteed to support up to 20 tags per request.
  repeated ExperimentTag tags = 3;

  message Response {
    // Unique identifier for the experiment.
    optional string experiment_id = 1;
  }
}

message SearchExperiments {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Maximum number of experiments desired.
  // Servers may select a desired default `max_results` value. All servers are
  // guaranteed to support a `max_results` threshold of at least 1,000 but may
  // support more. Callers of this endpoint are encouraged to pass max_results
  // explicitly and leverage page_token to iterate through experiments.
  optional int64 max_results = 1;

  // Token indicating the page of experiments to fetch
  optional string page_token = 2;

  // A filter expression over experiment attributes and tags that allows returning a subset of
  // experiments. The syntax is a subset of SQL that supports ANDing together binary operations
  // between an attribute or tag, and a constant.
  //
  // Example: ``name LIKE 'test-%' AND tags.key = 'value'``
  //
  // You can select columns with special characters (hyphen, space, period, etc.) by using
  // double quotes or backticks.
  //
  // Example: ``tags."extra-key" = 'value'`` or ``tags.`extra-key` = 'value'``
  //
  // Supported operators are ``=``, ``!=``, ``LIKE``, and ``ILIKE``.
  optional string filter = 3;

  // List of columns for ordering search results, which can include experiment name and id
  // with an optional "DESC" or "ASC" annotation, where "ASC" is the default.
  // Tiebreaks are done by experiment id DESC.
  repeated string order_by = 4;

  // Qualifier for type of experiments to be returned.
  // If unspecified, return only active experiments.
  optional ViewType view_type = 5;

  message Response {
    // Experiments that match the search criteria
    repeated Experiment experiments = 1;

    // Token that can be used to retrieve the next page of experiments.
    // An empty token means that no more experiments are available for retrieval.
    optional string next_page_token = 2;
  }
}

message GetExperiment {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1 [(validate_required) = true];

  message Response {
    // Experiment details.
    optional Experiment experiment = 1;

    // Reserved for runs field, which was removed in MLflow 2.0
    //
    // NB: We cannot use the reserved keyword for compatibility with
    // documentation generation tooling, so we comment out the line
    // below
    //
    // reserved 2;
  }
}

message DeleteExperiment {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1 [(validate_required) = true];

  message Response {}
}

message RestoreExperiment {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1 [(validate_required) = true];

  message Response {}
}

message UpdateExperiment {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1 [(validate_required) = true];

  // If provided, the experiment's name is changed to the new name. The new name must be unique.
  optional string new_name = 2;

  message Response {}
}

message CreateRun {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1;

  // ID of the user executing the run.
  // This field is deprecated as of MLflow 1.0, and will be removed in a future
  // MLflow release. Use 'mlflow.user' tag instead.
  optional string user_id = 2;

  // Name of the run.
  optional string run_name = 3;

  // Unix timestamp in milliseconds of when the run started.
  optional int64 start_time = 7;

  // Additional metadata for run.
  repeated RunTag tags = 9;

  message Response {
    // The newly created run.
    optional Run run = 1;
  }
}

message UpdateRun {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run to update. Must be provided.
  optional string run_id = 4;

  // [Deprecated, use run_id instead] ID of the run to update.. This field will
  // be removed in a future MLflow version.
  optional string run_uuid = 1;

  // Updated status of the run.
  optional RunStatus status = 2;

  //Unix timestamp in milliseconds of when the run ended.
  optional int64 end_time = 3;

  // Updated name of the run.
  optional string run_name = 5;

  message Response {
    // Updated metadata of the run.
    optional RunInfo run_info = 1;
  }
}

message DeleteRun {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run to delete.
  optional string run_id = 1 [(validate_required) = true];

  message Response {}
}

message RestoreRun {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run to restore.
  optional string run_id = 1 [(validate_required) = true];

  message Response {}
}

message LogMetric {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run under which to log the metric. Must be provided.
  optional string run_id = 6;

  // [Deprecated, use run_id instead] ID of the run under which to log the metric. This field will
  // be removed in a future MLflow version.
  optional string run_uuid = 1;

  // Name of the metric.
  optional string key = 2 [(validate_required) = true];

  // Double value of the metric being logged.
  optional double value = 3 [(validate_required) = true];

  // Unix timestamp in milliseconds at the time metric was logged.
  optional int64 timestamp = 4 [(validate_required) = true];

  // Step at which to log the metric
  optional int64 step = 5 [default = 0];

  // ID of the logged model associated with the metric, if applicable
  optional string model_id = 7 [(visibility) = PUBLIC_UNDOCUMENTED];

  // The name of the dataset associated with the metric.
  // E.g. "my.uc.table@2" "nyc-taxi-dataset", "fantastic-elk-3"
  optional string dataset_name = 8 [(visibility) = PUBLIC_UNDOCUMENTED];

  // Dataset digest of the dataset associated with the metric,
  // e.g. an md5 hash of the dataset that uniquely identifies it
  // within datasets of the same name.
  optional string dataset_digest = 9 [(visibility) = PUBLIC_UNDOCUMENTED];

  message Response {}
}

message LogParam {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run under which to log the param. Must be provided.
  optional string run_id = 4;

  // [Deprecated, use run_id instead] ID of the run under which to log the param. This field will
  // be removed in a future MLflow version.
  optional string run_uuid = 1;

  // Name of the param. Maximum size is 255 bytes.
  optional string key = 2 [(validate_required) = true];

  // String value of the param being logged. Maximum size is 6000 bytes.
  optional string value = 3 [(validate_required) = true];

  message Response {}
}

message SetExperimentTag {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the experiment under which to log the tag. Must be provided.
  optional string experiment_id = 1 [(validate_required) = true];

  // Name of the tag. Maximum size depends on storage backend.
  // All storage backends are guaranteed to support key values up to 250 bytes in size.
  optional string key = 2 [(validate_required) = true];

  // String value of the tag being logged. Maximum size depends on storage backend.
  // All storage backends are guaranteed to support key values up to 5000 bytes in size.
  optional string value = 3 [(validate_required) = true];

  message Response {}
}

message DeleteExperimentTag {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the experiment that the tag was logged under. Must be provided.
  optional string experiment_id = 1 [(validate_required) = true];

  // Name of the tag. Maximum size is 255 bytes. Must be provided.
  optional string key = 2 [(validate_required) = true];

  message Response {}
}

message SetTag {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run under which to log the tag. Must be provided.
  optional string run_id = 4;

  // [Deprecated, use run_id instead] ID of the run under which to log the tag. This field will
  // be removed in a future MLflow version.
  optional string run_uuid = 1;

  // Name of the tag. Maximum size depends on storage backend.
  // All storage backends are guaranteed to support key values up to 250 bytes in size.
  optional string key = 2 [(validate_required) = true];

  // String value of the tag being logged. Maximum size depends on storage backend.
  // All storage backends are guaranteed to support key values up to 5000 bytes in size.
  optional string value = 3 [(validate_required) = true];

  message Response {}
}

message DeleteTag {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run that the tag was logged under. Must be provided.
  optional string run_id = 1 [(validate_required) = true];

  // Name of the tag. Maximum size is 255 bytes. Must be provided.
  optional string key = 2 [(validate_required) = true];

  message Response {}
}

message GetRun {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run to fetch. Must be provided.
  optional string run_id = 2;

  // [Deprecated, use run_id instead] ID of the run to fetch. This field will
  // be removed in a future MLflow version.
  optional string run_uuid = 1;

  message Response {
    // Run metadata (name, start time, etc) and data (metrics, params, and tags).
    optional Run run = 1;
  }
}

message SearchRuns {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // List of experiment IDs to search over.
  repeated string experiment_ids = 1;

  // A filter expression over params, metrics, and tags, that allows returning a subset of
  // runs. The syntax is a subset of SQL that supports ANDing together binary operations
  // between a param, metric, or tag and a constant.
  //
  // Example: ``metrics.rmse < 1 and params.model_class = 'LogisticRegression'``
  //
  // You can select columns with special characters (hyphen, space, period, etc.) by using double quotes:
  // ``metrics."model class" = 'LinearRegression' and tags."user-name" = 'Tomas'``
  //
  // Supported operators are ``=``, ``!=``, ``>``, ``>=``, ``<``, and ``<=``.
  optional string filter = 4;

  // Whether to display only active, only deleted, or all runs.
  // Defaults to only active runs.
  optional ViewType run_view_type = 3 [default = ACTIVE_ONLY];

  // Maximum number of runs desired. If unspecified, defaults to 1000.
  // All servers are guaranteed to support a `max_results` threshold of at least 50,000
  // but may support more. Callers of this endpoint are encouraged to pass max_results
  // explicitly and leverage page_token to iterate through experiments.
  optional int32 max_results = 5 [default = 1000];

  // List of columns to be ordered by, including attributes, params, metrics, and tags with an
  // optional "DESC" or "ASC" annotation, where "ASC" is the default.
  // Example: ["params.input DESC", "metrics.alpha ASC", "metrics.rmse"]
  // Tiebreaks are done by start_time DESC followed by run_id for runs with the same start time
  // (and this is the default ordering criterion if order_by is not provided).
  repeated string order_by = 6;

  optional string page_token = 7;

  message Response {
    // Runs that match the search criteria.
    repeated Run runs = 1;
    optional string next_page_token = 2;
  }
}

message ListArtifacts {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run whose artifacts to list. Must be provided.
  optional string run_id = 3;

  // [Deprecated, use run_id instead] ID of the run whose artifacts to list. This field will
  // be removed in a future MLflow version.
  optional string run_uuid = 1;

  // Filter artifacts matching this path (a relative path from the root artifact directory).
  optional string path = 2;

  // Token indicating the page of artifact results to fetch
  optional string page_token = 4;

  message Response {
    // Root artifact directory for the run.
    optional string root_uri = 1;

    // File location and metadata for artifacts.
    repeated FileInfo files = 2;

    // Token that can be used to retrieve the next page of artifact results
    optional string next_page_token = 3;
  }
}

// Metadata of a single artifact file or directory.
message FileInfo {
  // Path relative to the root artifact directory run.
  optional string path = 1;

  // Whether the path is a directory.
  optional bool is_dir = 2;

  // Size in bytes. Unset for directories.
  optional int64 file_size = 3;
}

message GetMetricHistory {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run from which to fetch metric values. Must be provided.
  optional string run_id = 3;

  // [Deprecated, use run_id instead] ID of the run from which to fetch metric values. This field
  // will be removed in a future MLflow version.
  optional string run_uuid = 1;

  // Name of the metric.
  optional string metric_key = 2 [(validate_required) = true];

  // Token indicating the page of metric history to fetch
  optional string page_token = 4;

  // Maximum number of logged instances of a metric for a run to return per call.
  // Backend servers may restrict the value of `max_results` depending on performance requirements.
  // Requests that do not specify this value will behave as non-paginated queries where all
  // metric history values for a given metric within a run are returned in a single response.
  optional int32 max_results = 5;

  message Response {
    // All logged values for this metric.
    repeated Metric metrics = 1;

    // Token that can be used to issue a query for the next page of metric history values.
    // A missing token indicates that no additional metrics are available to fetch.
    optional string next_page_token = 2;
  }
}

message MetricWithRunId {
  // Key identifying this metric.
  optional string key = 1;

  // Value associated with this metric.
  optional double value = 2;

  // The timestamp at which this metric was recorded.
  optional int64 timestamp = 3;

  // Step at which to log the metric.
  optional int64 step = 4 [default = 0];

  // The ID of the run containing the metric
  optional string run_id = 5;
}

message GetMetricHistoryBulkInterval {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID(s) of the run(s) from which to fetch metric values. Must be provided.
  repeated string run_ids = 1;

  // Name of the metric.
  optional string metric_key = 2 [(validate_required) = true];

  // Optional start step to only fetch metrics after the specified step. Must be defined if
  // end_step is defined.
  optional int32 start_step = 3;

  // Optional end step to only fetch metrics before the specified step. Must be defined if
  // start_step is defined.
  optional int32 end_step = 4;

  // Maximum number of results to fetch per run specified. Must be set to a positive number.
  // Note, in reality, the API returns at most (max_results + # of run IDs) x (# run IDs) metric
  // data points.
  optional int32 max_results = 5;

  message Response {
    // List of metrics representing history of values and metadata.
    repeated MetricWithRunId metrics = 1;
  }
}

message LogBatch {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";
  // ID of the run to log under
  optional string run_id = 1;
  // Metrics to log. A single request can contain up to 1000 metrics, and up to 1000
  // metrics, params, and tags in total.
  repeated Metric metrics = 2;
  // Params to log. A single request can contain up to 100 params, and up to 1000
  // metrics, params, and tags in total.
  repeated Param params = 3;
  // Tags to log. A single request can contain up to 100 tags, and up to 1000
  // metrics, params, and tags in total.
  repeated RunTag tags = 4;
  message Response {}
}

message LogModel {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";
  // ID of the run to log under
  optional string run_id = 1;

  // MLmodel file in json format.
  optional string model_json = 2;

  message Response {}
}

message LogInputs {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";
  // ID of the run to log under
  optional string run_id = 1 [(validate_required) = true];

  // Dataset inputs
  repeated DatasetInput datasets = 2;

  // Model inputs
  // (Currently undocumented for LoggedModels private preview)
  repeated ModelInput models = 3 [(visibility) = PUBLIC_UNDOCUMENTED];

  message Response {}
}

message LogOutputs {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the Run from which to log outputs.
  optional string run_id = 1 [(validate_required) = true];

  // Model outputs from the Run.
  repeated ModelOutput models = 2;

  message Response {}
}

message GetExperimentByName {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Name of the associated experiment.
  optional string experiment_name = 1 [(validate_required) = true];

  message Response {
    // Experiment details.
    optional Experiment experiment = 1;
  }
}

message CreateAssessment {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // The assessment to create.
  optional assessments.Assessment assessment = 1 [(validate_required) = true];

  message Response {
    // The created assessment.
    optional assessments.Assessment assessment = 1;
  }
}

// A request to update an existing assessment.
message UpdateAssessment {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // The Assessment containing the fields which should be updated.
  optional assessments.Assessment assessment = 1 [(validate_required) = true];

  // The list of the assessment fields to update. These should correspond to the values (or lack thereof) present in `assessment`.
  optional google.protobuf.FieldMask update_mask = 2 [(validate_required) = true];

  message Response {
    // The Assessment after the update.
    optional assessments.Assessment assessment = 1;
  }
}

// A request to delete an assessment identified by its trace_id and assessment_id.
// The response is empty on successful deletion.
message DeleteAssessment {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";
  // The ID of the trace.
  optional string trace_id = 1 [(validate_required) = true];
  // The ID of the assessment.
  optional string assessment_id = 2 [(validate_required) = true];

  message Response {}
}

message GetAssessmentRequest {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";
  // The ID of the trace the assessment belongs to.
  optional string trace_id = 1 [(validate_required) = true];
  // The ID of the assessment.
  optional string assessment_id = 2 [(validate_required) = true];

  message Response {
    // The requested assessment.
    optional assessments.Assessment assessment = 1;
  }
}

// TraceInfo. Represents metadata of a trace.
message TraceInfo {
  // Unique identifier for the trace.
  optional string request_id = 1;

  // The ID of the experiment that contains the trace.
  optional string experiment_id = 2;

  // Unix timestamp of when the trace started in milliseconds.
  optional int64 timestamp_ms = 3;

  // Unix timestamp of the duration of the trace in milliseconds.
  optional int64 execution_time_ms = 4;

  // Overall status of the operation being traced (OK, error, etc.).
  optional TraceStatus status = 5;

  // Other trace metadata.
  repeated TraceRequestMetadata request_metadata = 6;

  // Tags for the trace.
  repeated TraceTag tags = 7;
}

message TraceRequestMetadata {
  // Key identifying this metadata.
  optional string key = 1;

  // Value identifying this metadata.
  optional string value = 2;
}

message TraceTag {
  // Key identifying this trace tag.
  optional string key = 1;

  // Value associated with this trace tag.
  optional string value = 2;
}

enum TraceStatus {
  TRACE_STATUS_UNSPECIFIED = 0;

  // The operation being traced was successful.
  OK = 1;

  // The operation being traced failed.
  ERROR = 2;

  // The operation being traced is still in progress.
  IN_PROGRESS = 3;
}

message StartTrace {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1;

  // Unix timestamp of when the trace started in milliseconds.
  optional int64 timestamp_ms = 2;

  // Metadata about the request that initiated the trace.
  repeated TraceRequestMetadata request_metadata = 3;

  // Tags for the trace.
  repeated TraceTag tags = 4;

  message Response {
    // The newly created trace.
    optional TraceInfo trace_info = 1;
  }
}

message EndTrace {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the trace to end.
  optional string request_id = 1;

  // Unix timestamp of when the trace ended in milliseconds.
  optional int64 timestamp_ms = 2;

  // Overall status of the operation being traced (OK, error, etc).
  optional TraceStatus status = 3;

  // Additional metadata about the operation being traced.
  repeated TraceRequestMetadata request_metadata = 4;

  // Additional tags to add to the trace.
  repeated TraceTag tags = 5;

  message Response {
    // The updated trace.
    optional TraceInfo trace_info = 1;
  }
}

message GetTraceInfo {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the trace to fetch. Must be provided.
  optional string request_id = 1;

  message Response {
    // Metadata of the requested trace.
    optional TraceInfo trace_info = 1;
  }
}

message GetTraceInfoV3 {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the trace to fetch. Must be provided.
  optional string trace_id = 1;

  message Response {
    optional Trace trace = 1;
  }
}

message BatchGetTraces {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the traces to fetch. Must be provided.
  repeated string trace_ids = 1;

  message Response {
    // The fetched trace information.
    repeated Trace traces = 1;
  }
}

message GetTrace {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the trace to fetch. Must be provided.
  optional string trace_id = 1 [(validate_required) = true];

  // Whether to allow partial traces. Default to False.
  optional bool allow_partial = 2 [default = false];

  message Response {
    // The fetched trace including spans.
    optional Trace trace = 1;
  }
}

message SearchTraces {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // List of experiment IDs to search over.
  repeated string experiment_ids = 1;

  // A filter expression over trace attributes and tags that allows returning a subset of
  // traces. The syntax is a subset of SQL that supports ANDing together binary operations
  // Example: ``trace.status = 'OK' and trace.timestamp_ms > 1711089570679``.
  optional string filter = 2;

  // Maximum number of traces desired. Max threshold is 500.
  optional int32 max_results = 3 [default = 100];

  // List of columns for ordering the results, e.g. ``["timestamp_ms DESC"]``.
  repeated string order_by = 4;

  // Token indicating the page of traces to fetch.
  optional string page_token = 5;

  message Response {
    // Information about traces that match the search criteria.
    repeated TraceInfo traces = 1;
    optional string next_page_token = 2;
  }
}

message SearchUnifiedTraces {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  optional string model_id = 1 [(validate_required) = true];

  optional string sql_warehouse_id = 2 [(validate_required) = true];

  // TODO: Eventually we want to provide an API that only uses model_id
  repeated string experiment_ids = 3;

  // A filter expression over trace attributes and tags that allows returning a subset of
  // traces. The syntax is a subset of SQL that supports ANDing together binary operations
  // Example: ``trace.status = 'OK' and trace.timestamp_ms > 1711089570679``.
  optional string filter = 4;

  // Maximum number of traces desired. Max threshold is 500.
  optional int32 max_results = 5 [default = 100];

  // List of columns for ordering the results, e.g. ``["timestamp_ms DESC"]``.
  repeated string order_by = 6;

  // Token indicating the page of traces to fetch. This is a unified token that encodes both online and offline traces
  // tokens.
  optional string page_token = 7;

  message Response {
    // Information about traces that match the search criteria.
    repeated TraceInfo traces = 1;
    optional string next_page_token = 2;
  }
}

message GetOnlineTraceDetails {
  // Trace ID to retrieve
  optional string trace_id = 1 [(validate_required) = true];

  // SQL warehouse to use for query
  optional string sql_warehouse_id = 2 [(validate_required) = true];

  // Source inference table to use for query
  // ie. "ml.bbqiu.codegen_payload"
  optional string source_inference_table = 3 [(validate_required) = true];

  // Source databricks request id to use for query
  // ie. "8d1992ce-ba3d-49e9-9701-e9b323c5cc8c"
  optional string source_databricks_request_id = 4 [(validate_required) = true];

  message Response {
    // Return trace JSON in string form
    // Note: we may change this to a TraceData object in the future
    optional string trace_data = 1;
  }
}

message DeleteTraces {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1 [(validate_required) = true];

  // Case 1: max_timestamp_millis and max_traces must be specified for time-based deletion
  // The maximum timestamp in milliseconds since the UNIX epoch for deleting traces.
  optional int64 max_timestamp_millis = 2;

  // The maximum number of traces to delete.
  optional int32 max_traces = 3;

  // Case 2: request_ids must be specified for ID-based deletion
  // A set of request IDs to delete
  repeated string request_ids = 4;

  message Response {
    optional int32 traces_deleted = 1;
  }
}

message DeleteTracesV3 {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1 [(validate_required) = true];

  // Case 1: max_timestamp_millis and max_traces must be specified for time-based deletion
  // The maximum timestamp in milliseconds since the UNIX epoch for deleting traces.
  optional int64 max_timestamp_millis = 2;

  // The maximum number of traces to delete.
  optional int32 max_traces = 3;

  // Case 2: request_ids must be specified for ID-based deletion
  // A set of request IDs to delete
  repeated string request_ids = 4;

  message Response {
    optional int32 traces_deleted = 1;
  }
}

message CalculateTraceFilterCorrelation {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // List of experiment IDs to search within.
  repeated string experiment_ids = 1;

  // First filter condition (e.g., "span.type = 'LLM'").
  optional string filter_string1 = 2;

  // Second filter condition (e.g., "feedback.quality > 0.8").
  optional string filter_string2 = 3;

  // Optional base filter that both filter1 and filter2 are tested on top of
  // (e.g., 'request_time > ... and request_time < ...' for time windows).
  optional string base_filter = 4;

  message Response {
    // Normalized Pointwise Mutual Information score (-1 to 1).
    optional double npmi = 1;

    // Smoothed NPMI value with Jeffreys prior for robustness.
    optional double npmi_smoothed = 2;

    // Number of traces matching the first filter.
    optional int32 filter1_count = 3;

    // Number of traces matching the second filter.
    optional int32 filter2_count = 4;

    // Number of traces matching both filters.
    optional int32 joint_count = 5;

    // Total number of traces in the experiments.
    optional int32 total_count = 6;
  }
}

// View type for metrics aggregation.
enum MetricViewType {
  // Aggregate at trace level.
  TRACES = 1;
  // Aggregate at span level.
  SPANS = 2;
  // Aggregate at assessment level.
  ASSESSMENTS = 3;
}

// Aggregation type for metrics.
enum AggregationType {
  // Count of entities.
  COUNT = 1;
  // Sum of values.
  SUM = 2;
  // Average of values.
  AVG = 3;
  // Percentile aggregation (requires percentile_value parameter).
  PERCENTILE = 4;
  // Minimum value.
  MIN = 5;
  // Maximum value.
  MAX = 6;
}

message MetricAggregation {
  // The type of aggregation to perform.
  optional AggregationType aggregation_type = 1;

  // The percentile value to compute (0-100), required when aggregation_type is PERCENTILE.
  // Examples: 50 (median), 75, 90, 95, 99.
  // This field is ignored for other aggregation types.
  optional double percentile_value = 2;
}

// Query aggregated metrics for traces, spans, or assessments.
message QueryTraceMetrics {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Required: The experiment IDs to search traces.
  repeated string experiment_ids = 1;

  // Required: The level at which to aggregate metrics.
  optional MetricViewType view_type = 2;

  // Required: The name of the metric to query (e.g. "latency").
  optional string metric_name = 3;

  // Required: The aggregations to apply.
  repeated MetricAggregation aggregations = 4;

  // Optional: Dimensions to group metrics by. (e.g. "name", "status")
  repeated string dimensions = 5;

  // Optional: Filter expressions to apply. (e.g. `trace.status="OK"`)
  repeated string filters = 6;

  // Optional: Time interval for grouping in seconds.
  // When set, results automatically include a time dimension grouped by
  // the specified interval.
  // Examples: 60 (minute), 3600 (hour), 86400 (day), 604800 (week), 2592000 (month).
  optional int64 time_interval_seconds = 7;

  // Optional: Start of time range in milliseconds since epoch.
  // Required if time_interval_seconds is set.
  optional int64 start_time_ms = 8;

  // Optional: End of time range in milliseconds since epoch.
  // Required if time_interval_seconds is set.
  optional int64 end_time_ms = 9;

  // Optional: Maximum number of data points to return.
  // Default: 1000
  optional int32 max_results = 10 [default = 1000];

  // Optional: Pagination token for fetching the next page of results.
  optional string page_token = 11;

  message Response {
    // Data points grouped by dimensions.
    repeated MetricDataPoint data_points = 1;

    // Pagination token for fetching the next page.
    // Empty if no more results are available.
    optional string next_page_token = 2;
  }
}

// A single data point with dimension values and metric values.
message MetricDataPoint {
  // Metric name, e.g. "latency"
  optional string metric_name = 1;

  // Dimension values for this data point
  // Keys correspond to dimensions
  // e.g., {"status": "OK"}
  map<string, string> dimensions = 2;

  // Metric values for this data point
  // Keys are aggregation types
  // e.g., {"AVG": 150, "P99": 234.5}
  map<string, double> values = 3;
}

message SetTraceTag {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the trace on which to set a tag.
  optional string request_id = 1;

  // Name of the tag. Maximum size depends on storage backend.
  // All storage backends are guaranteed to support key values up to 250 bytes in size.
  optional string key = 2;

  // String value of the tag being logged. Maximum size depends on storage backend.
  // All storage backends are guaranteed to support key values up to 250 bytes in size.
  optional string value = 3;

  message Response {}
}

message SetTraceTagV3 {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the trace on which to set a tag.
  optional string trace_id = 4;

  // Name of the tag. Maximum size depends on storage backend.
  // All storage backends are guaranteed to support key values up to 250 bytes in size.
  optional string key = 2;

  // String value of the tag being logged. Maximum size depends on storage backend.
  // All storage backends are guaranteed to support key values up to 250 bytes in size.
  optional string value = 3;

  message Response {}

  // request_id has been retired
  reserved 1;
  reserved "request_id";
}

message DeleteTraceTag {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the trace from which to delete the tag.
  optional string request_id = 1;

  // Name of the tag to delete.
  optional string key = 2;

  message Response {}
}

message DeleteTraceTagV3 {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the trace from which to delete the tag.
  optional string trace_id = 3;

  // Name of the tag to delete.
  optional string key = 2;

  message Response {}

  // request_id has been retired
  reserved 1;
  reserved "request_id";
}

message Trace {
  optional TraceInfoV3 trace_info = 1;
  repeated opentelemetry.proto.trace.v1.Span spans = 2;
}

// The location where the traces was stored and produced
message TraceLocation {
  enum TraceLocationType {
    TRACE_LOCATION_TYPE_UNSPECIFIED = 0;
    MLFLOW_EXPERIMENT = 1;
    INFERENCE_TABLE = 2;
  }
  optional TraceLocationType type = 1;

  message MlflowExperimentLocation {
    // MLflow experiment ID which is the ACL container holding the trace.
    optional string experiment_id = 1;
  }

  message InferenceTableLocation {
    // Full inference table name in the form of catalog.schema.table_name
    optional string full_table_name = 1;
  }

  oneof identifier {
    MlflowExperimentLocation mlflow_experiment = 2;
    InferenceTableLocation inference_table = 3;
  }
}

message TraceInfoV3 {
  // The primary key associated with the trace
  optional string trace_id = 1;

  // Client supplied request ID associated with the trace. This could be used to identify the trace/request from an
  // external system that produced the trace.
  optional string client_request_id = 2;

  optional TraceLocation trace_location = 3;

  // [Deprecated, please use `request_preview` instead.]
  // Request to the model/agent.
  // Equivalent to the input of the root span but added for ease of access.
  // Represented as a JSON string.
  optional string request = 4;

  // [Deprecated, please use `request_preview` instead.]
  // Response of the model/agent.
  // Equivalent to the output of the root span but added for ease of access.
  // Represented as a JSON string.
  optional string response = 5;

  // A preview of the request to the model/agent represented as a JSON string. This is equivalent to the input of the root
  // span. This preview value is truncated to 10KB while the full request is stored in the trace data in blob storage.
  optional string request_preview = 12;

  // A preview of the request to the model/agent represented as a JSON string. This is equivalent to the output of the root
  // span. This preview value is truncated to 10KB while the full response is stored in the trace data in blob storage.
  optional string response_preview = 13;

  // Start time of the trace
  optional google.protobuf.Timestamp request_time = 6;

  // Execution time of the trace
  optional google.protobuf.Duration execution_duration = 7;

  // Execution state of the trace at the time that it was logged.
  enum State {
    STATE_UNSPECIFIED = 0;

    // The operation being traced was successful.
    OK = 1;

    // The operation being traced failed.
    ERROR = 2;

    // The operation being traced is still in progress. This is useful for incremental/distributed tracing logging in
    // contrast with when the full trace is logged only upon its completion.
    IN_PROGRESS = 3;
  }
  optional State state = 8;

  // Metadata associated with the trace.
  // Examples include:
  // - run_id: The ID of the mlflow Run (i.e. evaluation job) that produced the trace. May not be
  //           applicable in certain situations such as if the trace was created via interactive vibe checks)
  // - model_id: The ID of the associated model that produced the trace.
  // - dataset_id: The ID of the mlflow Dataset (usually used together with dataset_record_id)
  // - dataset_record_id: The ID of the mlflow Dataset (usually used together with dataset_record_id)
  // - session_id: The ID of the session (e.g. chat conversation) where the request came from
  map<string, string> trace_metadata = 9;

  repeated assessments.Assessment assessments = 10;

  // Mutable, user-defined tags for the trace, e.g. "question_topic": "DBSQL"
  map<string, string> tags = 11;
}

message StartTraceV3 {
  // The information for the trace being created.
  optional Trace trace = 1 [(validate_required) = true];

  message Response {
    // The created trace information.
    optional Trace trace = 1;
  }
}

message LinkTracesToRun {
  // IDs of the traces to link to the run.
  // The maximum number of trace IDs that can be linked in a single request is 100.
  repeated string trace_ids = 1;

  // ID of the run to link the traces to.
  optional string run_id = 2 [(validate_required) = true];

  message Response {}
}

message LinkPromptsToTrace {
  // ID of the trace to link prompt versions to.
  optional string trace_id = 1 [(validate_required) = true];

  // Prompt version references to link to the trace.
  // Each reference contains the prompt name and version.
  message PromptVersionRef {
    optional string name = 1 [(validate_required) = true];
    optional string version = 2 [(validate_required) = true];
  }
  repeated PromptVersionRef prompt_versions = 2;

  message Response {}
}

// DatasetSummary. Represents a summary of information about a dataset.
message DatasetSummary {
  // Unique identifier for the experiment.
  optional string experiment_id = 1 [(validate_required) = true];

  // The name of the dataset. E.g. "my.uc.table@2" "nyc-taxi-dataset", "fantastic-elk-3"
  optional string name = 2 [(validate_required) = true];

  // Dataset digest, e.g. an md5 hash of the dataset that uniquely identifies it
  // within datasets of the same name.
  optional string digest = 3 [(validate_required) = true];

  // Value of "context" tag if set for the given dataset.
  optional string context = 4;
}

message SearchDatasets {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // List of experiment IDs to search over.
  repeated string experiment_ids = 1;

  message Response {
    // Return the summary for most recently created N datasets, as configured in backend
    repeated DatasetSummary dataset_summaries = 1;
  }
}

message CreateLoggedModel {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1 [(validate_required) = true];

  // Name of the model. Optional. If not specified, the backend will generate one.
  optional string name = 2;

  // The type of model, such as "Agent", "Classifier", "LLM".
  optional string model_type = 3;

  // Run ID of the run that created this model.
  optional string source_run_id = 4;

  // LoggedModel params.
  repeated LoggedModelParameter params = 5;

  // LoggedModel tags.
  repeated LoggedModelTag tags = 6;

  message Response {
    // The newly created LoggedModel.
    optional LoggedModel model = 1;
  }
}

message FinalizeLoggedModel {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // The ID of the LoggedModel to finalize
  optional string model_id = 1 [(validate_required) = true];

  // Whether or not the model is ready for use.
  // Valid values in this message: ENUM<LOGGED_MODEL_READY, LOGGED_MODEL_UPLOAD_FAILED>
  // ("LOGGED_MODEL_UPLOAD_FAILED" indicates that something went wrong when logging
  // the model weights / agent code)
  optional LoggedModelStatus status = 2 [(validate_required) = true];

  message Response {
    // The updated LoggedModel.
    optional LoggedModel model = 1;
  }
}

message GetLoggedModel {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // The ID of the LoggedModel to retrieve.
  optional string model_id = 1 [(validate_required) = true];

  message Response {
    // The retrieved LoggedModel.
    optional LoggedModel model = 1;
  }
}

message DeleteLoggedModel {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // The ID of the LoggedModel to delete.
  optional string model_id = 1 [(validate_required) = true];

  message Response {}
}

message SearchLoggedModels {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // IDs of the Experiments in which to search for Logged Models.
  repeated string experiment_ids = 1;

  // A filter expression over Logged Model info and data that allows returning a subset of
  // Logged Models. The syntax is a subset of SQL that supports ANDing together binary operations
  // Example: ``params.alpha < 0.3 AND metrics.accuracy > 0.9``.
  optional string filter = 2;

  // List of datasets on which to apply the metrics filter clauses.
  // For example, a filter with `metrics.accuracy > 0.9` and dataset info with name "test_dataset"
  // means we will return all logged models with accuracy > 0.9 on the test_dataset.
  // Metric values from ANY dataset matching the criteria are considered.
  // If no datasets are specified, then metrics across all datasets are considered in the filter.
  repeated Dataset datasets = 6;

  message Dataset {
    // The name of the dataset.
    optional string dataset_name = 1 [(validate_required) = true];
    // The digest of the dataset.
    optional string dataset_digest = 2;
  }

  // Maximum number of Logged Models to return. Max threshold is 50.
  optional int32 max_results = 3 [default = 50];

  // List of columns for ordering the results, with additional fields for sorting criteria.
  repeated OrderBy order_by = 4;

  // Token indicating the page of Logged Models to fetch.
  optional string page_token = 5;

  message OrderBy {
    // Name of the field to order by, e.g. "metrics.accuracy".
    optional string field_name = 1 [(validate_required) = true];

    // Whether the order is ascending or not.
    optional bool ascending = 2 [default = true];

    // If ``field_name`` refers to a metric, this field specifies the name of the dataset
    // associated with the metric. Only metrics associated with the specified dataset name will be
    // considered for ordering. This field may only be set if ``field_name`` refers to a metric.
    optional string dataset_name = 3;

    // If ``field_name`` refers to a metric, this field specifies the digest of the dataset
    // associated with the metric. Only metrics associated with the specified dataset name
    // and digest will be considered for ordering. This field may only be set if ``dataset_name``
    // is also set.
    optional string dataset_digest = 4;
  }

  message Response {
    // Logged Models that match the search criteria.
    repeated LoggedModel models = 1;

    // Token that can be used to retrieve the next page of Logged Models.
    optional string next_page_token = 2;
  }
}

message SetLoggedModelTags {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // The ID of the LoggedModel to set the tag on.
  optional string model_id = 1 [(validate_required) = true];

  // The tag key.
  repeated LoggedModelTag tags = 2;

  message Response {
    // The updated LoggedModel.
    optional LoggedModel model = 1;
  }
}

message DeleteLoggedModelTag {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // The ID of the LoggedModel to delete the tag from.
  optional string model_id = 1 [(validate_required) = true];

  // The tag key.
  optional string tag_key = 2 [(validate_required) = true];

  message Response {}
}

message ListLoggedModelArtifacts {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // The ID of the LoggedModel for which to list the artifacts
  optional string model_id = 1 [(validate_required) = true];

  // Filter artifacts matching this path (a relative path from the root artifact directory).
  optional string artifact_directory_path = 2;

  // Token indicating the page of artifact results to fetch
  optional string page_token = 3;

  message Response {
    // Root artifact directory for the logged model.
    optional string root_uri = 1;

    // File location and metadata for artifacts.
    repeated FileInfo files = 2;

    // Token that can be used to retrieve the next page of artifact results
    optional string next_page_token = 3;
  }
}

message LogLoggedModelParamsRequest {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // The ID of the logged model to log params for.
  optional string model_id = 1 [(validate_required) = true];

  // Parameters attached to the model.
  repeated LoggedModelParameter params = 2;

  message Response {}
}

// A LoggedModel message includes logged model attributes,
// tags, registration info, params, and linked run metrics.
message LoggedModel {
  // LoggedModel attributes such as model ID, status, tags, etc.
  optional LoggedModelInfo info = 1;

  // LoggedModel params and metrics.
  optional LoggedModelData data = 2;
}

// A LoggedModelStatus enum value represents the status of a logged
// model.
enum LoggedModelStatus {
  LOGGED_MODEL_STATUS_UNSPECIFIED = 0;
  // The LoggedModel has been created, but the LoggedModel files are not
  // completely uploaded.
  LOGGED_MODEL_PENDING = 1;
  // The LoggedModel is created, and the LoggedModel files are completely uploaded.
  LOGGED_MODEL_READY = 2;
  // The LoggedModel is created, but an error occurred when uploading the
  // LoggedModel files such as model weights / agent code.
  LOGGED_MODEL_UPLOAD_FAILED = 3;
}

// A LoggedModelInfo includes logged model attributes,
// tags, and registration info.
message LoggedModelInfo {
  // A unique identifier for the model.
  optional string model_id = 1;
  // The ID of the experiment that owns the model.
  optional string experiment_id = 2;
  // Name of the model.
  optional string name = 3;

  // Timestamp when the model was created, in milliseconds since the UNIX epoch.
  optional int64 creation_timestamp_ms = 4;
  // Timestamp when the model was last updated, in milliseconds since the UNIX epoch
  optional int64 last_updated_timestamp_ms = 5;

  // URI of the directory where model artifacts are stored.
  optional string artifact_uri = 6;

  // Whether or not the model is ready for use.
  optional LoggedModelStatus status = 7;

  // The ID of the user or principal that created the model.
  optional int64 creator_id = 8;

  // The type of model, such as "Agent", "Classifier", "LLM".
  optional string model_type = 9;
  // Run ID of the run that created the model.
  optional string source_run_id = 10;
  // Details on the current status.
  optional string status_message = 11;

  // Mutable String key-value pairs set on the model.
  repeated LoggedModelTag tags = 12;

  // If the model has been promoted to the Model Registry, this field includes
  // information like the Registered Model name, Model Version number, etc.
  repeated LoggedModelRegistrationInfo registrations = 13;
}

// Tag for a LoggedModel.
message LoggedModelTag {
  // The tag key.
  optional string key = 1;
  // The tag value.
  optional string value = 2;
}

// RegistrationInfo for a LoggedModel.
message LoggedModelRegistrationInfo {
  // The name of the Registered Model to which the model has been promoted.
  optional string name = 1;
  // The version number of the promoted model.
  optional string version = 2;
}

// A LoggedModelData message includes logged model params and linked metrics.
message LoggedModelData {
  // Immutable String key-value pairs of the model.
  repeated LoggedModelParameter params = 1;

  // Performance metrics linked to the model.
  repeated Metric metrics = 2;
}

// Parameter associated with a LoggedModel.
message LoggedModelParameter {
  // Key identifying this param.
  optional string key = 1;

  // Value associated with this param.
  optional string value = 2;
}

message SearchTracesV3 {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // A list of MLflow experiments to search over.
  repeated TraceLocation locations = 1;

  // A filter expression over trace attributes and tags that allows returning a subset of
  // traces. The syntax is a subset of SQL that supports ANDing together binary operations
  // Example: ``trace.status = 'OK' and trace.timestamp_ms > 1711089570679``.
  optional string filter = 2;

  // Maximum number of traces desired. Max threshold is 500.
  optional int32 max_results = 3 [default = 100];

  // List of columns for ordering the results, e.g. ``["timestamp_ms DESC"]``.
  repeated string order_by = 4;

  // Token indicating the page of traces to fetch.
  optional string page_token = 5;

  message Response {
    // Information about traces that match the search criteria.
    repeated TraceInfoV3 traces = 1;
    optional string next_page_token = 2;
  }
}

// Evaluation Dataset Messages

message CreateDataset {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Dataset name
  optional string name = 1 [(validate_required) = true];

  // Associated experiment IDs. If not provided, defaults to the current active experiment.
  repeated string experiment_ids = 2;

  // Source type
  optional datasets.DatasetRecordSource.SourceType source_type = 3;

  // Source information
  optional string source = 4;

  // Schema information (JSON)
  optional string schema = 5;

  // Profile information (JSON)
  optional string profile = 6;

  // User creating the dataset
  optional string created_by = 7;

  // Tags to set on the dataset (JSON string mapping keys to values)
  optional string tags = 8;

  message Response {
    // The created dataset
    optional datasets.Dataset dataset = 1;
  }
}

message GetDataset {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Dataset ID
  optional string dataset_id = 1 [(validate_required) = true];

  // Optional page token for paginating records
  optional string page_token = 2;

  message Response {
    // The dataset (without records for lazy loading)
    optional datasets.Dataset dataset = 1;

    // Next page token if more records exist
    optional string next_page_token = 2;
  }
}

message DeleteDataset {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Dataset ID to delete
  optional string dataset_id = 1 [(validate_required) = true];

  message Response {
    // Empty response
  }
}

message SearchEvaluationDatasets {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Associated experiment IDs to filter by
  repeated string experiment_ids = 1;

  // Filter string for dataset names
  optional string filter_string = 2;

  // Maximum number of results
  optional int32 max_results = 3 [default = 1000];

  // Ordering criteria
  repeated string order_by = 4;

  // Page token for pagination
  optional string page_token = 5;

  message Response {
    // List of datasets (metadata only)
    repeated datasets.Dataset datasets = 1;

    // Next page token if more results exist
    optional string next_page_token = 2;
  }
}

message SetDatasetTags {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Dataset ID to update tags for
  optional string dataset_id = 1 [(validate_required) = true];

  // Tags to update (JSON string).
  optional string tags = 2 [(validate_required) = true];

  message Response {
    // The updated dataset
    optional datasets.Dataset dataset = 1;
  }
}

message DeleteDatasetTag {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Dataset ID to delete tag from
  optional string dataset_id = 1 [(validate_required) = true];

  // Tag key to delete
  optional string key = 2 [(validate_required) = true];

  message Response {}
}

message UpsertDatasetRecords {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Dataset ID to upsert records for
  optional string dataset_id = 1 [(validate_required) = true];

  // Records to upsert (JSON serialized list of record dictionaries)
  optional string records = 2 [(validate_required) = true];

  // User performing the update
  optional string updated_by = 3;

  message Response {
    // Number of records inserted
    optional int32 inserted_count = 1;

    // Number of records updated
    optional int32 updated_count = 2;
  }
}

message GetDatasetExperimentIds {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Dataset ID to get experiment IDs for
  optional string dataset_id = 1 [(validate_required) = true];

  message Response {
    // List of experiment IDs associated with the dataset
    repeated string experiment_ids = 1;
  }
}

message GetDatasetRecords {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Dataset ID to get records for
  optional string dataset_id = 1 [(validate_required) = true];

  // Optional pagination - maximum number of records to return
  optional int32 max_results = 2 [default = 1000];

  // Optional pagination token for getting next page
  optional string page_token = 3;

  message Response {
    // Records in the dataset (JSON serialized list)
    optional string records = 1;

    // Pagination token for next page (if more records exist)
    optional string next_page_token = 2;
  }
}

message AddDatasetToExperiments {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Dataset ID to add to experiments
  optional string dataset_id = 1 [(validate_required) = true];

  // Experiment IDs to associate with the dataset
  repeated string experiment_ids = 2;

  message Response {
    // The updated dataset with new experiment associations
    optional datasets.Dataset dataset = 1;
  }
}

message RemoveDatasetFromExperiments {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Dataset ID to remove from experiments
  optional string dataset_id = 1 [(validate_required) = true];

  // Experiment IDs to disassociate from the dataset
  repeated string experiment_ids = 2;

  message Response {
    // The updated dataset after removing experiment associations
    optional datasets.Dataset dataset = 1;
  }
}

// =============================================================================
// Scorer Management Messages
// =============================================================================

// Register a scorer for an experiment.
message RegisterScorer {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // The experiment ID.
  optional string experiment_id = 1;
  // The scorer name.
  optional string name = 2;
  // The serialized scorer string (JSON).
  optional string serialized_scorer = 3;

  message Response {
    // The new version number for the scorer.
    optional int32 version = 1;
    // The unique identifier for the scorer.
    optional string scorer_id = 2;
    // The experiment ID (same as request).
    optional string experiment_id = 3;
    // The scorer name (same as request).
    optional string name = 4;
    // The serialized scorer string (same as request).
    optional string serialized_scorer = 5;
    // The creation time of the scorer version (in milliseconds since epoch).
    optional int64 creation_time = 6;
  }
}

// List all scorers for an experiment.
message ListScorers {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // The experiment ID.
  optional string experiment_id = 1;

  message Response {
    // List of scorer entities (latest version for each scorer name).
    repeated Scorer scorers = 1;
  }
}

// List all versions of a specific scorer for an experiment.
message ListScorerVersions {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // The experiment ID.
  optional string experiment_id = 1;
  // The scorer name.
  optional string name = 2;

  message Response {
    // List of scorer entities for all versions of the scorer.
    repeated Scorer scorers = 1;
  }
}

// Get a specific scorer for an experiment.
message GetScorer {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // The experiment ID.
  optional string experiment_id = 1;
  // The scorer name.
  optional string name = 2;
  // The scorer version. If not specified, returns the scorer with maximum version.
  optional int32 version = 3;

  message Response {
    // The scorer entity.
    optional Scorer scorer = 1;
  }
}

// Delete a scorer for an experiment.
message DeleteScorer {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // The experiment ID.
  optional string experiment_id = 1;
  // The scorer name.
  optional string name = 2;
  // The scorer version to delete. If not specified, deletes all versions.
  optional int32 version = 3;

  message Response {
    // Empty response.
  }
}

// Scorer entity representing a scorer in the database.
message Scorer {
  // The experiment ID.
  optional int32 experiment_id = 1;
  // The scorer name.
  optional string scorer_name = 2;
  // The scorer version.
  optional int32 scorer_version = 3;
  // The serialized scorer string.
  optional string serialized_scorer = 4;
  // The creation time of the scorer version (in milliseconds since epoch).
  optional int64 creation_time = 5;
  // The unique identifier for the scorer.
  optional string scorer_id = 6;
}

// ========== Gateway Secrets and Endpoints Entities ==========

// Secret metadata entity (does not include the decrypted secret value)
message GatewaySecretInfo {
  // Unique identifier for the secret (UUID)
  optional string secret_id = 1;
  // User-friendly name for the secret (must be unique)
  optional string secret_name = 2;
  // Masked version of the secret values for display as key-value pairs.
  // For simple API keys: {"api_key": "sk-...xyz123"}
  // For compound credentials: ``{"aws_access_key_id": "AKI...1234", "aws_secret_access_key": "***"}``
  map<string, string> masked_values = 3;
  // Timestamp (milliseconds since epoch) when the secret was created
  optional int64 created_at = 4;
  // Timestamp (milliseconds since epoch) when the secret was last updated
  optional int64 last_updated_at = 5;
  // LLM provider identifier (e.g., "openai", "anthropic", "cohere")
  optional string provider = 6;
  // User ID who created the secret
  optional string created_by = 7;
  // User ID who last updated the secret
  optional string last_updated_by = 8;
  // Provider-specific auth configuration (e.g., auth_mode, region, project_id)
  map<string, string> auth_config = 9;
}

// Reusable model definition that can be shared across endpoints
message GatewayModelDefinition {
  // Unique identifier for this model definition
  optional string model_definition_id = 1;
  // User-friendly name for identification and reuse
  optional string name = 2;
  // ID of the secret containing authentication credentials
  optional string secret_id = 3;
  // Name of the secret for display purposes
  optional string secret_name = 4;
  // LLM provider (e.g., "openai", "anthropic", "cohere", "bedrock")
  optional string provider = 5;
  // Provider-specific model identifier (e.g., "gpt-4o", "claude-3-5-sonnet")
  optional string model_name = 6;
  // Timestamp (milliseconds since epoch) when the model definition was created
  optional int64 created_at = 7;
  // Timestamp (milliseconds since epoch) when the model definition was last updated
  optional int64 last_updated_at = 8;
  // User ID who created the model definition
  optional string created_by = 9;
  // User ID who last updated the model definition
  optional string last_updated_by = 10;
  // Field 11 reserved - endpoint_count removed (compute client-side from mappings)
}

// Mapping between an endpoint and a model definition
message GatewayEndpointModelMapping {
  // Unique identifier for this mapping
  optional string mapping_id = 1;
  // ID of the endpoint
  optional string endpoint_id = 2;
  // ID of the model definition
  optional string model_definition_id = 3;
  // The full model definition (populated via JOIN)
  optional GatewayModelDefinition model_definition = 4;
  // Routing weight for traffic distribution
  optional float weight = 5;
  // Timestamp (milliseconds since epoch) when the mapping was created
  optional int64 created_at = 6;
  // User ID who created the mapping
  optional string created_by = 7;
  // Type of linkage
  optional GatewayModelLinkageType linkage_type = 8;
  // Order for fallback attempts (only for FALLBACK linkages, NULL for PRIMARY)
  optional int32 fallback_order = 9;
}

// Endpoint entity representing an LLM gateway endpoint
message GatewayEndpoint {
  // Unique identifier for the endpoint
  optional string endpoint_id = 1;
  // User-friendly name for the endpoint
  optional string name = 2;
  // Timestamp (milliseconds since epoch) when the endpoint was created
  optional int64 created_at = 3;
  // Timestamp (milliseconds since epoch) when the endpoint was last updated
  optional int64 last_updated_at = 4;
  // List of model mappings bound to this endpoint
  repeated GatewayEndpointModelMapping model_mappings = 5;
  // User ID who created the endpoint
  optional string created_by = 6;
  // User ID who last updated the endpoint
  optional string last_updated_by = 7;
  // Tags associated with the endpoint
  repeated GatewayEndpointTag tags = 8;
  // Routing strategy for the endpoint
  optional RoutingStrategy routing_strategy = 9;
  // Fallback configuration (populated if routing_strategy is FALLBACK)
  optional FallbackConfig fallback_config = 10;
}

// Tag associated with an endpoint
message GatewayEndpointTag {
  // Tag key
  optional string key = 1;
  // Tag value
  optional string value = 2;
}

// Binding between an endpoint and an MLflow resource.
// Uses composite key (endpoint_id, resource_type, resource_id) for identification.
message GatewayEndpointBinding {
  // ID of the endpoint this binding references
  optional string endpoint_id = 1;
  // Type of MLflow resource (e.g., "scorer_job")
  optional string resource_type = 2;
  // ID of the specific resource instance
  optional string resource_id = 3;
  // Timestamp (milliseconds since epoch) when the binding was created
  optional int64 created_at = 4;
  // Timestamp (milliseconds since epoch) when the binding was last updated
  optional int64 last_updated_at = 5;
  // User ID who created the binding
  optional string created_by = 6;
  // User ID who last updated the binding
  optional string last_updated_by = 7;
  // Fields 8-9 reserved - endpoint_name and model_mappings removed (join client-side)
}

// ========== Secrets API Messages ==========

message CreateGatewaySecret {
  // User-friendly name for the secret (must be unique)
  optional string secret_name = 1;
  // The secret value(s) to encrypt as key-value pairs.
  // For simple API keys: {"api_key": "sk-xxx"}
  // For compound credentials: {"aws_access_key_id": "...", "aws_secret_access_key": "..."}
  map<string, string> secret_value = 2;
  // Optional LLM provider (e.g., "openai", "anthropic")
  optional string provider = 3;
  // Reserved: credential_name was removed - auth_mode is now stored in auth_config
  reserved 4;
  reserved "credential_name";
  // Optional provider-specific auth configuration.
  // For multi-auth providers, include "auth_mode" key (e.g., {"auth_mode": "access_keys", "aws_region_name": "us-east-1"})
  map<string, string> auth_config = 5;
  // Username of the creator
  optional string created_by = 6;

  message Response {
    // The created secret metadata (does not include encrypted value)
    optional GatewaySecretInfo secret = 1;
  }
}

message GetGatewaySecretInfo {
  // Either secret_id or secret_name must be provided
  optional string secret_id = 1;
  optional string secret_name = 2;

  message Response {
    // Secret metadata (does not include encrypted value)
    optional GatewaySecretInfo secret = 1;
  }
}

message UpdateGatewaySecret {
  // ID of the secret to update
  optional string secret_id = 1;
  // Optional new secret value(s) for key rotation as key-value pairs (empty map = no change).
  // For simple API keys: {"api_key": "sk-xxx"}
  // For compound credentials: {"aws_access_key_id": "...", "aws_secret_access_key": "..."}
  map<string, string> secret_value = 2;
  // Reserved: credential_name was removed - auth_mode is now stored in auth_config
  reserved 3;
  reserved "credential_name";
  // Optional new auth configuration.
  // For multi-auth providers, include "auth_mode" key (e.g., {"auth_mode": "access_keys", "aws_region_name": "us-east-1"})
  map<string, string> auth_config = 4;
  // Username of the updater
  optional string updated_by = 5;

  message Response {
    // The updated secret metadata
    optional GatewaySecretInfo secret = 1;
  }
}

message DeleteGatewaySecret {
  // ID of the secret to delete
  optional string secret_id = 1;

  message Response {}
}

message ListGatewaySecretInfos {
  // Optional filter by provider (e.g., "openai", "anthropic")
  optional string provider = 1;

  message Response {
    // List of secret metadata (does not include encrypted values)
    repeated GatewaySecretInfo secrets = 1;
  }
}

// ========== Model Definitions API Messages ==========

message CreateGatewayModelDefinition {
  // User-friendly name for the model definition (must be unique)
  optional string name = 1;
  // ID of the secret containing authentication credentials
  optional string secret_id = 2;
  // LLM provider (e.g., "openai", "anthropic")
  optional string provider = 3;
  // Provider-specific model identifier (e.g., "gpt-4o", "claude-3-5-sonnet")
  optional string model_name = 4;
  // Username of the creator
  optional string created_by = 5;

  message Response {
    // The created model definition
    optional GatewayModelDefinition model_definition = 1;
  }
}

message GetGatewayModelDefinition {
  // ID of the model definition to retrieve
  optional string model_definition_id = 1;

  message Response {
    // The model definition
    optional GatewayModelDefinition model_definition = 1;
  }
}

message ListGatewayModelDefinitions {
  // Optional filter by provider
  optional string provider = 1;
  // Optional filter by secret ID
  optional string secret_id = 2;

  message Response {
    // List of model definitions
    repeated GatewayModelDefinition model_definitions = 1;
  }
}

message UpdateGatewayModelDefinition {
  // ID of the model definition to update
  optional string model_definition_id = 1;
  // Optional new name
  optional string name = 2;
  // Optional new secret ID
  optional string secret_id = 3;
  // Optional new model name
  optional string model_name = 4;
  // Username of the updater
  optional string updated_by = 5;
  // Optional new provider
  optional string provider = 6;

  message Response {
    // The updated model definition
    optional GatewayModelDefinition model_definition = 1;
  }
}

message DeleteGatewayModelDefinition {
  // ID of the model definition to delete (fails if in use by any endpoint)
  optional string model_definition_id = 1;

  message Response {}
}

// ========== Endpoints API Messages ==========

// Routing strategy for endpoints
enum RoutingStrategy {
  ROUTING_STRATEGY_UNSPECIFIED = 0 [(enum_value_visibility) = PUBLIC_UNDOCUMENTED];
  // Request-based traffic split: distributes traffic based on weights
  REQUEST_BASED_TRAFFIC_SPLIT = 1;
}

// Fallback strategy for routing (future-proof for additional strategies)
enum FallbackStrategy {
  FALLBACK_STRATEGY_UNSPECIFIED = 0 [(enum_value_visibility) = PUBLIC_UNDOCUMENTED];
  // Sequential fallback: tries models in the order specified
  SEQUENTIAL = 1;
}

// Type of linkage between endpoint and model definition
enum GatewayModelLinkageType {
  LINKAGE_TYPE_UNSPECIFIED = 0 [(enum_value_visibility) = PUBLIC_UNDOCUMENTED];
  // Primary linkage: used for routing traffic
  PRIMARY = 1;
  // Fallback linkage: used for failover
  FALLBACK = 2;
}

// Configuration for fallback routing
message FallbackConfig {
  // The fallback strategy.
  optional FallbackStrategy strategy = 1;
  // The max attempts for fallback routing (cannot exceed number of destinations).
  optional int32 max_attempts = 2;
}

// Configuration for a model attached to an endpoint
message GatewayEndpointModelConfig {
  // ID of the model definition
  optional string model_definition_id = 1;
  // Type of linkage
  optional GatewayModelLinkageType linkage_type = 2;
  // Routing weight for traffic distribution
  optional float weight = 3;
  // Order for fallback attempts (only for FALLBACK linkages, NULL for PRIMARY)
  optional int32 fallback_order = 4;
}

message CreateGatewayEndpoint {
  // Optional user-friendly name for the endpoint
  optional string name = 1;
  // List of model configurations
  repeated GatewayEndpointModelConfig model_configs = 2;
  // Username of the creator
  optional string created_by = 3;
  // Optional routing strategy for the endpoint
  optional RoutingStrategy routing_strategy = 4;
  // Optional fallback configuration (includes strategy, max_attempts)
  optional FallbackConfig fallback_config = 5;

  message Response {
    // The created endpoint with all model mappings
    optional GatewayEndpoint endpoint = 1;
  }
}

message GetGatewayEndpoint {
  // Either endpoint_id or name must be provided
  optional string endpoint_id = 1;
  optional string name = 2;

  message Response {
    // The endpoint with all model configurations
    optional GatewayEndpoint endpoint = 1;
  }
}

message UpdateGatewayEndpoint {
  // ID of the endpoint to update
  optional string endpoint_id = 1;
  // Optional new name for the endpoint
  optional string name = 2;
  // Username of the updater
  optional string updated_by = 3;
  // Optional new list of model configurations (replaces all existing model linkages)
  repeated GatewayEndpointModelConfig model_configs = 4;
  // Optional new routing strategy for the endpoint
  optional RoutingStrategy routing_strategy = 5;
  // Optional fallback configuration (includes strategy, max_attempts)
  optional FallbackConfig fallback_config = 6;

  message Response {
    // The updated endpoint
    optional GatewayEndpoint endpoint = 1;
  }
}

message DeleteGatewayEndpoint {
  // ID of the endpoint to delete
  optional string endpoint_id = 1;

  message Response {}
}

message ListGatewayEndpoints {
  // Optional filter by provider
  optional string provider = 1;
  // Optional filter by secret ID
  optional string secret_id = 2;

  message Response {
    // List of endpoints with their model configurations
    repeated GatewayEndpoint endpoints = 1;
  }
}

// ========== Endpoint Model Mappings API Messages ==========

message AttachModelToGatewayEndpoint {
  // ID of the endpoint to attach the model to
  optional string endpoint_id = 1;
  // Configuration for the model to attach
  optional GatewayEndpointModelConfig model_config = 2;
  // Username of the creator
  optional string created_by = 3;

  message Response {
    // The created mapping
    optional GatewayEndpointModelMapping mapping = 1;
  }
}

message DetachModelFromGatewayEndpoint {
  // ID of the endpoint
  optional string endpoint_id = 1;
  // ID of the model definition to detach
  optional string model_definition_id = 2;

  message Response {}
}

// ========== Endpoint Bindings API Messages ==========

message CreateGatewayEndpointBinding {
  // ID of the endpoint to bind
  optional string endpoint_id = 1;
  // Type of MLflow resource
  optional string resource_type = 2;
  // ID of the resource instance
  optional string resource_id = 3;
  // Username of the creator
  optional string created_by = 4;

  message Response {
    // The created binding
    optional GatewayEndpointBinding binding = 1;
  }
}

message DeleteGatewayEndpointBinding {
  // ID of the endpoint
  optional string endpoint_id = 1;
  // Type of resource bound to the endpoint
  optional string resource_type = 2;
  // ID of the resource
  optional string resource_id = 3;

  message Response {}
}

message ListGatewayEndpointBindings {
  // ID of the endpoint to list bindings for
  optional string endpoint_id = 1;
  // Type of resource to filter bindings by (e.g., "scorer_job")
  optional string resource_type = 2;
  // ID of the resource to filter bindings by
  optional string resource_id = 3;

  message Response {
    // List of bindings for the endpoint
    repeated GatewayEndpointBinding bindings = 1;
  }
}

message SetGatewayEndpointTag {
  // ID of the endpoint to set tag on
  optional string endpoint_id = 1;
  // Tag key to set
  optional string key = 2;
  // Tag value to set
  optional string value = 3;

  message Response {}
}

message DeleteGatewayEndpointTag {
  // ID of the endpoint to delete tag from
  optional string endpoint_id = 1;
  // Tag key to delete
  optional string key = 2;

  message Response {}
}

// ========== Secrets Configuration API Messages ==========

message GetSecretsConfig {
  message Response {
    // Whether the server is configured to handle secrets (encryption available)
    optional bool secrets_available = 1;
  }
}

message CreatePromptOptimizationJob {
  // ID of the MLflow experiment to track the optimization job in.
  optional string experiment_id = 1;

  // URI of the source prompt to optimize (e.g., "prompts:/my-prompt/1").
  optional string source_prompt_uri = 2;

  // Configuration for the optimization job.
  optional PromptOptimizationJobConfig config = 3;

  // Optional tags for the optimization job.
  repeated PromptOptimizationJobTag tags = 4;

  message Response {
    // The created optimization job.
    optional PromptOptimizationJob job = 1;
  }
}

message GetPromptOptimizationJob {
  // The unique identifier of the optimization job (same as run_id).
  optional string job_id = 1;

  message Response {
    // The optimization job details.
    optional PromptOptimizationJob job = 1;
  }
}

message SearchPromptOptimizationJobs {
  // ID of the MLflow experiment to search optimization jobs in.
  optional string experiment_id = 1;

  message Response {
    // List of optimization jobs.
    repeated PromptOptimizationJob jobs = 1;
  }
}

message CancelPromptOptimizationJob {
  // The unique identifier of the optimization job to cancel.
  optional string job_id = 1;

  message Response {
    // The cancelled optimization job.
    optional PromptOptimizationJob job = 1;
  }
}

message DeletePromptOptimizationJob {
  // The unique identifier of the optimization job to delete.
  optional string job_id = 1;

  message Response {
    // Empty response on successful deletion.
  }
}

syntax = "proto2";

package mlflow;

import "scalapb/scalapb.proto";
import "databricks.proto";

option java_package = "org.mlflow.api.proto";
option py_generic_services = true;
option (scalapb.options) = {
  flat_package: true,
};

service MlflowService {


  // Get metadata for an experiment.
  //
  // This endpoint will return deleted experiments, but prefers the active experiment
  // if an active and deleted experiment share the same name. If multiple deleted
  // experiments share the same name, the API will return one of them.
  //
  // Throws ``RESOURCE_DOES_NOT_EXIST`` if no experiment with the specified name exists.
  //
  rpc getExperimentByName (GetExperimentByName) returns (GetExperimentByName.Response) {
    option (rpc) = {
      endpoints: [{
        method: "GET",
        path: "/mlflow/experiments/get-by-name",
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC,
      rpc_doc_title: "Get Experiment By Name",
    };
  }

  // Create an experiment with a name. Returns the ID of the newly created experiment.
  // Validates that another experiment with the same name does not already exist and fails
  // if another experiment with the same name already exists.
  //
  //
  // Throws ``RESOURCE_ALREADY_EXISTS`` if a experiment with the given name exists.
  //
  rpc createExperiment (CreateExperiment) returns (CreateExperiment.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/experiments/create"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC,
      rpc_doc_title: "Create Experiment",
    };
  }

  rpc searchExperiments (SearchExperiments) returns (SearchExperiments.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/experiments/search"
        since { major: 2, minor: 0 },
      }, {
        method: "GET",
        path: "/mlflow/experiments/search"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC,
      rpc_doc_title: "Search Experiments",
    };
  }

  // Get metadata for an experiment. This method works on deleted experiments.
  rpc getExperiment (GetExperiment) returns (GetExperiment.Response) {
    option (rpc) = {
      endpoints: [{
        method: "GET",
        path: "/mlflow/experiments/get"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC,
      rpc_doc_title: "Get Experiment",
    };
    option (graphql) = {};
  }

  // Mark an experiment and associated metadata, runs, metrics, params, and tags for deletion.
  // If the experiment uses FileStore, artifacts associated with experiment are also deleted.
  //
  rpc deleteExperiment (DeleteExperiment) returns (DeleteExperiment.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/experiments/delete"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC,
      rpc_doc_title: "Delete Experiment",
    };
  }

  // Restore an experiment marked for deletion. This also restores
  // associated metadata, runs, metrics, params, and tags. If experiment uses FileStore, underlying
  // artifacts associated with experiment are also restored.
  //
  // Throws ``RESOURCE_DOES_NOT_EXIST`` if experiment was never created or was permanently deleted.
  //
  rpc restoreExperiment (RestoreExperiment) returns (RestoreExperiment.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/experiments/restore"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC,
      rpc_doc_title: "Restore Experiment",
    };
  }

  // Update experiment metadata.
  //
  rpc updateExperiment (UpdateExperiment) returns (UpdateExperiment.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/experiments/update"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC,
      rpc_doc_title: "Update Experiment",
    };
  }

  // Create a new run within an experiment. A run is usually a single execution of a
  // machine learning or data ETL pipeline. MLflow uses runs to track :ref:`mlflowParam`,
  // :ref:`mlflowMetric`, and :ref:`mlflowRunTag` associated with a single execution.
  //
  rpc createRun(CreateRun) returns (CreateRun.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/runs/create"
        since { major: 2, minor: 0 },
      }],

      visibility: PUBLIC,
      rpc_doc_title: "Create Run",
    };
  }

  // Update run metadata.
  //
  rpc updateRun(UpdateRun) returns (UpdateRun.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/runs/update"
        since { major: 2, minor: 0 },
      }],

      visibility: PUBLIC,
      rpc_doc_title: "Update Run",
    };
  }

  // Mark a run for deletion.
  rpc deleteRun(DeleteRun) returns (DeleteRun.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/runs/delete"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC,
      rpc_doc_title: "Delete Run",
    };
  }

  // Restore a deleted run.
  rpc restoreRun(RestoreRun) returns (RestoreRun.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/runs/restore"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC,
      rpc_doc_title: "Restore Run",
    };
  }

  // Log a metric for a run. A metric is a key-value pair (string key, float value) with an
  // associated timestamp. Examples include the various metrics that represent ML model accuracy.
  // A metric can be logged multiple times.
  //
  rpc logMetric(LogMetric) returns (LogMetric.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/runs/log-metric"
        since { major: 2, minor: 0 },
      }],

      visibility: PUBLIC,
      rpc_doc_title: "Log Metric",
    };
  }

  // Log a param used for a run. A param is a key-value pair (string key,
  // string value). Examples include hyperparameters used for ML model training and
  // constant dates and values used in an ETL pipeline. A param can be logged only once for a run.
  //
  rpc logParam(LogParam) returns (LogParam.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/runs/log-parameter"
        since { major: 2, minor: 0 },
      }],

      visibility: PUBLIC,
      rpc_doc_title: "Log Param",
    };
  }

  // Set a tag on an experiment. Experiment tags are metadata that can be updated.
  //
  rpc setExperimentTag(SetExperimentTag) returns (SetExperimentTag.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/experiments/set-experiment-tag"
        since { major: 2, minor: 0 },
      }],

      visibility: PUBLIC,
      rpc_doc_title: "Set Experiment Tag",
    };
  }

  // Set a tag on a run. Tags are run metadata that can be updated during a run and after
  // a run completes.
  //
  rpc setTag(SetTag) returns (SetTag.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/runs/set-tag"
        since { major: 2, minor: 0 },
      }],

      visibility: PUBLIC,
      rpc_doc_title: "Set Tag",
    };
  }

  // Set a tag on a trace. Tags are mutable and can be updated as desired.
  rpc setTraceTag(SetTraceTag) returns (SetTraceTag.Response) {
    option (rpc) = {
      endpoints: [{
        method: "PATCH",
        path: "/mlflow/traces/{request_id}/tags"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC_UNDOCUMENTED,
      rpc_doc_title: "Set Trace Tag",
    };
  }

  // Delete a tag from a trace.
  rpc deleteTraceTag(DeleteTraceTag) returns (DeleteTraceTag.Response) {
    option (rpc) = {
      endpoints: [{
        method: "DELETE",
        path: "/mlflow/traces/{request_id}/tags"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC_UNDOCUMENTED,
      rpc_doc_title: "Delete Trace Tag",
    };
  }

  // Delete a tag on a run. Tags are run metadata that can be updated during a run and after
  // a run completes.
  //
  rpc deleteTag(DeleteTag) returns (DeleteTag.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/runs/delete-tag"
        since { major: 2, minor: 0 },
      }],

      visibility: PUBLIC,
      rpc_doc_title: "Delete Tag",
    };
  }

  // Get metadata, metrics, params, and tags for a run. In the case where multiple metrics
  // with the same key are logged for a run, return only the value with the latest timestamp.
  // If there are multiple values with the latest timestamp, return the maximum of these values.
  rpc getRun (GetRun) returns (GetRun.Response) {
    option (rpc) = {
      endpoints: [{
        method: "GET",
        path: "/mlflow/runs/get"
        since { major: 2, minor: 0 },
      }],

      visibility: PUBLIC,
      rpc_doc_title: "Get Run",
    };
    option (graphql) = {};
  }

  // Search for runs that satisfy expressions. Search expressions can use :ref:`mlflowMetric` and
  // :ref:`mlflowParam` keys.
  //
  rpc searchRuns (SearchRuns) returns (SearchRuns.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/runs/search"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC,
      rpc_doc_title: "Search Runs",
    };
    option (graphql) = {};
  }

  // List artifacts for a run. Takes an optional ``artifact_path`` prefix which if specified,
  // the response contains only artifacts with the specified prefix.
  //
  rpc listArtifacts (ListArtifacts) returns (ListArtifacts.Response) {
    option (rpc) = {
      endpoints: [{
        method: "GET",
        path: "/mlflow/artifacts/list"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC,
      rpc_doc_title: "List Artifacts",
    };
    option (graphql) = {};
  }

  // Get a list of all values for the specified metric for a given run.
  //
  rpc getMetricHistory (GetMetricHistory) returns (GetMetricHistory.Response) {
    option (rpc) = {
      endpoints: [{
        method: "GET",
        path: "/mlflow/metrics/get-history"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC,
      rpc_doc_title: "Get Metric History",
    };
  }

  // Retrieves the value history for a specified metric across one or more specified runs.
  rpc getMetricHistoryBulkInterval (GetMetricHistoryBulkInterval) returns (GetMetricHistoryBulkInterval.Response) {
    option (rpc) = {
      endpoints: [{
        method: "GET",
        path: "/mlflow/metrics/get-history-bulk-interval"
        since { major: 2, minor: 11 },
      }],
      visibility: PUBLIC_UNDOCUMENTED,
    };
    option (graphql) = {};
  }

  // Log a batch of metrics, params, and tags for a run.
  // If any data failed to be persisted, the server will respond with an error (non-200 status code).
  // In case of error (due to internal server error or an invalid request), partial data may
  // be written.
  //
  // You can write metrics, params, and tags in interleaving fashion, but within a given entity
  // type are guaranteed to follow the order specified in the request body. That is, for an API
  // request like
  //
  // .. code-block:: json
  //
  //   {
  //      "run_id": "2a14ed5c6a87499199e0106c3501eab8",
  //      "metrics": [
  //        {"key": "mae", "value": 2.5, "timestamp": 1552550804},
  //        {"key": "rmse", "value": 2.7, "timestamp": 1552550804},
  //      ],
  //      "params": [
  //        {"key": "model_class", "value": "LogisticRegression"},
  //      ]
  //   }
  //
  // the server is guaranteed to write metric "rmse" after "mae", though it may write param
  // "model_class" before both metrics, after "mae", or after both metrics.
  //
  // The overwrite behavior for metrics, params, and tags is as follows:
  //
  // - Metrics: metric values are never overwritten. Logging a metric (key, value, timestamp) appends to the set of values for the metric with the provided key.
  //
  // - Tags: tag values can be overwritten by successive writes to the same tag key. That is, if multiple tag values with the same key are provided in the same API request, the last-provided tag value is written. Logging the same tag (key, value) is permitted - that is, logging a tag is idempotent.
  //
  // - Params: once written, param values cannot be changed (attempting to overwrite a param value will result in an error). However, logging the same param (key, value) is permitted - that is, logging a param is idempotent.
  //
  // Request Limits
  // --------------
  // A single JSON-serialized API request may be up to 1 MB in size and contain:
  //
  // - No more than 1000 metrics, params, and tags in total
  // - Up to 1000 metrics
  // - Up to 100 params
  // - Up to 100 tags
  //
  // For example, a valid request might contain 900 metrics, 50 params, and 50 tags, but logging
  // 900 metrics, 50 params, and 51 tags is invalid. The following limits also apply
  // to metric, param, and tag keys and values:
  //
  // - Metric, param, and tag keys can be up to 250 characters in length
  // - Param and tag values can be up to 250 characters in length
  //
  rpc logBatch (LogBatch) returns (LogBatch.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/runs/log-batch"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC,
      rpc_doc_title: "Log Batch",
    };
  }

  // .. note::
  //     Experimental: This API may change or be removed in a future release without warning.
  rpc logModel (LogModel) returns (LogModel.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/runs/log-model"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC,
      rpc_doc_title: "Log Model",
    };
  }

  rpc logInputs (LogInputs) returns (LogInputs.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/runs/log-inputs"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC,
      rpc_doc_title: "Log Inputs",
    };
  }

  rpc searchDatasets(SearchDatasets) returns (SearchDatasets.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "mlflow/experiments/search-datasets"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC_UNDOCUMENTED,
    };
    option (graphql) = {};
  }

  // Start a new trace within an experiment.
  rpc startTrace(StartTrace) returns (StartTrace.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/traces"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC_UNDOCUMENTED,
      rpc_doc_title: "Start Trace",
    };
  }

  // End a trace within an experiment.
  rpc endTrace(EndTrace) returns (EndTrace.Response) {
    option (rpc) = {
      endpoints: [{
        method: "PATCH",
        path: "/mlflow/traces/{request_id}"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC_UNDOCUMENTED,
      rpc_doc_title: "End Trace",
    };
  }

  // Get metadata of a trace.
  rpc getTraceInfo (GetTraceInfo) returns (GetTraceInfo.Response) {
    option (rpc) = {
      endpoints: [{
        method: "GET",
        path: "/mlflow/traces/{request_id}/info"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC_UNDOCUMENTED,
      rpc_doc_title: "Get TraceInfo",
    };
  }

  // Search for traces that satisfy specified filters
  // (e.g. ``trace.status = 'OK' and trace.timestamp_ms > 1711089570679``), and retrieve the traces
  // in a specified ordering (e.g. ``["timestamp_ms DESC"]``).
  rpc searchTraces (SearchTraces) returns (SearchTraces.Response) {
    option (rpc) = {
      endpoints: [{
        method: "GET",
        path: "/mlflow/traces"
        since { major: 2, minor: 0 }
      }],
      visibility: PUBLIC_UNDOCUMENTED,
      rpc_doc_title: "Search Traces",
    };
  }

  rpc deleteTraces(DeleteTraces) returns (DeleteTraces.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/traces/delete-traces"
        since { major: 2, minor: 0 },
      }],
      visibility: PUBLIC_UNDOCUMENTED,
      rpc_doc_title: "Delete Traces",
    };
  }
}

// View type for ListExperiments query.
enum ViewType {
  // Default. Return only active experiments.
  ACTIVE_ONLY = 1;

  // Return only deleted experiments.
  DELETED_ONLY = 2;

  // Get all experiments.
  ALL = 3;
}

// Source that generated a run.
enum SourceType {
  // Databricks notebook environment.
  NOTEBOOK = 1;

  // Scheduled or Run Now job.
  JOB = 2;

  // As a prepackaged project: either a Docker image or GitHub source, etc.
  PROJECT = 3;

  // Local run: Using CLI, IDE, or local notebook.
  LOCAL = 4;

  // Unknown source type.
  UNKNOWN = 1000;
}

// Status of a run.
enum RunStatus {
  // Run has been initiated.
  RUNNING = 1;

  // Run is scheduled to run at a later time.
  SCHEDULED = 2;

  // Run has completed.
  FINISHED = 3;

  // Run execution failed.
  FAILED = 4;

  // Run killed by user.
  KILLED = 5;
}

// Metric associated with a run, represented as a key-value pair.
message Metric {
  // Key identifying this metric.
  optional string key = 1;

  // Value associated with this metric.
  optional double value = 2;

  // The timestamp at which this metric was recorded.
  optional int64 timestamp = 3;

  // Step at which to log the metric.
  optional int64 step = 4 [default = 0];
}

// Param associated with a run.
message Param {
  // Key identifying this param.
  optional string key = 1;

  // Value associated with this param.
  optional string value = 2;
}

// A single run.
message Run {
  // Run metadata.
  optional RunInfo info = 1;
  // Run data.
  optional RunData data = 2;
  // Run inputs.
  optional RunInputs inputs = 3;
}

// Run data (metrics, params, and tags).
message RunData {
  // Run metrics.
  repeated Metric metrics = 1;
  // Run parameters.
  repeated Param params = 2;

  // Additional metadata key-value pairs.
  repeated RunTag tags = 3;
}

// Run inputs.
message RunInputs {
  // Dataset inputs to the Run.
  repeated DatasetInput dataset_inputs = 1;
}

// Tag for a run.
message RunTag {
  // The tag key.
  optional string key = 1;
  // The tag value.
  optional string value = 2;
}



// Tag for an experiment.
message ExperimentTag {
  // The tag key.
  optional string key = 1;
  // The tag value.
  optional string value = 2;
}

// Metadata of a single run.
message RunInfo {
  // Unique identifier for the run.
  optional string run_id = 15;

  // [Deprecated, use run_id instead] Unique identifier for the run. This field will
  // be removed in a future MLflow version.
  optional string run_uuid = 1;

  // The name of the run.
  optional string run_name = 3;

  // The experiment ID.
  optional string experiment_id = 2;

  // User who initiated the run.
  // This field is deprecated as of MLflow 1.0, and will be removed in a future
  // MLflow release. Use 'mlflow.user' tag instead.
  optional string user_id = 6;

  // Current status of the run.
  optional RunStatus status = 7;

  // Unix timestamp of when the run started in milliseconds.
  optional int64 start_time = 8;

  // Unix timestamp of when the run ended in milliseconds.
  optional int64 end_time = 9;

  // URI of the directory where artifacts should be uploaded.
  // This can be a local path (starting with "/"), or a distributed file system (DFS)
  // path, like ``s3://bucket/directory`` or ``dbfs:/my/directory``.
  // If not set, the local ``./mlruns`` directory is  chosen.
  optional string artifact_uri = 13;

  // Current life cycle stage of the experiment : OneOf("active", "deleted")
  optional string lifecycle_stage = 14;
}

// Experiment
message Experiment {
  // Unique identifier for the experiment.
  optional string experiment_id = 1;

  // Human readable name that identifies the experiment.
  optional string name = 2;

  // Location where artifacts for the experiment are stored.
  optional string artifact_location = 3;

  // Current life cycle stage of the experiment: "active" or "deleted".
  // Deleted experiments are not returned by APIs.
  optional string lifecycle_stage = 4;

  // Last update time
  optional int64 last_update_time = 5;

  // Creation time
  optional int64 creation_time = 6;

  // Tags: Additional metadata key-value pairs.
  repeated ExperimentTag tags = 7;
}

// DatasetInput. Represents a dataset and input tags.
message DatasetInput {
  // A list of tags for the dataset input, e.g. a “context” tag with value “training”
  repeated InputTag tags = 1;

  // The dataset being used as a Run input.
  optional Dataset dataset = 2 [(validate_required) = true];
}

// Tag for an input.
message InputTag {
  // The tag key.
  optional string key = 1 [(validate_required) = true];
  // The tag value.
  optional string value = 2 [(validate_required) = true];
}

// Dataset. Represents a reference to data used for training, testing, or evaluation during
// the model development process.
message Dataset {
  // The name of the dataset. E.g. “my.uc.table@2” “nyc-taxi-dataset”, “fantastic-elk-3”
  optional string name = 1 [(validate_required) = true];

  // Dataset digest, e.g. an md5 hash of the dataset that uniquely identifies it
  // within datasets of the same name.
  optional string digest = 2 [(validate_required) = true];

  // Source information for the dataset. Note that the source may not exactly reproduce the
  // dataset if it was transformed / modified before use with MLflow.
  optional string source_type = 3 [(validate_required) = true];

  // The type of the dataset source, e.g. ‘databricks-uc-table’, ‘DBFS’, ‘S3’, ...
  optional string source = 4 [(validate_required) = true];

  // The schema of the dataset. E.g., MLflow ColSpec JSON for a dataframe, MLflow TensorSpec JSON
  // for an ndarray, or another schema format.
  optional string schema = 5;

  // The profile of the dataset. Summary statistics for the dataset, such as the number of rows
  // in a table, the mean / std / mode of each column in a table, or the number of elements
  // in an array.
  optional string profile = 6;
}

message CreateExperiment {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Experiment name.
  optional string name = 1 [(validate_required) = true];

  // Location where all artifacts for the experiment are stored.
  // If not provided, the remote server will select an appropriate default.
  optional string artifact_location = 2;

  // A collection of tags to set on the experiment. Maximum tag size and number of tags per request
  // depends on the storage backend. All storage backends are guaranteed to support tag keys up
  // to 250 bytes in size and tag values up to 5000 bytes in size. All storage backends are also
  // guaranteed to support up to 20 tags per request.
  repeated ExperimentTag tags = 3;

  message Response {
    // Unique identifier for the experiment.
    optional string experiment_id = 1;
  }
}

message SearchExperiments {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Maximum number of experiments desired.
  // Servers may select a desired default `max_results` value. All servers are
  // guaranteed to support a `max_results` threshold of at least 1,000 but may
  // support more. Callers of this endpoint are encouraged to pass max_results
  // explicitly and leverage page_token to iterate through experiments.
  optional int64 max_results = 1;

  // Token indicating the page of experiments to fetch
  optional string page_token = 2;

  // A filter expression over experiment attributes and tags that allows returning a subset of
  // experiments. The syntax is a subset of SQL that supports ANDing together binary operations
  // between an attribute or tag, and a constant.
  //
  // Example: ``name LIKE 'test-%' AND tags.key = 'value'``
  //
  // You can select columns with special characters (hyphen, space, period, etc.) by using
  // double quotes or backticks.
  //
  // Example: ``tags."extra-key" = 'value'`` or ``tags.`extra-key` = 'value'``
  //
  // Supported operators are ``=``, ``!=``, ``LIKE``, and ``ILIKE``.
  optional string filter = 3;

  // List of columns for ordering search results, which can include experiment name and id
  // with an optional "DESC" or "ASC" annotation, where "ASC" is the default.
  // Tiebreaks are done by experiment id DESC.
  repeated string order_by = 4;

  // Qualifier for type of experiments to be returned.
  // If unspecified, return only active experiments.
  optional ViewType view_type = 5;

  message Response {
    // Experiments that match the search criteria
    repeated Experiment experiments = 1;

    // Token that can be used to retrieve the next page of experiments.
    // An empty token means that no more experiments are available for retrieval.
    optional string next_page_token = 2;
  }
}

message GetExperiment {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1 [(validate_required) = true];

  message Response {
    // Experiment details.
    optional Experiment experiment = 1;

    // Reserved for runs field, which was removed in MLflow 2.0
    //
    // NB: We cannot use the reserved keyword for compatibility with
    // documentation generation tooling, so we comment out the line
    // below
    //
    // reserved 2;
  }
}

message DeleteExperiment {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1 [(validate_required) = true];

  message Response {
  }
}

message RestoreExperiment {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1 [(validate_required) = true];

  message Response {
  }
}

message UpdateExperiment {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1 [(validate_required) = true];

  // If provided, the experiment's name is changed to the new name. The new name must be unique.
  optional string new_name = 2;

  message Response {
  }
}

message CreateRun {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1;

  // ID of the user executing the run.
  // This field is deprecated as of MLflow 1.0, and will be removed in a future
  // MLflow release. Use 'mlflow.user' tag instead.
  optional string user_id = 2;

  // Name of the run.
  optional string run_name = 3;

  // Unix timestamp in milliseconds of when the run started.
  optional int64 start_time = 7;

  // Additional metadata for run.
  repeated RunTag tags = 9;

  message Response {
    // The newly created run.
    optional Run run = 1;
  }
}

message UpdateRun {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run to update. Must be provided.
  optional string run_id = 4;

  // [Deprecated, use run_id instead] ID of the run to update.. This field will
  // be removed in a future MLflow version.
  optional string run_uuid = 1;

  // Updated status of the run.
  optional RunStatus status = 2;

  //Unix timestamp in milliseconds of when the run ended.
  optional int64 end_time = 3;

  // Updated name of the run.
  optional string run_name = 5;

  message Response {
    // Updated metadata of the run.
    optional RunInfo run_info = 1;
  }
}

message DeleteRun {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run to delete.
  optional string run_id = 1 [(validate_required) = true];

  message Response {}
}

message RestoreRun {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run to restore.
  optional string run_id = 1 [(validate_required) = true];

  message Response {}
}


message LogMetric {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run under which to log the metric. Must be provided.
  optional string run_id = 6;

  // [Deprecated, use run_id instead] ID of the run under which to log the metric. This field will
  // be removed in a future MLflow version.
  optional string run_uuid = 1;

  // Name of the metric.
  optional string key = 2 [(validate_required) = true];

  // Double value of the metric being logged.
  optional double value = 3 [(validate_required) = true];

  // Unix timestamp in milliseconds at the time metric was logged.
  optional int64 timestamp = 4 [(validate_required) = true];

  // Step at which to log the metric
  optional int64 step = 5 [default = 0];

  message Response {}
}

message LogParam {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run under which to log the param. Must be provided.
  optional string run_id = 4;

  // [Deprecated, use run_id instead] ID of the run under which to log the param. This field will
  // be removed in a future MLflow version.
  optional string run_uuid = 1;

  // Name of the param. Maximum size is 255 bytes.
  optional string key = 2 [(validate_required) = true];

  // String value of the param being logged. Maximum size is 6000 bytes.
  optional string value = 3 [(validate_required) = true];

  message Response {
  }
}

message SetExperimentTag {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the experiment under which to log the tag. Must be provided.
  optional string experiment_id = 1 [(validate_required) = true];

  // Name of the tag. Maximum size depends on storage backend.
  // All storage backends are guaranteed to support key values up to 250 bytes in size.
  optional string key = 2 [(validate_required) = true];

  // String value of the tag being logged. Maximum size depends on storage backend.
  // All storage backends are guaranteed to support key values up to 5000 bytes in size.
  optional string value = 3 [(validate_required) = true];

  message Response {
  }
}

message SetTag {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run under which to log the tag. Must be provided.
  optional string run_id = 4;

  // [Deprecated, use run_id instead] ID of the run under which to log the tag. This field will
  // be removed in a future MLflow version.
  optional string run_uuid = 1;

  // Name of the tag. Maximum size depends on storage backend.
  // All storage backends are guaranteed to support key values up to 250 bytes in size.
  optional string key = 2 [(validate_required) = true];

  // String value of the tag being logged. Maximum size depends on storage backend.
  // All storage backends are guaranteed to support key values up to 5000 bytes in size.
  optional string value = 3 [(validate_required) = true];

  message Response {
  }
}

message DeleteTag {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run that the tag was logged under. Must be provided.
  optional string run_id = 1 [(validate_required) = true];

  // Name of the tag. Maximum size is 255 bytes. Must be provided.
  optional string key = 2 [(validate_required) = true];

  message Response {
  }
}

message GetRun {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run to fetch. Must be provided.
  optional string run_id = 2;

  // [Deprecated, use run_id instead] ID of the run to fetch. This field will
  // be removed in a future MLflow version.
  optional string run_uuid = 1;

  message Response {
    // Run metadata (name, start time, etc) and data (metrics, params, and tags).
    optional Run run = 1;
  }
}

message SearchRuns {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // List of experiment IDs to search over.
  repeated string experiment_ids = 1;

  // A filter expression over params, metrics, and tags, that allows returning a subset of
  // runs. The syntax is a subset of SQL that supports ANDing together binary operations
  // between a param, metric, or tag and a constant.
  //
  // Example: ``metrics.rmse < 1 and params.model_class = 'LogisticRegression'``
  //
  // You can select columns with special characters (hyphen, space, period, etc.) by using double quotes:
  // ``metrics."model class" = 'LinearRegression' and tags."user-name" = 'Tomas'``
  //
  // Supported operators are ``=``, ``!=``, ``>``, ``>=``, ``<``, and ``<=``.
  optional string filter = 4;

  // Whether to display only active, only deleted, or all runs.
  // Defaults to only active runs.
  optional ViewType run_view_type = 3 [default = ACTIVE_ONLY];

  // Maximum number of runs desired. If unspecified, defaults to 1000.
  // All servers are guaranteed to support a `max_results` threshold of at least 50,000
  // but may support more. Callers of this endpoint are encouraged to pass max_results
  // explicitly and leverage page_token to iterate through experiments.
  optional int32 max_results = 5 [default = 1000];

  // List of columns to be ordered by, including attributes, params, metrics, and tags with an
  // optional "DESC" or "ASC" annotation, where "ASC" is the default.
  // Example: ["params.input DESC", "metrics.alpha ASC", "metrics.rmse"]
  // Tiebreaks are done by start_time DESC followed by run_id for runs with the same start time
  // (and this is the default ordering criterion if order_by is not provided).
  repeated string order_by = 6;

  optional string page_token = 7;

  message Response {
    // Runs that match the search criteria.
    repeated Run runs = 1;
    optional string next_page_token = 2;
  }
}

message ListArtifacts {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run whose artifacts to list. Must be provided.
  optional string run_id = 3;

  // [Deprecated, use run_id instead] ID of the run whose artifacts to list. This field will
  // be removed in a future MLflow version.
  optional string run_uuid = 1;

  // Filter artifacts matching this path (a relative path from the root artifact directory).
  optional string path = 2;

  // Token indicating the page of artifact results to fetch
  optional string page_token = 4;

  message Response {
    // Root artifact directory for the run.
    optional string root_uri = 1;

    // File location and metadata for artifacts.
    repeated FileInfo files = 2;

    // Token that can be used to retrieve the next page of artifact results
    optional string next_page_token = 3;
  }
}

// Metadata of a single artifact file or directory.
message FileInfo {
  // Path relative to the root artifact directory run.
  optional string path = 1;

  // Whether the path is a directory.
  optional bool is_dir = 2;

  // Size in bytes. Unset for directories.
  optional int64 file_size = 3;
}

message GetMetricHistory {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the run from which to fetch metric values. Must be provided.
  optional string run_id = 3;

  // [Deprecated, use run_id instead] ID of the run from which to fetch metric values. This field
  // will be removed in a future MLflow version.
  optional string run_uuid = 1;

  // Name of the metric.
  optional string metric_key = 2 [(validate_required) = true];

  // Token indicating the page of metric history to fetch
  optional string page_token = 4;

  // Maximum number of logged instances of a metric for a run to return per call.
  // Backend servers may restrict the value of `max_results` depending on performance requirements.
  // Requests that do not specify this value will behave as non-paginated queries where all
  // metric history values for a given metric within a run are returned in a single response.
  optional int32 max_results = 5;

  message Response {
    // All logged values for this metric.
    repeated Metric metrics = 1;

    // Token that can be used to issue a query for the next page of metric history values.
    // A missing token indicates that no additional metrics are available to fetch.
    optional string next_page_token = 2;
  }
}

message MetricWithRunId {
  // Key identifying this metric.
  optional string key = 1;

  // Value associated with this metric.
  optional double value = 2;

  // The timestamp at which this metric was recorded.
  optional int64 timestamp = 3;

  // Step at which to log the metric.
  optional int64 step = 4 [default = 0];

  // The ID of the run containing the metric
  optional string run_id = 5;
}

message GetMetricHistoryBulkInterval {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID(s) of the run(s) from which to fetch metric values. Must be provided.
  repeated string run_ids = 1;

  // Name of the metric.
  optional string metric_key = 2 [(validate_required) = true];

  // Optional start step to only fetch metrics after the specified step. Must be defined if
  // end_step is defined.
  optional int32 start_step = 3;

  // Optional end step to only fetch metrics before the specified step. Must be defined if
  // start_step is defined.
  optional int32 end_step = 4;

  // Maximum number of results to fetch per run specified. Must be set to a positive number.
  // Note, in reality, the API returns at most (max_results + # of run IDs) x (# run IDs) metric
  // data points.
  optional int32 max_results = 5;

  message Response {

    // List of metrics representing history of values and metadata.
    repeated MetricWithRunId metrics = 1;
  }
}

message LogBatch {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";
  // ID of the run to log under
  optional string run_id = 1;
  // Metrics to log. A single request can contain up to 1000 metrics, and up to 1000
  // metrics, params, and tags in total.
  repeated Metric metrics = 2;
  // Params to log. A single request can contain up to 100 params, and up to 1000
  // metrics, params, and tags in total.
  repeated Param params = 3;
  // Tags to log. A single request can contain up to 100 tags, and up to 1000
  // metrics, params, and tags in total.
  repeated RunTag tags = 4;
  message Response {
  }
}

message LogModel {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";
  // ID of the run to log under
  optional string run_id = 1;

  // MLmodel file in json format.
  optional string model_json = 2;

  message Response {
  }
}

message LogInputs {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";
  // ID of the run to log under
  optional string run_id = 1 [(validate_required) = true];

  // Dataset inputs
  repeated DatasetInput datasets = 2;

  message Response {
  }
}

message GetExperimentByName {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Name of the associated experiment.
  optional string experiment_name = 1 [(validate_required) = true];

  message Response {
    // Experiment details.
    optional Experiment experiment = 1;
  }
}

// TraceInfo. Represents metadata of a trace.
message TraceInfo {
  // Unique identifier for the trace.
  optional string request_id = 1;

  // The ID of the experiment that contains the trace.
  optional string experiment_id = 2;

  // Unix timestamp of when the trace started in milliseconds.
  optional int64 timestamp_ms = 3;

  // Unix timestamp of the duration of the trace in milliseconds.
  optional int64 execution_time_ms = 4;

  // Overall status of the operation being traced (OK, error, etc.).
  optional TraceStatus status = 5;

  // Other trace metadata.
  repeated TraceRequestMetadata request_metadata = 6;

  // Tags for the trace.
  repeated TraceTag tags = 7;
}

message TraceRequestMetadata{
  // Key identifying this metadata.
  optional string key = 1;

  // Value identifying this metadata.
  optional string value = 2;
}

message TraceTag {
  // Key identifying this trace tag.
  optional string key = 1;

  // Value associated with this trace tag.
  optional string value = 2;
}

enum TraceStatus {
  TRACE_STATUS_UNSPECIFIED = 0;

  // The operation being traced was successful.
  OK = 1;

  // The operation being traced failed.
  ERROR = 2;

  // The operation being traced is still in progress.
  IN_PROGRESS = 3;
}

message StartTrace {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1;

  // Unix timestamp of when the trace started in milliseconds.
  optional int64 timestamp_ms = 2;

  // Metadata about the request that initiated the trace.
  repeated TraceRequestMetadata request_metadata = 3;

  // Tags for the trace.
  repeated TraceTag tags = 4;

  message Response {
    // The newly created trace.
    optional TraceInfo trace_info = 1;
  }
}

message EndTrace {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the trace to end.
  optional string request_id = 1;

  // Unix timestamp of when the trace ended in milliseconds.
  optional int64 timestamp_ms = 2;

  // Overall status of the operation being traced (OK, error, etc).
  optional TraceStatus status = 3;

  // Additional metadata about the operation being traced.
  repeated TraceRequestMetadata request_metadata = 4;

  // Additional tags to add to the trace.
  repeated TraceTag tags = 5;

  message Response {
    // The updated trace.
    optional TraceInfo trace_info = 1;
  }
}

message GetTraceInfo {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the trace to fetch. Must be provided.
  optional string request_id = 1;

  message Response {
    // Metadata of the requested trace.
    optional TraceInfo trace_info = 1;
  }
}

message SearchTraces {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // List of experiment IDs to search over.
  repeated string experiment_ids = 1;

  // A filter expression over trace attributes and tags that allows returning a subset of
  // traces. The syntax is a subset of SQL that supports ANDing together binary operations
  // Example: ``trace.status = 'OK' and trace.timestamp_ms > 1711089570679``.
  optional string filter = 2;

  // Maximum number of traces desired. Max threshold is 500.
  optional int32 max_results = 3 [default = 100];

  // List of columns for ordering the results, e.g. ``["timestamp_ms DESC"]``.
  repeated string order_by = 4;

  // Token indicating the page of traces to fetch.
  optional string page_token = 5;

  message Response {
    // Information about traces that match the search criteria.
    repeated TraceInfo traces = 1;
    optional string next_page_token = 2;
  }
}

message DeleteTraces {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the associated experiment.
  optional string experiment_id = 1 [(validate_required) = true];

  // Case 1: max_timestamp_millis and max_traces must be specified for time-based deletion
  // The maximum timestamp in milliseconds since the UNIX epoch for deleting traces.
  optional int64 max_timestamp_millis = 2;

  // The maximum number of traces to delete.
  optional int32 max_traces = 3;

  // Case 2: request_ids must be specified for ID-based deletion
  // A set of request IDs to delete
  repeated string request_ids = 4;

  message Response {
    optional int32 traces_deleted = 1;
  }
}

message SetTraceTag {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the trace on which to set a tag.
  optional string request_id = 1;

  // Name of the tag. Maximum size depends on storage backend.
  // All storage backends are guaranteed to support key values up to 250 bytes in size.
  optional string key = 2;

  // String value of the tag being logged. Maximum size depends on storage backend.
  // All storage backends are guaranteed to support key values up to 250 bytes in size.
  optional string value = 3;

  message Response {
  }
}

message DeleteTraceTag {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // ID of the trace from which to delete the tag.
  optional string request_id = 1;

  // Name of the tag to delete.
  optional string key = 2;

  message Response {
  }
}

// DatasetSummary. Represents a summary of information about a dataset.
message DatasetSummary {
  // Unique identifier for the experiment.
  optional string experiment_id = 1 [(validate_required) = true];

  // The name of the dataset. E.g. “my.uc.table@2” “nyc-taxi-dataset”, “fantastic-elk-3”
  optional string name = 2 [(validate_required) = true];

  // Dataset digest, e.g. an md5 hash of the dataset that uniquely identifies it
  // within datasets of the same name.
  optional string digest = 3 [(validate_required) = true];

  // Value of "context" tag if set for the given dataset.
  optional string context = 4;
}

message SearchDatasets {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // List of experiment IDs to search over.
  repeated string experiment_ids = 1;

  message Response {
    // Return the summary for most recently created N datasets, as configured in backend
    repeated DatasetSummary dataset_summaries = 1;
  }
}

// This file contains the proto definition for communicating with the Databricks tracking server.
// The message definition should be kept in (mostly) sync with the MLflow service definition.
syntax = "proto2";

package mlflow.databricks;

import "assessments.proto";
import "databricks.proto";
import "scalapb/scalapb.proto";
import "google/protobuf/duration.proto";
import "google/protobuf/struct.proto";
import "google/protobuf/timestamp.proto";
import "opentelemetry/proto/trace/v1/trace.proto";

option py_generic_services = true;

service DatabricksTrackingService {
  rpc createTrace (CreateTrace) returns (CreateTrace.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/traces/{location}"
        since { major: 4, minor: 0 },
      }],
      visibility: PUBLIC_UNDOCUMENTED,
      rpc_doc_title: "Create Trace",
    };
  }

  // Get complete traces with spans for given trace identifiers.
  rpc getTraces (GetTraces) returns (GetTraces.Response) {
    option (rpc) = {
      endpoints: [{
        method: "POST",
        path: "/mlflow/traces/batch",
        since {major: 4, minor: 0},
      }],
      visibility: PUBLIC_UNDOCUMENTED,
      rpc_doc_title: "Get Traces",
    };
  }
}

message UCSchemaLocation {
  optional string catalog_name = 1;
  optional string schema_name = 2;
  // spans table name, only for output
  optional string otel_spans_table_name = 3;
  // logs table name, only for output
  optional string otel_logs_table_name = 4;
}

message MlflowExperimentLocation {
  // MLflow experiment ID which is the ACL container holding the trace.
  optional string experiment_id = 1;
}

message InferenceTableLocation {
  // Full inference table name in the form of catalog.schema.table_name
  optional string full_table_name = 1;
}

// The location where the traces was stored and produced
message TraceLocation {

  enum TraceLocationType {
    TRACE_LOCATION_TYPE_UNSPECIFIED = 0;
    MLFLOW_EXPERIMENT = 1;
    INFERENCE_TABLE = 2;
    UC_SCHEMA = 3;
  }
  optional TraceLocationType type = 1;

  oneof identifier {
    MlflowExperimentLocation mlflow_experiment = 2;
    InferenceTableLocation inference_table = 3;
    UCSchemaLocation uc_schema = 4;
  }
}


message TraceInfo {
  // The primary key associated with the trace
  optional string trace_id = 1;

  // Client supplied request ID associated with the trace. This could be used to identify the trace/request from an
  // external system that produced the trace.
  optional string client_request_id = 2;

  optional TraceLocation trace_location = 3;

  // A preview of the request to the model/agent represented as a JSON string. This is equivalent to the input of the root
  // span. This preview value is truncated to 10KB while the full request is stored in the trace data in blob storage.
  optional string request_preview = 4;

  // A preview of the request to the model/agent represented as a JSON string. This is equivalent to the output of the root
  // span. This preview value is truncated to 10KB while the full response is stored in the trace data in blob storage.
  optional string response_preview = 5;

  // Start time of the trace
  optional google.protobuf.Timestamp request_time = 6;

  // Execution time of the trace
  optional google.protobuf.Duration execution_duration = 7;

  // Execution state of the trace at the time that it was logged.
  enum State {
    STATE_UNSPECIFIED = 0;

    // The operation being traced was successful.
    OK = 1;

    // The operation being traced failed.
    ERROR = 2;

    // The operation being traced is still in progress. This is useful for incremental/distributed tracing logging in
    // contrast with when the full trace is logged only upon its completion.
    IN_PROGRESS = 3;
  }
  optional State state = 8;

  // Metadata associated with the trace.
  // Examples include:
  // - run_id: The ID of the mlflow Run (i.e. evaluation job) that produced the trace. May not be
  //           applicable in certain situations such as if the trace was created via interactive vibe checks)
  // - model_id: The ID of the associated model that produced the trace.
  // - dataset_id: The ID of the mlflow Dataset (usually used together with dataset_record_id)
  // - dataset_record_id: The ID of the mlflow Dataset (usually used together with dataset_record_id)
  // - session_id: The ID of the session (e.g. chat conversation) where the request came from
  map<string, string> trace_metadata = 9;

  // TODO: update to new Assessment proto
  repeated assessments.Assessment assessments = 10;

  // Mutable, user-defined tags for the trace, e.g. "question_topic": "DBSQL"
  map<string, string> tags = 11;
}

message CreateTrace {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // The information for the trace being created.
  optional TraceInfo trace_info = 1 [(validate_required) = true];

  // Optional SQL warehouse ID for fetching trace data.
  optional string sql_warehouse_id = 2;

  message Response {
    // The created trace information.
    optional TraceInfo trace_info = 1;
  }
}

message TraceIdentifier {
  // location of the trace.
  oneof location {
    UCSchemaLocation uc_schema = 1;
  }

  // ID of the trace.
  optional string trace_id = 2 [(validate_required) = true];
}

message Trace {
  optional TraceInfo trace_info = 1;
  repeated opentelemetry.proto.trace.v1.Span spans = 2;
}

message GetTraces {
  option (scalapb.message).extends = "com.databricks.rpc.RPC[$this.Response]";

  // Identifiers of the traces to fetch. Must be provided.
  repeated TraceIdentifier trace_ids = 1 [(validate_required) = true];
  
  // SQL warehouse to use for query.
  optional string sql_warehouse_id = 2;

  message Response {
    // The fetched trace information.
    repeated Trace traces = 1;
  }
}

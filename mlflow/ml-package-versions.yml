sklearn:
  package_info:
    pip_release: "scikit-learn"
    install_dev: |
      if [ ! -d "$CACHE_DIR" ] || [ -z $(find $CACHE_DIR -type f -name "scikit_learn-*.whl") ]; then
        pip wheel --no-deps --wheel-dir $CACHE_DIR git+https://github.com/scikit-learn/scikit-learn.git
      fi
      pip install $CACHE_DIR/scikit_learn-*.whl

  models:
    minimum: "0.22.1"
    maximum: "1.2.1"
    requirements:
      "< 1.0": ["scipy==1.7.3"]
    run: |
      pytest tests/sklearn/test_sklearn_model_export.py

  autologging:
    minimum: "0.22.1"
    maximum: "1.2.1"
    requirements:
      ">= 0.0.0": ["matplotlib"]
      "< 1.0": ["scipy==1.7.3"]
    run: |
      pytest tests/sklearn/test_sklearn_autolog.py

      # Ensure sklearn autologging works without matplotlib
      pip uninstall -q -y matplotlib
      pytest tests/sklearn/test_sklearn_autolog_without_matplotlib.py

pytorch:
  package_info:
    pip_release: "torch"
    install_dev: |
      pip install --upgrade --pre torch -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html

  models:
    minimum: "1.6.0"
    maximum: "1.13.1"
    requirements:
      ">= 0.0.0": ["torchvision", "scikit-learn", "transformers"]
    run: |
      pytest tests/pytorch/test_pytorch_model_export.py tests/pytorch/test_pytorch_metric_value_conversion_utils.py

  autologging:
    minimum: "1.6.0"
    maximum: "1.13.1"
    requirements:
      ">= 0.0.0": ["tensorboard"]
    run: |
      pytest tests/pytorch/test_tensorboard_autolog.py

pytorch-lightning:
  package_info:
    pip_release: "pytorch-lightning"
    install_dev: |
      export PACKAGE_NAME=pytorch
      pip install git+https://github.com/PytorchLightning/pytorch-lightning.git

  autologging:
    minimum: "1.0.5"
    maximum: "1.9.3"
    requirements:
      ">= 0.0.0": ["scikit-learn", "torchvision", "protobuf<4.0.0", "tensorboard"]
      "< 1.2.0": ["torch<1.11.0"]
      # torchmetrics==0.8.0 released a breaking change for versions 1.3 and 1.4 where
      # torchmetrics dependency was defined as non-upper-bounded in its requirements.
      # see: https://github.com/PyTorchLightning/metrics/commit/c537c9b3e8e801772a7e5670ff273321ed26e77b
      # for the removed function that causes pytorch-lightning imports to fail with torchmetrics==0.8.0
      ">= 1.3.0, < 1.5.0": ["torchmetrics<0.8.0"]
    run: |
      pytest tests/pytorch/test_pytorch_autolog.py

tensorflow:
  package_info:
    pip_release: "tensorflow"
    install_dev: |
      pip install tf-nightly

  models:
    minimum: "2.3.0"
    maximum: "2.11.0"
    requirements:
      # Requirements to run tests for keras
      ">= 0.0.0": ["scikit-learn", "pyspark", "pyarrow", "transformers"]
      "< 2.6.0": ["protobuf<4.0.0"]
      "< 2.7.0": ["pandas==1.3.5"]
      # TensorFlow 2.3.4, 2.4.4, 2.5.3, and 2.6.5 are incompatible with SQLAlchemy 2.x due to
      # transitive dependency version conflicts with the `typing-extensions` package
      # They are also incompatible with alembic 1.10.1 with the TypeGuard dependency in py3.8
      "== 2.3.4": ["sqlalchemy<2", "alembic<1.10"]
      "== 2.4.4": ["sqlalchemy<2", "alembic<1.10"]
      "== 2.5.3": ["sqlalchemy<2", "alembic<1.10"]
      "== 2.6.5": ["sqlalchemy<2", "alembic<1.10"]
    run: |
      pytest \
        tests/tensorflow/test_load_saved_tensorflow_estimator.py \
        tests/tensorflow/test_tensorflow2_core_model_export.py \
        tests/tensorflow/test_tensorflow2_metric_value_conversion_utils.py \
        tests/tensorflow/test_keras_model_export.py \
        tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py

  autologging:
    minimum: "2.3.0"
    maximum: "2.11.0"
    requirements:
      "== dev": ["scikit-learn"]
      "< 2.6.0": ["protobuf<4.0.0"]
      "< 2.7.0": ["pandas==1.3.5"]
      # TensorFlow 2.3.4, 2.4.4, 2.5.3, and 2.6.5 are incompatible with SQLAlchemy 2.x due to
      # transitive dependency version conflicts with the `typing-extensions` package
      # They are also incompatible with alembic 1.10.1 with the TypeGuard dependency in py3.8
      "== 2.3.4": ["sqlalchemy<2", "alembic<1.10"]
      "== 2.4.4": ["sqlalchemy<2", "alembic<1.10"]
      "== 2.5.3": ["sqlalchemy<2", "alembic<1.10"]
      "== 2.6.5": ["sqlalchemy<2", "alembic<1.10"]
    run: |
      pytest tests/tensorflow/test_tensorflow2_autolog.py

xgboost:
  package_info:
    pip_release: "xgboost"
    install_dev: |
      pip install git+https://github.com/dmlc/xgboost.git#subdirectory=python-package

  models:
    minimum: "1.1.1"
    maximum: "1.7.4"
    requirements:
      ">= 0.0.0": ["scikit-learn"]
    run: |
      pytest tests/xgboost/test_xgboost_model_export.py

  autologging:
    minimum: "1.1.1"
    maximum: "1.7.4"
    requirements:
      ">= 0.0.0": ["scikit-learn", "matplotlib"]
    run: |
      pytest tests/xgboost/test_xgboost_autolog.py

lightgbm:
  package_info:
    pip_release: "lightgbm"
    install_dev: |
      pip install git+https://github.com/microsoft/LightGBM.git#subdirectory=python-package

  models:
    minimum: "2.3.1"
    maximum: "3.3.5"
    requirements:
      ">= 0.0.0": ["scikit-learn"]
    run: |
      pytest tests/lightgbm/test_lightgbm_model_export.py

  autologging:
    minimum: "2.3.1"
    maximum: "3.3.5"
    requirements:
      ">= 0.0.0": ["scikit-learn", "matplotlib"]
    run: |
      pytest tests/lightgbm/test_lightgbm_autolog.py

catboost:
  package_info:
    pip_release: "catboost"
    install_dev: |
      # The cross-version-tests workflow runs this command with the environment variable `CACHE_DIR`
      if [ ! -d "$CACHE_DIR" ] || [ -z $(find $CACHE_DIR -type f -name "catboost-*.whl") ]; then
        # TODO: Remove the commit once https://github.com/catboost/catboost/issues/2242 is fixed
        pip wheel --no-deps --wheel-dir $CACHE_DIR \
          git+https://github.com/catboost/catboost.git@f8921d839eccf11e533a46347dde5b5b25b17190#subdirectory=catboost/python-package
      fi
      pip install $CACHE_DIR/catboost-*.whl

  models:
    minimum: "0.23.1"
    maximum: "1.1.1"
    requirements:
      ">= 0.0.0": ["scikit-learn"]
    run: |
      pytest tests/catboost/test_catboost_model_export.py

gluon:
  package_info:
    pip_release: "mxnet"
    install_dev: |
      pip install --pre mxnet -f https://dist.mxnet.io/python/cpu

  models:
    minimum: "1.5.1"
    maximum: "1.9.1"
    unsupported: ["1.8.0"] # MXNet 1.8.0 is a flawed release that we don't expect to work with
    run: |
      # Install libopenblas-dev for mxnet 1.8.0.post0
      sudo apt-get update -y
      sudo apt-get install libopenblas-dev -y
      pytest tests/gluon/test_gluon_model_export.py

  autologging:
    minimum: "1.5.1"
    maximum: "1.9.1"
    unsupported: ["1.8.0"] # MXNet 1.8.0 is a flawed release that we don't expect to work with
    run: |
      pytest tests/gluon/test_gluon_autolog.py

fastai:
  package_info:
    pip_release: "fastai"

  models:
    minimum: "2.4.1"
    maximum: "2.7.11"
    requirements:
      "< 2.8.0": ["torch<1.13.0", "torchvision<0.14.0"]
      ">= 2.8.0": ["torch", "torchvision"]
    run: |
      pytest tests/fastai/test_fastai_model_export.py

  autologging:
    minimum: "2.4.1"
    maximum: "2.7.11"
    requirements:
      "< 2.8.0": ["torch<1.13.0", "torchvision<0.14.0"]
      ">= 2.8.0": ["torch", "torchvision"]
    run: |
      pytest tests/fastai/test_fastai_autolog.py

onnx:
  package_info:
    pip_release: "onnx"
    install_dev: |
      # This workflow describes how to build a wheel for Linux:
      # https://github.com/onnx/onnx/blob/51a7d932356cbb1205341660a4a52f8c121d8f4b/.github/workflows/release_linux_x86_64.yml

      auth_header="$(git config --local --get http.https://github.com/.extraheader)"
      tmp_dir=$(mktemp -d)
      git clone https://github.com/onnx/onnx.git $tmp_dir
      cd $tmp_dir
      git submodule sync --recursive
      git -c "http.extraheader=$auth_header" -c protocol.version=2 submodule update --init --force --recursive --depth=1

      # Build wheel
      python_version=$(python -c 'import sys; print(".".join(map(str, sys.version_info[:2])))')
      docker run --rm -v $(pwd):/github/workspace --workdir /github/workspace --entrypoint bash \
        quay.io/pypa/manylinux2014_x86_64 .github/workflows/manylinux/entrypoint.sh $python_version manylinux2014_x86_64 pull_request

      # Install wheel
      pip install dist/*manylinux2014_x86_64.whl

  models:
    minimum: "1.7.0"
    maximum: "1.13.1"
    requirements:
      ">= 0.0.0": ["onnxruntime", "torch", "scikit-learn", "protobuf<4.0.0"]
    run: |
      pytest tests/onnx/test_onnx_model_export.py

spacy:
  package_info:
    pip_release: "spacy"
    install_dev: |
      pip install git+https://github.com/explosion/spaCy.git

  models:
    minimum: "2.2.4"
    maximum: "3.5.0"
    requirements:
      ">= 0.0.0": ["scikit-learn", "click<8.1.0"]
      "<= 3.0.9": ["flask<2.1.0"]
    run: |
      pytest tests/spacy/test_spacy_model_export.py

statsmodels:
  package_info:
    pip_release: "statsmodels"
    install_dev: |
      pip install git+https://github.com/statsmodels/statsmodels.git

  models:
    minimum: "0.11.1"
    maximum: "0.13.5"
    requirements:
      "< 0.13.0": ["pandas==1.3.5", "scipy==1.7.3"]
    run: |
      pytest tests/statsmodels/test_statsmodels_model_export.py

  autologging:
    minimum: "0.11.1"
    maximum: "0.13.5"
    requirements:
      "< 0.13.0": ["pandas==1.3.5", "scipy==1.7.3"]
    run: |
      pytest tests/statsmodels/test_statsmodels_autolog.py

spark:
  package_info:
    pip_release: "pyspark"
    install_dev: |
      # The cross-version-tests workflow runs this command with the environment variable `CACHE_DIR`
      if [ ! -d "$CACHE_DIR" ] || [ -z $(find $CACHE_DIR -type f -name "pyspark-*.whl") ]; then
        # Build wheel from source
        temp_dir=$(mktemp -d)
        git clone --depth 1 https://github.com/apache/spark.git $temp_dir
        git --git-dir=$temp_dir/.git rev-parse HEAD
        cd $temp_dir
        ./build/mvn -DskipTests --no-transfer-progress clean package
        cd python
        python setup.py bdist_wheel --dist-dir $CACHE_DIR
      fi
      pip install $CACHE_DIR/pyspark-*.whl

  models:
    minimum: "3.0.0"
    maximum: "3.4.0"
    # NB: Allow unreleased maximum versions for the pyspark package to support models and
    # autologging use cases in environments where newer versions of pyspark are available
    # prior to their release on PyPI (e.g. Databricks)
    allow_unreleased_max_version: True
    requirements:
      ">= 0.0.0": ["boto3", "scikit-learn", "pyarrow"]
      "<= 3.3.2": ["pandas<2"]
    run: |
      SAGEMAKER_OUT=$(mktemp)
      if mlflow sagemaker build-and-push-container --no-push --mlflow-home . > $SAGEMAKER_OUT 2>&1; then
        echo "Sagemaker container build succeeded.";
      else
        echo "Sagemaker container build failed, output:";
        cat $SAGEMAKER_OUT;
        exit 1
      fi
      pytest tests/spark --ignore tests/spark/autologging

  autologging:
    minimum: "3.0.0"
    maximum: "3.4.0"
    # NB: Allow unreleased maximum versions for the pyspark package to support models and
    # autologging use cases in environments where newer versions of pyspark are available
    # prior to their release on PyPI (e.g. Databricks)
    allow_unreleased_max_version: True
    requirements:
      ">= 0.0.0": ["scikit-learn"]
      "<= 3.3.2": ["pandas<2"]
    run: |
      find tests/spark/autologging/ml -name 'test*.py' | xargs -L 1 pytest

      # TODO: Fix spark datasource autologging and test it against non-preview versions of pyspark
      if [ "$(pip show pyspark | grep Version | cut -d' ' -f2)" = "3.0.0" ]; then
        YELLOW='\033[33;1;4m'
        NO_COLOR='\033[0m'
        echo -e "${YELLOW}WARNING: Spark datasource autologging currently only works for Spark 3.0.0-preview.${NO_COLOR}"
        pip uninstall -y pyspark
        ./dev/setup-spark-datasource-autologging.sh
        find tests/spark/autologging/datasource -name 'test*.py' | xargs -L 1 pytest
      fi

mleap:
  package_info:
    pip_release: "mleap"

  models:
    minimum: "0.18.0"
    maximum: "0.22.0"
    requirements:
      "> 0.17.0, < 0.21.0": ["pyspark==3.0.2"]
      ">= 0.21.0": ["pyspark"]
    run: |
      SAGEMAKER_OUT=$(mktemp)
      if mlflow sagemaker build-and-push-container --no-push --mlflow-home . > $SAGEMAKER_OUT 2>&1; then
        echo "Sagemaker container build succeeded.";
      else
        echo "Sagemaker container build failed, output:";
        cat $SAGEMAKER_OUT;
        exit 1
      fi
      pytest tests/mleap/test_mleap_model_export.py

prophet:
  package_info:
    pip_release: "prophet"
    install_dev: |
      sudo apt-get -y install libtbb2
      if [ ! -d "$CACHE_DIR" ] || [ -z $(find $CACHE_DIR -type f -name "prophet-*.whl") ]; then
        pip wheel --no-deps --wheel-dir $CACHE_DIR git+https://github.com/facebook/prophet.git#subdirectory=python
      fi
      pip install $CACHE_DIR/prophet-*.whl

  models:
    minimum: "1.0.1"
    maximum: "1.1.2"
    run: |
      pytest tests/prophet/test_prophet_model_export.py

pmdarima:
  package_info:
    pip_release: "pmdarima"
    install_dev: |
      if [ ! -d "$CACHE_DIR" ] || [ -z $(find $CACHE_DIR -type f -name "pmdarima-*.whl") ]; then
        pip install Cython
        pip wheel --no-deps --wheel-dir $CACHE_DIR git+https://github.com/alkaline-ml/pmdarima.git
      fi
      pip install $CACHE_DIR/pmdarima-*.whl

  models:
    minimum: "1.8.0"
    maximum: "2.0.2"
    requirements:
      ">= 0.0.0": ["prophet"]
    run: |
      pytest tests/pmdarima/test_pmdarima_model_export.py

diviner:
  package_info:
    pip_release: "diviner"
    install_dev: |
      pip install git+https://github.com/databricks/diviner.git

  models:
    minimum: "0.1.0"
    maximum: "0.1.1"
    requirements:
      # https://github.com/alan-turing-institute/sktime/issues/2898
      ">= 0.0": ["cmdstanpy!=1.0.2"]
      "<= 0.1.0": ["pmdarima<2.0.0"]
    run: |
      pytest tests/diviner/test_diviner_model_export.py

h2o:
  package_info:
    pip_release: "h2o"
  models:
    minimum: "3.40.0.1"
    maximum: "3.40.0.1"
    run: |
      pytest tests/h2o

shap:
  package_info:
    pip_release: "shap"
  models:
    minimum: "0.41.0"
    maximum: "0.41.0"
    run: |
      pytest tests/shap

paddle:
  package_info:
    pip_release: "paddlepaddle"
  models:
    minimum: "2.4.1"
    maximum: "2.4.2"
    run: |
      pytest tests/paddle/test_paddle_model_export.py
  autolog:
    minimum: "2.4.1"
    maximum: "2.4.1"
    run: |
      pytest tests/paddle/test_paddle_autolog.py

transformers:
  package_info:
    pip_release: "transformers"
    install_dev: |
      pip install git+https://github.com/huggingface/transformers
  models:
    minimum: "4.25.1"
    maximum: "4.27.4"
    requirements:
      ">= 0.0.0": ["datasets", "huggingface_hub", "torch", "torchvision", "tensorflow"]
    run: |
      pytest tests/transformers/test_transformers_model_export.py

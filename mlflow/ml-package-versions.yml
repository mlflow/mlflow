sklearn:
  package_info:
    pip_release: "scikit-learn"
    install_dev: |
      pip install git+https://github.com/scikit-learn/scikit-learn.git

  models:
    minimum: "1.3.0"
    maximum: "1.6.1"
    requirements:
      "<= 1.3.0": ["numpy<2"]
    python:
      "== dev": "3.10"
    run: |
      pytest tests/sklearn/test_sklearn_model_export.py

  autologging:
    minimum: "1.3.0"
    maximum: "1.6.1"
    requirements:
      "<= 1.3.0": ["numpy<2"]
      ">= 0.0.0": ["matplotlib"]
    python:
      "== dev": "3.10"
    run: |
      pytest tests/sklearn/test_sklearn_autolog.py

      # Ensure sklearn autologging works without matplotlib
      pip uninstall -q -y matplotlib
      pytest tests/sklearn/test_sklearn_autolog_without_matplotlib.py

pytorch:
  package_info:
    pip_release: "torch"
    module_name: "torch"
    install_dev: |
      pip install --upgrade --pre torch -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html

  models:
    minimum: "2.1.0"
    maximum: "2.7.0"
    requirements:
      ">= 0.0.0": ["torchvision", "scikit-learn"]
      ">= 1.8": ["transformers"]
      "< 2.3": ["numpy<2", "transformers<=4.49.0"]
    run: |
      pytest tests/pytorch/test_pytorch_model_export.py tests/pytorch/test_pytorch_metric_value_conversion_utils.py

  autologging:
    minimum: "2.1.0"
    maximum: "2.7.0"
    requirements:
      ">= 0.0.0": ["tensorboard"]
    run: |
      pytest tests/pytorch/test_tensorboard_autolog.py

pytorch-lightning:
  package_info:
    pip_release: "pytorch-lightning"
    module_name: "lightning"
    install_dev: |
      export PACKAGE_NAME=pytorch
      pip install git+https://github.com/PytorchLightning/pytorch-lightning.git

  autologging:
    minimum: "2.0.3"
    maximum: "2.5.1.post0"
    requirements:
      ">= 0.0.0": ["scikit-learn", "torchvision", "protobuf<4.0.0", "tensorboard", "greenlet<3"]
    run: |
      pytest tests/pytorch/test_pytorch_autolog.py

keras:
  package_info:
    pip_release: "keras"
    install_dev: |
      pip install --upgrade git+https://github.com/keras-team/keras.git

  models:
    minimum: "3.0.2"
    maximum: "3.9.2"
    requirements:
      ">= 3.0.0": ["jax[cpu]>0.4"]
      "< 3.10.0": ["jax[cpu]<0.6"]
    run: |
      export KERAS_BACKEND=jax
      pytest tests/keras/test_callback.py

  autologging:
    minimum: "3.0.2"
    maximum: "3.9.2"
    requirements:
      ">= 3.0.0": ["jax[cpu]>0.4"]
      "< 3.10.0": ["jax[cpu]<0.6"]
    run: |
      export KERAS_BACKEND=jax
      pytest tests/keras/test_autolog.py

tensorflow:
  package_info:
    pip_release: "tensorflow"
    install_dev: |
      pip install --pre tf-nightly

  models:
    minimum: "2.12.1"
    maximum: "2.19.0"
    requirements:
      # Requirements to run tests for keras
      ">= 0.0.0": ["scikit-learn", "pyspark", "pyarrow", "transformers!=4.38.0,!=4.38.1"]
      # TensorFlow 2.12.1 and 2.13.1 requires typing_extensions < 4.6.0, which is
      # incompatible with SQLAlchemy 2.0.25 and Pydantic v2 with error
      # `cannot import name 'TypeAliasType' from 'typing_extensions'`
      ">= 2.12.1, <= 2.13.1": ["sqlalchemy<2.0.25", "pydantic<2"]
      "== 2.15.1": ["transformers<4.39.0"]
    run: |
      pytest \
        tests/tensorflow/test_tensorflow2_core_model_export.py \
        tests/tensorflow/test_tensorflow2_metric_value_conversion_utils.py \
        tests/tensorflow/test_keras_model_export.py \
        tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py

  autologging:
    minimum: "2.12.1"
    maximum: "2.19.0"
    requirements:
      "== dev": ["scikit-learn"]
      # TensorFlow 2.12.1 and 2.13.1 requires typing_extensions < 4.6.0, which is
      # incompatible with SQLAlchemy 2.0.25 with error
      # `cannot import name 'TypeAliasType' from 'typing_extensions'`
      ">= 2.12.1, <= 2.13.1": ["sqlalchemy<2.0.25", "pydantic<2"]
    run: |
      pytest tests/tensorflow/test_tensorflow2_autolog.py

xgboost:
  package_info:
    pip_release: "xgboost"
    install_dev: |
      pip install git+https://github.com/dmlc/xgboost.git#subdirectory=python-package

  models:
    minimum: "1.7.6"
    maximum: "3.0.1"
    requirements:
      ">= 0.0.0": ["scikit-learn"]
    python:
      "== dev": "3.10"
    run: |
      pytest tests/xgboost/test_xgboost_model_export.py

  autologging:
    minimum: "1.7.6"
    maximum: "3.0.1"
    requirements:
      ">= 0.0.0": ["scikit-learn", "matplotlib"]
    python:
      "== dev": "3.10"
    run: |
      pytest tests/xgboost/test_xgboost_autolog.py

lightgbm:
  package_info:
    pip_release: "lightgbm"
    install_dev: |
      git clone --recursive https://github.com/microsoft/LightGBM --depth=1 --branch master /tmp/LightGBM
      cd /tmp/LightGBM
      bash build-python.sh install

  models:
    minimum: "4.0.0"
    maximum: "4.6.0"
    requirements:
      ">= 0.0.0": ["scikit-learn"]
      "== 4.0.*": ["numpy<2"]
    run: |
      pytest tests/lightgbm/test_lightgbm_model_export.py

  autologging:
    minimum: "4.0.0"
    maximum: "4.6.0"
    requirements:
      ">= 0.0.0": ["scikit-learn", "matplotlib"]
      "== 4.0.*": ["numpy<2"]
    run: |
      pytest tests/lightgbm/test_lightgbm_autolog.py

catboost:
  package_info:
    pip_release: "catboost"

  models:
    minimum: "1.2.1"
    maximum: "1.2.8"
    requirements:
      ">= 0.0.0": ["scikit-learn"]
      "< 1.3": ["numpy<2"]
    run: |
      pytest tests/catboost/test_catboost_model_export.py

onnx:
  package_info:
    pip_release: "onnx"
    install_dev: |
      # This workflow describes how to build a wheel for Linux:
      # https://github.com/onnx/onnx/blob/51a7d932356cbb1205341660a4a52f8c121d8f4b/.github/workflows/release_linux_x86_64.yml

      auth_header="$(git config --local --get http.https://github.com/.extraheader)"
      tmp_dir=$(mktemp -d)
      git clone https://github.com/onnx/onnx.git $tmp_dir
      cd $tmp_dir
      git submodule sync --recursive
      git -c "http.extraheader=$auth_header" -c protocol.version=2 submodule update --init --force --recursive --depth=1

      # Build wheel
      python_version=$(python -c 'import sys; print(".".join(map(str, sys.version_info[:2])))')
      docker run --rm -v $(pwd):/github/workspace --workdir /github/workspace --entrypoint bash \
        quay.io/pypa/manylinux2014_x86_64 .github/workflows/manylinux/entrypoint.sh $python_version manylinux2014_x86_64 pull_request

      # Install wheel
      pip install dist/*manylinux2014_x86_64.whl

  models:
    minimum: "1.14.1"
    maximum: "1.18.0"
    requirements:
      ">= 0.0.0": ["onnxruntime", "torch", "scikit-learn"]
    run: |
      pytest tests/onnx/test_onnx_model_export.py

spacy:
  package_info:
    pip_release: "spacy"
    install_dev: |
      pip install git+https://github.com/explosion/spaCy.git

  models:
    minimum: "3.5.3"
    maximum: "3.8.4"
    python:
      ">= 3.8.4": "3.10"
    requirements:
      "< 3.8": ["numpy<2"]
    run: |
      pytest tests/spacy/test_spacy_model_export.py

statsmodels:
  package_info:
    pip_release: "statsmodels"
    install_dev: |
      pip install git+https://github.com/statsmodels/statsmodels.git

  models:
    minimum: "0.14.1"
    maximum: "0.14.4"
    run: |
      pytest tests/statsmodels/test_statsmodels_model_export.py

  autologging:
    minimum: "0.14.1"
    maximum: "0.14.4"
    run: |
      pytest tests/statsmodels/test_statsmodels_autolog.py

spark:
  package_info:
    pip_release: "pyspark"
    module_name: "pyspark"
    install_dev: |
      temp_dir=$(mktemp -d)
      git clone --depth 1 https://github.com/apache/spark.git $temp_dir
      cd $temp_dir
      # -Pconnect -Phive is required by spark connect
      ./build/sbt -Pconnect -Phive clean package connect/assembly
      cd python/packaging/classic
      pip install '.[connect]'
      pyspark --version

  models:
    minimum: "3.2.1"
    maximum: "4.0.0"
    java:
      "> 3.4.1": "17"
    # NB: Allow unreleased maximum versions for the pyspark package to support models and
    # autologging use cases in environments where newer versions of pyspark are available
    # prior to their release on PyPI (e.g. Databricks)
    allow_unreleased_max_version: True
    requirements:
      ">= 0.0.0": ["boto3", "scikit-learn", "pyarrow", "numpy<2"]
      "< 3.4.0": ["pandas<2"]
      ">= 3.5.0": ["torch<2.6.0", "scikit-learn", "torcheval"]
      ">= 3.5.0, < dev": ["pyspark[connect]"]
    run: |
      SAGEMAKER_OUT=$(mktemp)
      if mlflow sagemaker build-and-push-container --no-push --mlflow-home . > $SAGEMAKER_OUT 2>&1; then
        echo "Sagemaker container build succeeded.";
      else
        echo "Sagemaker container build failed, output:";
        cat $SAGEMAKER_OUT;
        exit 1
      fi
      pytest tests/spark --ignore tests/spark/autologging --ignore tests/spark/test_spark_connect_model_export.py

      if [[ $(python -c "from packaging.version import Version;import pyspark;print(Version(pyspark.__version__) >= Version('3.5'))") = "True" ]]; then
        pytest tests/spark/test_spark_connect_model_export.py;
      fi

  autologging:
    minimum: "3.2.1"
    maximum: "4.0.0"
    java:
      ">= 3.4.1": "17"
    # NB: Allow unreleased maximum versions for the pyspark package to support models and
    # autologging use cases in environments where newer versions of pyspark are available
    # prior to their release on PyPI (e.g. Databricks)
    allow_unreleased_max_version: True
    requirements:
      ">= 0.0.0": ["scikit-learn", "numpy<2"]
      "< 3.4.0": ["pandas<2"]
    run: |
      # Build Java package
      # Pyspark 4.0 ('dev' version) exclusively supports Scala 2.13
      if [[ $(python -c "import pyspark;from packaging.version import Version;print(Version(pyspark.__version__).major >= 4)") = "True" ]]; then
        python dev/set-mlflow-spark-scala-version.py --scala-version 2.13.10
      fi
      pushd mlflow/java/spark
      mvn package -DskipTests -q
      popd

      # `test_spark_disable_autologging.py` is flaky if it runs with other tests
      # so run it individually
      pytest tests/spark/autologging/datasource/test_spark_disable_autologging.py

      # NB: Running each .py file individually is important (instead of
      # 'pytest tests/spark/autologging') not to share SparkSession across tests
      # `test_spark_datasource_autologging_crossframework.py` fails when run with other tests
      pytest tests/spark/autologging/datasource/test_spark_datasource_autologging_crossframework.py

      find tests/spark/autologging -name 'test*.py' | grep -v crossframework | grep -v test_spark_disable_autologging | xargs -L 1 pytest

prophet:
  package_info:
    pip_release: "prophet"

  models:
    minimum: "1.1.6"
    maximum: "1.1.6"
    requirements:
      # Prophet does not handle numpy 2 yet. https://github.com/facebook/prophet/issues/2595
      ">= 0.0.0": ["numpy<2"]
      # Avoid holidays 0.25 due to https://github.com/dr-prodigy/python-holidays/issues/1200 on
      # older version of prophet. Compatibility updates have been released as part of the 1.1.4
      # release of prophet.
    run: |
      pytest tests/prophet/test_prophet_model_export.py

pmdarima:
  package_info:
    pip_release: "pmdarima"
    # TODO: Uncomment once https://github.com/alkaline-ml/pmdarima/issues/582 is fixed.
    # install_dev: |
    #   # pip install Cython
    #   # pip install git+https://github.com/alkaline-ml/pmdarima.git

  models:
    minimum: "2.0.4"
    maximum: "2.0.4"
    requirements:
      ">= 0.0.0": [
          "prophet",
          # Avoid holidays 0.25 due to https://github.com/dr-prodigy/python-holidays/issues/1200
          "holidays!=0.25",
          "numpy<2",
          # TODO: Try the latest version of moto (https://github.com/getmoto/moto/issues/8498) and remove this pin
          "boto3<1.36",
        ]
    run: |
      pytest tests/pmdarima/test_pmdarima_model_export.py

diviner:
  package_info:
    pip_release: "diviner"
    install_dev: |
      pip install git+https://github.com/databricks/diviner.git

  models:
    minimum: "0.1.1"
    maximum: "0.1.1"
    requirements:
      # https://github.com/alan-turing-institute/sktime/issues/2898
      # Avoid holidays 0.25 due to https://github.com/dr-prodigy/python-holidays/issues/1200
      ">= 0.0": [
          "cmdstanpy!=1.0.2",
          "holidays!=0.25",
          "numpy<2",
          # TODO: Try the latest version of moto (https://github.com/getmoto/moto/issues/8498) and remove this pin
          "boto3<1.36",
        ]
      # Diviner <= 0.1.1 isn't compatible with pandas>=2
      "<= 0.1.1": ["pandas<2"]
      # As of Jun 7, 2023, Diviner dev isn't compatible with pandas>=2
      "== dev": ["pandas<2"]
    run: |
      pytest tests/diviner/test_diviner_model_export.py

h2o:
  package_info:
    pip_release: "h2o"
  models:
    minimum: "3.42.0.1"
    maximum: "3.46.0.7"
    run: |
      pytest tests/h2o

shap:
  package_info:
    pip_release: "shap"
  models:
    minimum: "0.42.1"
    maximum: "0.47.2"
    requirements:
      "< 0.46.0": ["numpy<1.24.0"]
    run: |
      pytest tests/shap

paddle:
  package_info:
    pip_release: "paddlepaddle"
  models:
    minimum: "2.5.2"
    maximum: "3.0.0"
    requirements:
      "< 2.6.0": ["numpy<2"]
    run: |
      pytest tests/paddle/test_paddle_model_export.py
  autologging:
    minimum: "2.5.2"
    maximum: "3.0.0"
    requirements:
      "< 2.6.0": ["numpy<2"]
    run: |
      pytest tests/paddle/test_paddle_autolog.py

transformers:
  package_info:
    pip_release: "transformers"
    install_dev: |
      pip install git+https://github.com/huggingface/transformers
  models:
    minimum: "4.35.2"
    maximum: "4.51.3"
    test_every_n_versions: 4
    unsupported: [
        # Avoid this patch: https://github.com/huggingface/transformers/pull/29032
        ">=4.38.0,<4.39.0",
        # https://github.com/huggingface/transformers/issues/38269
        "== 4.52.1",
        "== 4.52.2",
      ]
    requirements:
      ">= 0.0.0": [
          "datasets",
          # 0.22.0 is broken: https://github.com/huggingface/huggingface_hub/issues/2157
          "huggingface_hub!=0.22.0",
          "hf_transfer",
          "torch",
          "torchvision",
          "tensorflow",
          "peft", # optimized fine-tuning library developed by Hugging Face
          "accelerate", # required for large torch models where weights will not fit in RAM
          "librosa", # required for transformers audio pipelines for bitrate conversion
          "ffmpeg", # required for transformers audio pipelines for audio byte to numpy conversion
          "sentencepiece", # required for transformers text2text generation pipeline
          "protobuf<=3.20.3", # fix error `Couldn't build proto file into descriptor pool: duplicate file name sentencepiece_model.proto`
          "typing_extensions>=4.6.0", # fix error for SqlAlchemy == 2.0.25 cannot import name 'TypeAliasType' from 'typing_extensions'
          # TODO: Try the latest version of moto (https://github.com/getmoto/moto/issues/8498) and remove this pin
          "boto3<1.36",
        ]
      # peft >= 0.14 relies on classes from newer versions of transformers
      "< 4.43": ["peft<0.14.0"]
      # Pin torchvision to <0.20.0 to avoid https://github.com/pytorch/torchchat/issues/1158
      "< 4.38": ["tensorflow<2.14", "pydantic<2"] # Older versions of transformers are incompatible with tensorflow >= 2.14
      ">= 4.38": ["tf-keras"] # Transformers doesn't support Keras 3.0. tf-keras needs to be installed.
      "< 4.52.0.dev0": ["accelerate<1"]
    pre_test: |
      export PYTHONPATH=./
      python tests/transformers/helper.py
    run: |
      # Run all Transformers tests except autologging
      pytest tests/transformers --ignore tests/transformers/test_transformers_autolog.py
      pip uninstall -y accelerate
      pytest tests/transformers/test_transformers_model_export.py -k "test_transformers_tf_model_save_without_conda_env_uses_default_env_with_expected_dependencies or test_transformers_pt_model_save_dependencies_without_accelerate"
  autologging:
    minimum: "4.35.2"
    maximum: "4.51.3"
    test_every_n_versions: 4
    unsupported: [
        # Avoid this patch: https://github.com/huggingface/transformers/pull/29032
        ">=4.38.0,<4.39.0",
        # https://github.com/huggingface/transformers/issues/38269
        "== 4.52.1",
        "== 4.52.2",
      ]
    requirements:
      ">= 0.0.0": [
          "datasets",
          # 0.22.0 is broken: https://github.com/huggingface/huggingface_hub/issues/2157
          "huggingface_hub!=0.22.0",
          "hf_transfer",
          "torch",
          "torchvision",
          "tensorflow",
          "setfit",
          "optuna",
          # TODO: Try the latest version of moto (https://github.com/getmoto/moto/issues/8498) and remove this pin
          "boto3<1.36",
        ]
      "< 4.38": ["tensorflow<2.14", "pydantic<2"] # Older versions of transformers are incompatible with tensorflow >= 2.14
      ">= 4.38": ["tf-keras"] # Transformers doesn't support Keras 3.0. tf-keras needs to be installed.
      # hf_hub>=0.24.0 is broken with setfit<=1.0.3. the incompatibility was fixed in setfit>=1.1, but
      # that version of setfit requires tranformers>=4.41
      # datasets > 2.4.0 is incompatible with huggingface_hub<0.24.0
      # evaluate >= 0.4.3 is incompatible with datasets<=2.4.0
      "< 4.41": ["huggingface_hub<0.24.0", "datasets<=2.4.0", "evaluate<0.4.3"]
      "< 4.52.0.dev0": ["accelerate<1"]
    run: |
      pytest tests/transformers/test_transformers_autolog.py

openai:
  package_info:
    pip_release: "openai"
    install_dev: |
      pip install git+https://github.com/openai/openai-python
  models:
    minimum: "1.0.1"
    maximum: "1.78.1"
    requirements:
      ">= 0.0.0": [
          "pyspark",
          "tiktoken",
          "aiohttp",
          "tenacity",
          # Required to run tests/openai/mock_openai.py
          "fastapi",
          "uvicorn",
        ]
      "< 1.55.3": ["httpx<0.28.0"]
    run: |
      pytest tests/openai tests/openai/test_openai_model_export.py
    # Our CI runs tests for every minor version of the library by default, which results in
    # many test tasks for openai. Reducing the number of testing only for every 10 version.
    test_every_n_versions: 10
  autologging:
    minimum: "1.17.0"
    maximum: "1.78.1"
    python:
      # OpenAI Swarm requires Python >=3.10
      ">= 1.33.0": "3.10"
    requirements:
      ">= 0.0.0": [
          "pyspark",
          "tiktoken",
          "aiohttp",
          "tenacity",
          # Required to run tests/openai/mock_openai.py
          "fastapi",
          "uvicorn",
        ]
      "< 1.55.3": ["httpx<0.28.0"]
      ">= 1.66.2": ["openai-agents"]
    run: |
      pytest tests/openai/test_openai_autolog.py tests/openai/test_openai_agent_autolog.py
    test_every_n_versions: 10

dspy:
  package_info:
    pip_release: "dspy"
    install_dev: |
      pip install git+https://github.com/stanfordnlp/dspy.git
  models:
    minimum: "2.5.17"
    maximum: "2.6.23"
    requirements:
      ">= 0.0.0": ["openai"]
    run: |
      pytest tests/dspy --ignore tests/dspy/test_dspy_autolog.py
  autologging:
    minimum: "2.5.17"
    maximum: "2.6.23"
    requirements:
      ">= 0.0.0": ["openai"]
    run: |
      pytest tests/dspy/test_dspy_autolog.py

langchain:
  package_info:
    pip_release: "langchain"
    install_dev: |
      pip install git+https://github.com/langchain-ai/langchain#subdirectory=libs/langchain
  models:
    # Where the large package update was made (langchain-core, community, ...)
    minimum: "0.0.354"
    maximum: "0.3.25"
    requirements:
      ">= 0.0.0": [
          "pyspark",
          "transformers",
          "torch",
          "torchvision",
          "openai",
          "google-search-results",
          "psutil",
          "faiss-cpu",
          "langchain-experimental",
          "numexpr",
          "hf_transfer",
          "langchain-core!=0.1.39", # https://github.com/langchain-ai/langchain/issues/19947
          "langchain-openai",
          "langgraph",
          # Required to run tests/openai/mock_openai.py
          "fastapi",
          "uvicorn",
          # Required for testing Databricks dependency extraction
          "databricks-vectorsearch",
        ]
      # langchain-openai 0.1.22 is imcomptible with earlier langchain-core due to
      # https://github.com/langchain-ai/langchain/commit/b83f1eb0d56dbf99605a1fce93953ee09d77aabf
      "< 0.2": ["langchain-openai<=0.1.22"]
      ">= 0.2": [
          "langchain-huggingface",
          # Required for testing uc tools
          "unitycatalog-langchain",
        ]
      ">=0.3": ["databricks-langchain"]
    pre_test: |
      # Installing both pyspark and databricks-connect causes a conflict
      pip uninstall -y databricks-connect
      pip install --no-deps --force-reinstall pyspark
    run: |
      # Some dependencies above includes 'mlflow-skinny' but not full 'mlflow', such as databricks-vectorsearch.
      # This causes installation of mlflow-skinny from stable version, while 'mlflow' points to the dev version,
      # resulting in a weird module conflict issue.
      pip install './skinny'
      # Run all langchain tests except autologging and evaluation
      pytest tests/langchain --ignore tests/langchain/test_langchain_autolog.py --ignore tests/langchain/test_langchain_evaluation.py
      # test both pydantic v1 and v2
      PYDANTIC_VERSION=$(python -c "import pydantic; print(pydantic.__version__)")
      if [[ $PYDANTIC_VERSION == 1.* ]]; then
        pip install 'pydantic>=2' 'fastapi>=0.100.0'
        echo "Testing langchain model export with pydantic v2"
        pytest tests/langchain --ignore tests/langchain/test_langchain_autolog.py --ignore tests/langchain/test_langchain_evaluation.py
      fi
  autologging:
    minimum: "0.1.0"
    maximum: "0.3.25"
    requirements:
      ">= 0.0.0": [
          "pyspark",
          "openai",
          "google-search-results",
          "psutil",
          "faiss-cpu",
          "numexpr",
          "spacy",
          "langchain-core!=0.1.39", # https://github.com/langchain-ai/langchain/issues/19947
          # Required to run tests/openai/mock_openai.py
          "fastapi",
          "uvicorn",
          # Some model logging/loading requires langchain community
          "langchain-community",
        ]
      "< 0.3.0": ["langchain_openai<0.2.0"]
      ">= 0.3.0": [
          # Need to bump FasAPI version to support pydantic v2
          "fastapi>=0.100.0",
          "langchain-openai>=0.2.0",
        ]
    pre_test: |
      # Installing both pyspark and databricks-connect causes a conflict
      pip uninstall -y databricks-connect
      pip install --no-deps --force-reinstall pyspark
    run: |
      pytest tests/langchain/test_langchain_autolog.py
      # test both pydantic v1 and v2
      PYDANTIC_VERSION=$(python -c "import pydantic; print(pydantic.__version__)")
      if [[ $PYDANTIC_VERSION == 1.* ]]; then
        pip install 'pydantic>=2' 'fastapi>=0.100.0'
        echo "Testing langchain autolog with pydantic v2"
        pytest tests/langchain/test_langchain_autolog.py
      fi

      echo "Testing langchain autolog and evaluation with langchain-community"
      # Install with 'langchain' to ensure the compatible version is installed
      pip install langchain langchain-community

      # TODO: an unexpected issue happens when autolog test and evaluation test are run together, which need investigations
      pytest tests/langchain/test_langchain_autolog.py
      pytest tests/langchain/test_langchain_evaluation.py

langgraph:
  package_info:
    pip_release: "langgraph"
    install_dev: |
      pip install git+https://github.com/langchain-ai/langgraph#subdirectory=libs/langgraph

  models:
    minimum: "0.2.0"
    maximum: "0.4.3"
    requirements:
      ">= 0.0.0": [
          "langchain",
          "langchain_openai",
          # Required to run tests/openai/mock_openai.py
          "fastapi",
          "uvicorn",
        ]
      ">= 0.3.0": ["langgraph-prebuilt"]
    run: |
      pytest tests/langgraph --ignore tests/langgraph/test_langgraph_autolog.py

  autologging:
    minimum: "0.2.0"
    maximum: "0.4.3"
    requirements:
      ">= 0.0.0": [
          "langchain",
          "langchain_openai",
          # Required to run tests/openai/mock_openai.py
          "fastapi",
          "uvicorn",
        ]
      ">= 0.3.0": ["langgraph-prebuilt"]
    run: |
      pytest tests/langgraph/test_langgraph_autolog.py

llama_index:
  package_info:
    pip_release: "llama-index"
    module_name: "llama_index.core"
    install_dev: |
      pip install git+https://github.com/run-llama/llama_index.git
  models:
    # New event/span framework is fully implemented in 0.10.44
    minimum: "0.10.44"
    maximum: "0.12.36"
    requirements:
      ">= 0.0.0": [
          "openai",
          # Required to test Databricks integration
          "llama-index-llms-databricks",
          "llama-index-embeddings-databricks",
          # Required to test external vector stores
          "llama-index-vector-stores-qdrant",
          # Required to run tests/openai/mock_openai.py
          "fastapi",
          "uvicorn",
        ]
    run: pytest tests/llama_index --ignore tests/llama_index/test_llama_index_autolog.py --ignore tests/llama_index/test_llama_index_tracer.py
  autologging:
    minimum: "0.10.44"
    maximum: "0.12.36"
    requirements:
      ">= 0.0.0": [
          "openai",
          # Required to run tests/openai/mock_openai.py
          "fastapi",
          "uvicorn",
        ]
      "< 0.11.0": ["pydantic<2"]
    run: pytest tests/llama_index/test_llama_index_autolog.py tests/llama_index/test_llama_index_tracer.py

ag2:
  package_info:
    pip_release: "ag2"
    module_name: "autogen"
  autologging:
    minimum: "0.7.0"
    maximum: "0.9.0"
    python:
      "== dev": "3.10"
    requirements:
      ">= 0.0.0": [
          # Required to run tests/openai/mock_openai.py
          "fastapi",
          "uvicorn",
          "openai",
          "numpy<2",
        ]
    run: pytest tests/ag2

autogen:
  package_info:
    pip_release: "autogen-agentchat"
    module_name: "autogen_agentchat"
  autologging:
    minimum: "0.4.9"
    maximum: "0.5.7"
    python:
      "== dev": "3.10"
    requirements:
      ">= 0.0.0": [
          # Required to run tests/openai/mock_openai.py
          "fastapi",
          "uvicorn",
          "autogen_ext",
        ]
    run: pytest tests/autogen

gemini:
  package_info:
    pip_release: "google-genai"
    module_name: "google.genai"
    install_dev: |
      pip install git+https://github.com/googleapis/python-genai
  autologging:
    minimum: "1.0.0"
    maximum: "1.15.0"
    requirements:
    run: |
      # Install legacy gemini SDK to ensure the integration works for the legacy SDK 
      pip install google-generativeai
      pytest tests/gemini

anthropic:
  package_info:
    pip_release: "anthropic"
    install_dev: |
      pip install git+https://github.com/anthropics/anthropic-sdk-python
  autologging:
    minimum: "0.30.0"
    maximum: "0.51.0"
    requirements:
      "< 0.40.0": ["httpx<0.28.0"]
    run: pytest tests/anthropic
    # Our CI runs tests for every minor version of the library by default, which results in
    # many test tasks for anthropic. Reducing the number of testing only for every 5 version.
    test_every_n_versions: 5

crewai:
  package_info:
    pip_release: "crewai"
    module_name: "crewai"
    install_dev: |
      pip install git+https://github.com/crewAIInc/crewAI
  autologging:
    minimum: "0.80.0"
    maximum: "0.120.1"
    unsupported: ["==0.114.0"]
    python:
      ">= 0.80.0": "3.10"
    requirements:
    run: pytest tests/crewai

pydantic_ai:
  package_info:
    pip_release: "pydantic-ai"
    module_name: "pydantic_ai"

    install_dev: |
      # Install the stable version first to install dependencies
      pip install pydantic-ai 
      # We need to install deno to run test suite for MCPServer as deno is used to start the MCPServer
      curl -fsSL https://deno.land/install.sh | sh -s -- -y --no-modify-path
      # Update key libraries from source w/ no-deps
      pip install --no-deps \
      # We need to install pydantic_graph and pydantic_ai_slim as pydantic_ai is dependent on both of them
      # and we need to install them seperately. Without pinning them seperately would result in dependency
      # conflict errors and the installation of pydantic_ai would get failed. 
      # Ref: https://github.com/pydantic/pydantic-ai/blob/main/pydantic_ai_slim/pyproject.toml#L45-L52
        "git+https://github.com/pydantic/pydantic-ai.git#egg=pydantic-graph&subdirectory=pydantic_graph" \
        "git+https://github.com/pydantic/pydantic-ai.git#egg=pydantic-ai-slim&subdirectory=pydantic_ai_slim" \
        "git+https://github.com/pydantic/pydantic-ai.git#egg=pydantic-ai"
  autologging:
    python:
      ">= 0.1.0": "3.10"
    minimum: "0.1.9"
    maximum: "0.2.4"
    requirements:
      ">= 0.0.0": ["mcp"]
    run: pytest tests/pydantic_ai

smolagents:
  package_info:
    pip_release: "smolagents"
    module_name: "smolagents"
    install_dev: |
      pip install "git+https://github.com/huggingface/smolagents"
  autologging:
    minimum: "1.14.0"
    maximum: "1.15.0"
    python:
      ">=1.14.0": "3.10"
    requirements:
      ">= 0.0.0": ["duckduckgo-search"]
    run: pytest tests/smolagents

mistral:
  package_info:
    pip_release: "mistralai"
    module_name: "mistralai"
    install_dev: |
      TMP_DIR=$(mktemp -d)
      git clone --depth 1 https://github.com/mistralai/client-python $TMP_DIR
      cd $TMP_DIR
      python scripts/prepare_readme.py
      pip install .
      rm -rf $TMP_DIR
  autologging:
    minimum: "1.0.0"
    maximum: "1.7.0"
    requirements:
    run: pytest tests/mistral

sentence_transformers:
  package_info:
    pip_release: "sentence-transformers"
    install_dev: |
      pip install git+https://github.com/UKPLab/sentence-transformers#egg=sentence-transformers
  models:
    minimum: "2.3.1"
    maximum: "4.1.0"
    requirements:
      ">= 0.0.0": [
          "pyspark",
          "torch>1.6",
          "transformers>4.25",
          "hf_transfer",
          # Required by a test model (nomic-ai/nomic-embed-text-v1.5)
          "einops",
          # TODO: Try the latest version of moto (https://github.com/getmoto/moto/issues/8498) and remove this pin
          "boto3<1.36",
          # Fix for https://github.com/huggingface/transformers/issues/37326
          "accelerate",
        ]
    run: |
      pytest tests/sentence_transformers/test_sentence_transformers_model_export.py

johnsnowlabs:
  package_info:
    pip_release: "johnsnowlabs"
  models:
    minimum: "4.4.6"
    maximum: "6.0.0"
    requirements:
      ">= 0.0.0": ["pandas<=1.5.3"]
      "< 5.2.8": ["pyspark<3.4"]
    run: |
      if [ ! -z "$JOHNSNOWLABS_LICENSE_JSON" ]; then
        pytest tests/johnsnowlabs/test_johnsnowlabs_model_export.py
      else
        echo "Skipping tests due to missing license key"
      fi

promptflow:
  package_info:
    pip_release: "promptflow"
    # Install dev subpackages to ensure test running on the latest code
    install_dev: |
      pip install git+https://github.com/microsoft/promptflow#subdirectory=src/promptflow
  models:
    minimum: "1.3.0"
    maximum: "1.18.0"
    requirements:
      # Requirements to run sparkudf predict test
      # marshmallow 3.24.0 has breaking change causes `from marshmallow.fields import _T` error
      # inside promptflow
      ">= 0.0.0": ["pyspark", "jinja2", "marshmallow<3.24.0"]
      ">= 1.11.0": ["openai>=1"]
      "< 1.18": ["numpy<2"]
    run: |
      pytest tests/promptflow/test_promptflow_model_export.py

litellm:
  package_info:
    pip_release: "litellm"
    install_dev: |
      pip install git+https://github.com/BerriAI/litellm.git
  autologging:
    minimum: "1.52.9"
    maximum: "1.58.4"
    # TODO: Remove this once https://github.com/BerriAI/litellm/issues/9656 is fixed
    unsupported: [">=1.59"]
    requirements:
      ">= 0.0.0": [
          "openai",
          # Required to run tests/openai/mock_openai.py
          "fastapi",
          "uvicorn",
        ]
    run: pytest tests/litellm

groq:
  package_info:
    pip_release: "groq"
    install_dev: |
      pip install git+https://github.com/groq/groq-python
  autologging:
    minimum: "0.13.0"
    maximum: "0.24.0"
    requirements:
    run: pytest tests/groq

bedrock:
  package_info:
    pip_release: "boto3"
    module_name: "boto3"
  autologging:
    # BedrockRuntime client is added in boto3 1.33
    minimum: "1.33.0"
    maximum: "1.38.16"
    run: pytest tests/bedrock

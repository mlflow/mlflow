import logging
import os
import posixpath
import shutil
import tempfile
import urllib.parse
import urllib.request

from spython.utils import check_install
from spython.main import Client

from mlflow import tracking
from mlflow.projects.utils import get_databricks_env_vars, get_run_env_vars, get_local_uri_or_none
from mlflow.exceptions import ExecutionException
from mlflow.projects.utils import MLFLOW_CONTAINER_WORKDIR_PATH
from mlflow.tracking.context.git_context import _get_git_commit
from mlflow.utils import process, file_utils
from mlflow.utils.mlflow_tags import MLFLOW_SINGULARITY_IMAGE_URI, MLFLOW_SINGULARITY_IMAGE_ID


_logger = logging.getLogger(__name__)

_GENERATED_RECIPE_NAME = "Singularity.mlflow-autogenerated"
_MLFLOW_SINGULARITY_TRACKING_DIR_PATH = "/mlflow/tmp/mlruns"
_PROJECT_TAR_ARCHIVE_NAME = "mlflow-project-singularity-build-context"


def validate_singularity_installation():
    """
    Verify if Singularity is installed on host machine.
    """
    if not check_install():
        raise ExecutionException(
            "Could not find Singularity executable. "
            "Ensure Singularity is installed as per the instructions "
            "at https://sylabs.io/guides/3.3/user-guide/installation.html."
        )


def validate_singularity_env(project):
    if not project.name:
        raise ExecutionException(
            "Project name in MLProject must be specified when using singularity " "for image tagging."
        )
    if not project.singularity_env.get("image"):
        raise ExecutionException(
            "Project with singularity environment must specify the singularity image "
            "to use via an 'image' field under the 'singularity_env' field."
        )


def build_singularity_image(work_dir, repository_uri, base_image, run_id):
    """
    Build a docker image containing the project in `work_dir`, using the base image.
    """
    image_uri = _get_singularity_image_uri(repository_uri=repository_uri, work_dir=work_dir)

    # Bootstrap type varies based on base image
    bootstrap = "localimage"
    recipe_image = base_image
    if base_image.startswith('library://'):
        bootstrap = "library"
    elif base_image.startswith('shub://'):
        bootstrap = "shub"
    else:
        recipe_image = os.path.join(work_dir, base_image)
        if not os.path.exists(recipe_image):
            raise ExecutionException("Base image in project working directory not found: %s" % base_image)

    recipe = (
        "Bootstrap: {bootstrap}\nFrom: {imagename}\n%files\n. {workdir}\n%runscript\ncd {workdir}\n"
    ).format(
        bootstrap=bootstrap,
        imagename=recipe_image,
        workdir=MLFLOW_CONTAINER_WORKDIR_PATH,
    )
    build_ctx_path = _create_singularity_build_ctx(work_dir, recipe)
    final_image = os.path.join(work_dir, image_uri)

    # Build the image, or use from a previous commit
    if os.path.exists(final_image):
        _logger.info("Final image %s already exists in working directory, will not rebuild." % image_uri)
    else:
        _logger.info("Building Singularity container...")
        final_image = Client.build(build_folder=build_ctx_path, recipe=os.path.join(build_ctx_path, _GENERATED_RECIPE_NAME), image=final_image, force=True)
        try:
            os.remove(build_ctx_path)
        except Exception:  # pylint: disable=broad-except
            _logger.info("Temporary docker context file %s was not deleted.", build_ctx_path)
    tracking.MlflowClient().set_tag(run_id, MLFLOW_SINGULARITY_IMAGE_URI, image_uri)
    tracking.MlflowClient().set_tag(run_id, MLFLOW_SINGULARITY_IMAGE_ID, image_uri)
    return final_image


def _get_singularity_image_uri(repository_uri, work_dir):
    """
    Returns an appropriate Docker image URI for a project based on the git hash of the specified
    working directory.

    :param repository_uri: The URI of the Docker repository with which to tag the image. The
                           repository URI is used as the prefix of the image URI.
    :param work_dir: Path to the working directory in which to search for a git commit hash
    """
    repository_uri = repository_uri if repository_uri else "singularity-project"
    # Optionally include first 7 digits of git SHA in tag name, if available.
    git_commit = _get_git_commit(work_dir)
    version_string = ":" + git_commit[:7] if git_commit else ""
    return repository_uri + version_string + ".sif"


def _create_singularity_build_ctx(work_dir, recipe_contents):
    """
    Creates build context containing Singularity recipe and project code, returning path to folder
    """
    directory = tempfile.mkdtemp()
    try:
        dst_path = os.path.join(directory, "mlflow-project-contents")
        shutil.copytree(src=work_dir, dst=dst_path)
        with open(os.path.join(dst_path, _GENERATED_RECIPE_NAME), "w") as handle:
            handle.write(recipe_contents)
    except Exception as exc:
        raise ExecutionException(
            "Issue creating Singularity build context at %s" % dst_path
        )
    return dst_path


def get_singularity_tracking_cmd_and_envs(tracking_uri):
    cmds = []
    env_vars = dict()

    local_path, container_tracking_uri = get_local_uri_or_none(tracking_uri)
    if local_path is not None:
        cmds = ["--bind", "%s:%s" % (local_path, _MLFLOW_SINGULARITY_TRACKING_DIR_PATH)]
        env_vars[tracking._TRACKING_URI_ENV_VAR] = container_tracking_uri
    env_vars.update(get_databricks_env_vars(tracking_uri))
    return cmds, env_vars


def get_singularity_command(image, active_run, singularity_args=None, volumes=None, user_env_vars=None):

    cmd = Client._init_command("run", singularity_args)
    if volumes:
        cmd += Client._generate_bind_list(volumes)

    # TODO: include singularity options too?

    env_vars = get_run_env_vars(
        run_id=active_run.info.run_id, experiment_id=active_run.info.experiment_id
    )
    tracking_uri = tracking.get_tracking_uri()
    tracking_cmds, tracking_envs = get_singularity_tracking_cmd_and_envs(tracking_uri)
    artifact_cmds, artifact_envs = _get_singularity_artifact_storage_cmd_and_envs(
        active_run.info.artifact_uri
    )

    cmd += tracking_cmds + artifact_cmds
    env_vars.update(tracking_envs)
    env_vars.update(artifact_envs)

    # This could also be consolidated between two container technologies
    if user_env_vars is not None:
        for user_entry in user_env_vars:
            if isinstance(user_entry, list):
                # User has defined a new environment variable for the docker environment
                env_vars[user_entry[0]] = user_entry[1]
            else:
                # User wants to copy an environment variable from system environment
                system_var = os.environ.get(user_entry)
                if system_var is None:
                    raise MlflowException(
                        "This project expects the %s environment variables to "
                        "be set on the machine running the project, but %s was "
                        "not set. Please ensure all expected environment variables "
                        "are set" % (", ".join(user_env_vars), user_entry)
                    )
                env_vars[user_entry] = system_var

    for key, value in env_vars.items():
        cmd += ["--env", "{key}={value}".format(key=key, value=value)]
    cmd += [image]
    return cmd

def _get_singularity_artifact_storage_cmd_and_envs(artifact_uri):
    return [], {}

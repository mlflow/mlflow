// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: mlflow/protos/databricks.proto

package com.databricks.api.proto.databricks;

public final class Databricks {
  private Databricks() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
    registry.add(com.databricks.api.proto.databricks.Databricks.visibility);
    registry.add(com.databricks.api.proto.databricks.Databricks.validateRequired);
    registry.add(com.databricks.api.proto.databricks.Databricks.jsonInline);
    registry.add(com.databricks.api.proto.databricks.Databricks.jsonMap);
    registry.add(com.databricks.api.proto.databricks.Databricks.fieldDoc);
    registry.add(com.databricks.api.proto.databricks.Databricks.rpc);
    registry.add(com.databricks.api.proto.databricks.Databricks.methodDoc);
    registry.add(com.databricks.api.proto.databricks.Databricks.graphql);
    registry.add(com.databricks.api.proto.databricks.Databricks.messageDoc);
    registry.add(com.databricks.api.proto.databricks.Databricks.serviceDoc);
    registry.add(com.databricks.api.proto.databricks.Databricks.enumDoc);
    registry.add(com.databricks.api.proto.databricks.Databricks.enumValueVisibility);
    registry.add(com.databricks.api.proto.databricks.Databricks.enumValueDoc);
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  /**
   * <pre>
   * Visibility defines who is allowed to use the RPC.
   * </pre>
   *
   * Protobuf enum {@code mlflow.Visibility}
   */
  public enum Visibility
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <pre>
     * Public indicates visible to both external and internal customers.
     * </pre>
     *
     * <code>PUBLIC = 1;</code>
     */
    PUBLIC(1),
    /**
     * <pre>
     * Internal is only available to Databricks-internal clients.
     * </pre>
     *
     * <code>INTERNAL = 2;</code>
     */
    INTERNAL(2),
    /**
     * <pre>
     * Public-undocumented are accessible via public endpoints, but not documented. This is useful
     * for internal clients that depend on public endpoints (e.g. workflows running in the driver).
     * </pre>
     *
     * <code>PUBLIC_UNDOCUMENTED = 3;</code>
     */
    PUBLIC_UNDOCUMENTED(3),
    ;

    /**
     * <pre>
     * Public indicates visible to both external and internal customers.
     * </pre>
     *
     * <code>PUBLIC = 1;</code>
     */
    public static final int PUBLIC_VALUE = 1;
    /**
     * <pre>
     * Internal is only available to Databricks-internal clients.
     * </pre>
     *
     * <code>INTERNAL = 2;</code>
     */
    public static final int INTERNAL_VALUE = 2;
    /**
     * <pre>
     * Public-undocumented are accessible via public endpoints, but not documented. This is useful
     * for internal clients that depend on public endpoints (e.g. workflows running in the driver).
     * </pre>
     *
     * <code>PUBLIC_UNDOCUMENTED = 3;</code>
     */
    public static final int PUBLIC_UNDOCUMENTED_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static Visibility valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static Visibility forNumber(int value) {
      switch (value) {
        case 1: return PUBLIC;
        case 2: return INTERNAL;
        case 3: return PUBLIC_UNDOCUMENTED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<Visibility>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        Visibility> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<Visibility>() {
            public Visibility findValueByNumber(int number) {
              return Visibility.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.getDescriptor().getEnumTypes().get(0);
    }

    private static final Visibility[] VALUES = values();

    public static Visibility valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private Visibility(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:mlflow.Visibility)
  }

  /**
   * Protobuf enum {@code mlflow.ErrorCode}
   */
  public enum ErrorCode
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <pre>
     * Internal error. This means that some invariants expected by the underlying system have been
     * broken. This error code is reserved for serious errors, which generally cannot be resolved
     * by the user.
     * Prefer this over all kinds of detailed error messages (e.g IO_ERROR), unless there's some
     * automation that relies on the custom error code.
     * Maps to:
     * - google.rpc.Code: INTERNAL = 13;
     * - HTTP code: 500 Internal Server Error
     * </pre>
     *
     * <code>INTERNAL_ERROR = 1;</code>
     */
    INTERNAL_ERROR(1),
    /**
     * <pre>
     * The service is currently unavailable. This is most likely a transient condition, which can be
     * corrected by retrying with a backoff. Note that it is not always safe to retrynon-idempotent
     * operations.
     * Prefer this over SERVICE_UNDER_MAINTENANCE, WORKSPACE_TEMPORARILY_UNAVAILABLE.
     * Maps to:
     * - google.rpc.Code: UNAVAILABLE = 14;
     * - HTTP code: 503 Service Unavailable
     * </pre>
     *
     * <code>TEMPORARILY_UNAVAILABLE = 2;</code>
     */
    TEMPORARILY_UNAVAILABLE(2),
    /**
     * <pre>
     * Indicates that an IOException has been internally thrown.
     * </pre>
     *
     * <code>IO_ERROR = 3;</code>
     */
    IO_ERROR(3),
    /**
     * <pre>
     * The request is invalid. Prefer more specific error code whenever possible.
     * Also see similar recommendation for the google.rpc.Code.FAILED_PRECONDITION.
     * Prefer this error code over MALFORMED_REQUEST, INVALID_STATE, UNPARSEABLE_HTTP_ERROR.
     * Maps to:
     * - google.rpc.Code: FAILED_PRECONDITION = 9;
     * - HTTP code: 400 Bad Request
     * </pre>
     *
     * <code>BAD_REQUEST = 4;</code>
     */
    BAD_REQUEST(4),
    /**
     * <pre>
     * An external service is unavailable temporarily as it is being updated/re-deployed. Indicates
     * gateway proxy to safely retry the request.
     * </pre>
     *
     * <code>SERVICE_UNDER_MAINTENANCE = 5;</code>
     */
    SERVICE_UNDER_MAINTENANCE(5),
    /**
     * <pre>
     * A workspace is temporarily unavailable as the workspace is being re-assigned.
     * </pre>
     *
     * <code>WORKSPACE_TEMPORARILY_UNAVAILABLE = 6;</code>
     */
    WORKSPACE_TEMPORARILY_UNAVAILABLE(6),
    /**
     * <pre>
     * The deadline expired before the operation could complete. For operations that change the state
     * of the system, this error may be returned even if the operation has completed successfully.
     * For example, a successful response from a server could have been delayed long enough for
     * the deadline to expire. When possible - implementations should make sure further processing of
     * the request is aborted, e.g. by throwing an exception instead of making the RPC request,
     * making the database query, etc.
     * Maps to:
     * - google.rpc.Code: DEADLINE_EXCEEDED = 4;
     * - HTTP code: 504 Gateway Timeout
     * </pre>
     *
     * <code>DEADLINE_EXCEEDED = 7;</code>
     */
    DEADLINE_EXCEEDED(7),
    /**
     * <pre>
     * The operation was canceled by the caller. An example - client closed the connection without
     * waiting for a response.
     * Maps to:
     * - google.rpc.Code: CANCELLED = 1;
     * - HTTP code: 499 Client Closed Request
     * </pre>
     *
     * <code>CANCELLED = 8;</code>
     */
    CANCELLED(8),
    /**
     * <pre>
     * Operation is rejected due to throttling, e.g. some resource has been exhausted, per-user quota
     * triggered, or the entire file system is out of space.
     * Maps to:
     * - google.rpc.Code: RESOURCE_EXHAUSTED = 8;
     * - HTTP code: 429 Too Many Requests
     * </pre>
     *
     * <code>RESOURCE_EXHAUSTED = 9;</code>
     */
    RESOURCE_EXHAUSTED(9),
    /**
     * <pre>
     * The operation was aborted, typically due to a concurrency issue such as a sequencer
     * check failure, transaction abort, or transaction conflict.
     * Maps to:
     * - google.rpc.Code: ABORTED = 10;
     * - HTTP code: 409 Conflict
     * </pre>
     *
     * <code>ABORTED = 10;</code>
     */
    ABORTED(10),
    /**
     * <pre>
     * Operation was performed on a resource that does not exist,
     * e.g. file or directory was not found.
     * Maps to:
     * - google.rpc.Code: NOT_FOUND = 5;
     * - HTTP code: 404 Not Found
     * </pre>
     *
     * <code>NOT_FOUND = 11;</code>
     */
    NOT_FOUND(11),
    /**
     * <pre>
     * Operation was rejected due a conflict with an existing resource, e.g. attempted to create
     * file or directory that already exists.
     * Prefer this over RESOURCE_CONFLICT.
     * Maps to:
     * - google.rpc.Code: ALREADY_EXISTS = 6;
     * - HTTP code: 409 Conflict
     * </pre>
     *
     * <code>ALREADY_EXISTS = 12;</code>
     */
    ALREADY_EXISTS(12),
    /**
     * <pre>
     * The request does not have valid authentication (AuthN) credentials for the operation.
     * Prefer this over CUSTOMER_UNAUTHORIZED, unless you need to keep consistent behavior with legacy
     * code.
     * For authorization (AuthZ) errors use PERMISSION_DENIED.
     * Maps to:
     * - google.rpc.Code: UNAUTHENTICATED = 16;
     * - HTTP code: 401 Unauthorized
     * </pre>
     *
     * <code>UNAUTHENTICATED = 13;</code>
     */
    UNAUTHENTICATED(13),
    /**
     * <pre>
     * Supplied value for a parameter was invalid (e.g., giving a number for a string parameter).
     * Maps to:
     * - google.rpc.Code: INVALID_ARGUMENT = 3;
     * - HTTP code: 400 Bad Request
     * </pre>
     *
     * <code>INVALID_PARAMETER_VALUE = 1000;</code>
     */
    INVALID_PARAMETER_VALUE(1000),
    /**
     * <pre>
     * Indicates that the given API endpoint does not exist. Legacy, when possible - NOT_IMPLEMENTED
     * should be used instead to indicate that API doesn't exist.
     * Maps to:
     * - google.rpc.Code: NOT_FOUND = 5;
     * - HTTP code: 404 Not Found
     * </pre>
     *
     * <code>ENDPOINT_NOT_FOUND = 1001;</code>
     */
    ENDPOINT_NOT_FOUND(1001),
    /**
     * <pre>
     * Indicates that the given API request was malformed.
     * </pre>
     *
     * <code>MALFORMED_REQUEST = 1002;</code>
     */
    MALFORMED_REQUEST(1002),
    /**
     * <pre>
     * If one or more of the inputs to a given RPC are not in a valid state for the action.
     * </pre>
     *
     * <code>INVALID_STATE = 1003;</code>
     */
    INVALID_STATE(1003),
    /**
     * <pre>
     * The caller does not have permission to execute the specified operation.
     * PERMISSION_DENIED must not be used for rejections caused by exhausting some resource,
     * use RESOURCE_EXHAUSTED instead for those errors.
     * PERMISSION_DENIED must not be used if the caller can not be identified,
     * use CUSTOMER_UNAUTHORIZED instead for those errors.
     * This error code does not imply the request is valid or the requested entity exists or
     * satisfies other pre-conditions.
     * Maps to:
     * - google.rpc.Code: PERMISSION_DENIED = 7;
     * - HTTP code: 403 Forbidden
     * </pre>
     *
     * <code>PERMISSION_DENIED = 1004;</code>
     */
    PERMISSION_DENIED(1004),
    /**
     * <pre>
     * If a given user/entity is trying to use a feature which has been disabled.
     * Maps to:
     * - google.rpc.Code: NOT_FOUND = 5;
     * - HTTP code: 404 Not Found
     * </pre>
     *
     * <code>FEATURE_DISABLED = 1005;</code>
     */
    FEATURE_DISABLED(1005),
    /**
     * <pre>
     * The request does not have valid authentication (AuthN) credentials for the operation.
     * For authentication (AuthN) errors prefer using UNAUTHENTICATED, unless you need to keep
     * consistent behavior with legacy code.
     * For authorization (AuthZ) errors use PERMISSION_DENIED.
     * Important: name is confusing, this error code is for authentication (AuthN) errors, not
     * authorization (AuthZ) errors. It maps to 401 Unauthorized and suffers from the same confusing
     * naming. See https://datatracker.ietf.org/doc/html/rfc7235#section-3.1 - "[...] status code
     * indicates that the request has not been applied because it lacks valid authentication
     * credentials for the target resource. [...] If the request included authentication credentials,
     * then the 401 response indicates that authorization has been refused for those credentials."
     * Also, see https://stackoverflow.com/a/6937030/16352922, it covers it pretty well.
     * Maps to:
     * - google.rpc.Code: UNAUTHENTICATED = 16;
     * - HTTP code: 401 Unauthorized
     * </pre>
     *
     * <code>CUSTOMER_UNAUTHORIZED = 1006;</code>
     */
    CUSTOMER_UNAUTHORIZED(1006),
    /**
     * <pre>
     * If the API request is rejected due to throttling.
     * Prefer a more generic RESOURCE_EXHAUSTED for the new use cases.
     * Maps to:
     * - google.rpc.Code: RESOURCE_EXHAUSTED = 8;
     * - HTTP code: 429 Too Many Requests
     * </pre>
     *
     * <code>REQUEST_LIMIT_EXCEEDED = 1007;</code>
     */
    REQUEST_LIMIT_EXCEEDED(1007),
    /**
     * <pre>
     * Indicates API request was rejected due a conflict with an existing resource.
     * </pre>
     *
     * <code>RESOURCE_CONFLICT = 1008;</code>
     */
    RESOURCE_CONFLICT(1008),
    /**
     * <pre>
     * Indicates that the HTTP response cannot be correctly deserialized.
     * This currently is only used in DUST test clients, and not by any real service code.
     * </pre>
     *
     * <code>UNPARSEABLE_HTTP_ERROR = 1009;</code>
     */
    UNPARSEABLE_HTTP_ERROR(1009),
    /**
     * <pre>
     * The operation is not implemented or is not supported/enabled in this service.
     * Maps to:
     * - google.rpc.Code: UNIMPLEMENTED = 12;
     * - HTTP code: 501 Not Implemented
     * </pre>
     *
     * <code>NOT_IMPLEMENTED = 1010;</code>
     */
    NOT_IMPLEMENTED(1010),
    /**
     * <pre>
     * Unrecoverable data loss or corruption.
     * One of the major use cases is to indicate that server failed to validate the integrity of
     * the request. This error can occur when the checksum specified in the `X-Databricks-Checksum`
     * request header (or trailer) doesn't match the actual request content checksum.
     * Note, in case of the severe corruption that results in a malformed request, the server may
     * send a generic `400 Bad Request` response rather than sending this error code.
     * Maps to:
     * - google.rpc.Code: DATA_LOSS = 15;
     * - HTTP code: 500 Internal Server Error
     * </pre>
     *
     * <code>DATA_LOSS = 1011;</code>
     */
    DATA_LOSS(1011),
    /**
     * <pre>
     * If the user attempts to perform an invalid state transition on a shard.
     * </pre>
     *
     * <code>INVALID_STATE_TRANSITION = 2001;</code>
     */
    INVALID_STATE_TRANSITION(2001),
    /**
     * <pre>
     * Unable to perform the operation because the shard was locked by some other operation.
     * </pre>
     *
     * <code>COULD_NOT_ACQUIRE_LOCK = 2002;</code>
     */
    COULD_NOT_ACQUIRE_LOCK(2002),
    /**
     * <pre>
     * Operation was performed on a resource that already exists.
     * Prefer using ALREADY_EXISTS. Unlike ALREADY_EXISTS - this maps to HTTP code
     * 500 Internal Server Error due to legacy reasons, remapping will be a backwards incompatible
     * change.
     * </pre>
     *
     * <code>RESOURCE_ALREADY_EXISTS = 3001;</code>
     */
    RESOURCE_ALREADY_EXISTS(3001),
    /**
     * <pre>
     * Operation was performed on a resource that does not exist.
     * Prefer using NOT_FOUND - see the note for the RESOURCE_ALREADY_EXISTS, because this pair of
     * codes is related and RESOURCE_ALREADY_EXISTS has bad mapping to the HTTP codes we added
     * new error codes NOT_FOUND and ALREADY_EXISTS, and recommend to use them instead.
     * </pre>
     *
     * <code>RESOURCE_DOES_NOT_EXIST = 3002;</code>
     */
    RESOURCE_DOES_NOT_EXIST(3002),
    /**
     * <code>QUOTA_EXCEEDED = 4001;</code>
     */
    QUOTA_EXCEEDED(4001),
    /**
     * <code>MAX_BLOCK_SIZE_EXCEEDED = 4002;</code>
     */
    MAX_BLOCK_SIZE_EXCEEDED(4002),
    /**
     * <code>MAX_READ_SIZE_EXCEEDED = 4003;</code>
     */
    MAX_READ_SIZE_EXCEEDED(4003),
    /**
     * <code>PARTIAL_DELETE = 4004;</code>
     */
    PARTIAL_DELETE(4004),
    /**
     * <code>MAX_LIST_SIZE_EXCEEDED = 4005;</code>
     */
    MAX_LIST_SIZE_EXCEEDED(4005),
    /**
     * <code>DRY_RUN_FAILED = 5001;</code>
     */
    DRY_RUN_FAILED(5001),
    /**
     * <pre>
     * Cluster request was rejected because it would exceed a resource limit.
     * </pre>
     *
     * <code>RESOURCE_LIMIT_EXCEEDED = 5002;</code>
     */
    RESOURCE_LIMIT_EXCEEDED(5002),
    /**
     * <code>DIRECTORY_NOT_EMPTY = 6001;</code>
     */
    DIRECTORY_NOT_EMPTY(6001),
    /**
     * <code>DIRECTORY_PROTECTED = 6002;</code>
     */
    DIRECTORY_PROTECTED(6002),
    /**
     * <code>MAX_NOTEBOOK_SIZE_EXCEEDED = 6003;</code>
     */
    MAX_NOTEBOOK_SIZE_EXCEEDED(6003),
    /**
     * <code>MAX_CHILD_NODE_SIZE_EXCEEDED = 6004;</code>
     */
    MAX_CHILD_NODE_SIZE_EXCEEDED(6004),
    /**
     * <code>SEARCH_QUERY_TOO_LONG = 6100;</code>
     */
    SEARCH_QUERY_TOO_LONG(6100),
    /**
     * <code>SEARCH_QUERY_TOO_SHORT = 6101;</code>
     */
    SEARCH_QUERY_TOO_SHORT(6101),
    /**
     * <code>MANAGED_RESOURCE_GROUP_DOES_NOT_EXIST = 7001;</code>
     */
    MANAGED_RESOURCE_GROUP_DOES_NOT_EXIST(7001),
    /**
     * <code>PERMISSION_NOT_PROPAGATED = 7002;</code>
     */
    PERMISSION_NOT_PROPAGATED(7002),
    /**
     * <code>DEPLOYMENT_TIMEOUT = 7003;</code>
     */
    DEPLOYMENT_TIMEOUT(7003),
    /**
     * <code>GIT_CONFLICT = 8001;</code>
     */
    GIT_CONFLICT(8001),
    /**
     * <code>GIT_UNKNOWN_REF = 8002;</code>
     */
    GIT_UNKNOWN_REF(8002),
    /**
     * <code>GIT_SENSITIVE_TOKEN_DETECTED = 8003;</code>
     */
    GIT_SENSITIVE_TOKEN_DETECTED(8003),
    /**
     * <code>GIT_URL_NOT_ON_ALLOW_LIST = 8004;</code>
     */
    GIT_URL_NOT_ON_ALLOW_LIST(8004),
    /**
     * <code>GIT_REMOTE_ERROR = 8005;</code>
     */
    GIT_REMOTE_ERROR(8005),
    /**
     * <code>PROJECTS_OPERATION_TIMEOUT = 8006;</code>
     */
    PROJECTS_OPERATION_TIMEOUT(8006),
    /**
     * <code>IPYNB_FILE_IN_REPO = 8007;</code>
     */
    IPYNB_FILE_IN_REPO(8007),
    /**
     * <code>INSECURE_PARTNER_RESPONSE = 8100;</code>
     */
    INSECURE_PARTNER_RESPONSE(8100),
    /**
     * <code>MALFORMED_PARTNER_RESPONSE = 8101;</code>
     */
    MALFORMED_PARTNER_RESPONSE(8101),
    /**
     * <code>METASTORE_DOES_NOT_EXIST = 9000;</code>
     */
    METASTORE_DOES_NOT_EXIST(9000),
    /**
     * <code>DAC_DOES_NOT_EXIST = 9001;</code>
     */
    DAC_DOES_NOT_EXIST(9001),
    /**
     * <code>CATALOG_DOES_NOT_EXIST = 9002;</code>
     */
    CATALOG_DOES_NOT_EXIST(9002),
    /**
     * <code>SCHEMA_DOES_NOT_EXIST = 9003;</code>
     */
    SCHEMA_DOES_NOT_EXIST(9003),
    /**
     * <code>TABLE_DOES_NOT_EXIST = 9004;</code>
     */
    TABLE_DOES_NOT_EXIST(9004),
    /**
     * <code>SHARE_DOES_NOT_EXIST = 9005;</code>
     */
    SHARE_DOES_NOT_EXIST(9005),
    /**
     * <code>RECIPIENT_DOES_NOT_EXIST = 9006;</code>
     */
    RECIPIENT_DOES_NOT_EXIST(9006),
    /**
     * <code>STORAGE_CREDENTIAL_DOES_NOT_EXIST = 9007;</code>
     */
    STORAGE_CREDENTIAL_DOES_NOT_EXIST(9007),
    /**
     * <code>EXTERNAL_LOCATION_DOES_NOT_EXIST = 9008;</code>
     */
    EXTERNAL_LOCATION_DOES_NOT_EXIST(9008),
    /**
     * <code>PRINCIPAL_DOES_NOT_EXIST = 9009;</code>
     */
    PRINCIPAL_DOES_NOT_EXIST(9009),
    /**
     * <code>PROVIDER_DOES_NOT_EXIST = 9010;</code>
     */
    PROVIDER_DOES_NOT_EXIST(9010),
    /**
     * <code>METASTORE_ALREADY_EXISTS = 9020;</code>
     */
    METASTORE_ALREADY_EXISTS(9020),
    /**
     * <code>DAC_ALREADY_EXISTS = 9021;</code>
     */
    DAC_ALREADY_EXISTS(9021),
    /**
     * <code>CATALOG_ALREADY_EXISTS = 9022;</code>
     */
    CATALOG_ALREADY_EXISTS(9022),
    /**
     * <code>SCHEMA_ALREADY_EXISTS = 9023;</code>
     */
    SCHEMA_ALREADY_EXISTS(9023),
    /**
     * <code>TABLE_ALREADY_EXISTS = 9024;</code>
     */
    TABLE_ALREADY_EXISTS(9024),
    /**
     * <code>SHARE_ALREADY_EXISTS = 9025;</code>
     */
    SHARE_ALREADY_EXISTS(9025),
    /**
     * <code>RECIPIENT_ALREADY_EXISTS = 9026;</code>
     */
    RECIPIENT_ALREADY_EXISTS(9026),
    /**
     * <code>STORAGE_CREDENTIAL_ALREADY_EXISTS = 9027;</code>
     */
    STORAGE_CREDENTIAL_ALREADY_EXISTS(9027),
    /**
     * <code>EXTERNAL_LOCATION_ALREADY_EXISTS = 9028;</code>
     */
    EXTERNAL_LOCATION_ALREADY_EXISTS(9028),
    /**
     * <code>PROVIDER_ALREADY_EXISTS = 9029;</code>
     */
    PROVIDER_ALREADY_EXISTS(9029),
    /**
     * <code>CATALOG_NOT_EMPTY = 9040;</code>
     */
    CATALOG_NOT_EMPTY(9040),
    /**
     * <code>SCHEMA_NOT_EMPTY = 9041;</code>
     */
    SCHEMA_NOT_EMPTY(9041),
    /**
     * <code>METASTORE_NOT_EMPTY = 9042;</code>
     */
    METASTORE_NOT_EMPTY(9042),
    /**
     * <code>PROVIDER_SHARE_NOT_ACCESSIBLE = 9060;</code>
     */
    PROVIDER_SHARE_NOT_ACCESSIBLE(9060),
    ;

    /**
     * <pre>
     * Internal error. This means that some invariants expected by the underlying system have been
     * broken. This error code is reserved for serious errors, which generally cannot be resolved
     * by the user.
     * Prefer this over all kinds of detailed error messages (e.g IO_ERROR), unless there's some
     * automation that relies on the custom error code.
     * Maps to:
     * - google.rpc.Code: INTERNAL = 13;
     * - HTTP code: 500 Internal Server Error
     * </pre>
     *
     * <code>INTERNAL_ERROR = 1;</code>
     */
    public static final int INTERNAL_ERROR_VALUE = 1;
    /**
     * <pre>
     * The service is currently unavailable. This is most likely a transient condition, which can be
     * corrected by retrying with a backoff. Note that it is not always safe to retrynon-idempotent
     * operations.
     * Prefer this over SERVICE_UNDER_MAINTENANCE, WORKSPACE_TEMPORARILY_UNAVAILABLE.
     * Maps to:
     * - google.rpc.Code: UNAVAILABLE = 14;
     * - HTTP code: 503 Service Unavailable
     * </pre>
     *
     * <code>TEMPORARILY_UNAVAILABLE = 2;</code>
     */
    public static final int TEMPORARILY_UNAVAILABLE_VALUE = 2;
    /**
     * <pre>
     * Indicates that an IOException has been internally thrown.
     * </pre>
     *
     * <code>IO_ERROR = 3;</code>
     */
    public static final int IO_ERROR_VALUE = 3;
    /**
     * <pre>
     * The request is invalid. Prefer more specific error code whenever possible.
     * Also see similar recommendation for the google.rpc.Code.FAILED_PRECONDITION.
     * Prefer this error code over MALFORMED_REQUEST, INVALID_STATE, UNPARSEABLE_HTTP_ERROR.
     * Maps to:
     * - google.rpc.Code: FAILED_PRECONDITION = 9;
     * - HTTP code: 400 Bad Request
     * </pre>
     *
     * <code>BAD_REQUEST = 4;</code>
     */
    public static final int BAD_REQUEST_VALUE = 4;
    /**
     * <pre>
     * An external service is unavailable temporarily as it is being updated/re-deployed. Indicates
     * gateway proxy to safely retry the request.
     * </pre>
     *
     * <code>SERVICE_UNDER_MAINTENANCE = 5;</code>
     */
    public static final int SERVICE_UNDER_MAINTENANCE_VALUE = 5;
    /**
     * <pre>
     * A workspace is temporarily unavailable as the workspace is being re-assigned.
     * </pre>
     *
     * <code>WORKSPACE_TEMPORARILY_UNAVAILABLE = 6;</code>
     */
    public static final int WORKSPACE_TEMPORARILY_UNAVAILABLE_VALUE = 6;
    /**
     * <pre>
     * The deadline expired before the operation could complete. For operations that change the state
     * of the system, this error may be returned even if the operation has completed successfully.
     * For example, a successful response from a server could have been delayed long enough for
     * the deadline to expire. When possible - implementations should make sure further processing of
     * the request is aborted, e.g. by throwing an exception instead of making the RPC request,
     * making the database query, etc.
     * Maps to:
     * - google.rpc.Code: DEADLINE_EXCEEDED = 4;
     * - HTTP code: 504 Gateway Timeout
     * </pre>
     *
     * <code>DEADLINE_EXCEEDED = 7;</code>
     */
    public static final int DEADLINE_EXCEEDED_VALUE = 7;
    /**
     * <pre>
     * The operation was canceled by the caller. An example - client closed the connection without
     * waiting for a response.
     * Maps to:
     * - google.rpc.Code: CANCELLED = 1;
     * - HTTP code: 499 Client Closed Request
     * </pre>
     *
     * <code>CANCELLED = 8;</code>
     */
    public static final int CANCELLED_VALUE = 8;
    /**
     * <pre>
     * Operation is rejected due to throttling, e.g. some resource has been exhausted, per-user quota
     * triggered, or the entire file system is out of space.
     * Maps to:
     * - google.rpc.Code: RESOURCE_EXHAUSTED = 8;
     * - HTTP code: 429 Too Many Requests
     * </pre>
     *
     * <code>RESOURCE_EXHAUSTED = 9;</code>
     */
    public static final int RESOURCE_EXHAUSTED_VALUE = 9;
    /**
     * <pre>
     * The operation was aborted, typically due to a concurrency issue such as a sequencer
     * check failure, transaction abort, or transaction conflict.
     * Maps to:
     * - google.rpc.Code: ABORTED = 10;
     * - HTTP code: 409 Conflict
     * </pre>
     *
     * <code>ABORTED = 10;</code>
     */
    public static final int ABORTED_VALUE = 10;
    /**
     * <pre>
     * Operation was performed on a resource that does not exist,
     * e.g. file or directory was not found.
     * Maps to:
     * - google.rpc.Code: NOT_FOUND = 5;
     * - HTTP code: 404 Not Found
     * </pre>
     *
     * <code>NOT_FOUND = 11;</code>
     */
    public static final int NOT_FOUND_VALUE = 11;
    /**
     * <pre>
     * Operation was rejected due a conflict with an existing resource, e.g. attempted to create
     * file or directory that already exists.
     * Prefer this over RESOURCE_CONFLICT.
     * Maps to:
     * - google.rpc.Code: ALREADY_EXISTS = 6;
     * - HTTP code: 409 Conflict
     * </pre>
     *
     * <code>ALREADY_EXISTS = 12;</code>
     */
    public static final int ALREADY_EXISTS_VALUE = 12;
    /**
     * <pre>
     * The request does not have valid authentication (AuthN) credentials for the operation.
     * Prefer this over CUSTOMER_UNAUTHORIZED, unless you need to keep consistent behavior with legacy
     * code.
     * For authorization (AuthZ) errors use PERMISSION_DENIED.
     * Maps to:
     * - google.rpc.Code: UNAUTHENTICATED = 16;
     * - HTTP code: 401 Unauthorized
     * </pre>
     *
     * <code>UNAUTHENTICATED = 13;</code>
     */
    public static final int UNAUTHENTICATED_VALUE = 13;
    /**
     * <pre>
     * Supplied value for a parameter was invalid (e.g., giving a number for a string parameter).
     * Maps to:
     * - google.rpc.Code: INVALID_ARGUMENT = 3;
     * - HTTP code: 400 Bad Request
     * </pre>
     *
     * <code>INVALID_PARAMETER_VALUE = 1000;</code>
     */
    public static final int INVALID_PARAMETER_VALUE_VALUE = 1000;
    /**
     * <pre>
     * Indicates that the given API endpoint does not exist. Legacy, when possible - NOT_IMPLEMENTED
     * should be used instead to indicate that API doesn't exist.
     * Maps to:
     * - google.rpc.Code: NOT_FOUND = 5;
     * - HTTP code: 404 Not Found
     * </pre>
     *
     * <code>ENDPOINT_NOT_FOUND = 1001;</code>
     */
    public static final int ENDPOINT_NOT_FOUND_VALUE = 1001;
    /**
     * <pre>
     * Indicates that the given API request was malformed.
     * </pre>
     *
     * <code>MALFORMED_REQUEST = 1002;</code>
     */
    public static final int MALFORMED_REQUEST_VALUE = 1002;
    /**
     * <pre>
     * If one or more of the inputs to a given RPC are not in a valid state for the action.
     * </pre>
     *
     * <code>INVALID_STATE = 1003;</code>
     */
    public static final int INVALID_STATE_VALUE = 1003;
    /**
     * <pre>
     * The caller does not have permission to execute the specified operation.
     * PERMISSION_DENIED must not be used for rejections caused by exhausting some resource,
     * use RESOURCE_EXHAUSTED instead for those errors.
     * PERMISSION_DENIED must not be used if the caller can not be identified,
     * use CUSTOMER_UNAUTHORIZED instead for those errors.
     * This error code does not imply the request is valid or the requested entity exists or
     * satisfies other pre-conditions.
     * Maps to:
     * - google.rpc.Code: PERMISSION_DENIED = 7;
     * - HTTP code: 403 Forbidden
     * </pre>
     *
     * <code>PERMISSION_DENIED = 1004;</code>
     */
    public static final int PERMISSION_DENIED_VALUE = 1004;
    /**
     * <pre>
     * If a given user/entity is trying to use a feature which has been disabled.
     * Maps to:
     * - google.rpc.Code: NOT_FOUND = 5;
     * - HTTP code: 404 Not Found
     * </pre>
     *
     * <code>FEATURE_DISABLED = 1005;</code>
     */
    public static final int FEATURE_DISABLED_VALUE = 1005;
    /**
     * <pre>
     * The request does not have valid authentication (AuthN) credentials for the operation.
     * For authentication (AuthN) errors prefer using UNAUTHENTICATED, unless you need to keep
     * consistent behavior with legacy code.
     * For authorization (AuthZ) errors use PERMISSION_DENIED.
     * Important: name is confusing, this error code is for authentication (AuthN) errors, not
     * authorization (AuthZ) errors. It maps to 401 Unauthorized and suffers from the same confusing
     * naming. See https://datatracker.ietf.org/doc/html/rfc7235#section-3.1 - "[...] status code
     * indicates that the request has not been applied because it lacks valid authentication
     * credentials for the target resource. [...] If the request included authentication credentials,
     * then the 401 response indicates that authorization has been refused for those credentials."
     * Also, see https://stackoverflow.com/a/6937030/16352922, it covers it pretty well.
     * Maps to:
     * - google.rpc.Code: UNAUTHENTICATED = 16;
     * - HTTP code: 401 Unauthorized
     * </pre>
     *
     * <code>CUSTOMER_UNAUTHORIZED = 1006;</code>
     */
    public static final int CUSTOMER_UNAUTHORIZED_VALUE = 1006;
    /**
     * <pre>
     * If the API request is rejected due to throttling.
     * Prefer a more generic RESOURCE_EXHAUSTED for the new use cases.
     * Maps to:
     * - google.rpc.Code: RESOURCE_EXHAUSTED = 8;
     * - HTTP code: 429 Too Many Requests
     * </pre>
     *
     * <code>REQUEST_LIMIT_EXCEEDED = 1007;</code>
     */
    public static final int REQUEST_LIMIT_EXCEEDED_VALUE = 1007;
    /**
     * <pre>
     * Indicates API request was rejected due a conflict with an existing resource.
     * </pre>
     *
     * <code>RESOURCE_CONFLICT = 1008;</code>
     */
    public static final int RESOURCE_CONFLICT_VALUE = 1008;
    /**
     * <pre>
     * Indicates that the HTTP response cannot be correctly deserialized.
     * This currently is only used in DUST test clients, and not by any real service code.
     * </pre>
     *
     * <code>UNPARSEABLE_HTTP_ERROR = 1009;</code>
     */
    public static final int UNPARSEABLE_HTTP_ERROR_VALUE = 1009;
    /**
     * <pre>
     * The operation is not implemented or is not supported/enabled in this service.
     * Maps to:
     * - google.rpc.Code: UNIMPLEMENTED = 12;
     * - HTTP code: 501 Not Implemented
     * </pre>
     *
     * <code>NOT_IMPLEMENTED = 1010;</code>
     */
    public static final int NOT_IMPLEMENTED_VALUE = 1010;
    /**
     * <pre>
     * Unrecoverable data loss or corruption.
     * One of the major use cases is to indicate that server failed to validate the integrity of
     * the request. This error can occur when the checksum specified in the `X-Databricks-Checksum`
     * request header (or trailer) doesn't match the actual request content checksum.
     * Note, in case of the severe corruption that results in a malformed request, the server may
     * send a generic `400 Bad Request` response rather than sending this error code.
     * Maps to:
     * - google.rpc.Code: DATA_LOSS = 15;
     * - HTTP code: 500 Internal Server Error
     * </pre>
     *
     * <code>DATA_LOSS = 1011;</code>
     */
    public static final int DATA_LOSS_VALUE = 1011;
    /**
     * <pre>
     * If the user attempts to perform an invalid state transition on a shard.
     * </pre>
     *
     * <code>INVALID_STATE_TRANSITION = 2001;</code>
     */
    public static final int INVALID_STATE_TRANSITION_VALUE = 2001;
    /**
     * <pre>
     * Unable to perform the operation because the shard was locked by some other operation.
     * </pre>
     *
     * <code>COULD_NOT_ACQUIRE_LOCK = 2002;</code>
     */
    public static final int COULD_NOT_ACQUIRE_LOCK_VALUE = 2002;
    /**
     * <pre>
     * Operation was performed on a resource that already exists.
     * Prefer using ALREADY_EXISTS. Unlike ALREADY_EXISTS - this maps to HTTP code
     * 500 Internal Server Error due to legacy reasons, remapping will be a backwards incompatible
     * change.
     * </pre>
     *
     * <code>RESOURCE_ALREADY_EXISTS = 3001;</code>
     */
    public static final int RESOURCE_ALREADY_EXISTS_VALUE = 3001;
    /**
     * <pre>
     * Operation was performed on a resource that does not exist.
     * Prefer using NOT_FOUND - see the note for the RESOURCE_ALREADY_EXISTS, because this pair of
     * codes is related and RESOURCE_ALREADY_EXISTS has bad mapping to the HTTP codes we added
     * new error codes NOT_FOUND and ALREADY_EXISTS, and recommend to use them instead.
     * </pre>
     *
     * <code>RESOURCE_DOES_NOT_EXIST = 3002;</code>
     */
    public static final int RESOURCE_DOES_NOT_EXIST_VALUE = 3002;
    /**
     * <code>QUOTA_EXCEEDED = 4001;</code>
     */
    public static final int QUOTA_EXCEEDED_VALUE = 4001;
    /**
     * <code>MAX_BLOCK_SIZE_EXCEEDED = 4002;</code>
     */
    public static final int MAX_BLOCK_SIZE_EXCEEDED_VALUE = 4002;
    /**
     * <code>MAX_READ_SIZE_EXCEEDED = 4003;</code>
     */
    public static final int MAX_READ_SIZE_EXCEEDED_VALUE = 4003;
    /**
     * <code>PARTIAL_DELETE = 4004;</code>
     */
    public static final int PARTIAL_DELETE_VALUE = 4004;
    /**
     * <code>MAX_LIST_SIZE_EXCEEDED = 4005;</code>
     */
    public static final int MAX_LIST_SIZE_EXCEEDED_VALUE = 4005;
    /**
     * <code>DRY_RUN_FAILED = 5001;</code>
     */
    public static final int DRY_RUN_FAILED_VALUE = 5001;
    /**
     * <pre>
     * Cluster request was rejected because it would exceed a resource limit.
     * </pre>
     *
     * <code>RESOURCE_LIMIT_EXCEEDED = 5002;</code>
     */
    public static final int RESOURCE_LIMIT_EXCEEDED_VALUE = 5002;
    /**
     * <code>DIRECTORY_NOT_EMPTY = 6001;</code>
     */
    public static final int DIRECTORY_NOT_EMPTY_VALUE = 6001;
    /**
     * <code>DIRECTORY_PROTECTED = 6002;</code>
     */
    public static final int DIRECTORY_PROTECTED_VALUE = 6002;
    /**
     * <code>MAX_NOTEBOOK_SIZE_EXCEEDED = 6003;</code>
     */
    public static final int MAX_NOTEBOOK_SIZE_EXCEEDED_VALUE = 6003;
    /**
     * <code>MAX_CHILD_NODE_SIZE_EXCEEDED = 6004;</code>
     */
    public static final int MAX_CHILD_NODE_SIZE_EXCEEDED_VALUE = 6004;
    /**
     * <code>SEARCH_QUERY_TOO_LONG = 6100;</code>
     */
    public static final int SEARCH_QUERY_TOO_LONG_VALUE = 6100;
    /**
     * <code>SEARCH_QUERY_TOO_SHORT = 6101;</code>
     */
    public static final int SEARCH_QUERY_TOO_SHORT_VALUE = 6101;
    /**
     * <code>MANAGED_RESOURCE_GROUP_DOES_NOT_EXIST = 7001;</code>
     */
    public static final int MANAGED_RESOURCE_GROUP_DOES_NOT_EXIST_VALUE = 7001;
    /**
     * <code>PERMISSION_NOT_PROPAGATED = 7002;</code>
     */
    public static final int PERMISSION_NOT_PROPAGATED_VALUE = 7002;
    /**
     * <code>DEPLOYMENT_TIMEOUT = 7003;</code>
     */
    public static final int DEPLOYMENT_TIMEOUT_VALUE = 7003;
    /**
     * <code>GIT_CONFLICT = 8001;</code>
     */
    public static final int GIT_CONFLICT_VALUE = 8001;
    /**
     * <code>GIT_UNKNOWN_REF = 8002;</code>
     */
    public static final int GIT_UNKNOWN_REF_VALUE = 8002;
    /**
     * <code>GIT_SENSITIVE_TOKEN_DETECTED = 8003;</code>
     */
    public static final int GIT_SENSITIVE_TOKEN_DETECTED_VALUE = 8003;
    /**
     * <code>GIT_URL_NOT_ON_ALLOW_LIST = 8004;</code>
     */
    public static final int GIT_URL_NOT_ON_ALLOW_LIST_VALUE = 8004;
    /**
     * <code>GIT_REMOTE_ERROR = 8005;</code>
     */
    public static final int GIT_REMOTE_ERROR_VALUE = 8005;
    /**
     * <code>PROJECTS_OPERATION_TIMEOUT = 8006;</code>
     */
    public static final int PROJECTS_OPERATION_TIMEOUT_VALUE = 8006;
    /**
     * <code>IPYNB_FILE_IN_REPO = 8007;</code>
     */
    public static final int IPYNB_FILE_IN_REPO_VALUE = 8007;
    /**
     * <code>INSECURE_PARTNER_RESPONSE = 8100;</code>
     */
    public static final int INSECURE_PARTNER_RESPONSE_VALUE = 8100;
    /**
     * <code>MALFORMED_PARTNER_RESPONSE = 8101;</code>
     */
    public static final int MALFORMED_PARTNER_RESPONSE_VALUE = 8101;
    /**
     * <code>METASTORE_DOES_NOT_EXIST = 9000;</code>
     */
    public static final int METASTORE_DOES_NOT_EXIST_VALUE = 9000;
    /**
     * <code>DAC_DOES_NOT_EXIST = 9001;</code>
     */
    public static final int DAC_DOES_NOT_EXIST_VALUE = 9001;
    /**
     * <code>CATALOG_DOES_NOT_EXIST = 9002;</code>
     */
    public static final int CATALOG_DOES_NOT_EXIST_VALUE = 9002;
    /**
     * <code>SCHEMA_DOES_NOT_EXIST = 9003;</code>
     */
    public static final int SCHEMA_DOES_NOT_EXIST_VALUE = 9003;
    /**
     * <code>TABLE_DOES_NOT_EXIST = 9004;</code>
     */
    public static final int TABLE_DOES_NOT_EXIST_VALUE = 9004;
    /**
     * <code>SHARE_DOES_NOT_EXIST = 9005;</code>
     */
    public static final int SHARE_DOES_NOT_EXIST_VALUE = 9005;
    /**
     * <code>RECIPIENT_DOES_NOT_EXIST = 9006;</code>
     */
    public static final int RECIPIENT_DOES_NOT_EXIST_VALUE = 9006;
    /**
     * <code>STORAGE_CREDENTIAL_DOES_NOT_EXIST = 9007;</code>
     */
    public static final int STORAGE_CREDENTIAL_DOES_NOT_EXIST_VALUE = 9007;
    /**
     * <code>EXTERNAL_LOCATION_DOES_NOT_EXIST = 9008;</code>
     */
    public static final int EXTERNAL_LOCATION_DOES_NOT_EXIST_VALUE = 9008;
    /**
     * <code>PRINCIPAL_DOES_NOT_EXIST = 9009;</code>
     */
    public static final int PRINCIPAL_DOES_NOT_EXIST_VALUE = 9009;
    /**
     * <code>PROVIDER_DOES_NOT_EXIST = 9010;</code>
     */
    public static final int PROVIDER_DOES_NOT_EXIST_VALUE = 9010;
    /**
     * <code>METASTORE_ALREADY_EXISTS = 9020;</code>
     */
    public static final int METASTORE_ALREADY_EXISTS_VALUE = 9020;
    /**
     * <code>DAC_ALREADY_EXISTS = 9021;</code>
     */
    public static final int DAC_ALREADY_EXISTS_VALUE = 9021;
    /**
     * <code>CATALOG_ALREADY_EXISTS = 9022;</code>
     */
    public static final int CATALOG_ALREADY_EXISTS_VALUE = 9022;
    /**
     * <code>SCHEMA_ALREADY_EXISTS = 9023;</code>
     */
    public static final int SCHEMA_ALREADY_EXISTS_VALUE = 9023;
    /**
     * <code>TABLE_ALREADY_EXISTS = 9024;</code>
     */
    public static final int TABLE_ALREADY_EXISTS_VALUE = 9024;
    /**
     * <code>SHARE_ALREADY_EXISTS = 9025;</code>
     */
    public static final int SHARE_ALREADY_EXISTS_VALUE = 9025;
    /**
     * <code>RECIPIENT_ALREADY_EXISTS = 9026;</code>
     */
    public static final int RECIPIENT_ALREADY_EXISTS_VALUE = 9026;
    /**
     * <code>STORAGE_CREDENTIAL_ALREADY_EXISTS = 9027;</code>
     */
    public static final int STORAGE_CREDENTIAL_ALREADY_EXISTS_VALUE = 9027;
    /**
     * <code>EXTERNAL_LOCATION_ALREADY_EXISTS = 9028;</code>
     */
    public static final int EXTERNAL_LOCATION_ALREADY_EXISTS_VALUE = 9028;
    /**
     * <code>PROVIDER_ALREADY_EXISTS = 9029;</code>
     */
    public static final int PROVIDER_ALREADY_EXISTS_VALUE = 9029;
    /**
     * <code>CATALOG_NOT_EMPTY = 9040;</code>
     */
    public static final int CATALOG_NOT_EMPTY_VALUE = 9040;
    /**
     * <code>SCHEMA_NOT_EMPTY = 9041;</code>
     */
    public static final int SCHEMA_NOT_EMPTY_VALUE = 9041;
    /**
     * <code>METASTORE_NOT_EMPTY = 9042;</code>
     */
    public static final int METASTORE_NOT_EMPTY_VALUE = 9042;
    /**
     * <code>PROVIDER_SHARE_NOT_ACCESSIBLE = 9060;</code>
     */
    public static final int PROVIDER_SHARE_NOT_ACCESSIBLE_VALUE = 9060;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ErrorCode valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static ErrorCode forNumber(int value) {
      switch (value) {
        case 1: return INTERNAL_ERROR;
        case 2: return TEMPORARILY_UNAVAILABLE;
        case 3: return IO_ERROR;
        case 4: return BAD_REQUEST;
        case 5: return SERVICE_UNDER_MAINTENANCE;
        case 6: return WORKSPACE_TEMPORARILY_UNAVAILABLE;
        case 7: return DEADLINE_EXCEEDED;
        case 8: return CANCELLED;
        case 9: return RESOURCE_EXHAUSTED;
        case 10: return ABORTED;
        case 11: return NOT_FOUND;
        case 12: return ALREADY_EXISTS;
        case 13: return UNAUTHENTICATED;
        case 1000: return INVALID_PARAMETER_VALUE;
        case 1001: return ENDPOINT_NOT_FOUND;
        case 1002: return MALFORMED_REQUEST;
        case 1003: return INVALID_STATE;
        case 1004: return PERMISSION_DENIED;
        case 1005: return FEATURE_DISABLED;
        case 1006: return CUSTOMER_UNAUTHORIZED;
        case 1007: return REQUEST_LIMIT_EXCEEDED;
        case 1008: return RESOURCE_CONFLICT;
        case 1009: return UNPARSEABLE_HTTP_ERROR;
        case 1010: return NOT_IMPLEMENTED;
        case 1011: return DATA_LOSS;
        case 2001: return INVALID_STATE_TRANSITION;
        case 2002: return COULD_NOT_ACQUIRE_LOCK;
        case 3001: return RESOURCE_ALREADY_EXISTS;
        case 3002: return RESOURCE_DOES_NOT_EXIST;
        case 4001: return QUOTA_EXCEEDED;
        case 4002: return MAX_BLOCK_SIZE_EXCEEDED;
        case 4003: return MAX_READ_SIZE_EXCEEDED;
        case 4004: return PARTIAL_DELETE;
        case 4005: return MAX_LIST_SIZE_EXCEEDED;
        case 5001: return DRY_RUN_FAILED;
        case 5002: return RESOURCE_LIMIT_EXCEEDED;
        case 6001: return DIRECTORY_NOT_EMPTY;
        case 6002: return DIRECTORY_PROTECTED;
        case 6003: return MAX_NOTEBOOK_SIZE_EXCEEDED;
        case 6004: return MAX_CHILD_NODE_SIZE_EXCEEDED;
        case 6100: return SEARCH_QUERY_TOO_LONG;
        case 6101: return SEARCH_QUERY_TOO_SHORT;
        case 7001: return MANAGED_RESOURCE_GROUP_DOES_NOT_EXIST;
        case 7002: return PERMISSION_NOT_PROPAGATED;
        case 7003: return DEPLOYMENT_TIMEOUT;
        case 8001: return GIT_CONFLICT;
        case 8002: return GIT_UNKNOWN_REF;
        case 8003: return GIT_SENSITIVE_TOKEN_DETECTED;
        case 8004: return GIT_URL_NOT_ON_ALLOW_LIST;
        case 8005: return GIT_REMOTE_ERROR;
        case 8006: return PROJECTS_OPERATION_TIMEOUT;
        case 8007: return IPYNB_FILE_IN_REPO;
        case 8100: return INSECURE_PARTNER_RESPONSE;
        case 8101: return MALFORMED_PARTNER_RESPONSE;
        case 9000: return METASTORE_DOES_NOT_EXIST;
        case 9001: return DAC_DOES_NOT_EXIST;
        case 9002: return CATALOG_DOES_NOT_EXIST;
        case 9003: return SCHEMA_DOES_NOT_EXIST;
        case 9004: return TABLE_DOES_NOT_EXIST;
        case 9005: return SHARE_DOES_NOT_EXIST;
        case 9006: return RECIPIENT_DOES_NOT_EXIST;
        case 9007: return STORAGE_CREDENTIAL_DOES_NOT_EXIST;
        case 9008: return EXTERNAL_LOCATION_DOES_NOT_EXIST;
        case 9009: return PRINCIPAL_DOES_NOT_EXIST;
        case 9010: return PROVIDER_DOES_NOT_EXIST;
        case 9020: return METASTORE_ALREADY_EXISTS;
        case 9021: return DAC_ALREADY_EXISTS;
        case 9022: return CATALOG_ALREADY_EXISTS;
        case 9023: return SCHEMA_ALREADY_EXISTS;
        case 9024: return TABLE_ALREADY_EXISTS;
        case 9025: return SHARE_ALREADY_EXISTS;
        case 9026: return RECIPIENT_ALREADY_EXISTS;
        case 9027: return STORAGE_CREDENTIAL_ALREADY_EXISTS;
        case 9028: return EXTERNAL_LOCATION_ALREADY_EXISTS;
        case 9029: return PROVIDER_ALREADY_EXISTS;
        case 9040: return CATALOG_NOT_EMPTY;
        case 9041: return SCHEMA_NOT_EMPTY;
        case 9042: return METASTORE_NOT_EMPTY;
        case 9060: return PROVIDER_SHARE_NOT_ACCESSIBLE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ErrorCode>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        ErrorCode> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ErrorCode>() {
            public ErrorCode findValueByNumber(int number) {
              return ErrorCode.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.getDescriptor().getEnumTypes().get(1);
    }

    private static final ErrorCode[] VALUES = values();

    public static ErrorCode valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ErrorCode(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:mlflow.ErrorCode)
  }

  public interface DatabricksRpcOptionsOrBuilder extends
      // @@protoc_insertion_point(interface_extends:mlflow.DatabricksRpcOptions)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    java.util.List<com.databricks.api.proto.databricks.Databricks.HttpEndpoint> 
        getEndpointsList();
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    com.databricks.api.proto.databricks.Databricks.HttpEndpoint getEndpoints(int index);
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    int getEndpointsCount();
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    java.util.List<? extends com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder> 
        getEndpointsOrBuilderList();
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder getEndpointsOrBuilder(
        int index);

    /**
     * <pre>
     * Indicates which users are allowed to initiate this RPC.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 2;</code>
     * @return Whether the visibility field is set.
     */
    boolean hasVisibility();
    /**
     * <pre>
     * Indicates which users are allowed to initiate this RPC.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 2;</code>
     * @return The visibility.
     */
    com.databricks.api.proto.databricks.Databricks.Visibility getVisibility();

    /**
     * <pre>
     * Complete definition of all error codes (from a statically defined set) which this method
     * may return.
     * </pre>
     *
     * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
     * @return A list containing the errorCodes.
     */
    java.util.List<com.databricks.api.proto.databricks.Databricks.ErrorCode> getErrorCodesList();
    /**
     * <pre>
     * Complete definition of all error codes (from a statically defined set) which this method
     * may return.
     * </pre>
     *
     * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
     * @return The count of errorCodes.
     */
    int getErrorCodesCount();
    /**
     * <pre>
     * Complete definition of all error codes (from a statically defined set) which this method
     * may return.
     * </pre>
     *
     * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
     * @param index The index of the element to return.
     * @return The errorCodes at the given index.
     */
    com.databricks.api.proto.databricks.Databricks.ErrorCode getErrorCodes(int index);

    /**
     * <pre>
     * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
     * </pre>
     *
     * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
     * @return Whether the rateLimit field is set.
     */
    boolean hasRateLimit();
    /**
     * <pre>
     * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
     * </pre>
     *
     * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
     * @return The rateLimit.
     */
    com.databricks.api.proto.databricks.Databricks.RateLimit getRateLimit();
    /**
     * <pre>
     * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
     * </pre>
     *
     * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
     */
    com.databricks.api.proto.databricks.Databricks.RateLimitOrBuilder getRateLimitOrBuilder();

    /**
     * <pre>
     * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
     * for more info.
     * </pre>
     *
     * <code>optional string rpc_doc_title = 5;</code>
     * @return Whether the rpcDocTitle field is set.
     */
    boolean hasRpcDocTitle();
    /**
     * <pre>
     * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
     * for more info.
     * </pre>
     *
     * <code>optional string rpc_doc_title = 5;</code>
     * @return The rpcDocTitle.
     */
    java.lang.String getRpcDocTitle();
    /**
     * <pre>
     * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
     * for more info.
     * </pre>
     *
     * <code>optional string rpc_doc_title = 5;</code>
     * @return The bytes for rpcDocTitle.
     */
    com.google.protobuf.ByteString
        getRpcDocTitleBytes();
  }
  /**
   * <pre>
   * Defines the set of options declared for every service RPC which are used to
   * direct RPCs to endpoints, as well as other metadata about the RPC.
   * </pre>
   *
   * Protobuf type {@code mlflow.DatabricksRpcOptions}
   */
  public static final class DatabricksRpcOptions extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:mlflow.DatabricksRpcOptions)
      DatabricksRpcOptionsOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DatabricksRpcOptions.newBuilder() to construct.
    private DatabricksRpcOptions(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DatabricksRpcOptions() {
      endpoints_ = java.util.Collections.emptyList();
      visibility_ = 1;
      errorCodes_ = java.util.Collections.emptyList();
      rpcDocTitle_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DatabricksRpcOptions();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DatabricksRpcOptions(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                endpoints_ = new java.util.ArrayList<com.databricks.api.proto.databricks.Databricks.HttpEndpoint>();
                mutable_bitField0_ |= 0x00000001;
              }
              endpoints_.add(
                  input.readMessage(com.databricks.api.proto.databricks.Databricks.HttpEndpoint.PARSER, extensionRegistry));
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
                @SuppressWarnings("deprecation")
              com.databricks.api.proto.databricks.Databricks.Visibility value = com.databricks.api.proto.databricks.Databricks.Visibility.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                visibility_ = rawValue;
              }
              break;
            }
            case 24: {
              int rawValue = input.readEnum();
              @SuppressWarnings("deprecation")
              com.databricks.api.proto.databricks.Databricks.ErrorCode value = com.databricks.api.proto.databricks.Databricks.ErrorCode.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(3, rawValue);
              } else {
                if (!((mutable_bitField0_ & 0x00000004) != 0)) {
                  errorCodes_ = new java.util.ArrayList<java.lang.Integer>();
                  mutable_bitField0_ |= 0x00000004;
                }
                errorCodes_.add(rawValue);
              }
              break;
            }
            case 26: {
              int length = input.readRawVarint32();
              int oldLimit = input.pushLimit(length);
              while(input.getBytesUntilLimit() > 0) {
                int rawValue = input.readEnum();
                @SuppressWarnings("deprecation")
                com.databricks.api.proto.databricks.Databricks.ErrorCode value = com.databricks.api.proto.databricks.Databricks.ErrorCode.valueOf(rawValue);
                if (value == null) {
                  unknownFields.mergeVarintField(3, rawValue);
                } else {
                  if (!((mutable_bitField0_ & 0x00000004) != 0)) {
                    errorCodes_ = new java.util.ArrayList<java.lang.Integer>();
                    mutable_bitField0_ |= 0x00000004;
                  }
                  errorCodes_.add(rawValue);
                }
              }
              input.popLimit(oldLimit);
              break;
            }
            case 34: {
              com.databricks.api.proto.databricks.Databricks.RateLimit.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) != 0)) {
                subBuilder = rateLimit_.toBuilder();
              }
              rateLimit_ = input.readMessage(com.databricks.api.proto.databricks.Databricks.RateLimit.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(rateLimit_);
                rateLimit_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 42: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000004;
              rpcDocTitle_ = bs;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          endpoints_ = java.util.Collections.unmodifiableList(endpoints_);
        }
        if (((mutable_bitField0_ & 0x00000004) != 0)) {
          errorCodes_ = java.util.Collections.unmodifiableList(errorCodes_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksRpcOptions_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksRpcOptions_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.class, com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.Builder.class);
    }

    private int bitField0_;
    public static final int ENDPOINTS_FIELD_NUMBER = 1;
    private java.util.List<com.databricks.api.proto.databricks.Databricks.HttpEndpoint> endpoints_;
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    @java.lang.Override
    public java.util.List<com.databricks.api.proto.databricks.Databricks.HttpEndpoint> getEndpointsList() {
      return endpoints_;
    }
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder> 
        getEndpointsOrBuilderList() {
      return endpoints_;
    }
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    @java.lang.Override
    public int getEndpointsCount() {
      return endpoints_.size();
    }
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.HttpEndpoint getEndpoints(int index) {
      return endpoints_.get(index);
    }
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder getEndpointsOrBuilder(
        int index) {
      return endpoints_.get(index);
    }

    public static final int VISIBILITY_FIELD_NUMBER = 2;
    private int visibility_;
    /**
     * <pre>
     * Indicates which users are allowed to initiate this RPC.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 2;</code>
     * @return Whether the visibility field is set.
     */
    @java.lang.Override public boolean hasVisibility() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * Indicates which users are allowed to initiate this RPC.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 2;</code>
     * @return The visibility.
     */
    @java.lang.Override public com.databricks.api.proto.databricks.Databricks.Visibility getVisibility() {
      @SuppressWarnings("deprecation")
      com.databricks.api.proto.databricks.Databricks.Visibility result = com.databricks.api.proto.databricks.Databricks.Visibility.valueOf(visibility_);
      return result == null ? com.databricks.api.proto.databricks.Databricks.Visibility.PUBLIC : result;
    }

    public static final int ERROR_CODES_FIELD_NUMBER = 3;
    private java.util.List<java.lang.Integer> errorCodes_;
    private static final com.google.protobuf.Internal.ListAdapter.Converter<
        java.lang.Integer, com.databricks.api.proto.databricks.Databricks.ErrorCode> errorCodes_converter_ =
            new com.google.protobuf.Internal.ListAdapter.Converter<
                java.lang.Integer, com.databricks.api.proto.databricks.Databricks.ErrorCode>() {
              public com.databricks.api.proto.databricks.Databricks.ErrorCode convert(java.lang.Integer from) {
                @SuppressWarnings("deprecation")
                com.databricks.api.proto.databricks.Databricks.ErrorCode result = com.databricks.api.proto.databricks.Databricks.ErrorCode.valueOf(from);
                return result == null ? com.databricks.api.proto.databricks.Databricks.ErrorCode.INTERNAL_ERROR : result;
              }
            };
    /**
     * <pre>
     * Complete definition of all error codes (from a statically defined set) which this method
     * may return.
     * </pre>
     *
     * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
     * @return A list containing the errorCodes.
     */
    @java.lang.Override
    public java.util.List<com.databricks.api.proto.databricks.Databricks.ErrorCode> getErrorCodesList() {
      return new com.google.protobuf.Internal.ListAdapter<
          java.lang.Integer, com.databricks.api.proto.databricks.Databricks.ErrorCode>(errorCodes_, errorCodes_converter_);
    }
    /**
     * <pre>
     * Complete definition of all error codes (from a statically defined set) which this method
     * may return.
     * </pre>
     *
     * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
     * @return The count of errorCodes.
     */
    @java.lang.Override
    public int getErrorCodesCount() {
      return errorCodes_.size();
    }
    /**
     * <pre>
     * Complete definition of all error codes (from a statically defined set) which this method
     * may return.
     * </pre>
     *
     * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
     * @param index The index of the element to return.
     * @return The errorCodes at the given index.
     */
    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.ErrorCode getErrorCodes(int index) {
      return errorCodes_converter_.convert(errorCodes_.get(index));
    }

    public static final int RATE_LIMIT_FIELD_NUMBER = 4;
    private com.databricks.api.proto.databricks.Databricks.RateLimit rateLimit_;
    /**
     * <pre>
     * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
     * </pre>
     *
     * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
     * @return Whether the rateLimit field is set.
     */
    @java.lang.Override
    public boolean hasRateLimit() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
     * </pre>
     *
     * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
     * @return The rateLimit.
     */
    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.RateLimit getRateLimit() {
      return rateLimit_ == null ? com.databricks.api.proto.databricks.Databricks.RateLimit.getDefaultInstance() : rateLimit_;
    }
    /**
     * <pre>
     * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
     * </pre>
     *
     * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
     */
    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.RateLimitOrBuilder getRateLimitOrBuilder() {
      return rateLimit_ == null ? com.databricks.api.proto.databricks.Databricks.RateLimit.getDefaultInstance() : rateLimit_;
    }

    public static final int RPC_DOC_TITLE_FIELD_NUMBER = 5;
    private volatile java.lang.Object rpcDocTitle_;
    /**
     * <pre>
     * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
     * for more info.
     * </pre>
     *
     * <code>optional string rpc_doc_title = 5;</code>
     * @return Whether the rpcDocTitle field is set.
     */
    @java.lang.Override
    public boolean hasRpcDocTitle() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
     * for more info.
     * </pre>
     *
     * <code>optional string rpc_doc_title = 5;</code>
     * @return The rpcDocTitle.
     */
    @java.lang.Override
    public java.lang.String getRpcDocTitle() {
      java.lang.Object ref = rpcDocTitle_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          rpcDocTitle_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
     * for more info.
     * </pre>
     *
     * <code>optional string rpc_doc_title = 5;</code>
     * @return The bytes for rpcDocTitle.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getRpcDocTitleBytes() {
      java.lang.Object ref = rpcDocTitle_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        rpcDocTitle_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < endpoints_.size(); i++) {
        output.writeMessage(1, endpoints_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeEnum(2, visibility_);
      }
      for (int i = 0; i < errorCodes_.size(); i++) {
        output.writeEnum(3, errorCodes_.get(i));
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(4, getRateLimit());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, rpcDocTitle_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < endpoints_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, endpoints_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, visibility_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < errorCodes_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeEnumSizeNoTag(errorCodes_.get(i));
        }
        size += dataSize;
        size += 1 * errorCodes_.size();
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getRateLimit());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, rpcDocTitle_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions)) {
        return super.equals(obj);
      }
      com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions other = (com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions) obj;

      if (!getEndpointsList()
          .equals(other.getEndpointsList())) return false;
      if (hasVisibility() != other.hasVisibility()) return false;
      if (hasVisibility()) {
        if (visibility_ != other.visibility_) return false;
      }
      if (!errorCodes_.equals(other.errorCodes_)) return false;
      if (hasRateLimit() != other.hasRateLimit()) return false;
      if (hasRateLimit()) {
        if (!getRateLimit()
            .equals(other.getRateLimit())) return false;
      }
      if (hasRpcDocTitle() != other.hasRpcDocTitle()) return false;
      if (hasRpcDocTitle()) {
        if (!getRpcDocTitle()
            .equals(other.getRpcDocTitle())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getEndpointsCount() > 0) {
        hash = (37 * hash) + ENDPOINTS_FIELD_NUMBER;
        hash = (53 * hash) + getEndpointsList().hashCode();
      }
      if (hasVisibility()) {
        hash = (37 * hash) + VISIBILITY_FIELD_NUMBER;
        hash = (53 * hash) + visibility_;
      }
      if (getErrorCodesCount() > 0) {
        hash = (37 * hash) + ERROR_CODES_FIELD_NUMBER;
        hash = (53 * hash) + errorCodes_.hashCode();
      }
      if (hasRateLimit()) {
        hash = (37 * hash) + RATE_LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + getRateLimit().hashCode();
      }
      if (hasRpcDocTitle()) {
        hash = (37 * hash) + RPC_DOC_TITLE_FIELD_NUMBER;
        hash = (53 * hash) + getRpcDocTitle().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Defines the set of options declared for every service RPC which are used to
     * direct RPCs to endpoints, as well as other metadata about the RPC.
     * </pre>
     *
     * Protobuf type {@code mlflow.DatabricksRpcOptions}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:mlflow.DatabricksRpcOptions)
        com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptionsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksRpcOptions_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksRpcOptions_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.class, com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.Builder.class);
      }

      // Construct using com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getEndpointsFieldBuilder();
          getRateLimitFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (endpointsBuilder_ == null) {
          endpoints_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          endpointsBuilder_.clear();
        }
        visibility_ = 1;
        bitField0_ = (bitField0_ & ~0x00000002);
        errorCodes_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000004);
        if (rateLimitBuilder_ == null) {
          rateLimit_ = null;
        } else {
          rateLimitBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        rpcDocTitle_ = "";
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksRpcOptions_descriptor;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions getDefaultInstanceForType() {
        return com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.getDefaultInstance();
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions build() {
        com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions buildPartial() {
        com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions result = new com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (endpointsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            endpoints_ = java.util.Collections.unmodifiableList(endpoints_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.endpoints_ = endpoints_;
        } else {
          result.endpoints_ = endpointsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.visibility_ = visibility_;
        if (((bitField0_ & 0x00000004) != 0)) {
          errorCodes_ = java.util.Collections.unmodifiableList(errorCodes_);
          bitField0_ = (bitField0_ & ~0x00000004);
        }
        result.errorCodes_ = errorCodes_;
        if (((from_bitField0_ & 0x00000008) != 0)) {
          if (rateLimitBuilder_ == null) {
            result.rateLimit_ = rateLimit_;
          } else {
            result.rateLimit_ = rateLimitBuilder_.build();
          }
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          to_bitField0_ |= 0x00000004;
        }
        result.rpcDocTitle_ = rpcDocTitle_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions) {
          return mergeFrom((com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions other) {
        if (other == com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.getDefaultInstance()) return this;
        if (endpointsBuilder_ == null) {
          if (!other.endpoints_.isEmpty()) {
            if (endpoints_.isEmpty()) {
              endpoints_ = other.endpoints_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureEndpointsIsMutable();
              endpoints_.addAll(other.endpoints_);
            }
            onChanged();
          }
        } else {
          if (!other.endpoints_.isEmpty()) {
            if (endpointsBuilder_.isEmpty()) {
              endpointsBuilder_.dispose();
              endpointsBuilder_ = null;
              endpoints_ = other.endpoints_;
              bitField0_ = (bitField0_ & ~0x00000001);
              endpointsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getEndpointsFieldBuilder() : null;
            } else {
              endpointsBuilder_.addAllMessages(other.endpoints_);
            }
          }
        }
        if (other.hasVisibility()) {
          setVisibility(other.getVisibility());
        }
        if (!other.errorCodes_.isEmpty()) {
          if (errorCodes_.isEmpty()) {
            errorCodes_ = other.errorCodes_;
            bitField0_ = (bitField0_ & ~0x00000004);
          } else {
            ensureErrorCodesIsMutable();
            errorCodes_.addAll(other.errorCodes_);
          }
          onChanged();
        }
        if (other.hasRateLimit()) {
          mergeRateLimit(other.getRateLimit());
        }
        if (other.hasRpcDocTitle()) {
          bitField0_ |= 0x00000010;
          rpcDocTitle_ = other.rpcDocTitle_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<com.databricks.api.proto.databricks.Databricks.HttpEndpoint> endpoints_ =
        java.util.Collections.emptyList();
      private void ensureEndpointsIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          endpoints_ = new java.util.ArrayList<com.databricks.api.proto.databricks.Databricks.HttpEndpoint>(endpoints_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          com.databricks.api.proto.databricks.Databricks.HttpEndpoint, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder, com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder> endpointsBuilder_;

      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public java.util.List<com.databricks.api.proto.databricks.Databricks.HttpEndpoint> getEndpointsList() {
        if (endpointsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(endpoints_);
        } else {
          return endpointsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public int getEndpointsCount() {
        if (endpointsBuilder_ == null) {
          return endpoints_.size();
        } else {
          return endpointsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.HttpEndpoint getEndpoints(int index) {
        if (endpointsBuilder_ == null) {
          return endpoints_.get(index);
        } else {
          return endpointsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder setEndpoints(
          int index, com.databricks.api.proto.databricks.Databricks.HttpEndpoint value) {
        if (endpointsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEndpointsIsMutable();
          endpoints_.set(index, value);
          onChanged();
        } else {
          endpointsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder setEndpoints(
          int index, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder builderForValue) {
        if (endpointsBuilder_ == null) {
          ensureEndpointsIsMutable();
          endpoints_.set(index, builderForValue.build());
          onChanged();
        } else {
          endpointsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder addEndpoints(com.databricks.api.proto.databricks.Databricks.HttpEndpoint value) {
        if (endpointsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEndpointsIsMutable();
          endpoints_.add(value);
          onChanged();
        } else {
          endpointsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder addEndpoints(
          int index, com.databricks.api.proto.databricks.Databricks.HttpEndpoint value) {
        if (endpointsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEndpointsIsMutable();
          endpoints_.add(index, value);
          onChanged();
        } else {
          endpointsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder addEndpoints(
          com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder builderForValue) {
        if (endpointsBuilder_ == null) {
          ensureEndpointsIsMutable();
          endpoints_.add(builderForValue.build());
          onChanged();
        } else {
          endpointsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder addEndpoints(
          int index, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder builderForValue) {
        if (endpointsBuilder_ == null) {
          ensureEndpointsIsMutable();
          endpoints_.add(index, builderForValue.build());
          onChanged();
        } else {
          endpointsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder addAllEndpoints(
          java.lang.Iterable<? extends com.databricks.api.proto.databricks.Databricks.HttpEndpoint> values) {
        if (endpointsBuilder_ == null) {
          ensureEndpointsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, endpoints_);
          onChanged();
        } else {
          endpointsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder clearEndpoints() {
        if (endpointsBuilder_ == null) {
          endpoints_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          endpointsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder removeEndpoints(int index) {
        if (endpointsBuilder_ == null) {
          ensureEndpointsIsMutable();
          endpoints_.remove(index);
          onChanged();
        } else {
          endpointsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder getEndpointsBuilder(
          int index) {
        return getEndpointsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder getEndpointsOrBuilder(
          int index) {
        if (endpointsBuilder_ == null) {
          return endpoints_.get(index);  } else {
          return endpointsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public java.util.List<? extends com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder> 
           getEndpointsOrBuilderList() {
        if (endpointsBuilder_ != null) {
          return endpointsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(endpoints_);
        }
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder addEndpointsBuilder() {
        return getEndpointsFieldBuilder().addBuilder(
            com.databricks.api.proto.databricks.Databricks.HttpEndpoint.getDefaultInstance());
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder addEndpointsBuilder(
          int index) {
        return getEndpointsFieldBuilder().addBuilder(
            index, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.getDefaultInstance());
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public java.util.List<com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder> 
           getEndpointsBuilderList() {
        return getEndpointsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          com.databricks.api.proto.databricks.Databricks.HttpEndpoint, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder, com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder> 
          getEndpointsFieldBuilder() {
        if (endpointsBuilder_ == null) {
          endpointsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              com.databricks.api.proto.databricks.Databricks.HttpEndpoint, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder, com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder>(
                  endpoints_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          endpoints_ = null;
        }
        return endpointsBuilder_;
      }

      private int visibility_ = 1;
      /**
       * <pre>
       * Indicates which users are allowed to initiate this RPC.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 2;</code>
       * @return Whether the visibility field is set.
       */
      @java.lang.Override public boolean hasVisibility() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * Indicates which users are allowed to initiate this RPC.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 2;</code>
       * @return The visibility.
       */
      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.Visibility getVisibility() {
        @SuppressWarnings("deprecation")
        com.databricks.api.proto.databricks.Databricks.Visibility result = com.databricks.api.proto.databricks.Databricks.Visibility.valueOf(visibility_);
        return result == null ? com.databricks.api.proto.databricks.Databricks.Visibility.PUBLIC : result;
      }
      /**
       * <pre>
       * Indicates which users are allowed to initiate this RPC.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 2;</code>
       * @param value The visibility to set.
       * @return This builder for chaining.
       */
      public Builder setVisibility(com.databricks.api.proto.databricks.Databricks.Visibility value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        visibility_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Indicates which users are allowed to initiate this RPC.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearVisibility() {
        bitField0_ = (bitField0_ & ~0x00000002);
        visibility_ = 1;
        onChanged();
        return this;
      }

      private java.util.List<java.lang.Integer> errorCodes_ =
        java.util.Collections.emptyList();
      private void ensureErrorCodesIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          errorCodes_ = new java.util.ArrayList<java.lang.Integer>(errorCodes_);
          bitField0_ |= 0x00000004;
        }
      }
      /**
       * <pre>
       * Complete definition of all error codes (from a statically defined set) which this method
       * may return.
       * </pre>
       *
       * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
       * @return A list containing the errorCodes.
       */
      public java.util.List<com.databricks.api.proto.databricks.Databricks.ErrorCode> getErrorCodesList() {
        return new com.google.protobuf.Internal.ListAdapter<
            java.lang.Integer, com.databricks.api.proto.databricks.Databricks.ErrorCode>(errorCodes_, errorCodes_converter_);
      }
      /**
       * <pre>
       * Complete definition of all error codes (from a statically defined set) which this method
       * may return.
       * </pre>
       *
       * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
       * @return The count of errorCodes.
       */
      public int getErrorCodesCount() {
        return errorCodes_.size();
      }
      /**
       * <pre>
       * Complete definition of all error codes (from a statically defined set) which this method
       * may return.
       * </pre>
       *
       * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
       * @param index The index of the element to return.
       * @return The errorCodes at the given index.
       */
      public com.databricks.api.proto.databricks.Databricks.ErrorCode getErrorCodes(int index) {
        return errorCodes_converter_.convert(errorCodes_.get(index));
      }
      /**
       * <pre>
       * Complete definition of all error codes (from a statically defined set) which this method
       * may return.
       * </pre>
       *
       * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
       * @param index The index to set the value at.
       * @param value The errorCodes to set.
       * @return This builder for chaining.
       */
      public Builder setErrorCodes(
          int index, com.databricks.api.proto.databricks.Databricks.ErrorCode value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureErrorCodesIsMutable();
        errorCodes_.set(index, value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Complete definition of all error codes (from a statically defined set) which this method
       * may return.
       * </pre>
       *
       * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
       * @param value The errorCodes to add.
       * @return This builder for chaining.
       */
      public Builder addErrorCodes(com.databricks.api.proto.databricks.Databricks.ErrorCode value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureErrorCodesIsMutable();
        errorCodes_.add(value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Complete definition of all error codes (from a statically defined set) which this method
       * may return.
       * </pre>
       *
       * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
       * @param values The errorCodes to add.
       * @return This builder for chaining.
       */
      public Builder addAllErrorCodes(
          java.lang.Iterable<? extends com.databricks.api.proto.databricks.Databricks.ErrorCode> values) {
        ensureErrorCodesIsMutable();
        for (com.databricks.api.proto.databricks.Databricks.ErrorCode value : values) {
          errorCodes_.add(value.getNumber());
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Complete definition of all error codes (from a statically defined set) which this method
       * may return.
       * </pre>
       *
       * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearErrorCodes() {
        errorCodes_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }

      private com.databricks.api.proto.databricks.Databricks.RateLimit rateLimit_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.databricks.api.proto.databricks.Databricks.RateLimit, com.databricks.api.proto.databricks.Databricks.RateLimit.Builder, com.databricks.api.proto.databricks.Databricks.RateLimitOrBuilder> rateLimitBuilder_;
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       * @return Whether the rateLimit field is set.
       */
      public boolean hasRateLimit() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       * @return The rateLimit.
       */
      public com.databricks.api.proto.databricks.Databricks.RateLimit getRateLimit() {
        if (rateLimitBuilder_ == null) {
          return rateLimit_ == null ? com.databricks.api.proto.databricks.Databricks.RateLimit.getDefaultInstance() : rateLimit_;
        } else {
          return rateLimitBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      public Builder setRateLimit(com.databricks.api.proto.databricks.Databricks.RateLimit value) {
        if (rateLimitBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          rateLimit_ = value;
          onChanged();
        } else {
          rateLimitBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      public Builder setRateLimit(
          com.databricks.api.proto.databricks.Databricks.RateLimit.Builder builderForValue) {
        if (rateLimitBuilder_ == null) {
          rateLimit_ = builderForValue.build();
          onChanged();
        } else {
          rateLimitBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      public Builder mergeRateLimit(com.databricks.api.proto.databricks.Databricks.RateLimit value) {
        if (rateLimitBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
              rateLimit_ != null &&
              rateLimit_ != com.databricks.api.proto.databricks.Databricks.RateLimit.getDefaultInstance()) {
            rateLimit_ =
              com.databricks.api.proto.databricks.Databricks.RateLimit.newBuilder(rateLimit_).mergeFrom(value).buildPartial();
          } else {
            rateLimit_ = value;
          }
          onChanged();
        } else {
          rateLimitBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      public Builder clearRateLimit() {
        if (rateLimitBuilder_ == null) {
          rateLimit_ = null;
          onChanged();
        } else {
          rateLimitBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.RateLimit.Builder getRateLimitBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getRateLimitFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.RateLimitOrBuilder getRateLimitOrBuilder() {
        if (rateLimitBuilder_ != null) {
          return rateLimitBuilder_.getMessageOrBuilder();
        } else {
          return rateLimit_ == null ?
              com.databricks.api.proto.databricks.Databricks.RateLimit.getDefaultInstance() : rateLimit_;
        }
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.databricks.api.proto.databricks.Databricks.RateLimit, com.databricks.api.proto.databricks.Databricks.RateLimit.Builder, com.databricks.api.proto.databricks.Databricks.RateLimitOrBuilder> 
          getRateLimitFieldBuilder() {
        if (rateLimitBuilder_ == null) {
          rateLimitBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.databricks.api.proto.databricks.Databricks.RateLimit, com.databricks.api.proto.databricks.Databricks.RateLimit.Builder, com.databricks.api.proto.databricks.Databricks.RateLimitOrBuilder>(
                  getRateLimit(),
                  getParentForChildren(),
                  isClean());
          rateLimit_ = null;
        }
        return rateLimitBuilder_;
      }

      private java.lang.Object rpcDocTitle_ = "";
      /**
       * <pre>
       * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
       * for more info.
       * </pre>
       *
       * <code>optional string rpc_doc_title = 5;</code>
       * @return Whether the rpcDocTitle field is set.
       */
      public boolean hasRpcDocTitle() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <pre>
       * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
       * for more info.
       * </pre>
       *
       * <code>optional string rpc_doc_title = 5;</code>
       * @return The rpcDocTitle.
       */
      public java.lang.String getRpcDocTitle() {
        java.lang.Object ref = rpcDocTitle_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            rpcDocTitle_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
       * for more info.
       * </pre>
       *
       * <code>optional string rpc_doc_title = 5;</code>
       * @return The bytes for rpcDocTitle.
       */
      public com.google.protobuf.ByteString
          getRpcDocTitleBytes() {
        java.lang.Object ref = rpcDocTitle_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          rpcDocTitle_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
       * for more info.
       * </pre>
       *
       * <code>optional string rpc_doc_title = 5;</code>
       * @param value The rpcDocTitle to set.
       * @return This builder for chaining.
       */
      public Builder setRpcDocTitle(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        rpcDocTitle_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
       * for more info.
       * </pre>
       *
       * <code>optional string rpc_doc_title = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearRpcDocTitle() {
        bitField0_ = (bitField0_ & ~0x00000010);
        rpcDocTitle_ = getDefaultInstance().getRpcDocTitle();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
       * for more info.
       * </pre>
       *
       * <code>optional string rpc_doc_title = 5;</code>
       * @param value The bytes for rpcDocTitle to set.
       * @return This builder for chaining.
       */
      public Builder setRpcDocTitleBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        rpcDocTitle_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:mlflow.DatabricksRpcOptions)
    }

    // @@protoc_insertion_point(class_scope:mlflow.DatabricksRpcOptions)
    private static final com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions();
    }

    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<DatabricksRpcOptions>
        PARSER = new com.google.protobuf.AbstractParser<DatabricksRpcOptions>() {
      @java.lang.Override
      public DatabricksRpcOptions parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DatabricksRpcOptions(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DatabricksRpcOptions> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DatabricksRpcOptions> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DatabricksGraphqlOptionsOrBuilder extends
      // @@protoc_insertion_point(interface_extends:mlflow.DatabricksGraphqlOptions)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * <pre>
   * Defines the set of options needed for autogenerating graphql modules.
   * Will add more fields (batch loader, renaming) later.
   * Empty for now. The rpc will be visible for graphql module autogeneration if this field is set.
   * </pre>
   *
   * Protobuf type {@code mlflow.DatabricksGraphqlOptions}
   */
  public static final class DatabricksGraphqlOptions extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:mlflow.DatabricksGraphqlOptions)
      DatabricksGraphqlOptionsOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DatabricksGraphqlOptions.newBuilder() to construct.
    private DatabricksGraphqlOptions(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DatabricksGraphqlOptions() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DatabricksGraphqlOptions();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DatabricksGraphqlOptions(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksGraphqlOptions_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksGraphqlOptions_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions.class, com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions)) {
        return super.equals(obj);
      }
      com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions other = (com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions) obj;

      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Defines the set of options needed for autogenerating graphql modules.
     * Will add more fields (batch loader, renaming) later.
     * Empty for now. The rpc will be visible for graphql module autogeneration if this field is set.
     * </pre>
     *
     * Protobuf type {@code mlflow.DatabricksGraphqlOptions}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:mlflow.DatabricksGraphqlOptions)
        com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptionsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksGraphqlOptions_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksGraphqlOptions_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions.class, com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions.Builder.class);
      }

      // Construct using com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksGraphqlOptions_descriptor;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions getDefaultInstanceForType() {
        return com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions.getDefaultInstance();
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions build() {
        com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions buildPartial() {
        com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions result = new com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions) {
          return mergeFrom((com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions other) {
        if (other == com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:mlflow.DatabricksGraphqlOptions)
    }

    // @@protoc_insertion_point(class_scope:mlflow.DatabricksGraphqlOptions)
    private static final com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions();
    }

    public static com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<DatabricksGraphqlOptions>
        PARSER = new com.google.protobuf.AbstractParser<DatabricksGraphqlOptions>() {
      @java.lang.Override
      public DatabricksGraphqlOptions parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DatabricksGraphqlOptions(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DatabricksGraphqlOptions> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DatabricksGraphqlOptions> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface HttpEndpointOrBuilder extends
      // @@protoc_insertion_point(interface_extends:mlflow.HttpEndpoint)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * HTTP method like POST or GET.
     * </pre>
     *
     * <code>optional string method = 1 [default = "POST"];</code>
     * @return Whether the method field is set.
     */
    boolean hasMethod();
    /**
     * <pre>
     * HTTP method like POST or GET.
     * </pre>
     *
     * <code>optional string method = 1 [default = "POST"];</code>
     * @return The method.
     */
    java.lang.String getMethod();
    /**
     * <pre>
     * HTTP method like POST or GET.
     * </pre>
     *
     * <code>optional string method = 1 [default = "POST"];</code>
     * @return The bytes for method.
     */
    com.google.protobuf.ByteString
        getMethodBytes();

    /**
     * <pre>
     * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
     * </pre>
     *
     * <code>optional string path = 2;</code>
     * @return Whether the path field is set.
     */
    boolean hasPath();
    /**
     * <pre>
     * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
     * </pre>
     *
     * <code>optional string path = 2;</code>
     * @return The path.
     */
    java.lang.String getPath();
    /**
     * <pre>
     * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
     * </pre>
     *
     * <code>optional string path = 2;</code>
     * @return The bytes for path.
     */
    com.google.protobuf.ByteString
        getPathBytes();

    /**
     * <pre>
     * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
     * Breaking changes to an RPC must use a different version number.
     * </pre>
     *
     * <code>optional .mlflow.ApiVersion since = 3;</code>
     * @return Whether the since field is set.
     */
    boolean hasSince();
    /**
     * <pre>
     * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
     * Breaking changes to an RPC must use a different version number.
     * </pre>
     *
     * <code>optional .mlflow.ApiVersion since = 3;</code>
     * @return The since.
     */
    com.databricks.api.proto.databricks.Databricks.ApiVersion getSince();
    /**
     * <pre>
     * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
     * Breaking changes to an RPC must use a different version number.
     * </pre>
     *
     * <code>optional .mlflow.ApiVersion since = 3;</code>
     */
    com.databricks.api.proto.databricks.Databricks.ApiVersionOrBuilder getSinceOrBuilder();
  }
  /**
   * Protobuf type {@code mlflow.HttpEndpoint}
   */
  public static final class HttpEndpoint extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:mlflow.HttpEndpoint)
      HttpEndpointOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use HttpEndpoint.newBuilder() to construct.
    private HttpEndpoint(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private HttpEndpoint() {
      method_ = "POST";
      path_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new HttpEndpoint();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private HttpEndpoint(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              method_ = bs;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              path_ = bs;
              break;
            }
            case 26: {
              com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) != 0)) {
                subBuilder = since_.toBuilder();
              }
              since_ = input.readMessage(com.databricks.api.proto.databricks.Databricks.ApiVersion.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(since_);
                since_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_HttpEndpoint_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_HttpEndpoint_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.databricks.api.proto.databricks.Databricks.HttpEndpoint.class, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder.class);
    }

    private int bitField0_;
    public static final int METHOD_FIELD_NUMBER = 1;
    private volatile java.lang.Object method_;
    /**
     * <pre>
     * HTTP method like POST or GET.
     * </pre>
     *
     * <code>optional string method = 1 [default = "POST"];</code>
     * @return Whether the method field is set.
     */
    @java.lang.Override
    public boolean hasMethod() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * HTTP method like POST or GET.
     * </pre>
     *
     * <code>optional string method = 1 [default = "POST"];</code>
     * @return The method.
     */
    @java.lang.Override
    public java.lang.String getMethod() {
      java.lang.Object ref = method_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          method_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * HTTP method like POST or GET.
     * </pre>
     *
     * <code>optional string method = 1 [default = "POST"];</code>
     * @return The bytes for method.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getMethodBytes() {
      java.lang.Object ref = method_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        method_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int PATH_FIELD_NUMBER = 2;
    private volatile java.lang.Object path_;
    /**
     * <pre>
     * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
     * </pre>
     *
     * <code>optional string path = 2;</code>
     * @return Whether the path field is set.
     */
    @java.lang.Override
    public boolean hasPath() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
     * </pre>
     *
     * <code>optional string path = 2;</code>
     * @return The path.
     */
    @java.lang.Override
    public java.lang.String getPath() {
      java.lang.Object ref = path_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          path_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
     * </pre>
     *
     * <code>optional string path = 2;</code>
     * @return The bytes for path.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getPathBytes() {
      java.lang.Object ref = path_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        path_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int SINCE_FIELD_NUMBER = 3;
    private com.databricks.api.proto.databricks.Databricks.ApiVersion since_;
    /**
     * <pre>
     * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
     * Breaking changes to an RPC must use a different version number.
     * </pre>
     *
     * <code>optional .mlflow.ApiVersion since = 3;</code>
     * @return Whether the since field is set.
     */
    @java.lang.Override
    public boolean hasSince() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
     * Breaking changes to an RPC must use a different version number.
     * </pre>
     *
     * <code>optional .mlflow.ApiVersion since = 3;</code>
     * @return The since.
     */
    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.ApiVersion getSince() {
      return since_ == null ? com.databricks.api.proto.databricks.Databricks.ApiVersion.getDefaultInstance() : since_;
    }
    /**
     * <pre>
     * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
     * Breaking changes to an RPC must use a different version number.
     * </pre>
     *
     * <code>optional .mlflow.ApiVersion since = 3;</code>
     */
    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.ApiVersionOrBuilder getSinceOrBuilder() {
      return since_ == null ? com.databricks.api.proto.databricks.Databricks.ApiVersion.getDefaultInstance() : since_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, method_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, path_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getSince());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, method_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, path_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getSince());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.databricks.api.proto.databricks.Databricks.HttpEndpoint)) {
        return super.equals(obj);
      }
      com.databricks.api.proto.databricks.Databricks.HttpEndpoint other = (com.databricks.api.proto.databricks.Databricks.HttpEndpoint) obj;

      if (hasMethod() != other.hasMethod()) return false;
      if (hasMethod()) {
        if (!getMethod()
            .equals(other.getMethod())) return false;
      }
      if (hasPath() != other.hasPath()) return false;
      if (hasPath()) {
        if (!getPath()
            .equals(other.getPath())) return false;
      }
      if (hasSince() != other.hasSince()) return false;
      if (hasSince()) {
        if (!getSince()
            .equals(other.getSince())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasMethod()) {
        hash = (37 * hash) + METHOD_FIELD_NUMBER;
        hash = (53 * hash) + getMethod().hashCode();
      }
      if (hasPath()) {
        hash = (37 * hash) + PATH_FIELD_NUMBER;
        hash = (53 * hash) + getPath().hashCode();
      }
      if (hasSince()) {
        hash = (37 * hash) + SINCE_FIELD_NUMBER;
        hash = (53 * hash) + getSince().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.databricks.api.proto.databricks.Databricks.HttpEndpoint prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code mlflow.HttpEndpoint}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:mlflow.HttpEndpoint)
        com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_HttpEndpoint_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_HttpEndpoint_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.databricks.api.proto.databricks.Databricks.HttpEndpoint.class, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder.class);
      }

      // Construct using com.databricks.api.proto.databricks.Databricks.HttpEndpoint.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getSinceFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        method_ = "POST";
        bitField0_ = (bitField0_ & ~0x00000001);
        path_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        if (sinceBuilder_ == null) {
          since_ = null;
        } else {
          sinceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_HttpEndpoint_descriptor;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.HttpEndpoint getDefaultInstanceForType() {
        return com.databricks.api.proto.databricks.Databricks.HttpEndpoint.getDefaultInstance();
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.HttpEndpoint build() {
        com.databricks.api.proto.databricks.Databricks.HttpEndpoint result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.HttpEndpoint buildPartial() {
        com.databricks.api.proto.databricks.Databricks.HttpEndpoint result = new com.databricks.api.proto.databricks.Databricks.HttpEndpoint(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.method_ = method_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          to_bitField0_ |= 0x00000002;
        }
        result.path_ = path_;
        if (((from_bitField0_ & 0x00000004) != 0)) {
          if (sinceBuilder_ == null) {
            result.since_ = since_;
          } else {
            result.since_ = sinceBuilder_.build();
          }
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.databricks.api.proto.databricks.Databricks.HttpEndpoint) {
          return mergeFrom((com.databricks.api.proto.databricks.Databricks.HttpEndpoint)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.databricks.api.proto.databricks.Databricks.HttpEndpoint other) {
        if (other == com.databricks.api.proto.databricks.Databricks.HttpEndpoint.getDefaultInstance()) return this;
        if (other.hasMethod()) {
          bitField0_ |= 0x00000001;
          method_ = other.method_;
          onChanged();
        }
        if (other.hasPath()) {
          bitField0_ |= 0x00000002;
          path_ = other.path_;
          onChanged();
        }
        if (other.hasSince()) {
          mergeSince(other.getSince());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.databricks.api.proto.databricks.Databricks.HttpEndpoint parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (com.databricks.api.proto.databricks.Databricks.HttpEndpoint) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object method_ = "POST";
      /**
       * <pre>
       * HTTP method like POST or GET.
       * </pre>
       *
       * <code>optional string method = 1 [default = "POST"];</code>
       * @return Whether the method field is set.
       */
      public boolean hasMethod() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * HTTP method like POST or GET.
       * </pre>
       *
       * <code>optional string method = 1 [default = "POST"];</code>
       * @return The method.
       */
      public java.lang.String getMethod() {
        java.lang.Object ref = method_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            method_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * HTTP method like POST or GET.
       * </pre>
       *
       * <code>optional string method = 1 [default = "POST"];</code>
       * @return The bytes for method.
       */
      public com.google.protobuf.ByteString
          getMethodBytes() {
        java.lang.Object ref = method_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          method_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * HTTP method like POST or GET.
       * </pre>
       *
       * <code>optional string method = 1 [default = "POST"];</code>
       * @param value The method to set.
       * @return This builder for chaining.
       */
      public Builder setMethod(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        method_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * HTTP method like POST or GET.
       * </pre>
       *
       * <code>optional string method = 1 [default = "POST"];</code>
       * @return This builder for chaining.
       */
      public Builder clearMethod() {
        bitField0_ = (bitField0_ & ~0x00000001);
        method_ = getDefaultInstance().getMethod();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * HTTP method like POST or GET.
       * </pre>
       *
       * <code>optional string method = 1 [default = "POST"];</code>
       * @param value The bytes for method to set.
       * @return This builder for chaining.
       */
      public Builder setMethodBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        method_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object path_ = "";
      /**
       * <pre>
       * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
       * </pre>
       *
       * <code>optional string path = 2;</code>
       * @return Whether the path field is set.
       */
      public boolean hasPath() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
       * </pre>
       *
       * <code>optional string path = 2;</code>
       * @return The path.
       */
      public java.lang.String getPath() {
        java.lang.Object ref = path_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            path_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
       * </pre>
       *
       * <code>optional string path = 2;</code>
       * @return The bytes for path.
       */
      public com.google.protobuf.ByteString
          getPathBytes() {
        java.lang.Object ref = path_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          path_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
       * </pre>
       *
       * <code>optional string path = 2;</code>
       * @param value The path to set.
       * @return This builder for chaining.
       */
      public Builder setPath(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        path_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
       * </pre>
       *
       * <code>optional string path = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearPath() {
        bitField0_ = (bitField0_ & ~0x00000002);
        path_ = getDefaultInstance().getPath();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
       * </pre>
       *
       * <code>optional string path = 2;</code>
       * @param value The bytes for path to set.
       * @return This builder for chaining.
       */
      public Builder setPathBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        path_ = value;
        onChanged();
        return this;
      }

      private com.databricks.api.proto.databricks.Databricks.ApiVersion since_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.databricks.api.proto.databricks.Databricks.ApiVersion, com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder, com.databricks.api.proto.databricks.Databricks.ApiVersionOrBuilder> sinceBuilder_;
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       * @return Whether the since field is set.
       */
      public boolean hasSince() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       * @return The since.
       */
      public com.databricks.api.proto.databricks.Databricks.ApiVersion getSince() {
        if (sinceBuilder_ == null) {
          return since_ == null ? com.databricks.api.proto.databricks.Databricks.ApiVersion.getDefaultInstance() : since_;
        } else {
          return sinceBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      public Builder setSince(com.databricks.api.proto.databricks.Databricks.ApiVersion value) {
        if (sinceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          since_ = value;
          onChanged();
        } else {
          sinceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      public Builder setSince(
          com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder builderForValue) {
        if (sinceBuilder_ == null) {
          since_ = builderForValue.build();
          onChanged();
        } else {
          sinceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      public Builder mergeSince(com.databricks.api.proto.databricks.Databricks.ApiVersion value) {
        if (sinceBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
              since_ != null &&
              since_ != com.databricks.api.proto.databricks.Databricks.ApiVersion.getDefaultInstance()) {
            since_ =
              com.databricks.api.proto.databricks.Databricks.ApiVersion.newBuilder(since_).mergeFrom(value).buildPartial();
          } else {
            since_ = value;
          }
          onChanged();
        } else {
          sinceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      public Builder clearSince() {
        if (sinceBuilder_ == null) {
          since_ = null;
          onChanged();
        } else {
          sinceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder getSinceBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getSinceFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.ApiVersionOrBuilder getSinceOrBuilder() {
        if (sinceBuilder_ != null) {
          return sinceBuilder_.getMessageOrBuilder();
        } else {
          return since_ == null ?
              com.databricks.api.proto.databricks.Databricks.ApiVersion.getDefaultInstance() : since_;
        }
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.databricks.api.proto.databricks.Databricks.ApiVersion, com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder, com.databricks.api.proto.databricks.Databricks.ApiVersionOrBuilder> 
          getSinceFieldBuilder() {
        if (sinceBuilder_ == null) {
          sinceBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.databricks.api.proto.databricks.Databricks.ApiVersion, com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder, com.databricks.api.proto.databricks.Databricks.ApiVersionOrBuilder>(
                  getSince(),
                  getParentForChildren(),
                  isClean());
          since_ = null;
        }
        return sinceBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:mlflow.HttpEndpoint)
    }

    // @@protoc_insertion_point(class_scope:mlflow.HttpEndpoint)
    private static final com.databricks.api.proto.databricks.Databricks.HttpEndpoint DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.databricks.api.proto.databricks.Databricks.HttpEndpoint();
    }

    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<HttpEndpoint>
        PARSER = new com.google.protobuf.AbstractParser<HttpEndpoint>() {
      @java.lang.Override
      public HttpEndpoint parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new HttpEndpoint(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<HttpEndpoint> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<HttpEndpoint> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.HttpEndpoint getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ApiVersionOrBuilder extends
      // @@protoc_insertion_point(interface_extends:mlflow.ApiVersion)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int32 major = 1;</code>
     * @return Whether the major field is set.
     */
    boolean hasMajor();
    /**
     * <code>optional int32 major = 1;</code>
     * @return The major.
     */
    int getMajor();

    /**
     * <code>optional int32 minor = 2;</code>
     * @return Whether the minor field is set.
     */
    boolean hasMinor();
    /**
     * <code>optional int32 minor = 2;</code>
     * @return The minor.
     */
    int getMinor();
  }
  /**
   * Protobuf type {@code mlflow.ApiVersion}
   */
  public static final class ApiVersion extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:mlflow.ApiVersion)
      ApiVersionOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ApiVersion.newBuilder() to construct.
    private ApiVersion(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ApiVersion() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ApiVersion();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ApiVersion(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              major_ = input.readInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              minor_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_ApiVersion_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_ApiVersion_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.databricks.api.proto.databricks.Databricks.ApiVersion.class, com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder.class);
    }

    private int bitField0_;
    public static final int MAJOR_FIELD_NUMBER = 1;
    private int major_;
    /**
     * <code>optional int32 major = 1;</code>
     * @return Whether the major field is set.
     */
    @java.lang.Override
    public boolean hasMajor() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional int32 major = 1;</code>
     * @return The major.
     */
    @java.lang.Override
    public int getMajor() {
      return major_;
    }

    public static final int MINOR_FIELD_NUMBER = 2;
    private int minor_;
    /**
     * <code>optional int32 minor = 2;</code>
     * @return Whether the minor field is set.
     */
    @java.lang.Override
    public boolean hasMinor() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional int32 minor = 2;</code>
     * @return The minor.
     */
    @java.lang.Override
    public int getMinor() {
      return minor_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(1, major_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeInt32(2, minor_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, major_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, minor_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.databricks.api.proto.databricks.Databricks.ApiVersion)) {
        return super.equals(obj);
      }
      com.databricks.api.proto.databricks.Databricks.ApiVersion other = (com.databricks.api.proto.databricks.Databricks.ApiVersion) obj;

      if (hasMajor() != other.hasMajor()) return false;
      if (hasMajor()) {
        if (getMajor()
            != other.getMajor()) return false;
      }
      if (hasMinor() != other.hasMinor()) return false;
      if (hasMinor()) {
        if (getMinor()
            != other.getMinor()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasMajor()) {
        hash = (37 * hash) + MAJOR_FIELD_NUMBER;
        hash = (53 * hash) + getMajor();
      }
      if (hasMinor()) {
        hash = (37 * hash) + MINOR_FIELD_NUMBER;
        hash = (53 * hash) + getMinor();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.databricks.api.proto.databricks.Databricks.ApiVersion prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code mlflow.ApiVersion}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:mlflow.ApiVersion)
        com.databricks.api.proto.databricks.Databricks.ApiVersionOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_ApiVersion_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_ApiVersion_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.databricks.api.proto.databricks.Databricks.ApiVersion.class, com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder.class);
      }

      // Construct using com.databricks.api.proto.databricks.Databricks.ApiVersion.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        major_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        minor_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_ApiVersion_descriptor;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.ApiVersion getDefaultInstanceForType() {
        return com.databricks.api.proto.databricks.Databricks.ApiVersion.getDefaultInstance();
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.ApiVersion build() {
        com.databricks.api.proto.databricks.Databricks.ApiVersion result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.ApiVersion buildPartial() {
        com.databricks.api.proto.databricks.Databricks.ApiVersion result = new com.databricks.api.proto.databricks.Databricks.ApiVersion(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.major_ = major_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.minor_ = minor_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.databricks.api.proto.databricks.Databricks.ApiVersion) {
          return mergeFrom((com.databricks.api.proto.databricks.Databricks.ApiVersion)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.databricks.api.proto.databricks.Databricks.ApiVersion other) {
        if (other == com.databricks.api.proto.databricks.Databricks.ApiVersion.getDefaultInstance()) return this;
        if (other.hasMajor()) {
          setMajor(other.getMajor());
        }
        if (other.hasMinor()) {
          setMinor(other.getMinor());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.databricks.api.proto.databricks.Databricks.ApiVersion parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (com.databricks.api.proto.databricks.Databricks.ApiVersion) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int major_ ;
      /**
       * <code>optional int32 major = 1;</code>
       * @return Whether the major field is set.
       */
      @java.lang.Override
      public boolean hasMajor() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional int32 major = 1;</code>
       * @return The major.
       */
      @java.lang.Override
      public int getMajor() {
        return major_;
      }
      /**
       * <code>optional int32 major = 1;</code>
       * @param value The major to set.
       * @return This builder for chaining.
       */
      public Builder setMajor(int value) {
        bitField0_ |= 0x00000001;
        major_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 major = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearMajor() {
        bitField0_ = (bitField0_ & ~0x00000001);
        major_ = 0;
        onChanged();
        return this;
      }

      private int minor_ ;
      /**
       * <code>optional int32 minor = 2;</code>
       * @return Whether the minor field is set.
       */
      @java.lang.Override
      public boolean hasMinor() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional int32 minor = 2;</code>
       * @return The minor.
       */
      @java.lang.Override
      public int getMinor() {
        return minor_;
      }
      /**
       * <code>optional int32 minor = 2;</code>
       * @param value The minor to set.
       * @return This builder for chaining.
       */
      public Builder setMinor(int value) {
        bitField0_ |= 0x00000002;
        minor_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 minor = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearMinor() {
        bitField0_ = (bitField0_ & ~0x00000002);
        minor_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:mlflow.ApiVersion)
    }

    // @@protoc_insertion_point(class_scope:mlflow.ApiVersion)
    private static final com.databricks.api.proto.databricks.Databricks.ApiVersion DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.databricks.api.proto.databricks.Databricks.ApiVersion();
    }

    public static com.databricks.api.proto.databricks.Databricks.ApiVersion getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ApiVersion>
        PARSER = new com.google.protobuf.AbstractParser<ApiVersion>() {
      @java.lang.Override
      public ApiVersion parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApiVersion(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ApiVersion> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ApiVersion> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.ApiVersion getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RateLimitOrBuilder extends
      // @@protoc_insertion_point(interface_extends:mlflow.RateLimit)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * The maximum burst of API requests allowed for a single endpoint. In the context of the
     * token bucket algorithm, this constant represents the total capacity of the token bucket.
     * </pre>
     *
     * <code>optional int64 max_burst = 1;</code>
     * @return Whether the maxBurst field is set.
     */
    boolean hasMaxBurst();
    /**
     * <pre>
     * The maximum burst of API requests allowed for a single endpoint. In the context of the
     * token bucket algorithm, this constant represents the total capacity of the token bucket.
     * </pre>
     *
     * <code>optional int64 max_burst = 1;</code>
     * @return The maxBurst.
     */
    long getMaxBurst();

    /**
     * <pre>
     * The maximum sustained request per second limit for a single endpoint. In the context of the,
     * token bucket algorithm, this constant represents the rate at which the token bucket fills.
     * </pre>
     *
     * <code>optional int64 max_sustained_per_second = 2;</code>
     * @return Whether the maxSustainedPerSecond field is set.
     */
    boolean hasMaxSustainedPerSecond();
    /**
     * <pre>
     * The maximum sustained request per second limit for a single endpoint. In the context of the,
     * token bucket algorithm, this constant represents the rate at which the token bucket fills.
     * </pre>
     *
     * <code>optional int64 max_sustained_per_second = 2;</code>
     * @return The maxSustainedPerSecond.
     */
    long getMaxSustainedPerSecond();
  }
  /**
   * <pre>
   * API rate limits applied to RPCs coming from the API Proxy. The rate limits are applied on a
   * per organization basis.
   * </pre>
   *
   * Protobuf type {@code mlflow.RateLimit}
   */
  public static final class RateLimit extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:mlflow.RateLimit)
      RateLimitOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RateLimit.newBuilder() to construct.
    private RateLimit(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RateLimit() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RateLimit();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RateLimit(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              maxBurst_ = input.readInt64();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              maxSustainedPerSecond_ = input.readInt64();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_RateLimit_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_RateLimit_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.databricks.api.proto.databricks.Databricks.RateLimit.class, com.databricks.api.proto.databricks.Databricks.RateLimit.Builder.class);
    }

    private int bitField0_;
    public static final int MAX_BURST_FIELD_NUMBER = 1;
    private long maxBurst_;
    /**
     * <pre>
     * The maximum burst of API requests allowed for a single endpoint. In the context of the
     * token bucket algorithm, this constant represents the total capacity of the token bucket.
     * </pre>
     *
     * <code>optional int64 max_burst = 1;</code>
     * @return Whether the maxBurst field is set.
     */
    @java.lang.Override
    public boolean hasMaxBurst() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * The maximum burst of API requests allowed for a single endpoint. In the context of the
     * token bucket algorithm, this constant represents the total capacity of the token bucket.
     * </pre>
     *
     * <code>optional int64 max_burst = 1;</code>
     * @return The maxBurst.
     */
    @java.lang.Override
    public long getMaxBurst() {
      return maxBurst_;
    }

    public static final int MAX_SUSTAINED_PER_SECOND_FIELD_NUMBER = 2;
    private long maxSustainedPerSecond_;
    /**
     * <pre>
     * The maximum sustained request per second limit for a single endpoint. In the context of the,
     * token bucket algorithm, this constant represents the rate at which the token bucket fills.
     * </pre>
     *
     * <code>optional int64 max_sustained_per_second = 2;</code>
     * @return Whether the maxSustainedPerSecond field is set.
     */
    @java.lang.Override
    public boolean hasMaxSustainedPerSecond() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * The maximum sustained request per second limit for a single endpoint. In the context of the,
     * token bucket algorithm, this constant represents the rate at which the token bucket fills.
     * </pre>
     *
     * <code>optional int64 max_sustained_per_second = 2;</code>
     * @return The maxSustainedPerSecond.
     */
    @java.lang.Override
    public long getMaxSustainedPerSecond() {
      return maxSustainedPerSecond_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt64(1, maxBurst_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeInt64(2, maxSustainedPerSecond_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(1, maxBurst_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, maxSustainedPerSecond_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.databricks.api.proto.databricks.Databricks.RateLimit)) {
        return super.equals(obj);
      }
      com.databricks.api.proto.databricks.Databricks.RateLimit other = (com.databricks.api.proto.databricks.Databricks.RateLimit) obj;

      if (hasMaxBurst() != other.hasMaxBurst()) return false;
      if (hasMaxBurst()) {
        if (getMaxBurst()
            != other.getMaxBurst()) return false;
      }
      if (hasMaxSustainedPerSecond() != other.hasMaxSustainedPerSecond()) return false;
      if (hasMaxSustainedPerSecond()) {
        if (getMaxSustainedPerSecond()
            != other.getMaxSustainedPerSecond()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasMaxBurst()) {
        hash = (37 * hash) + MAX_BURST_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getMaxBurst());
      }
      if (hasMaxSustainedPerSecond()) {
        hash = (37 * hash) + MAX_SUSTAINED_PER_SECOND_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getMaxSustainedPerSecond());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.databricks.api.proto.databricks.Databricks.RateLimit prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * API rate limits applied to RPCs coming from the API Proxy. The rate limits are applied on a
     * per organization basis.
     * </pre>
     *
     * Protobuf type {@code mlflow.RateLimit}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:mlflow.RateLimit)
        com.databricks.api.proto.databricks.Databricks.RateLimitOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_RateLimit_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_RateLimit_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.databricks.api.proto.databricks.Databricks.RateLimit.class, com.databricks.api.proto.databricks.Databricks.RateLimit.Builder.class);
      }

      // Construct using com.databricks.api.proto.databricks.Databricks.RateLimit.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        maxBurst_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        maxSustainedPerSecond_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_RateLimit_descriptor;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.RateLimit getDefaultInstanceForType() {
        return com.databricks.api.proto.databricks.Databricks.RateLimit.getDefaultInstance();
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.RateLimit build() {
        com.databricks.api.proto.databricks.Databricks.RateLimit result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.RateLimit buildPartial() {
        com.databricks.api.proto.databricks.Databricks.RateLimit result = new com.databricks.api.proto.databricks.Databricks.RateLimit(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.maxBurst_ = maxBurst_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.maxSustainedPerSecond_ = maxSustainedPerSecond_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.databricks.api.proto.databricks.Databricks.RateLimit) {
          return mergeFrom((com.databricks.api.proto.databricks.Databricks.RateLimit)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.databricks.api.proto.databricks.Databricks.RateLimit other) {
        if (other == com.databricks.api.proto.databricks.Databricks.RateLimit.getDefaultInstance()) return this;
        if (other.hasMaxBurst()) {
          setMaxBurst(other.getMaxBurst());
        }
        if (other.hasMaxSustainedPerSecond()) {
          setMaxSustainedPerSecond(other.getMaxSustainedPerSecond());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.databricks.api.proto.databricks.Databricks.RateLimit parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (com.databricks.api.proto.databricks.Databricks.RateLimit) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private long maxBurst_ ;
      /**
       * <pre>
       * The maximum burst of API requests allowed for a single endpoint. In the context of the
       * token bucket algorithm, this constant represents the total capacity of the token bucket.
       * </pre>
       *
       * <code>optional int64 max_burst = 1;</code>
       * @return Whether the maxBurst field is set.
       */
      @java.lang.Override
      public boolean hasMaxBurst() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * The maximum burst of API requests allowed for a single endpoint. In the context of the
       * token bucket algorithm, this constant represents the total capacity of the token bucket.
       * </pre>
       *
       * <code>optional int64 max_burst = 1;</code>
       * @return The maxBurst.
       */
      @java.lang.Override
      public long getMaxBurst() {
        return maxBurst_;
      }
      /**
       * <pre>
       * The maximum burst of API requests allowed for a single endpoint. In the context of the
       * token bucket algorithm, this constant represents the total capacity of the token bucket.
       * </pre>
       *
       * <code>optional int64 max_burst = 1;</code>
       * @param value The maxBurst to set.
       * @return This builder for chaining.
       */
      public Builder setMaxBurst(long value) {
        bitField0_ |= 0x00000001;
        maxBurst_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The maximum burst of API requests allowed for a single endpoint. In the context of the
       * token bucket algorithm, this constant represents the total capacity of the token bucket.
       * </pre>
       *
       * <code>optional int64 max_burst = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearMaxBurst() {
        bitField0_ = (bitField0_ & ~0x00000001);
        maxBurst_ = 0L;
        onChanged();
        return this;
      }

      private long maxSustainedPerSecond_ ;
      /**
       * <pre>
       * The maximum sustained request per second limit for a single endpoint. In the context of the,
       * token bucket algorithm, this constant represents the rate at which the token bucket fills.
       * </pre>
       *
       * <code>optional int64 max_sustained_per_second = 2;</code>
       * @return Whether the maxSustainedPerSecond field is set.
       */
      @java.lang.Override
      public boolean hasMaxSustainedPerSecond() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * The maximum sustained request per second limit for a single endpoint. In the context of the,
       * token bucket algorithm, this constant represents the rate at which the token bucket fills.
       * </pre>
       *
       * <code>optional int64 max_sustained_per_second = 2;</code>
       * @return The maxSustainedPerSecond.
       */
      @java.lang.Override
      public long getMaxSustainedPerSecond() {
        return maxSustainedPerSecond_;
      }
      /**
       * <pre>
       * The maximum sustained request per second limit for a single endpoint. In the context of the,
       * token bucket algorithm, this constant represents the rate at which the token bucket fills.
       * </pre>
       *
       * <code>optional int64 max_sustained_per_second = 2;</code>
       * @param value The maxSustainedPerSecond to set.
       * @return This builder for chaining.
       */
      public Builder setMaxSustainedPerSecond(long value) {
        bitField0_ |= 0x00000002;
        maxSustainedPerSecond_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The maximum sustained request per second limit for a single endpoint. In the context of the,
       * token bucket algorithm, this constant represents the rate at which the token bucket fills.
       * </pre>
       *
       * <code>optional int64 max_sustained_per_second = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearMaxSustainedPerSecond() {
        bitField0_ = (bitField0_ & ~0x00000002);
        maxSustainedPerSecond_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:mlflow.RateLimit)
    }

    // @@protoc_insertion_point(class_scope:mlflow.RateLimit)
    private static final com.databricks.api.proto.databricks.Databricks.RateLimit DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.databricks.api.proto.databricks.Databricks.RateLimit();
    }

    public static com.databricks.api.proto.databricks.Databricks.RateLimit getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<RateLimit>
        PARSER = new com.google.protobuf.AbstractParser<RateLimit>() {
      @java.lang.Override
      public RateLimit parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new RateLimit(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<RateLimit> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<RateLimit> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.RateLimit getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DocumentationMetadataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:mlflow.DocumentationMetadata)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * The string of documentation attached to this particular item.
     * </pre>
     *
     * <code>optional string docstring = 1;</code>
     * @return Whether the docstring field is set.
     */
    boolean hasDocstring();
    /**
     * <pre>
     * The string of documentation attached to this particular item.
     * </pre>
     *
     * <code>optional string docstring = 1;</code>
     * @return The docstring.
     */
    java.lang.String getDocstring();
    /**
     * <pre>
     * The string of documentation attached to this particular item.
     * </pre>
     *
     * <code>optional string docstring = 1;</code>
     * @return The bytes for docstring.
     */
    com.google.protobuf.ByteString
        getDocstringBytes();

    /**
     * <pre>
     * The string of documentation that is *before* this item. This only makes sense for top-level
     * items such as (top-level) messages, (top-level) enumerations, or services. In all other
     * cases, this string is empty.
     * </pre>
     *
     * <code>optional string lead_doc = 2;</code>
     * @return Whether the leadDoc field is set.
     */
    boolean hasLeadDoc();
    /**
     * <pre>
     * The string of documentation that is *before* this item. This only makes sense for top-level
     * items such as (top-level) messages, (top-level) enumerations, or services. In all other
     * cases, this string is empty.
     * </pre>
     *
     * <code>optional string lead_doc = 2;</code>
     * @return The leadDoc.
     */
    java.lang.String getLeadDoc();
    /**
     * <pre>
     * The string of documentation that is *before* this item. This only makes sense for top-level
     * items such as (top-level) messages, (top-level) enumerations, or services. In all other
     * cases, this string is empty.
     * </pre>
     *
     * <code>optional string lead_doc = 2;</code>
     * @return The bytes for leadDoc.
     */
    com.google.protobuf.ByteString
        getLeadDocBytes();

    /**
     * <pre>
     * The visibility level when the docstring was generated.
     * The documentation extractor builds multiple versions of the documentation, one for each
     * visibility level. The documentation is then generated for each visibility level.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 3;</code>
     * @return Whether the visibility field is set.
     */
    boolean hasVisibility();
    /**
     * <pre>
     * The visibility level when the docstring was generated.
     * The documentation extractor builds multiple versions of the documentation, one for each
     * visibility level. The documentation is then generated for each visibility level.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 3;</code>
     * @return The visibility.
     */
    com.databricks.api.proto.databricks.Databricks.Visibility getVisibility();

    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     * @return A list containing the originalProtoPath.
     */
    java.util.List<java.lang.String>
        getOriginalProtoPathList();
    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     * @return The count of originalProtoPath.
     */
    int getOriginalProtoPathCount();
    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     * @param index The index of the element to return.
     * @return The originalProtoPath at the given index.
     */
    java.lang.String getOriginalProtoPath(int index);
    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     * @param index The index of the value to return.
     * @return The bytes of the originalProtoPath at the given index.
     */
    com.google.protobuf.ByteString
        getOriginalProtoPathBytes(int index);

    /**
     * <pre>
     * The location (line number) of the start of the documentation. This is required to keep the
     * pieces of documentation sorted.
     * </pre>
     *
     * <code>optional int32 position = 5;</code>
     * @return Whether the position field is set.
     */
    boolean hasPosition();
    /**
     * <pre>
     * The location (line number) of the start of the documentation. This is required to keep the
     * pieces of documentation sorted.
     * </pre>
     *
     * <code>optional int32 position = 5;</code>
     * @return The position.
     */
    int getPosition();
  }
  /**
   * <pre>
   * A block of documentation that is added to the AST after parsing the original protocol buffer.
   * </pre>
   *
   * Protobuf type {@code mlflow.DocumentationMetadata}
   */
  public static final class DocumentationMetadata extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:mlflow.DocumentationMetadata)
      DocumentationMetadataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DocumentationMetadata.newBuilder() to construct.
    private DocumentationMetadata(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DocumentationMetadata() {
      docstring_ = "";
      leadDoc_ = "";
      visibility_ = 1;
      originalProtoPath_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DocumentationMetadata();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DocumentationMetadata(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              docstring_ = bs;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              leadDoc_ = bs;
              break;
            }
            case 24: {
              int rawValue = input.readEnum();
                @SuppressWarnings("deprecation")
              com.databricks.api.proto.databricks.Databricks.Visibility value = com.databricks.api.proto.databricks.Databricks.Visibility.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(3, rawValue);
              } else {
                bitField0_ |= 0x00000004;
                visibility_ = rawValue;
              }
              break;
            }
            case 34: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000008) != 0)) {
                originalProtoPath_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000008;
              }
              originalProtoPath_.add(bs);
              break;
            }
            case 40: {
              bitField0_ |= 0x00000008;
              position_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000008) != 0)) {
          originalProtoPath_ = originalProtoPath_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DocumentationMetadata_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DocumentationMetadata_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class, com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.Builder.class);
    }

    private int bitField0_;
    public static final int DOCSTRING_FIELD_NUMBER = 1;
    private volatile java.lang.Object docstring_;
    /**
     * <pre>
     * The string of documentation attached to this particular item.
     * </pre>
     *
     * <code>optional string docstring = 1;</code>
     * @return Whether the docstring field is set.
     */
    @java.lang.Override
    public boolean hasDocstring() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * The string of documentation attached to this particular item.
     * </pre>
     *
     * <code>optional string docstring = 1;</code>
     * @return The docstring.
     */
    @java.lang.Override
    public java.lang.String getDocstring() {
      java.lang.Object ref = docstring_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          docstring_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * The string of documentation attached to this particular item.
     * </pre>
     *
     * <code>optional string docstring = 1;</code>
     * @return The bytes for docstring.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getDocstringBytes() {
      java.lang.Object ref = docstring_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        docstring_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int LEAD_DOC_FIELD_NUMBER = 2;
    private volatile java.lang.Object leadDoc_;
    /**
     * <pre>
     * The string of documentation that is *before* this item. This only makes sense for top-level
     * items such as (top-level) messages, (top-level) enumerations, or services. In all other
     * cases, this string is empty.
     * </pre>
     *
     * <code>optional string lead_doc = 2;</code>
     * @return Whether the leadDoc field is set.
     */
    @java.lang.Override
    public boolean hasLeadDoc() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * The string of documentation that is *before* this item. This only makes sense for top-level
     * items such as (top-level) messages, (top-level) enumerations, or services. In all other
     * cases, this string is empty.
     * </pre>
     *
     * <code>optional string lead_doc = 2;</code>
     * @return The leadDoc.
     */
    @java.lang.Override
    public java.lang.String getLeadDoc() {
      java.lang.Object ref = leadDoc_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          leadDoc_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * The string of documentation that is *before* this item. This only makes sense for top-level
     * items such as (top-level) messages, (top-level) enumerations, or services. In all other
     * cases, this string is empty.
     * </pre>
     *
     * <code>optional string lead_doc = 2;</code>
     * @return The bytes for leadDoc.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getLeadDocBytes() {
      java.lang.Object ref = leadDoc_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        leadDoc_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int VISIBILITY_FIELD_NUMBER = 3;
    private int visibility_;
    /**
     * <pre>
     * The visibility level when the docstring was generated.
     * The documentation extractor builds multiple versions of the documentation, one for each
     * visibility level. The documentation is then generated for each visibility level.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 3;</code>
     * @return Whether the visibility field is set.
     */
    @java.lang.Override public boolean hasVisibility() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * The visibility level when the docstring was generated.
     * The documentation extractor builds multiple versions of the documentation, one for each
     * visibility level. The documentation is then generated for each visibility level.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 3;</code>
     * @return The visibility.
     */
    @java.lang.Override public com.databricks.api.proto.databricks.Databricks.Visibility getVisibility() {
      @SuppressWarnings("deprecation")
      com.databricks.api.proto.databricks.Databricks.Visibility result = com.databricks.api.proto.databricks.Databricks.Visibility.valueOf(visibility_);
      return result == null ? com.databricks.api.proto.databricks.Databricks.Visibility.PUBLIC : result;
    }

    public static final int ORIGINAL_PROTO_PATH_FIELD_NUMBER = 4;
    private com.google.protobuf.LazyStringList originalProtoPath_;
    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     * @return A list containing the originalProtoPath.
     */
    public com.google.protobuf.ProtocolStringList
        getOriginalProtoPathList() {
      return originalProtoPath_;
    }
    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     * @return The count of originalProtoPath.
     */
    public int getOriginalProtoPathCount() {
      return originalProtoPath_.size();
    }
    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     * @param index The index of the element to return.
     * @return The originalProtoPath at the given index.
     */
    public java.lang.String getOriginalProtoPath(int index) {
      return originalProtoPath_.get(index);
    }
    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     * @param index The index of the value to return.
     * @return The bytes of the originalProtoPath at the given index.
     */
    public com.google.protobuf.ByteString
        getOriginalProtoPathBytes(int index) {
      return originalProtoPath_.getByteString(index);
    }

    public static final int POSITION_FIELD_NUMBER = 5;
    private int position_;
    /**
     * <pre>
     * The location (line number) of the start of the documentation. This is required to keep the
     * pieces of documentation sorted.
     * </pre>
     *
     * <code>optional int32 position = 5;</code>
     * @return Whether the position field is set.
     */
    @java.lang.Override
    public boolean hasPosition() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <pre>
     * The location (line number) of the start of the documentation. This is required to keep the
     * pieces of documentation sorted.
     * </pre>
     *
     * <code>optional int32 position = 5;</code>
     * @return The position.
     */
    @java.lang.Override
    public int getPosition() {
      return position_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, docstring_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, leadDoc_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeEnum(3, visibility_);
      }
      for (int i = 0; i < originalProtoPath_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, originalProtoPath_.getRaw(i));
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeInt32(5, position_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, docstring_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, leadDoc_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(3, visibility_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < originalProtoPath_.size(); i++) {
          dataSize += computeStringSizeNoTag(originalProtoPath_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getOriginalProtoPathList().size();
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(5, position_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.databricks.api.proto.databricks.Databricks.DocumentationMetadata)) {
        return super.equals(obj);
      }
      com.databricks.api.proto.databricks.Databricks.DocumentationMetadata other = (com.databricks.api.proto.databricks.Databricks.DocumentationMetadata) obj;

      if (hasDocstring() != other.hasDocstring()) return false;
      if (hasDocstring()) {
        if (!getDocstring()
            .equals(other.getDocstring())) return false;
      }
      if (hasLeadDoc() != other.hasLeadDoc()) return false;
      if (hasLeadDoc()) {
        if (!getLeadDoc()
            .equals(other.getLeadDoc())) return false;
      }
      if (hasVisibility() != other.hasVisibility()) return false;
      if (hasVisibility()) {
        if (visibility_ != other.visibility_) return false;
      }
      if (!getOriginalProtoPathList()
          .equals(other.getOriginalProtoPathList())) return false;
      if (hasPosition() != other.hasPosition()) return false;
      if (hasPosition()) {
        if (getPosition()
            != other.getPosition()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasDocstring()) {
        hash = (37 * hash) + DOCSTRING_FIELD_NUMBER;
        hash = (53 * hash) + getDocstring().hashCode();
      }
      if (hasLeadDoc()) {
        hash = (37 * hash) + LEAD_DOC_FIELD_NUMBER;
        hash = (53 * hash) + getLeadDoc().hashCode();
      }
      if (hasVisibility()) {
        hash = (37 * hash) + VISIBILITY_FIELD_NUMBER;
        hash = (53 * hash) + visibility_;
      }
      if (getOriginalProtoPathCount() > 0) {
        hash = (37 * hash) + ORIGINAL_PROTO_PATH_FIELD_NUMBER;
        hash = (53 * hash) + getOriginalProtoPathList().hashCode();
      }
      if (hasPosition()) {
        hash = (37 * hash) + POSITION_FIELD_NUMBER;
        hash = (53 * hash) + getPosition();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.databricks.api.proto.databricks.Databricks.DocumentationMetadata prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * A block of documentation that is added to the AST after parsing the original protocol buffer.
     * </pre>
     *
     * Protobuf type {@code mlflow.DocumentationMetadata}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:mlflow.DocumentationMetadata)
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DocumentationMetadata_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DocumentationMetadata_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class, com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.Builder.class);
      }

      // Construct using com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        docstring_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        leadDoc_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        visibility_ = 1;
        bitField0_ = (bitField0_ & ~0x00000004);
        originalProtoPath_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        position_ = 0;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DocumentationMetadata_descriptor;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DocumentationMetadata getDefaultInstanceForType() {
        return com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance();
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DocumentationMetadata build() {
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DocumentationMetadata buildPartial() {
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata result = new com.databricks.api.proto.databricks.Databricks.DocumentationMetadata(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.docstring_ = docstring_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          to_bitField0_ |= 0x00000002;
        }
        result.leadDoc_ = leadDoc_;
        if (((from_bitField0_ & 0x00000004) != 0)) {
          to_bitField0_ |= 0x00000004;
        }
        result.visibility_ = visibility_;
        if (((bitField0_ & 0x00000008) != 0)) {
          originalProtoPath_ = originalProtoPath_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000008);
        }
        result.originalProtoPath_ = originalProtoPath_;
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.position_ = position_;
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.databricks.api.proto.databricks.Databricks.DocumentationMetadata) {
          return mergeFrom((com.databricks.api.proto.databricks.Databricks.DocumentationMetadata)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.databricks.api.proto.databricks.Databricks.DocumentationMetadata other) {
        if (other == com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance()) return this;
        if (other.hasDocstring()) {
          bitField0_ |= 0x00000001;
          docstring_ = other.docstring_;
          onChanged();
        }
        if (other.hasLeadDoc()) {
          bitField0_ |= 0x00000002;
          leadDoc_ = other.leadDoc_;
          onChanged();
        }
        if (other.hasVisibility()) {
          setVisibility(other.getVisibility());
        }
        if (!other.originalProtoPath_.isEmpty()) {
          if (originalProtoPath_.isEmpty()) {
            originalProtoPath_ = other.originalProtoPath_;
            bitField0_ = (bitField0_ & ~0x00000008);
          } else {
            ensureOriginalProtoPathIsMutable();
            originalProtoPath_.addAll(other.originalProtoPath_);
          }
          onChanged();
        }
        if (other.hasPosition()) {
          setPosition(other.getPosition());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (com.databricks.api.proto.databricks.Databricks.DocumentationMetadata) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object docstring_ = "";
      /**
       * <pre>
       * The string of documentation attached to this particular item.
       * </pre>
       *
       * <code>optional string docstring = 1;</code>
       * @return Whether the docstring field is set.
       */
      public boolean hasDocstring() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * The string of documentation attached to this particular item.
       * </pre>
       *
       * <code>optional string docstring = 1;</code>
       * @return The docstring.
       */
      public java.lang.String getDocstring() {
        java.lang.Object ref = docstring_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            docstring_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * The string of documentation attached to this particular item.
       * </pre>
       *
       * <code>optional string docstring = 1;</code>
       * @return The bytes for docstring.
       */
      public com.google.protobuf.ByteString
          getDocstringBytes() {
        java.lang.Object ref = docstring_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          docstring_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * The string of documentation attached to this particular item.
       * </pre>
       *
       * <code>optional string docstring = 1;</code>
       * @param value The docstring to set.
       * @return This builder for chaining.
       */
      public Builder setDocstring(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        docstring_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The string of documentation attached to this particular item.
       * </pre>
       *
       * <code>optional string docstring = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearDocstring() {
        bitField0_ = (bitField0_ & ~0x00000001);
        docstring_ = getDefaultInstance().getDocstring();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The string of documentation attached to this particular item.
       * </pre>
       *
       * <code>optional string docstring = 1;</code>
       * @param value The bytes for docstring to set.
       * @return This builder for chaining.
       */
      public Builder setDocstringBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        docstring_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object leadDoc_ = "";
      /**
       * <pre>
       * The string of documentation that is *before* this item. This only makes sense for top-level
       * items such as (top-level) messages, (top-level) enumerations, or services. In all other
       * cases, this string is empty.
       * </pre>
       *
       * <code>optional string lead_doc = 2;</code>
       * @return Whether the leadDoc field is set.
       */
      public boolean hasLeadDoc() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * The string of documentation that is *before* this item. This only makes sense for top-level
       * items such as (top-level) messages, (top-level) enumerations, or services. In all other
       * cases, this string is empty.
       * </pre>
       *
       * <code>optional string lead_doc = 2;</code>
       * @return The leadDoc.
       */
      public java.lang.String getLeadDoc() {
        java.lang.Object ref = leadDoc_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            leadDoc_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * The string of documentation that is *before* this item. This only makes sense for top-level
       * items such as (top-level) messages, (top-level) enumerations, or services. In all other
       * cases, this string is empty.
       * </pre>
       *
       * <code>optional string lead_doc = 2;</code>
       * @return The bytes for leadDoc.
       */
      public com.google.protobuf.ByteString
          getLeadDocBytes() {
        java.lang.Object ref = leadDoc_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          leadDoc_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * The string of documentation that is *before* this item. This only makes sense for top-level
       * items such as (top-level) messages, (top-level) enumerations, or services. In all other
       * cases, this string is empty.
       * </pre>
       *
       * <code>optional string lead_doc = 2;</code>
       * @param value The leadDoc to set.
       * @return This builder for chaining.
       */
      public Builder setLeadDoc(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        leadDoc_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The string of documentation that is *before* this item. This only makes sense for top-level
       * items such as (top-level) messages, (top-level) enumerations, or services. In all other
       * cases, this string is empty.
       * </pre>
       *
       * <code>optional string lead_doc = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearLeadDoc() {
        bitField0_ = (bitField0_ & ~0x00000002);
        leadDoc_ = getDefaultInstance().getLeadDoc();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The string of documentation that is *before* this item. This only makes sense for top-level
       * items such as (top-level) messages, (top-level) enumerations, or services. In all other
       * cases, this string is empty.
       * </pre>
       *
       * <code>optional string lead_doc = 2;</code>
       * @param value The bytes for leadDoc to set.
       * @return This builder for chaining.
       */
      public Builder setLeadDocBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        leadDoc_ = value;
        onChanged();
        return this;
      }

      private int visibility_ = 1;
      /**
       * <pre>
       * The visibility level when the docstring was generated.
       * The documentation extractor builds multiple versions of the documentation, one for each
       * visibility level. The documentation is then generated for each visibility level.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 3;</code>
       * @return Whether the visibility field is set.
       */
      @java.lang.Override public boolean hasVisibility() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * The visibility level when the docstring was generated.
       * The documentation extractor builds multiple versions of the documentation, one for each
       * visibility level. The documentation is then generated for each visibility level.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 3;</code>
       * @return The visibility.
       */
      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.Visibility getVisibility() {
        @SuppressWarnings("deprecation")
        com.databricks.api.proto.databricks.Databricks.Visibility result = com.databricks.api.proto.databricks.Databricks.Visibility.valueOf(visibility_);
        return result == null ? com.databricks.api.proto.databricks.Databricks.Visibility.PUBLIC : result;
      }
      /**
       * <pre>
       * The visibility level when the docstring was generated.
       * The documentation extractor builds multiple versions of the documentation, one for each
       * visibility level. The documentation is then generated for each visibility level.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 3;</code>
       * @param value The visibility to set.
       * @return This builder for chaining.
       */
      public Builder setVisibility(com.databricks.api.proto.databricks.Databricks.Visibility value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000004;
        visibility_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The visibility level when the docstring was generated.
       * The documentation extractor builds multiple versions of the documentation, one for each
       * visibility level. The documentation is then generated for each visibility level.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearVisibility() {
        bitField0_ = (bitField0_ & ~0x00000004);
        visibility_ = 1;
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList originalProtoPath_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureOriginalProtoPathIsMutable() {
        if (!((bitField0_ & 0x00000008) != 0)) {
          originalProtoPath_ = new com.google.protobuf.LazyStringArrayList(originalProtoPath_);
          bitField0_ |= 0x00000008;
         }
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       * @return A list containing the originalProtoPath.
       */
      public com.google.protobuf.ProtocolStringList
          getOriginalProtoPathList() {
        return originalProtoPath_.getUnmodifiableView();
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       * @return The count of originalProtoPath.
       */
      public int getOriginalProtoPathCount() {
        return originalProtoPath_.size();
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       * @param index The index of the element to return.
       * @return The originalProtoPath at the given index.
       */
      public java.lang.String getOriginalProtoPath(int index) {
        return originalProtoPath_.get(index);
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       * @param index The index of the value to return.
       * @return The bytes of the originalProtoPath at the given index.
       */
      public com.google.protobuf.ByteString
          getOriginalProtoPathBytes(int index) {
        return originalProtoPath_.getByteString(index);
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       * @param index The index to set the value at.
       * @param value The originalProtoPath to set.
       * @return This builder for chaining.
       */
      public Builder setOriginalProtoPath(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureOriginalProtoPathIsMutable();
        originalProtoPath_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       * @param value The originalProtoPath to add.
       * @return This builder for chaining.
       */
      public Builder addOriginalProtoPath(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureOriginalProtoPathIsMutable();
        originalProtoPath_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       * @param values The originalProtoPath to add.
       * @return This builder for chaining.
       */
      public Builder addAllOriginalProtoPath(
          java.lang.Iterable<java.lang.String> values) {
        ensureOriginalProtoPathIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, originalProtoPath_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearOriginalProtoPath() {
        originalProtoPath_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       * @param value The bytes of the originalProtoPath to add.
       * @return This builder for chaining.
       */
      public Builder addOriginalProtoPathBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureOriginalProtoPathIsMutable();
        originalProtoPath_.add(value);
        onChanged();
        return this;
      }

      private int position_ ;
      /**
       * <pre>
       * The location (line number) of the start of the documentation. This is required to keep the
       * pieces of documentation sorted.
       * </pre>
       *
       * <code>optional int32 position = 5;</code>
       * @return Whether the position field is set.
       */
      @java.lang.Override
      public boolean hasPosition() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <pre>
       * The location (line number) of the start of the documentation. This is required to keep the
       * pieces of documentation sorted.
       * </pre>
       *
       * <code>optional int32 position = 5;</code>
       * @return The position.
       */
      @java.lang.Override
      public int getPosition() {
        return position_;
      }
      /**
       * <pre>
       * The location (line number) of the start of the documentation. This is required to keep the
       * pieces of documentation sorted.
       * </pre>
       *
       * <code>optional int32 position = 5;</code>
       * @param value The position to set.
       * @return This builder for chaining.
       */
      public Builder setPosition(int value) {
        bitField0_ |= 0x00000010;
        position_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The location (line number) of the start of the documentation. This is required to keep the
       * pieces of documentation sorted.
       * </pre>
       *
       * <code>optional int32 position = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearPosition() {
        bitField0_ = (bitField0_ & ~0x00000010);
        position_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:mlflow.DocumentationMetadata)
    }

    // @@protoc_insertion_point(class_scope:mlflow.DocumentationMetadata)
    private static final com.databricks.api.proto.databricks.Databricks.DocumentationMetadata DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.databricks.api.proto.databricks.Databricks.DocumentationMetadata();
    }

    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<DocumentationMetadata>
        PARSER = new com.google.protobuf.AbstractParser<DocumentationMetadata>() {
      @java.lang.Override
      public DocumentationMetadata parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DocumentationMetadata(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DocumentationMetadata> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DocumentationMetadata> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.DocumentationMetadata getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public static final int VISIBILITY_FIELD_NUMBER = 51310;
  /**
   * <pre>
   * Indicates an overriding visibility for this field. This can only reduce the visibility;
   * a public field in an internal API will not have an effect.
   * </pre>
   *
   * <code>extend .google.protobuf.FieldOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.FieldOptions,
      com.databricks.api.proto.databricks.Databricks.Visibility> visibility = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.Visibility.class,
        null);
  public static final int VALIDATE_REQUIRED_FIELD_NUMBER = 51311;
  /**
   * <pre>
   * This annotation indicates that certain fields must be supplied for the request to be carried
   * out successfully.
   * A request field may go from being required to optional over time, but a field may not
   * go from being optional to required, for backwards compatiblity reasons.
   * Request RPCs are validated automatically prior to processing for required fields, but
   * returned values are not validated in any way.
   * </pre>
   *
   * <code>extend .google.protobuf.FieldOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.FieldOptions,
      java.lang.Boolean> validateRequired = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        java.lang.Boolean.class,
        null);
  public static final int JSON_INLINE_FIELD_NUMBER = 51312;
  /**
   * <pre>
   * Causes the fields within the tagged Message to be inlined into this Message, for the purposes
   * of our JSON API.
   * For example, rather than serializing
   *   {
   *     "attrs" : {
   *       "cluster_name" : "Foo"
   *     }
   *   }
   * If "attrs" were marked json_inline, we would upgrade cluster_name to a top-level field:
   *   {
   *     "cluster_name" : "Foo"
   *   }
   * Note that this is only applicable to singular Message fields.
   * </pre>
   *
   * <code>extend .google.protobuf.FieldOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.FieldOptions,
      java.lang.Boolean> jsonInline = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        java.lang.Boolean.class,
        null);
  public static final int JSON_MAP_FIELD_NUMBER = 51313;
  /**
   * <pre>
   * Causes a field which conceptually represents a Map to be serialized as a JSON Map.
   * The given field must be a Message with exactly 2 fields called "key" and "value", where key
   * must be a string.
   * For example, rather than serializing
   *   [ { "key" : "spark.speculation", "value" : "false" } ]
   * If this field were marked json_map, we would serialize it as
   *   { "spark.speculation" : "false" }
   * </pre>
   *
   * <code>extend .google.protobuf.FieldOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.FieldOptions,
      java.lang.Boolean> jsonMap = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        java.lang.Boolean.class,
        null);
  public static final int FIELD_DOC_FIELD_NUMBER = 51314;
  /**
   * <pre>
   * The documentation meta data for this field. This gets added automatically when the proto is
   * parsed.
   * There are as many doc blocks as visibility levels.
   * This is not meant to be crafted by hand; this will be automatically generated when parsing
   * the proto file.
   * </pre>
   *
   * <code>extend .google.protobuf.FieldOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.FieldOptions,
      java.util.List<com.databricks.api.proto.databricks.Databricks.DocumentationMetadata>> fieldDoc = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class,
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance());
  public static final int RPC_FIELD_NUMBER = 51310;
  /**
   * <code>extend .google.protobuf.MethodOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.MethodOptions,
      com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions> rpc = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.class,
        com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.getDefaultInstance());
  public static final int METHOD_DOC_FIELD_NUMBER = 51314;
  /**
   * <pre>
   * The documentation metadata.
   * This is not meant to be crafted by hand; this will be automatically generated when parsing
   * the proto file.
   * </pre>
   *
   * <code>extend .google.protobuf.MethodOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.MethodOptions,
      java.util.List<com.databricks.api.proto.databricks.Databricks.DocumentationMetadata>> methodDoc = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class,
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance());
  public static final int GRAPHQL_FIELD_NUMBER = 51399;
  /**
   * <pre>
   * If this is set, this rpc will be visible for graphql module autogeneration.
   * </pre>
   *
   * <code>extend .google.protobuf.MethodOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.MethodOptions,
      com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions> graphql = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions.class,
        com.databricks.api.proto.databricks.Databricks.DatabricksGraphqlOptions.getDefaultInstance());
  public static final int MESSAGE_DOC_FIELD_NUMBER = 51314;
  /**
   * <pre>
   * The documentation metadata.
   * This is not meant to be crafted by hand; this will be automatically generated when parsing
   * the proto file.
   * </pre>
   *
   * <code>extend .google.protobuf.MessageOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.MessageOptions,
      java.util.List<com.databricks.api.proto.databricks.Databricks.DocumentationMetadata>> messageDoc = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class,
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance());
  public static final int SERVICE_DOC_FIELD_NUMBER = 51314;
  /**
   * <pre>
   * The documentation metadata.
   * This is not meant to be crafted by hand; this will be automatically generated when parsing
   * the proto file.
   * </pre>
   *
   * <code>extend .google.protobuf.ServiceOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.ServiceOptions,
      java.util.List<com.databricks.api.proto.databricks.Databricks.DocumentationMetadata>> serviceDoc = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class,
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance());
  public static final int ENUM_DOC_FIELD_NUMBER = 51314;
  /**
   * <pre>
   * The documentation metadata.
   * This is not meant to be crafted by hand; this will be automatically generated when parsing
   * the proto file.
   * </pre>
   *
   * <code>extend .google.protobuf.EnumOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.EnumOptions,
      java.util.List<com.databricks.api.proto.databricks.Databricks.DocumentationMetadata>> enumDoc = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class,
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance());
  public static final int ENUM_VALUE_VISIBILITY_FIELD_NUMBER = 51310;
  /**
   * <pre>
   * Indicates an overriding visibility for this field. This can only reduce the visibility;
   * a public field in an internal API will not have an effect.
   * </pre>
   *
   * <code>extend .google.protobuf.EnumValueOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.EnumValueOptions,
      com.databricks.api.proto.databricks.Databricks.Visibility> enumValueVisibility = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.Visibility.class,
        null);
  public static final int ENUM_VALUE_DOC_FIELD_NUMBER = 51314;
  /**
   * <pre>
   * The documentation metadata.
   * This is not meant to be crafted by hand; this will be automatically generated when parsing
   * the proto file.
   * </pre>
   *
   * <code>extend .google.protobuf.EnumValueOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.EnumValueOptions,
      java.util.List<com.databricks.api.proto.databricks.Databricks.DocumentationMetadata>> enumValueDoc = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class,
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance());
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_mlflow_DatabricksRpcOptions_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_mlflow_DatabricksRpcOptions_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_mlflow_DatabricksGraphqlOptions_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_mlflow_DatabricksGraphqlOptions_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_mlflow_HttpEndpoint_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_mlflow_HttpEndpoint_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_mlflow_ApiVersion_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_mlflow_ApiVersion_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_mlflow_RateLimit_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_mlflow_RateLimit_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_mlflow_DocumentationMetadata_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_mlflow_DocumentationMetadata_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\036mlflow/protos/databricks.proto\022\006mlflow" +
      "\032 google/protobuf/descriptor.proto\032#mlfl" +
      "ow/protos/scalapb/scalapb.proto\"\315\001\n\024Data" +
      "bricksRpcOptions\022\'\n\tendpoints\030\001 \003(\0132\024.ml" +
      "flow.HttpEndpoint\022&\n\nvisibility\030\002 \001(\0162\022." +
      "mlflow.Visibility\022&\n\013error_codes\030\003 \003(\0162\021" +
      ".mlflow.ErrorCode\022%\n\nrate_limit\030\004 \001(\0132\021." +
      "mlflow.RateLimit\022\025\n\rrpc_doc_title\030\005 \001(\t\"" +
      "\032\n\030DatabricksGraphqlOptions\"U\n\014HttpEndpo" +
      "int\022\024\n\006method\030\001 \001(\t:\004POST\022\014\n\004path\030\002 \001(\t\022" +
      "!\n\005since\030\003 \001(\0132\022.mlflow.ApiVersion\"*\n\nAp" +
      "iVersion\022\r\n\005major\030\001 \001(\005\022\r\n\005minor\030\002 \001(\005\"@" +
      "\n\tRateLimit\022\021\n\tmax_burst\030\001 \001(\003\022 \n\030max_su" +
      "stained_per_second\030\002 \001(\003\"\223\001\n\025Documentati" +
      "onMetadata\022\021\n\tdocstring\030\001 \001(\t\022\020\n\010lead_do" +
      "c\030\002 \001(\t\022&\n\nvisibility\030\003 \001(\0162\022.mlflow.Vis" +
      "ibility\022\033\n\023original_proto_path\030\004 \003(\t\022\020\n\010" +
      "position\030\005 \001(\005*?\n\nVisibility\022\n\n\006PUBLIC\020\001" +
      "\022\014\n\010INTERNAL\020\002\022\027\n\023PUBLIC_UNDOCUMENTED\020\003*" +
      "\375\020\n\tErrorCode\022\022\n\016INTERNAL_ERROR\020\001\022\033\n\027TEM" +
      "PORARILY_UNAVAILABLE\020\002\022\014\n\010IO_ERROR\020\003\022\017\n\013" +
      "BAD_REQUEST\020\004\022\035\n\031SERVICE_UNDER_MAINTENAN" +
      "CE\020\005\022%\n!WORKSPACE_TEMPORARILY_UNAVAILABL" +
      "E\020\006\022\025\n\021DEADLINE_EXCEEDED\020\007\022\r\n\tCANCELLED\020" +
      "\010\022\026\n\022RESOURCE_EXHAUSTED\020\t\022\013\n\007ABORTED\020\n\022\r" +
      "\n\tNOT_FOUND\020\013\022\022\n\016ALREADY_EXISTS\020\014\022\023\n\017UNA" +
      "UTHENTICATED\020\r\022\034\n\027INVALID_PARAMETER_VALU" +
      "E\020\350\007\022\027\n\022ENDPOINT_NOT_FOUND\020\351\007\022\026\n\021MALFORM" +
      "ED_REQUEST\020\352\007\022\022\n\rINVALID_STATE\020\353\007\022\026\n\021PER" +
      "MISSION_DENIED\020\354\007\022\025\n\020FEATURE_DISABLED\020\355\007" +
      "\022\032\n\025CUSTOMER_UNAUTHORIZED\020\356\007\022\033\n\026REQUEST_" +
      "LIMIT_EXCEEDED\020\357\007\022\026\n\021RESOURCE_CONFLICT\020\360" +
      "\007\022\033\n\026UNPARSEABLE_HTTP_ERROR\020\361\007\022\024\n\017NOT_IM" +
      "PLEMENTED\020\362\007\022\016\n\tDATA_LOSS\020\363\007\022\035\n\030INVALID_" +
      "STATE_TRANSITION\020\321\017\022\033\n\026COULD_NOT_ACQUIRE" +
      "_LOCK\020\322\017\022\034\n\027RESOURCE_ALREADY_EXISTS\020\271\027\022\034" +
      "\n\027RESOURCE_DOES_NOT_EXIST\020\272\027\022\023\n\016QUOTA_EX" +
      "CEEDED\020\241\037\022\034\n\027MAX_BLOCK_SIZE_EXCEEDED\020\242\037\022" +
      "\033\n\026MAX_READ_SIZE_EXCEEDED\020\243\037\022\023\n\016PARTIAL_" +
      "DELETE\020\244\037\022\033\n\026MAX_LIST_SIZE_EXCEEDED\020\245\037\022\023" +
      "\n\016DRY_RUN_FAILED\020\211\'\022\034\n\027RESOURCE_LIMIT_EX" +
      "CEEDED\020\212\'\022\030\n\023DIRECTORY_NOT_EMPTY\020\361.\022\030\n\023D" +
      "IRECTORY_PROTECTED\020\362.\022\037\n\032MAX_NOTEBOOK_SI" +
      "ZE_EXCEEDED\020\363.\022!\n\034MAX_CHILD_NODE_SIZE_EX" +
      "CEEDED\020\364.\022\032\n\025SEARCH_QUERY_TOO_LONG\020\324/\022\033\n" +
      "\026SEARCH_QUERY_TOO_SHORT\020\325/\022*\n%MANAGED_RE" +
      "SOURCE_GROUP_DOES_NOT_EXIST\020\3316\022\036\n\031PERMIS" +
      "SION_NOT_PROPAGATED\020\3326\022\027\n\022DEPLOYMENT_TIM" +
      "EOUT\020\3336\022\021\n\014GIT_CONFLICT\020\301>\022\024\n\017GIT_UNKNOW" +
      "N_REF\020\302>\022!\n\034GIT_SENSITIVE_TOKEN_DETECTED" +
      "\020\303>\022\036\n\031GIT_URL_NOT_ON_ALLOW_LIST\020\304>\022\025\n\020G" +
      "IT_REMOTE_ERROR\020\305>\022\037\n\032PROJECTS_OPERATION" +
      "_TIMEOUT\020\306>\022\027\n\022IPYNB_FILE_IN_REPO\020\307>\022\036\n\031" +
      "INSECURE_PARTNER_RESPONSE\020\244?\022\037\n\032MALFORME" +
      "D_PARTNER_RESPONSE\020\245?\022\035\n\030METASTORE_DOES_" +
      "NOT_EXIST\020\250F\022\027\n\022DAC_DOES_NOT_EXIST\020\251F\022\033\n" +
      "\026CATALOG_DOES_NOT_EXIST\020\252F\022\032\n\025SCHEMA_DOE" +
      "S_NOT_EXIST\020\253F\022\031\n\024TABLE_DOES_NOT_EXIST\020\254" +
      "F\022\031\n\024SHARE_DOES_NOT_EXIST\020\255F\022\035\n\030RECIPIEN" +
      "T_DOES_NOT_EXIST\020\256F\022&\n!STORAGE_CREDENTIA" +
      "L_DOES_NOT_EXIST\020\257F\022%\n EXTERNAL_LOCATION" +
      "_DOES_NOT_EXIST\020\260F\022\035\n\030PRINCIPAL_DOES_NOT" +
      "_EXIST\020\261F\022\034\n\027PROVIDER_DOES_NOT_EXIST\020\262F\022" +
      "\035\n\030METASTORE_ALREADY_EXISTS\020\274F\022\027\n\022DAC_AL" +
      "READY_EXISTS\020\275F\022\033\n\026CATALOG_ALREADY_EXIST" +
      "S\020\276F\022\032\n\025SCHEMA_ALREADY_EXISTS\020\277F\022\031\n\024TABL" +
      "E_ALREADY_EXISTS\020\300F\022\031\n\024SHARE_ALREADY_EXI" +
      "STS\020\301F\022\035\n\030RECIPIENT_ALREADY_EXISTS\020\302F\022&\n" +
      "!STORAGE_CREDENTIAL_ALREADY_EXISTS\020\303F\022%\n" +
      " EXTERNAL_LOCATION_ALREADY_EXISTS\020\304F\022\034\n\027" +
      "PROVIDER_ALREADY_EXISTS\020\305F\022\026\n\021CATALOG_NO" +
      "T_EMPTY\020\320F\022\025\n\020SCHEMA_NOT_EMPTY\020\321F\022\030\n\023MET" +
      "ASTORE_NOT_EMPTY\020\322F\022\"\n\035PROVIDER_SHARE_NO" +
      "T_ACCESSIBLE\020\344F:G\n\nvisibility\022\035.google.p" +
      "rotobuf.FieldOptions\030\356\220\003 \001(\0162\022.mlflow.Vi" +
      "sibility::\n\021validate_required\022\035.google.p" +
      "rotobuf.FieldOptions\030\357\220\003 \001(\010:4\n\013json_inl" +
      "ine\022\035.google.protobuf.FieldOptions\030\360\220\003 \001" +
      "(\010:1\n\010json_map\022\035.google.protobuf.FieldOp" +
      "tions\030\361\220\003 \001(\010:Q\n\tfield_doc\022\035.google.prot" +
      "obuf.FieldOptions\030\362\220\003 \003(\0132\035.mlflow.Docum" +
      "entationMetadata:K\n\003rpc\022\036.google.protobu" +
      "f.MethodOptions\030\356\220\003 \001(\0132\034.mlflow.Databri" +
      "cksRpcOptions:S\n\nmethod_doc\022\036.google.pro" +
      "tobuf.MethodOptions\030\362\220\003 \003(\0132\035.mlflow.Doc" +
      "umentationMetadata:S\n\007graphql\022\036.google.p" +
      "rotobuf.MethodOptions\030\307\221\003 \001(\0132 .mlflow.D" +
      "atabricksGraphqlOptions:U\n\013message_doc\022\037" +
      ".google.protobuf.MessageOptions\030\362\220\003 \003(\0132" +
      "\035.mlflow.DocumentationMetadata:U\n\013servic" +
      "e_doc\022\037.google.protobuf.ServiceOptions\030\362" +
      "\220\003 \003(\0132\035.mlflow.DocumentationMetadata:O\n" +
      "\010enum_doc\022\034.google.protobuf.EnumOptions\030" +
      "\362\220\003 \003(\0132\035.mlflow.DocumentationMetadata:V" +
      "\n\025enum_value_visibility\022!.google.protobu" +
      "f.EnumValueOptions\030\356\220\003 \001(\0162\022.mlflow.Visi" +
      "bility:Z\n\016enum_value_doc\022!.google.protob" +
      "uf.EnumValueOptions\030\362\220\003 \003(\0132\035.mlflow.Doc" +
      "umentationMetadataB*\n#com.databricks.api" +
      ".proto.databricks\342?\002\020\001"
    };
    descriptor = com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          com.google.protobuf.DescriptorProtos.getDescriptor(),
          org.mlflow.scalapb_interface.Scalapb.getDescriptor(),
        });
    internal_static_mlflow_DatabricksRpcOptions_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_mlflow_DatabricksRpcOptions_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_mlflow_DatabricksRpcOptions_descriptor,
        new java.lang.String[] { "Endpoints", "Visibility", "ErrorCodes", "RateLimit", "RpcDocTitle", });
    internal_static_mlflow_DatabricksGraphqlOptions_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_mlflow_DatabricksGraphqlOptions_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_mlflow_DatabricksGraphqlOptions_descriptor,
        new java.lang.String[] { });
    internal_static_mlflow_HttpEndpoint_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_mlflow_HttpEndpoint_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_mlflow_HttpEndpoint_descriptor,
        new java.lang.String[] { "Method", "Path", "Since", });
    internal_static_mlflow_ApiVersion_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_mlflow_ApiVersion_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_mlflow_ApiVersion_descriptor,
        new java.lang.String[] { "Major", "Minor", });
    internal_static_mlflow_RateLimit_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_mlflow_RateLimit_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_mlflow_RateLimit_descriptor,
        new java.lang.String[] { "MaxBurst", "MaxSustainedPerSecond", });
    internal_static_mlflow_DocumentationMetadata_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_mlflow_DocumentationMetadata_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_mlflow_DocumentationMetadata_descriptor,
        new java.lang.String[] { "Docstring", "LeadDoc", "Visibility", "OriginalProtoPath", "Position", });
    visibility.internalInit(descriptor.getExtensions().get(0));
    validateRequired.internalInit(descriptor.getExtensions().get(1));
    jsonInline.internalInit(descriptor.getExtensions().get(2));
    jsonMap.internalInit(descriptor.getExtensions().get(3));
    fieldDoc.internalInit(descriptor.getExtensions().get(4));
    rpc.internalInit(descriptor.getExtensions().get(5));
    methodDoc.internalInit(descriptor.getExtensions().get(6));
    graphql.internalInit(descriptor.getExtensions().get(7));
    messageDoc.internalInit(descriptor.getExtensions().get(8));
    serviceDoc.internalInit(descriptor.getExtensions().get(9));
    enumDoc.internalInit(descriptor.getExtensions().get(10));
    enumValueVisibility.internalInit(descriptor.getExtensions().get(11));
    enumValueDoc.internalInit(descriptor.getExtensions().get(12));
    com.google.protobuf.ExtensionRegistry registry =
        com.google.protobuf.ExtensionRegistry.newInstance();
    registry.add(org.mlflow.scalapb_interface.Scalapb.options);
    com.google.protobuf.Descriptors.FileDescriptor
        .internalUpdateFileDescriptor(descriptor, registry);
    com.google.protobuf.DescriptorProtos.getDescriptor();
    org.mlflow.scalapb_interface.Scalapb.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}

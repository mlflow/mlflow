

<!DOCTYPE html>
<!-- source: docs/source/_modules/mlflow/openai -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mlflow.openai</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/_modules/mlflow/openai.html">
  
  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    

    

  
    

  

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../../genindex.html"/>
        <link rel="search" title="Search" href="../../search.html"/>
    <link rel="top" title="MLflow 2.17.1.dev0 documentation" href="../../index.html"/>
        <link rel="up" title="Module code" href="../index.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../../_static/jquery.js"></script>
<script type="text/javascript" src="../../_static/underscore.js"></script>
<script type="text/javascript" src="../../_static/doctools.js"></script>
<script type="text/javascript" src="../../_static/tabs.js"></script>
<script type="text/javascript" src="../../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="../../_static/runllm.js"></script>

<body class="wy-body-for-nav" role="document">
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <ul>
  <li class="menu-toggle">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
    <a href="../../index.html" class="wy-nav-top-logo"
      ><img src="../../_static/MLflow-logo-final-black.png" alt="MLflow"
    /></a>
    <span class="version">2.17.1.dev0</span>
  </li>
</ul>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../index.html" class="main-navigation-home"><img src="../../_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul>
<li class="toctree-l1"><a class="reference internal" href="../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rest-api.html">REST API</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../index.html">Module code</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>mlflow.openai</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/_modules/mlflow/openai" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <h1>Source code for mlflow.openai</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">The ``mlflow.openai`` module provides an API for logging and loading OpenAI models.</span>

<span class="sd">Credential management for OpenAI on Databricks</span>
<span class="sd">~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>

<span class="sd">.. warning::</span>

<span class="sd">    Specifying secrets for model serving with ``MLFLOW_OPENAI_SECRET_SCOPE`` is deprecated.</span>
<span class="sd">    Use `secrets-based environment variables &lt;https://docs.databricks.com/en/machine-learning/model-serving/store-env-variable-model-serving.html&gt;`_</span>
<span class="sd">    instead.</span>

<span class="sd">When this flavor logs a model on Databricks, it saves a YAML file with the following contents as</span>
<span class="sd">``openai.yaml`` if the ``MLFLOW_OPENAI_SECRET_SCOPE`` environment variable is set.</span>

<span class="sd">.. code-block:: yaml</span>

<span class="sd">    OPENAI_API_BASE: {scope}:openai_api_base</span>
<span class="sd">    OPENAI_API_KEY: {scope}:openai_api_key</span>
<span class="sd">    OPENAI_API_KEY_PATH: {scope}:openai_api_key_path</span>
<span class="sd">    OPENAI_API_TYPE: {scope}:openai_api_type</span>
<span class="sd">    OPENAI_ORGANIZATION: {scope}:openai_organization</span>

<span class="sd">- ``{scope}`` is the value of the ``MLFLOW_OPENAI_SECRET_SCOPE`` environment variable.</span>
<span class="sd">- The keys are the environment variables that the ``openai-python`` package uses to</span>
<span class="sd">  configure the API client.</span>
<span class="sd">- The values are the references to the secrets that store the values of the environment</span>
<span class="sd">  variables.</span>

<span class="sd">When the logged model is served on Databricks, each secret will be resolved and set as the</span>
<span class="sd">corresponding environment variable. See https://docs.databricks.com/security/secrets/index.html</span>
<span class="sd">for how to set up secrets on Databricks.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">importlib.metadata</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">string</span> <span class="kn">import</span> <span class="n">Formatter</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Set</span>

<span class="kn">import</span> <span class="nn">yaml</span>
<span class="kn">from</span> <span class="nn">packaging.version</span> <span class="kn">import</span> <span class="n">Version</span>

<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">from</span> <span class="nn">mlflow</span> <span class="kn">import</span> <span class="n">pyfunc</span>
<span class="kn">from</span> <span class="nn">mlflow.environment_variables</span> <span class="kn">import</span> <span class="n">MLFLOW_OPENAI_SECRET_SCOPE</span>
<span class="kn">from</span> <span class="nn">mlflow.exceptions</span> <span class="kn">import</span> <span class="n">MlflowException</span>
<span class="kn">from</span> <span class="nn">mlflow.models</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">ModelInputExample</span><span class="p">,</span> <span class="n">ModelSignature</span>
<span class="kn">from</span> <span class="nn">mlflow.models.model</span> <span class="kn">import</span> <span class="n">MLMODEL_FILE_NAME</span>
<span class="kn">from</span> <span class="nn">mlflow.models.signature</span> <span class="kn">import</span> <span class="n">_infer_signature_from_input_example</span>
<span class="kn">from</span> <span class="nn">mlflow.models.utils</span> <span class="kn">import</span> <span class="n">_save_example</span>
<span class="kn">from</span> <span class="nn">mlflow.openai._openai_autolog</span> <span class="kn">import</span> <span class="n">patched_call</span>
<span class="kn">from</span> <span class="nn">mlflow.protos.databricks_pb2</span> <span class="kn">import</span> <span class="n">INVALID_PARAMETER_VALUE</span>
<span class="kn">from</span> <span class="nn">mlflow.tracking._model_registry</span> <span class="kn">import</span> <span class="n">DEFAULT_AWAIT_MAX_SLEEP_SECONDS</span>
<span class="kn">from</span> <span class="nn">mlflow.tracking.artifact_utils</span> <span class="kn">import</span> <span class="n">_download_artifact_from_uri</span>
<span class="kn">from</span> <span class="nn">mlflow.types</span> <span class="kn">import</span> <span class="n">ColSpec</span><span class="p">,</span> <span class="n">Schema</span><span class="p">,</span> <span class="n">TensorSpec</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.annotations</span> <span class="kn">import</span> <span class="n">experimental</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.autologging_utils</span> <span class="kn">import</span> <span class="n">autologging_integration</span><span class="p">,</span> <span class="n">safe_patch</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.databricks_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">check_databricks_secret_scope_access</span><span class="p">,</span>
    <span class="n">is_in_databricks_runtime</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.docstring_utils</span> <span class="kn">import</span> <span class="n">LOG_MODEL_PARAM_DOCS</span><span class="p">,</span> <span class="n">format_docstring</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.environment</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_CONDA_ENV_FILE_NAME</span><span class="p">,</span>
    <span class="n">_CONSTRAINTS_FILE_NAME</span><span class="p">,</span>
    <span class="n">_PYTHON_ENV_FILE_NAME</span><span class="p">,</span>
    <span class="n">_REQUIREMENTS_FILE_NAME</span><span class="p">,</span>
    <span class="n">_mlflow_conda_env</span><span class="p">,</span>
    <span class="n">_process_conda_env</span><span class="p">,</span>
    <span class="n">_process_pip_requirements</span><span class="p">,</span>
    <span class="n">_PythonEnv</span><span class="p">,</span>
    <span class="n">_validate_env_arguments</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.file_utils</span> <span class="kn">import</span> <span class="n">write_to</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.model_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_add_code_from_conf_to_system_path</span><span class="p">,</span>
    <span class="n">_get_flavor_configuration</span><span class="p">,</span>
    <span class="n">_validate_and_copy_code_paths</span><span class="p">,</span>
    <span class="n">_validate_and_prepare_target_save_path</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.openai_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">REQUEST_URL_CHAT</span><span class="p">,</span>
    <span class="n">REQUEST_URL_COMPLETIONS</span><span class="p">,</span>
    <span class="n">REQUEST_URL_EMBEDDINGS</span><span class="p">,</span>
    <span class="n">_OAITokenHolder</span><span class="p">,</span>
    <span class="n">_OpenAIApiConfig</span><span class="p">,</span>
    <span class="n">_OpenAIEnvVar</span><span class="p">,</span>
    <span class="n">_validate_model_params</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.requirements_utils</span> <span class="kn">import</span> <span class="n">_get_pinned_requirement</span>

<span class="n">FLAVOR_NAME</span> <span class="o">=</span> <span class="s2">&quot;openai&quot;</span>
<span class="n">MODEL_FILENAME</span> <span class="o">=</span> <span class="s2">&quot;model.yaml&quot;</span>
<span class="n">_PYFUNC_SUPPORTED_TASKS</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;chat.completions&quot;</span><span class="p">,</span> <span class="s2">&quot;embeddings&quot;</span><span class="p">,</span> <span class="s2">&quot;completions&quot;</span><span class="p">)</span>

<span class="n">_logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="get_default_pip_requirements"><a class="viewcode-back" href="../../python_api/mlflow.openai.html#mlflow.openai.get_default_pip_requirements">[docs]</a><span class="nd">@experimental</span>
<span class="k">def</span> <span class="nf">get_default_pip_requirements</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns:</span>
<span class="sd">        A list of default pip requirements for MLflow Models produced by this flavor.</span>
<span class="sd">        Calls to :func:`save_model()` and :func:`log_model()` produce a pip environment</span>
<span class="sd">        that, at minimum, contains these requirements.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">_get_pinned_requirement</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;openai&quot;</span><span class="p">,</span> <span class="s2">&quot;tiktoken&quot;</span><span class="p">,</span> <span class="s2">&quot;tenacity&quot;</span><span class="p">]))</span></div>


<div class="viewcode-block" id="get_default_conda_env"><a class="viewcode-back" href="../../python_api/mlflow.openai.html#mlflow.openai.get_default_conda_env">[docs]</a><span class="nd">@experimental</span>
<span class="k">def</span> <span class="nf">get_default_conda_env</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns:</span>
<span class="sd">        The default Conda environment for MLflow Models produced by calls to</span>
<span class="sd">        :func:`save_model()` and :func:`log_model()`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_mlflow_conda_env</span><span class="p">(</span><span class="n">additional_pip_deps</span><span class="o">=</span><span class="n">get_default_pip_requirements</span><span class="p">())</span></div>


<span class="k">def</span> <span class="nf">_get_obj_to_task_mapping</span><span class="p">():</span>
    <span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">resources</span> <span class="k">as</span> <span class="n">r</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="n">r</span><span class="o">.</span><span class="n">Audio</span><span class="p">:</span> <span class="s2">&quot;audio&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">Completions</span><span class="p">:</span> <span class="s2">&quot;chat.completions&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="o">.</span><span class="n">Completions</span><span class="p">:</span> <span class="s2">&quot;completions&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="o">.</span><span class="n">Images</span><span class="o">.</span><span class="n">edit</span><span class="p">:</span> <span class="s2">&quot;images.edit&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="o">.</span><span class="n">Embeddings</span><span class="p">:</span> <span class="s2">&quot;embeddings&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="o">.</span><span class="n">Files</span><span class="p">:</span> <span class="s2">&quot;files&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="o">.</span><span class="n">Images</span><span class="p">:</span> <span class="s2">&quot;images&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="o">.</span><span class="n">FineTuning</span><span class="p">:</span> <span class="s2">&quot;fine_tuning&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="o">.</span><span class="n">Moderations</span><span class="p">:</span> <span class="s2">&quot;moderations&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="o">.</span><span class="n">Models</span><span class="p">:</span> <span class="s2">&quot;models&quot;</span><span class="p">,</span>
    <span class="p">}</span>


<span class="k">def</span> <span class="nf">_get_model_name</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">openai</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">model</span>

    <span class="k">if</span> <span class="n">Version</span><span class="p">(</span><span class="n">_get_openai_package_version</span><span class="p">())</span><span class="o">.</span><span class="n">major</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">openai</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">id</span>

    <span class="k">raise</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">MlflowException</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Unsupported model type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_task_name</span><span class="p">(</span><span class="n">task</span><span class="p">):</span>
    <span class="n">mapping</span> <span class="o">=</span> <span class="n">_get_obj_to_task_mapping</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">task</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">mapping</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">raise</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">MlflowException</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unsupported task: </span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">task</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">task_name</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">task</span><span class="p">)</span>
            <span class="ow">or</span> <span class="n">mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="vm">__class__</span><span class="p">)</span>
            <span class="ow">or</span> <span class="n">mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="s2">&quot;__func__&quot;</span><span class="p">))</span>  <span class="c1"># if task is a method</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">task_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">MlflowException</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unsupported task object: </span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">task_name</span>


<span class="k">def</span> <span class="nf">_get_api_config</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">_OpenAIApiConfig</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Gets the parameters and configuration of the OpenAI API connected to.&quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">openai</span>

    <span class="n">api_type</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="n">_OpenAIEnvVar</span><span class="o">.</span><span class="n">OPENAI_API_TYPE</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">openai</span><span class="o">.</span><span class="n">api_type</span><span class="p">)</span>
    <span class="n">api_version</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="n">_OpenAIEnvVar</span><span class="o">.</span><span class="n">OPENAI_API_VERSION</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">openai</span><span class="o">.</span><span class="n">api_version</span><span class="p">)</span>
    <span class="n">api_base</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="n">_OpenAIEnvVar</span><span class="o">.</span><span class="n">OPENAI_API_BASE</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">engine</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="n">_OpenAIEnvVar</span><span class="o">.</span><span class="n">OPENAI_ENGINE</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">deployment_id</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="n">_OpenAIEnvVar</span><span class="o">.</span><span class="n">OPENAI_DEPLOYMENT_NAME</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">api_type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;azure&quot;</span><span class="p">,</span> <span class="s2">&quot;azure_ad&quot;</span><span class="p">,</span> <span class="s2">&quot;azuread&quot;</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
        <span class="n">max_tokens_per_minute</span> <span class="o">=</span> <span class="mi">60_000</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># The maximum batch size is 2048:</span>
        <span class="c1"># https://github.com/openai/openai-python/blob/b82a3f7e4c462a8a10fa445193301a3cefef9a4a/openai/embeddings_utils.py#L43</span>
        <span class="c1"># We use a smaller batch size to be safe.</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1024</span>
        <span class="n">max_tokens_per_minute</span> <span class="o">=</span> <span class="mi">90_000</span>
    <span class="k">return</span> <span class="n">_OpenAIApiConfig</span><span class="p">(</span>
        <span class="n">api_type</span><span class="o">=</span><span class="n">api_type</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">max_requests_per_minute</span><span class="o">=</span><span class="mi">3_500</span><span class="p">,</span>
        <span class="n">max_tokens_per_minute</span><span class="o">=</span><span class="n">max_tokens_per_minute</span><span class="p">,</span>
        <span class="n">api_base</span><span class="o">=</span><span class="n">api_base</span><span class="p">,</span>
        <span class="n">api_version</span><span class="o">=</span><span class="n">api_version</span><span class="p">,</span>
        <span class="n">engine</span><span class="o">=</span><span class="n">engine</span><span class="p">,</span>
        <span class="n">deployment_id</span><span class="o">=</span><span class="n">deployment_id</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_openai_package_version</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;openai&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_log_secrets_yaml</span><span class="p">(</span><span class="n">local_model_dir</span><span class="p">,</span> <span class="n">scope</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">local_model_dir</span><span class="p">,</span> <span class="s2">&quot;openai.yaml&quot;</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">yaml</span><span class="o">.</span><span class="n">safe_dump</span><span class="p">({</span><span class="n">e</span><span class="o">.</span><span class="n">value</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">scope</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">e</span><span class="o">.</span><span class="n">secret_key</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">_OpenAIEnvVar</span><span class="p">},</span> <span class="n">f</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_parse_format_fields</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Parses format fields from a given string, e.g. &quot;Hello {name}&quot; -&gt; [&quot;name&quot;].&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">fn</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">Formatter</span><span class="p">()</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">if</span> <span class="n">fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">}</span>


<span class="k">def</span> <span class="nf">_get_input_schema</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">content</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">content</span><span class="p">:</span>
        <span class="n">formatter</span> <span class="o">=</span> <span class="n">_ContentFormatter</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">content</span><span class="p">)</span>
        <span class="n">variables</span> <span class="o">=</span> <span class="n">formatter</span><span class="o">.</span><span class="n">variables</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">)])</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">v</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">)])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">)])</span>


<div class="viewcode-block" id="save_model"><a class="viewcode-back" href="../../python_api/mlflow.openai.html#mlflow.openai.save_model">[docs]</a><span class="nd">@experimental</span>
<span class="nd">@format_docstring</span><span class="p">(</span><span class="n">LOG_MODEL_PARAM_DOCS</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">package_name</span><span class="o">=</span><span class="n">FLAVOR_NAME</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">task</span><span class="p">,</span>
    <span class="n">path</span><span class="p">,</span>
    <span class="n">conda_env</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">code_paths</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">mlflow_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">signature</span><span class="p">:</span> <span class="n">ModelSignature</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_example</span><span class="p">:</span> <span class="n">ModelInputExample</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">pip_requirements</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_pip_requirements</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">example_no_conversion</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save an OpenAI model to a path on the local file system.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: The OpenAI model name.</span>
<span class="sd">        task: The task the model is performing, e.g., ``openai.chat.completions`` or</span>
<span class="sd">            ``&#39;chat.completions&#39;``.</span>
<span class="sd">        path: Local path where the model is to be saved.</span>
<span class="sd">        conda_env: {{ conda_env }}</span>
<span class="sd">        code_paths: {{ code_paths }}</span>
<span class="sd">        mlflow_model: :py:mod:`mlflow.models.Model` this flavor is being added to.</span>
<span class="sd">        signature: :py:class:`ModelSignature &lt;mlflow.models.ModelSignature&gt;`</span>
<span class="sd">            describes model input and output :py:class:`Schema &lt;mlflow.types.Schema&gt;`.</span>
<span class="sd">            The model signature can be :py:func:`inferred &lt;mlflow.models.infer_signature&gt;`</span>
<span class="sd">            from datasets with valid model input (e.g. the training dataset with target</span>
<span class="sd">            column omitted) and valid model output (e.g. model predictions generated on</span>
<span class="sd">            the training dataset), for example:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                from mlflow.models import infer_signature</span>

<span class="sd">                train = df.drop_column(&quot;target_label&quot;)</span>
<span class="sd">                predictions = ...  # compute model predictions</span>
<span class="sd">                signature = infer_signature(train, predictions)</span>
<span class="sd">        input_example: {{ input_example }}</span>
<span class="sd">        pip_requirements: {{ pip_requirements }}</span>
<span class="sd">        extra_pip_requirements: {{ extra_pip_requirements }}</span>
<span class="sd">        metadata: {{ metadata }}</span>
<span class="sd">        example_no_conversion: {{ example_no_conversion }}</span>
<span class="sd">        kwargs: Keyword arguments specific to the OpenAI task, such as the ``messages`` (see</span>
<span class="sd">            :ref:`mlflow.openai.messages` for more details on this parameter)</span>
<span class="sd">            or ``top_p`` value to use for chat completion.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        import openai</span>

<span class="sd">        # Chat</span>
<span class="sd">        mlflow.openai.save_model(</span>
<span class="sd">            model=&quot;gpt-4o-mini&quot;,</span>
<span class="sd">            task=openai.chat.completions,</span>
<span class="sd">            messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Tell me a joke.&quot;}],</span>
<span class="sd">            path=&quot;model&quot;,</span>
<span class="sd">        )</span>

<span class="sd">        # Completions</span>
<span class="sd">        mlflow.openai.save_model(</span>
<span class="sd">            model=&quot;text-davinci-002&quot;,</span>
<span class="sd">            task=openai.completions,</span>
<span class="sd">            prompt=&quot;{text}. The general sentiment of the text is&quot;,</span>
<span class="sd">            path=&quot;model&quot;,</span>
<span class="sd">        )</span>

<span class="sd">        # Embeddings</span>
<span class="sd">        mlflow.openai.save_model(</span>
<span class="sd">            model=&quot;text-embedding-ada-002&quot;,</span>
<span class="sd">            task=openai.embeddings,</span>
<span class="sd">            path=&quot;model&quot;,</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">Version</span><span class="p">(</span><span class="n">_get_openai_package_version</span><span class="p">())</span><span class="o">.</span><span class="n">major</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span><span class="s2">&quot;Only openai&gt;=1.0 is supported.&quot;</span><span class="p">)</span>

    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

    <span class="n">_validate_env_arguments</span><span class="p">(</span><span class="n">conda_env</span><span class="p">,</span> <span class="n">pip_requirements</span><span class="p">,</span> <span class="n">extra_pip_requirements</span><span class="p">)</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">_validate_and_prepare_target_save_path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">code_dir_subpath</span> <span class="o">=</span> <span class="n">_validate_and_copy_code_paths</span><span class="p">(</span><span class="n">code_paths</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
    <span class="n">task</span> <span class="o">=</span> <span class="n">_get_task_name</span><span class="p">(</span><span class="n">task</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">mlflow_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mlflow_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">signature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">signature</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="n">_validate_model_params</span><span class="p">(</span>
                <span class="n">task</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="p">{</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">default</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">signature</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">params</span><span class="p">}</span>
            <span class="p">)</span>
    <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;chat.completions&quot;</span><span class="p">:</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;messages&quot;</span><span class="p">,</span> <span class="p">[])</span>
        <span class="k">if</span> <span class="n">messages</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span>
            <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">messages</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">_is_valid_message</span><span class="p">,</span> <span class="n">messages</span><span class="p">))</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
                <span class="s2">&quot;If `messages` is provided, it must be a list of dictionaries with keys &quot;</span>
                <span class="s2">&quot;&#39;role&#39; and &#39;content&#39;.&quot;</span>
            <span class="p">)</span>

        <span class="n">signature</span> <span class="o">=</span> <span class="n">ModelSignature</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">_get_input_schema</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">messages</span><span class="p">),</span>
            <span class="n">outputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)]),</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;completions&quot;</span><span class="p">:</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">)</span>
        <span class="n">signature</span> <span class="o">=</span> <span class="n">ModelSignature</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">_get_input_schema</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">prompt</span><span class="p">),</span>
            <span class="n">outputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)]),</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;embeddings&quot;</span><span class="p">:</span>
        <span class="n">signature</span> <span class="o">=</span> <span class="n">ModelSignature</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)]),</span>
            <span class="n">outputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">TensorSpec</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s2">&quot;float64&quot;</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))]),</span>
        <span class="p">)</span>

    <span class="n">saved_example</span> <span class="o">=</span> <span class="n">_save_example</span><span class="p">(</span><span class="n">mlflow_model</span><span class="p">,</span> <span class="n">input_example</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">example_no_conversion</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">signature</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">saved_example</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">wrapped_model</span> <span class="o">=</span> <span class="n">_OpenAIWrapper</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">signature</span> <span class="o">=</span> <span class="n">_infer_signature_from_input_example</span><span class="p">(</span><span class="n">saved_example</span><span class="p">,</span> <span class="n">wrapped_model</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">signature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mlflow_model</span><span class="o">.</span><span class="n">signature</span> <span class="o">=</span> <span class="n">signature</span>

    <span class="k">if</span> <span class="n">metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mlflow_model</span><span class="o">.</span><span class="n">metadata</span> <span class="o">=</span> <span class="n">metadata</span>
    <span class="n">model_data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">MODEL_FILENAME</span><span class="p">)</span>
    <span class="n">model_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">_get_model_name</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
        <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="n">task</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_data_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">yaml</span><span class="o">.</span><span class="n">safe_dump</span><span class="p">(</span><span class="n">model_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">_PYFUNC_SUPPORTED_TASKS</span><span class="p">:</span>
        <span class="n">pyfunc</span><span class="o">.</span><span class="n">add_to_model</span><span class="p">(</span>
            <span class="n">mlflow_model</span><span class="p">,</span>
            <span class="n">loader_module</span><span class="o">=</span><span class="s2">&quot;mlflow.openai&quot;</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">MODEL_FILENAME</span><span class="p">,</span>
            <span class="n">conda_env</span><span class="o">=</span><span class="n">_CONDA_ENV_FILE_NAME</span><span class="p">,</span>
            <span class="n">python_env</span><span class="o">=</span><span class="n">_PYTHON_ENV_FILE_NAME</span><span class="p">,</span>
            <span class="n">code</span><span class="o">=</span><span class="n">code_dir_subpath</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="n">mlflow_model</span><span class="o">.</span><span class="n">add_flavor</span><span class="p">(</span>
        <span class="n">FLAVOR_NAME</span><span class="p">,</span>
        <span class="n">openai_version</span><span class="o">=</span><span class="n">_get_openai_package_version</span><span class="p">(),</span>
        <span class="n">data</span><span class="o">=</span><span class="n">MODEL_FILENAME</span><span class="p">,</span>
        <span class="n">code</span><span class="o">=</span><span class="n">code_dir_subpath</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">mlflow_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">MLMODEL_FILE_NAME</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">is_in_databricks_runtime</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">scope</span> <span class="o">:=</span> <span class="n">MLFLOW_OPENAI_SECRET_SCOPE</span><span class="o">.</span><span class="n">get</span><span class="p">():</span>
            <span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://docs.databricks.com/en/machine-learning/model-serving/store-env-variable-model-serving.html&quot;</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Specifying secrets for model serving with `MLFLOW_OPENAI_SECRET_SCOPE` is &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;deprecated. Use secrets-based environment variables (</span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">) instead.&quot;</span><span class="p">,</span>
                <span class="ne">FutureWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">check_databricks_secret_scope_access</span><span class="p">(</span><span class="n">scope</span><span class="p">)</span>
            <span class="n">_log_secrets_yaml</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">scope</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">conda_env</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">pip_requirements</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">default_reqs</span> <span class="o">=</span> <span class="n">get_default_pip_requirements</span><span class="p">()</span>
            <span class="n">inferred_reqs</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">infer_pip_requirements</span><span class="p">(</span>
                <span class="n">path</span><span class="p">,</span> <span class="n">FLAVOR_NAME</span><span class="p">,</span> <span class="n">fallback</span><span class="o">=</span><span class="n">default_reqs</span>
            <span class="p">)</span>
            <span class="n">default_reqs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">inferred_reqs</span><span class="p">)</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">default_reqs</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">default_reqs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conda_env</span><span class="p">,</span> <span class="n">pip_requirements</span><span class="p">,</span> <span class="n">pip_constraints</span> <span class="o">=</span> <span class="n">_process_pip_requirements</span><span class="p">(</span>
            <span class="n">default_reqs</span><span class="p">,</span>
            <span class="n">pip_requirements</span><span class="p">,</span>
            <span class="n">extra_pip_requirements</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">conda_env</span><span class="p">,</span> <span class="n">pip_requirements</span><span class="p">,</span> <span class="n">pip_constraints</span> <span class="o">=</span> <span class="n">_process_conda_env</span><span class="p">(</span><span class="n">conda_env</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">_CONDA_ENV_FILE_NAME</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">yaml</span><span class="o">.</span><span class="n">safe_dump</span><span class="p">(</span><span class="n">conda_env</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Save `constraints.txt` if necessary</span>
    <span class="k">if</span> <span class="n">pip_constraints</span><span class="p">:</span>
        <span class="n">write_to</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">_CONSTRAINTS_FILE_NAME</span><span class="p">),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pip_constraints</span><span class="p">))</span>

    <span class="c1"># Save `requirements.txt`</span>
    <span class="n">write_to</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">_REQUIREMENTS_FILE_NAME</span><span class="p">),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pip_requirements</span><span class="p">))</span>

    <span class="n">_PythonEnv</span><span class="o">.</span><span class="n">current</span><span class="p">()</span><span class="o">.</span><span class="n">to_yaml</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">_PYTHON_ENV_FILE_NAME</span><span class="p">))</span></div>


<div class="viewcode-block" id="log_model"><a class="viewcode-back" href="../../python_api/mlflow.openai.html#mlflow.openai.log_model">[docs]</a><span class="nd">@experimental</span>
<span class="nd">@format_docstring</span><span class="p">(</span><span class="n">LOG_MODEL_PARAM_DOCS</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">package_name</span><span class="o">=</span><span class="n">FLAVOR_NAME</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">log_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">task</span><span class="p">,</span>
    <span class="n">artifact_path</span><span class="p">,</span>
    <span class="n">conda_env</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">code_paths</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">registered_model_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">signature</span><span class="p">:</span> <span class="n">ModelSignature</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_example</span><span class="p">:</span> <span class="n">ModelInputExample</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">await_registration_for</span><span class="o">=</span><span class="n">DEFAULT_AWAIT_MAX_SLEEP_SECONDS</span><span class="p">,</span>
    <span class="n">pip_requirements</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_pip_requirements</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">example_no_conversion</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Log an OpenAI model as an MLflow artifact for the current run.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: The OpenAI model name or reference instance, e.g.,</span>
<span class="sd">            ``openai.Model.retrieve(&quot;gpt-4o-mini&quot;)``.</span>
<span class="sd">        task: The task the model is performing, e.g., ``openai.chat.completions`` or</span>
<span class="sd">            ``&#39;chat.completions&#39;``.</span>
<span class="sd">        artifact_path: Run-relative artifact path.</span>
<span class="sd">        conda_env: {{ conda_env }}</span>
<span class="sd">        code_paths: {{ code_paths }}</span>
<span class="sd">        registered_model_name: If given, create a model version under</span>
<span class="sd">            ``registered_model_name``, also creating a registered model if one</span>
<span class="sd">            with the given name does not exist.</span>
<span class="sd">        signature: :py:class:`ModelSignature &lt;mlflow.models.ModelSignature&gt;`</span>
<span class="sd">            describes model input and output :py:class:`Schema &lt;mlflow.types.Schema&gt;`.</span>
<span class="sd">            The model signature can be :py:func:`inferred &lt;mlflow.models.infer_signature&gt;`</span>
<span class="sd">            from datasets with valid model input (e.g. the training dataset with target</span>
<span class="sd">            column omitted) and valid model output (e.g. model predictions generated on</span>
<span class="sd">            the training dataset), for example:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                from mlflow.models import infer_signature</span>

<span class="sd">                train = df.drop_column(&quot;target_label&quot;)</span>
<span class="sd">                predictions = ...  # compute model predictions</span>
<span class="sd">                signature = infer_signature(train, predictions)</span>

<span class="sd">        input_example: {{ input_example }}</span>
<span class="sd">        await_registration_for: Number of seconds to wait for the model version to finish</span>
<span class="sd">            being created and is in ``READY`` status. By default, the function</span>
<span class="sd">            waits for five minutes. Specify 0 or None to skip waiting.</span>
<span class="sd">        pip_requirements: {{ pip_requirements }}</span>
<span class="sd">        extra_pip_requirements: {{ extra_pip_requirements }}</span>
<span class="sd">        metadata: {{ metadata }}</span>
<span class="sd">        example_no_conversion: {{ example_no_conversion }}</span>
<span class="sd">        kwargs: Keyword arguments specific to the OpenAI task, such as the ``messages`` (see</span>
<span class="sd">            :ref:`mlflow.openai.messages` for more details on this parameter)</span>
<span class="sd">            or ``top_p`` value to use for chat completion.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :py:class:`ModelInfo &lt;mlflow.models.model.ModelInfo&gt;` instance that contains the</span>
<span class="sd">        metadata of the logged model.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        import openai</span>

<span class="sd">        # Chat</span>
<span class="sd">        with mlflow.start_run():</span>
<span class="sd">            info = mlflow.openai.log_model(</span>
<span class="sd">                model=&quot;gpt-4o-mini&quot;,</span>
<span class="sd">                task=openai.chat.completions,</span>
<span class="sd">                messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Tell me a joke about {animal}.&quot;}],</span>
<span class="sd">                artifact_path=&quot;model&quot;,</span>
<span class="sd">            )</span>
<span class="sd">            model = mlflow.pyfunc.load_model(info.model_uri)</span>
<span class="sd">            df = pd.DataFrame({&quot;animal&quot;: [&quot;cats&quot;, &quot;dogs&quot;]})</span>
<span class="sd">            print(model.predict(df))</span>

<span class="sd">        # Embeddings</span>
<span class="sd">        with mlflow.start_run():</span>
<span class="sd">            info = mlflow.openai.log_model(</span>
<span class="sd">                model=&quot;text-embedding-ada-002&quot;,</span>
<span class="sd">                task=openai.embeddings,</span>
<span class="sd">                artifact_path=&quot;embeddings&quot;,</span>
<span class="sd">            )</span>
<span class="sd">            model = mlflow.pyfunc.load_model(info.model_uri)</span>
<span class="sd">            print(model.predict([&quot;hello&quot;, &quot;world&quot;]))</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">Model</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="n">artifact_path</span><span class="p">,</span>
        <span class="n">flavor</span><span class="o">=</span><span class="n">mlflow</span><span class="o">.</span><span class="n">openai</span><span class="p">,</span>
        <span class="n">registered_model_name</span><span class="o">=</span><span class="n">registered_model_name</span><span class="p">,</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span>
        <span class="n">conda_env</span><span class="o">=</span><span class="n">conda_env</span><span class="p">,</span>
        <span class="n">code_paths</span><span class="o">=</span><span class="n">code_paths</span><span class="p">,</span>
        <span class="n">signature</span><span class="o">=</span><span class="n">signature</span><span class="p">,</span>
        <span class="n">input_example</span><span class="o">=</span><span class="n">input_example</span><span class="p">,</span>
        <span class="n">await_registration_for</span><span class="o">=</span><span class="n">await_registration_for</span><span class="p">,</span>
        <span class="n">pip_requirements</span><span class="o">=</span><span class="n">pip_requirements</span><span class="p">,</span>
        <span class="n">extra_pip_requirements</span><span class="o">=</span><span class="n">extra_pip_requirements</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
        <span class="n">example_no_conversion</span><span class="o">=</span><span class="n">example_no_conversion</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_load_model</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_is_valid_message</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;content&quot;</span> <span class="ow">in</span> <span class="n">d</span> <span class="ow">and</span> <span class="s2">&quot;role&quot;</span> <span class="ow">in</span> <span class="n">d</span>


<span class="k">class</span> <span class="nc">_ContentFormatter</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task</span><span class="p">,</span> <span class="n">template</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;completions&quot;</span><span class="p">:</span>
            <span class="n">template</span> <span class="o">=</span> <span class="n">template</span> <span class="ow">or</span> <span class="s2">&quot;</span><span class="si">{prompt}</span><span class="s2">&quot;</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">template</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="k">raise</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Template for task </span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2"> expects type `str`, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">template</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">template</span> <span class="o">=</span> <span class="n">template</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">format_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">format_prompt</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">variables</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">_parse_format_fields</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">template</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;chat.completions&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">template</span><span class="p">:</span>
                <span class="n">template</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;</span><span class="si">{content}</span><span class="s2">&quot;</span><span class="p">}]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">_is_valid_message</span><span class="p">,</span> <span class="n">template</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Template for task </span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2"> expects type `dict` with keys &#39;content&#39; &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;and &#39;role&#39;, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">template</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">template</span> <span class="o">=</span> <span class="n">template</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">format_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">format_chat</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">variables</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
                <span class="nb">set</span><span class="p">(</span>
                    <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span>
                        <span class="n">_parse_format_fields</span><span class="p">(</span><span class="n">message</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;content&quot;</span><span class="p">))</span>
                        <span class="o">|</span> <span class="n">_parse_format_fields</span><span class="p">(</span><span class="n">message</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;role&quot;</span><span class="p">))</span>
                        <span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">template</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">variables</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">template</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;</span><span class="si">{content}</span><span class="s2">&quot;</span><span class="p">})</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">variables</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;content&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Task type ``</span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2">`` is not supported for formatting.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">format</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">missing_params</span> <span class="o">:=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected parameters </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">variables</span><span class="si">}</span><span class="s2"> to be provided, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;only got </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">params</span><span class="p">)</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">missing_params</span><span class="p">)</span><span class="si">}</span><span class="s2"> are missing.&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">format_fn</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">format_prompt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">params</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">variables</span><span class="p">})</span>

    <span class="k">def</span> <span class="nf">format_chat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
        <span class="n">format_args</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">params</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">variables</span><span class="p">}</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">message</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;role&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="n">format_args</span><span class="p">),</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">message</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;content&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="n">format_args</span><span class="p">),</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">template</span>
        <span class="p">]</span>


<span class="k">def</span> <span class="nf">_first_string_column</span><span class="p">(</span><span class="n">pdf</span><span class="p">):</span>
    <span class="n">iter_str_cols</span> <span class="o">=</span> <span class="p">(</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">pdf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">str</span><span class="p">))</span>
    <span class="n">col</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iter_str_cols</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">col</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Could not find a string column in the input data: </span><span class="si">{</span><span class="n">pdf</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">col</span>


<span class="k">class</span> <span class="nc">_OpenAIWrapper</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="n">task</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;task&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">task</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_PYFUNC_SUPPORTED_TASKS</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unsupported task: </span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2">. Supported tasks: </span><span class="si">{</span><span class="n">_PYFUNC_SUPPORTED_TASKS</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">=</span> <span class="n">task</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">api_config</span> <span class="o">=</span> <span class="n">_get_api_config</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">api_token</span> <span class="o">=</span> <span class="n">_OAITokenHolder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">api_config</span><span class="o">.</span><span class="n">api_type</span><span class="p">)</span>
        <span class="c1"># If the same parameter exists in self.model &amp; self.api_config,</span>
        <span class="c1"># we use the parameter from self.model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">request_configs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;api_base&quot;</span><span class="p">,</span> <span class="s2">&quot;api_version&quot;</span><span class="p">,</span> <span class="s2">&quot;api_type&quot;</span><span class="p">,</span> <span class="s2">&quot;engine&quot;</span><span class="p">,</span> <span class="s2">&quot;deployment_id&quot;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">request_configs</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">value</span> <span class="o">:=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">api_config</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">request_configs</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">request_configs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;api_type&quot;</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;azure&quot;</span><span class="p">,</span> <span class="s2">&quot;azure_ad&quot;</span><span class="p">,</span> <span class="s2">&quot;azuread&quot;</span><span class="p">):</span>
            <span class="n">deployment_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">request_configs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;deployment_id&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">request_configs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;engine&quot;</span><span class="p">):</span>
                <span class="c1"># Avoid using both parameters as they serve the same purpose</span>
                <span class="c1"># Invalid inputs:</span>
                <span class="c1">#   - Wrong engine + correct/wrong deployment_id</span>
                <span class="c1">#   - No engine + wrong deployment_id</span>
                <span class="c1"># Valid inputs:</span>
                <span class="c1">#   - Correct engine + correct/wrong deployment_id</span>
                <span class="c1">#   - No engine + correct deployment_id</span>
                <span class="k">if</span> <span class="n">deployment_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="s2">&quot;Both engine and deployment_id are set. &quot;</span>
                        <span class="s2">&quot;Using engine as it takes precedence.&quot;</span>
                    <span class="p">)</span>
            <span class="k">elif</span> <span class="n">deployment_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                    <span class="s2">&quot;Either engine or deployment_id must be set for Azure OpenAI API&quot;</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">!=</span> <span class="s2">&quot;embeddings&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_setup_completions</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_raw_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the underlying model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>

    <span class="k">def</span> <span class="nf">_setup_completions</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;chat.completions&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">template</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;messages&quot;</span><span class="p">,</span> <span class="p">[])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">template</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">formater</span> <span class="o">=</span> <span class="n">_ContentFormatter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">template</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">format_completions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params_list</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">formater</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span> <span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">params_list</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">get_params_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">formater</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">variable</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">formater</span><span class="o">.</span><span class="n">variables</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">variable</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">data</span><span class="p">[[</span><span class="n">variable</span><span class="p">]]</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="n">orient</span><span class="o">=</span><span class="s2">&quot;records&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">first_string_column</span> <span class="o">=</span> <span class="n">_first_string_column</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="k">return</span> <span class="p">[{</span><span class="n">variable</span><span class="p">:</span> <span class="n">s</span><span class="p">}</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="n">first_string_column</span><span class="p">]]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">formater</span><span class="o">.</span><span class="n">variables</span><span class="p">]</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="n">orient</span><span class="o">=</span><span class="s2">&quot;records&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_construct_request_url</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task_url</span><span class="p">,</span> <span class="n">default_url</span><span class="p">):</span>
        <span class="n">api_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">request_configs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;api_type&quot;</span><span class="p">)</span>
        <span class="n">api_base</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">request_configs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;api_base&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">api_type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;azure&quot;</span><span class="p">,</span> <span class="s2">&quot;azure_ad&quot;</span><span class="p">,</span> <span class="s2">&quot;azuread&quot;</span><span class="p">):</span>
            <span class="n">api_version</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">request_configs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;api_version&quot;</span><span class="p">)</span>
            <span class="n">deployment_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">request_configs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;deployment_id&quot;</span><span class="p">)</span>

            <span class="k">return</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">api_base</span><span class="si">}</span><span class="s2">/openai/deployments/</span><span class="si">{</span><span class="n">deployment_id</span><span class="si">}</span><span class="s2">/&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">task_url</span><span class="si">}</span><span class="s2">?api-version=</span><span class="si">{</span><span class="n">api_version</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">api_base</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">task_url</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="n">api_base</span> <span class="k">else</span> <span class="n">default_url</span>

    <span class="k">def</span> <span class="nf">_predict_chat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">mlflow.openai.api_request_parallel_processor</span> <span class="kn">import</span> <span class="n">process_api_requests</span>

        <span class="n">_validate_model_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="n">messages_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">format_completions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_params_list</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
        <span class="n">requests</span> <span class="o">=</span> <span class="p">[{</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">,</span> <span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">}</span> <span class="k">for</span> <span class="n">messages</span> <span class="ow">in</span> <span class="n">messages_list</span><span class="p">]</span>
        <span class="n">request_url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_construct_request_url</span><span class="p">(</span><span class="s2">&quot;chat/completions&quot;</span><span class="p">,</span> <span class="n">REQUEST_URL_CHAT</span><span class="p">)</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">process_api_requests</span><span class="p">(</span>
            <span class="n">requests</span><span class="p">,</span>
            <span class="n">request_url</span><span class="p">,</span>
            <span class="n">api_token</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">api_token</span><span class="p">,</span>
            <span class="n">max_requests_per_minute</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">api_config</span><span class="o">.</span><span class="n">max_requests_per_minute</span><span class="p">,</span>
            <span class="n">max_tokens_per_minute</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">api_config</span><span class="o">.</span><span class="n">max_tokens_per_minute</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;choices&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;message&quot;</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_predict_completions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">mlflow.openai.api_request_parallel_processor</span> <span class="kn">import</span> <span class="n">process_api_requests</span>

        <span class="n">_validate_model_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="n">prompts_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">format_completions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_params_list</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">api_config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Requests are being batched by </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2"> samples.&quot;</span><span class="p">)</span>
        <span class="n">requests</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="o">**</span><span class="n">params</span><span class="p">,</span>
                <span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="n">prompts_list</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">],</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompts_list</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">request_url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_construct_request_url</span><span class="p">(</span><span class="s2">&quot;completions&quot;</span><span class="p">,</span> <span class="n">REQUEST_URL_COMPLETIONS</span><span class="p">)</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">process_api_requests</span><span class="p">(</span>
            <span class="n">requests</span><span class="p">,</span>
            <span class="n">request_url</span><span class="p">,</span>
            <span class="n">api_token</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">api_token</span><span class="p">,</span>
            <span class="n">max_requests_per_minute</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">api_config</span><span class="o">.</span><span class="n">max_requests_per_minute</span><span class="p">,</span>
            <span class="n">max_tokens_per_minute</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">api_config</span><span class="o">.</span><span class="n">max_tokens_per_minute</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">row</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">results</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;choices&quot;</span><span class="p">]]</span>

    <span class="k">def</span> <span class="nf">_predict_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">mlflow.openai.api_request_parallel_processor</span> <span class="kn">import</span> <span class="n">process_api_requests</span>

        <span class="n">_validate_model_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">api_config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Requests are being batched by </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2"> samples.&quot;</span><span class="p">)</span>

        <span class="n">first_string_column</span> <span class="o">=</span> <span class="n">_first_string_column</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">texts</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">first_string_column</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">requests</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="o">**</span><span class="n">params</span><span class="p">,</span>
                <span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="n">texts</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">],</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">request_url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_construct_request_url</span><span class="p">(</span><span class="s2">&quot;embeddings&quot;</span><span class="p">,</span> <span class="n">REQUEST_URL_EMBEDDINGS</span><span class="p">)</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">process_api_requests</span><span class="p">(</span>
            <span class="n">requests</span><span class="p">,</span>
            <span class="n">request_url</span><span class="p">,</span>
            <span class="n">api_token</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">api_token</span><span class="p">,</span>
            <span class="n">max_requests_per_minute</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">api_config</span><span class="o">.</span><span class="n">max_requests_per_minute</span><span class="p">,</span>
            <span class="n">max_tokens_per_minute</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">api_config</span><span class="o">.</span><span class="n">max_tokens_per_minute</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">row</span><span class="p">[</span><span class="s2">&quot;embedding&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">results</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]]</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            data: Model input data.</span>
<span class="sd">            params: Additional parameters to pass to the model for inference.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Model predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">api_token</span><span class="o">.</span><span class="n">refresh</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;chat.completions&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_chat</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">params</span> <span class="ow">or</span> <span class="p">{})</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;completions&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_completions</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">params</span> <span class="ow">or</span> <span class="p">{})</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;embeddings&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_embeddings</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">params</span> <span class="ow">or</span> <span class="p">{})</span>


<span class="k">def</span> <span class="nf">_load_pyfunc</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Loads PyFunc implementation. Called by ``pyfunc.load_model``.</span>

<span class="sd">    Args:</span>
<span class="sd">        path: Local filesystem path to the MLflow Model with the ``openai`` flavor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_OpenAIWrapper</span><span class="p">(</span><span class="n">_load_model</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>


<div class="viewcode-block" id="load_model"><a class="viewcode-back" href="../../python_api/mlflow.openai.html#mlflow.openai.load_model">[docs]</a><span class="nd">@experimental</span>
<span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="n">model_uri</span><span class="p">,</span> <span class="n">dst_path</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load an OpenAI model from a local file or a run.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_uri: The location, in URI format, of the MLflow model. For example:</span>

<span class="sd">            - ``/Users/me/path/to/local/model``</span>
<span class="sd">            - ``relative/path/to/local/model``</span>
<span class="sd">            - ``s3://my_bucket/path/to/model``</span>
<span class="sd">            - ``runs:/&lt;mlflow_run_id&gt;/run-relative/path/to/model``</span>

<span class="sd">            For more information about supported URI schemes, see</span>
<span class="sd">            `Referencing Artifacts &lt;https://www.mlflow.org/docs/latest/tracking.html#</span>
<span class="sd">            artifact-locations&gt;`_.</span>
<span class="sd">        dst_path: The local filesystem path to which to download the model artifact.</span>
<span class="sd">            This directory must already exist. If unspecified, a local output</span>
<span class="sd">            path will be created.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A dictionary representing the OpenAI model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">local_model_path</span> <span class="o">=</span> <span class="n">_download_artifact_from_uri</span><span class="p">(</span><span class="n">artifact_uri</span><span class="o">=</span><span class="n">model_uri</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="n">dst_path</span><span class="p">)</span>
    <span class="n">flavor_conf</span> <span class="o">=</span> <span class="n">_get_flavor_configuration</span><span class="p">(</span><span class="n">local_model_path</span><span class="p">,</span> <span class="n">FLAVOR_NAME</span><span class="p">)</span>
    <span class="n">_add_code_from_conf_to_system_path</span><span class="p">(</span><span class="n">local_model_path</span><span class="p">,</span> <span class="n">flavor_conf</span><span class="p">)</span>
    <span class="n">model_data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">local_model_path</span><span class="p">,</span> <span class="n">flavor_conf</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">MODEL_FILENAME</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">_load_model</span><span class="p">(</span><span class="n">model_data_path</span><span class="p">)</span></div>


<div class="viewcode-block" id="autolog"><a class="viewcode-back" href="../../python_api/mlflow.openai.html#mlflow.openai.autolog">[docs]</a><span class="nd">@experimental</span>
<span class="nd">@autologging_integration</span><span class="p">(</span><span class="n">FLAVOR_NAME</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">autolog</span><span class="p">(</span>
    <span class="n">log_input_examples</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">log_model_signatures</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">log_models</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">log_datasets</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">disable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">exclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">disable_for_unsupported_versions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">silent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">registered_model_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_tags</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">log_traces</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Enables (or disables) and configures autologging from OpenAI to MLflow.</span>
<span class="sd">    Raises :py:class:`MlflowException &lt;mlflow.exceptions.MlflowException&gt;`</span>
<span class="sd">    if the OpenAI version &lt; 1.0.</span>

<span class="sd">    Args:</span>
<span class="sd">        log_input_examples: If ``True``, input examples from inference data are collected and</span>
<span class="sd">            logged along with Langchain model artifacts during inference. If</span>
<span class="sd">            ``False``, input examples are not logged.</span>
<span class="sd">            Note: Input examples are MLflow model attributes</span>
<span class="sd">            and are only collected if ``log_models`` is also ``True``.</span>
<span class="sd">        log_model_signatures: If ``True``,</span>
<span class="sd">            :py:class:`ModelSignatures &lt;mlflow.models.ModelSignature&gt;`</span>
<span class="sd">            describing model inputs and outputs are collected and logged along</span>
<span class="sd">            with OpenAI model artifacts during inference. If ``False``,</span>
<span class="sd">            signatures are not logged.</span>
<span class="sd">            Note: Model signatures are MLflow model attributes</span>
<span class="sd">            and are only collected if ``log_models`` is also ``True``.</span>
<span class="sd">        log_models: If ``True``, OpenAI models are logged as MLflow model artifacts.</span>
<span class="sd">            If ``False``, OpenAI models are not logged.</span>
<span class="sd">            Input examples and model signatures, which are attributes of MLflow models,</span>
<span class="sd">            are also omitted when ``log_models`` is ``False``.</span>
<span class="sd">        log_datasets: If ``True``, dataset information is logged to MLflow Tracking</span>
<span class="sd">            if applicable. If ``False``, dataset information is not logged.</span>
<span class="sd">        disable: If ``True``, disables the OpenAI autologging integration. If ``False``,</span>
<span class="sd">            enables the OpenAI autologging integration.</span>
<span class="sd">        exclusive: If ``True``, autologged content is not logged to user-created fluent runs.</span>
<span class="sd">            If ``False``, autologged content is logged to the active fluent run,</span>
<span class="sd">            which may be user-created.</span>
<span class="sd">        disable_for_unsupported_versions: If ``True``, disable autologging for versions of</span>
<span class="sd">            OpenAI that have not been tested against this version of the MLflow</span>
<span class="sd">            client or are incompatible.</span>
<span class="sd">        silent: If ``True``, suppress all event logs and warnings from MLflow during OpenAI</span>
<span class="sd">            autologging. If ``False``, show all events and warnings during OpenAI</span>
<span class="sd">            autologging.</span>
<span class="sd">        registered_model_name: If given, each time a model is trained, it is registered as a</span>
<span class="sd">            new model version of the registered model with this name.</span>
<span class="sd">            The registered model is created if it does not already exist.</span>
<span class="sd">        extra_tags: A dictionary of extra tags to set on each managed run created by autologging.</span>
<span class="sd">        log_traces: If ``True``, traces are logged for OpenAI models. If ``False``, no traces are</span>
<span class="sd">            collected during inference. Default to ``True``.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">Version</span><span class="p">(</span><span class="n">_get_openai_package_version</span><span class="p">())</span><span class="o">.</span><span class="n">major</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span><span class="s2">&quot;OpenAI autologging is only supported for openai &gt;= 1.0.0&quot;</span><span class="p">)</span>

    <span class="kn">from</span> <span class="nn">openai.resources.chat.completions</span> <span class="kn">import</span> <span class="n">Completions</span> <span class="k">as</span> <span class="n">ChatCompletions</span>
    <span class="kn">from</span> <span class="nn">openai.resources.completions</span> <span class="kn">import</span> <span class="n">Completions</span>
    <span class="kn">from</span> <span class="nn">openai.resources.embeddings</span> <span class="kn">import</span> <span class="n">Embeddings</span>

    <span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="p">(</span><span class="n">ChatCompletions</span><span class="p">,</span> <span class="n">Completions</span><span class="p">,</span> <span class="n">Embeddings</span><span class="p">):</span>
        <span class="n">safe_patch</span><span class="p">(</span>
            <span class="n">FLAVOR_NAME</span><span class="p">,</span>
            <span class="n">task</span><span class="p">,</span>
            <span class="s2">&quot;create&quot;</span><span class="p">,</span>
            <span class="n">patched_call</span><span class="p">,</span>
        <span class="p">)</span></div>
</pre></div>

              </div>
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../../',
      VERSION:'2.17.1.dev0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../../_static/clippy.svg";</script>
  <script type="text/javascript" src="../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>
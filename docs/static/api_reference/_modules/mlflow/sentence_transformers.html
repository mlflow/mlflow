

<!DOCTYPE html>
<!-- source: docs/source/_modules/mlflow/sentence_transformers -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mlflow.sentence_transformers</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/_modules/mlflow/sentence_transformers.html">
  
  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    

    

  
    

  

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../../genindex.html"/>
        <link rel="search" title="Search" href="../../search.html"/>
    <link rel="top" title="MLflow 2.17.1.dev0 documentation" href="../../index.html"/>
        <link rel="up" title="Module code" href="../index.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../../_static/jquery.js"></script>
<script type="text/javascript" src="../../_static/underscore.js"></script>
<script type="text/javascript" src="../../_static/doctools.js"></script>
<script type="text/javascript" src="../../_static/tabs.js"></script>
<script type="text/javascript" src="../../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="../../_static/runllm.js"></script>

<body class="wy-body-for-nav" role="document">
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <ul>
  <li class="menu-toggle">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
    <a href="../../index.html" class="wy-nav-top-logo"
      ><img src="../../_static/MLflow-logo-final-black.png" alt="MLflow"
    /></a>
    <span class="version">2.17.1.dev0</span>
  </li>
</ul>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../index.html" class="main-navigation-home"><img src="../../_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul>
<li class="toctree-l1"><a class="reference internal" href="../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rest-api.html">REST API</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../index.html">Module code</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>mlflow.sentence_transformers</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/_modules/mlflow/sentence_transformers" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <h1>Source code for mlflow.sentence_transformers</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">yaml</span>
<span class="kn">from</span> <span class="nn">packaging.version</span> <span class="kn">import</span> <span class="n">Version</span>

<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">from</span> <span class="nn">mlflow</span> <span class="kn">import</span> <span class="n">pyfunc</span>
<span class="kn">from</span> <span class="nn">mlflow.exceptions</span> <span class="kn">import</span> <span class="n">MlflowException</span>
<span class="kn">from</span> <span class="nn">mlflow.models</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">ModelInputExample</span><span class="p">,</span> <span class="n">ModelSignature</span><span class="p">,</span> <span class="n">infer_pip_requirements</span>
<span class="kn">from</span> <span class="nn">mlflow.models.model</span> <span class="kn">import</span> <span class="n">MLMODEL_FILE_NAME</span>
<span class="kn">from</span> <span class="nn">mlflow.models.signature</span> <span class="kn">import</span> <span class="n">_infer_signature_from_input_example</span>
<span class="kn">from</span> <span class="nn">mlflow.models.utils</span> <span class="kn">import</span> <span class="n">_save_example</span>
<span class="kn">from</span> <span class="nn">mlflow.tracking._model_registry</span> <span class="kn">import</span> <span class="n">DEFAULT_AWAIT_MAX_SLEEP_SECONDS</span>
<span class="kn">from</span> <span class="nn">mlflow.transformers.llm_inference_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_LLM_INFERENCE_TASK_EMBEDDING</span><span class="p">,</span>
    <span class="n">_LLM_V1_EMBEDDING_INPUT_KEY</span><span class="p">,</span>
    <span class="n">postprocess_output_for_llm_v1_embedding_task</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.types.llm</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">EMBEDDING_MODEL_INPUT_SCHEMA</span><span class="p">,</span>
    <span class="n">EMBEDDING_MODEL_OUTPUT_SCHEMA</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.types.schema</span> <span class="kn">import</span> <span class="n">ColSpec</span><span class="p">,</span> <span class="n">Schema</span><span class="p">,</span> <span class="n">TensorSpec</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.annotations</span> <span class="kn">import</span> <span class="n">experimental</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.docstring_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">LOG_MODEL_PARAM_DOCS</span><span class="p">,</span>
    <span class="n">docstring_version_compatibility_warning</span><span class="p">,</span>
    <span class="n">format_docstring</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.environment</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_CONDA_ENV_FILE_NAME</span><span class="p">,</span>
    <span class="n">_CONSTRAINTS_FILE_NAME</span><span class="p">,</span>
    <span class="n">_PYTHON_ENV_FILE_NAME</span><span class="p">,</span>
    <span class="n">_REQUIREMENTS_FILE_NAME</span><span class="p">,</span>
    <span class="n">_mlflow_conda_env</span><span class="p">,</span>
    <span class="n">_process_conda_env</span><span class="p">,</span>
    <span class="n">_process_pip_requirements</span><span class="p">,</span>
    <span class="n">_PythonEnv</span><span class="p">,</span>
    <span class="n">_validate_env_arguments</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.file_utils</span> <span class="kn">import</span> <span class="n">get_total_file_size</span><span class="p">,</span> <span class="n">write_to</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.model_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_add_code_from_conf_to_system_path</span><span class="p">,</span>
    <span class="n">_download_artifact_from_uri</span><span class="p">,</span>
    <span class="n">_get_flavor_configuration_from_uri</span><span class="p">,</span>
    <span class="n">_validate_and_copy_code_paths</span><span class="p">,</span>
    <span class="n">_validate_and_prepare_target_save_path</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.requirements_utils</span> <span class="kn">import</span> <span class="n">_get_pinned_requirement</span>

<span class="n">FLAVOR_NAME</span> <span class="o">=</span> <span class="s2">&quot;sentence_transformers&quot;</span>
<span class="n">_TRANSFORMER_SOURCE_MODEL_NAME_KEY</span> <span class="o">=</span> <span class="s2">&quot;source_model_name&quot;</span>
<span class="n">_TRANSFORMER_MODEL_TYPE_KEY</span> <span class="o">=</span> <span class="s2">&quot;pipeline_model_type&quot;</span>

<span class="n">SENTENCE_TRANSFORMERS_DATA_PATH</span> <span class="o">=</span> <span class="s2">&quot;model.sentence_transformer&quot;</span>
<span class="n">_INFERENCE_CONFIG_PATH</span> <span class="o">=</span> <span class="s2">&quot;inference_config&quot;</span>

<span class="c1"># Patterns to extract HuggingFace model repository name from the local snapshot path.</span>
<span class="c1"># The path format would be like /path/to/{username}_{modelname}, where user name can</span>
<span class="c1"># only contain number, letters, and dashes.</span>
<span class="n">_LOCAL_SNAPSHOT_PATH_PATTERN</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;/([0-9a-zA-Z-]+)_([^\/]+)/$&quot;</span><span class="p">)</span>

<span class="n">_logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="get_default_pip_requirements"><a class="viewcode-back" href="../../python_api/mlflow.sentence_transformers.html#mlflow.sentence_transformers.get_default_pip_requirements">[docs]</a><span class="nd">@experimental</span>
<span class="k">def</span> <span class="nf">get_default_pip_requirements</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Retrieves the set of minimal dependencies for the ``sentence_transformers`` flavor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A list of default pip requirements for MLflow Models that have been produced with the</span>
<span class="sd">        ``sentence-transformers`` flavor. Calls to :py:func:`save_model()` and</span>
<span class="sd">        :py:func:`log_model()` produce a pip environment that contain these</span>
<span class="sd">        requirements at a minimum.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">base_reqs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sentence-transformers&quot;</span><span class="p">,</span> <span class="s2">&quot;transformers&quot;</span><span class="p">,</span> <span class="s2">&quot;torch&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">_get_pinned_requirement</span><span class="p">(</span><span class="n">module</span><span class="p">)</span> <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">base_reqs</span><span class="p">]</span></div>


<div class="viewcode-block" id="get_default_conda_env"><a class="viewcode-back" href="../../python_api/mlflow.sentence_transformers.html#mlflow.sentence_transformers.get_default_conda_env">[docs]</a><span class="nd">@experimental</span>
<span class="k">def</span> <span class="nf">get_default_conda_env</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns:</span>
<span class="sd">        The default Conda environment for MLflow Models produced with the</span>
<span class="sd">        ``sentence_transformers`` flavor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_mlflow_conda_env</span><span class="p">(</span><span class="n">additional_pip_deps</span><span class="o">=</span><span class="n">get_default_pip_requirements</span><span class="p">())</span></div>


<span class="nd">@experimental</span>
<span class="k">def</span> <span class="nf">_verify_task_and_update_metadata</span><span class="p">(</span>
    <span class="n">task</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">task</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">_LLM_INFERENCE_TASK_EMBEDDING</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Received invalid parameter value for `task` argument </span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2">. Task type could &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;only be </span><span class="si">{</span><span class="n">_LLM_INFERENCE_TASK_EMBEDDING</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">metadata</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="s2">&quot;task&quot;</span> <span class="ow">in</span> <span class="n">metadata</span> <span class="ow">and</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;task&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="n">task</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Received invalid parameter value for `task` argument </span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2">. Task type is &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;inconsistent with the task value from metadata </span><span class="si">{</span><span class="n">metadata</span><span class="p">[</span><span class="s1">&#39;task&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;task&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">task</span>
    <span class="k">return</span> <span class="n">metadata</span>


<div class="viewcode-block" id="save_model"><a class="viewcode-back" href="../../python_api/mlflow.sentence_transformers.html#mlflow.sentence_transformers.save_model">[docs]</a><span class="nd">@experimental</span>
<span class="nd">@docstring_version_compatibility_warning</span><span class="p">(</span><span class="n">integration_name</span><span class="o">=</span><span class="n">FLAVOR_NAME</span><span class="p">)</span>
<span class="nd">@format_docstring</span><span class="p">(</span><span class="n">LOG_MODEL_PARAM_DOCS</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">package_name</span><span class="o">=</span><span class="n">FLAVOR_NAME</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">task</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">inference_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">code_paths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mlflow_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Model</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">signature</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelSignature</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_example</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelInputExample</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">pip_requirements</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_pip_requirements</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">conda_env</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">example_no_conversion</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    .. note::</span>

<span class="sd">        Saving Sentence Transformers models with custom code (i.e. models that require</span>
<span class="sd">        ``trust_remote_code=True``) is supported in MLflow 2.12.0 and above.</span>


<span class="sd">    Save a trained ``sentence-transformers`` model to a path on the local file system.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: A trained ``sentence-transformers`` model.</span>
<span class="sd">        path: Local path destination for the serialized model to be saved.</span>
<span class="sd">        task: MLflow inference task type for ``sentence-transformers`` model. Candidate task type</span>
<span class="sd">            is `llm/v1/embeddings`.</span>
<span class="sd">        inference_config:</span>
<span class="sd">            A dict of valid inference parameters that can be applied to a ``sentence-transformer``</span>
<span class="sd">            model instance during inference.</span>
<span class="sd">            These arguments are used exclusively for the case of loading the model as a ``pyfunc``</span>
<span class="sd">            Model or for use in Spark.</span>
<span class="sd">            These values are not applied to a returned model from a call to</span>
<span class="sd">            ``mlflow.sentence_transformers.load_model()``</span>
<span class="sd">        code_paths: {{ code_paths }}</span>
<span class="sd">        mlflow_model: An MLflow model object that specifies the flavor that this model is being</span>
<span class="sd">            added to.</span>
<span class="sd">        signature: an instance of the :py:class:`ModelSignature &lt;mlflow.models.ModelSignature&gt;`</span>
<span class="sd">            class that describes the model&#39;s inputs and outputs. If not specified but an</span>
<span class="sd">            ``input_example`` is supplied, a signature will be automatically inferred</span>
<span class="sd">            based on the supplied input example and model. If both ``signature`` and</span>
<span class="sd">            ``input_example`` are not specified or the automatic signature inference</span>
<span class="sd">            fails, a default signature will be adopted. To prevent a signature from being</span>
<span class="sd">            adopted, set ``signature`` to ``False``. To manually infer a model signature,</span>
<span class="sd">            call :py:func:`infer_signature() &lt;mlflow.models.infer_signature&gt;` on datasets</span>
<span class="sd">            with valid model inputs and valid model outputs.</span>
<span class="sd">        input_example: {{ input_example }}</span>
<span class="sd">        pip_requirements: {{ pip_requirements }}</span>
<span class="sd">        extra_pip_requirements: {{ extra_pip_requirements }}</span>
<span class="sd">        conda_env: {{ conda_env }}</span>
<span class="sd">        metadata: {{ metadata }}</span>
<span class="sd">        example_no_conversion: {{ example_no_conversion }}</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">sentence_transformers</span>

    <span class="n">_validate_env_arguments</span><span class="p">(</span><span class="n">conda_env</span><span class="p">,</span> <span class="n">pip_requirements</span><span class="p">,</span> <span class="n">extra_pip_requirements</span><span class="p">)</span>

    <span class="n">path</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span>
    <span class="n">model_data_path</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">SENTENCE_TRANSFORMERS_DATA_PATH</span><span class="p">)</span>

    <span class="n">_validate_and_prepare_target_save_path</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>

    <span class="n">code_dir_subpath</span> <span class="o">=</span> <span class="n">_validate_and_copy_code_paths</span><span class="p">(</span><span class="n">code_paths</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">mlflow_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mlflow_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>
    <span class="n">saved_example</span> <span class="o">=</span> <span class="n">_save_example</span><span class="p">(</span>
        <span class="n">mlflow_model</span><span class="p">,</span> <span class="n">input_example</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">no_conversion</span><span class="o">=</span><span class="n">example_no_conversion</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">task</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">signature</span> <span class="o">=</span> <span class="n">ModelSignature</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">EMBEDDING_MODEL_INPUT_SCHEMA</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">EMBEDDING_MODEL_OUTPUT_SCHEMA</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">signature</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">saved_example</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">wrapped_model</span> <span class="o">=</span> <span class="n">_SentenceTransformerModelWrapper</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">signature</span> <span class="o">=</span> <span class="n">_infer_signature_from_input_example</span><span class="p">(</span><span class="n">saved_example</span><span class="p">,</span> <span class="n">wrapped_model</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">signature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">signature</span> <span class="o">=</span> <span class="n">_get_default_signature</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">signature</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
        <span class="n">signature</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">signature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mlflow_model</span><span class="o">.</span><span class="n">signature</span> <span class="o">=</span> <span class="n">signature</span>
    <span class="k">if</span> <span class="n">metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mlflow_model</span><span class="o">.</span><span class="n">metadata</span> <span class="o">=</span> <span class="n">metadata</span>
    <span class="n">model_config</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">task</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mlflow_model</span><span class="o">.</span><span class="n">metadata</span> <span class="o">=</span> <span class="n">_verify_task_and_update_metadata</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">mlflow_model</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span>
        <span class="n">model_config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="n">_LLM_INFERENCE_TASK_EMBEDDING</span><span class="p">}</span>

    <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">model_data_path</span><span class="p">))</span>

    <span class="n">pyfunc</span><span class="o">.</span><span class="n">add_to_model</span><span class="p">(</span>
        <span class="n">mlflow_model</span><span class="p">,</span>
        <span class="n">loader_module</span><span class="o">=</span><span class="s2">&quot;mlflow.sentence_transformers&quot;</span><span class="p">,</span>
        <span class="n">data</span><span class="o">=</span><span class="n">SENTENCE_TRANSFORMERS_DATA_PATH</span><span class="p">,</span>
        <span class="n">conda_env</span><span class="o">=</span><span class="n">_CONDA_ENV_FILE_NAME</span><span class="p">,</span>
        <span class="n">python_env</span><span class="o">=</span><span class="n">_PYTHON_ENV_FILE_NAME</span><span class="p">,</span>
        <span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">,</span>
        <span class="n">code</span><span class="o">=</span><span class="n">code_dir_subpath</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">mlflow_model</span><span class="o">.</span><span class="n">add_flavor</span><span class="p">(</span>
        <span class="n">FLAVOR_NAME</span><span class="p">,</span>
        <span class="n">sentence_transformers_version</span><span class="o">=</span><span class="n">sentence_transformers</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
        <span class="n">code</span><span class="o">=</span><span class="n">code_dir_subpath</span><span class="p">,</span>
        <span class="o">**</span><span class="n">_get_transformers_model_metadata</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">size</span> <span class="o">:=</span> <span class="n">get_total_file_size</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="n">mlflow_model</span><span class="o">.</span><span class="n">model_size_bytes</span> <span class="o">=</span> <span class="n">size</span>
    <span class="n">mlflow_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">MLMODEL_FILE_NAME</span><span class="p">)))</span>

    <span class="k">if</span> <span class="n">inference_config</span><span class="p">:</span>
        <span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_INFERENCE_CONFIG_PATH</span><span class="p">)</span><span class="o">.</span><span class="n">write_text</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">inference_config</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">conda_env</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">pip_requirements</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">default_reqs</span> <span class="o">=</span> <span class="n">get_default_pip_requirements</span><span class="p">()</span>
            <span class="n">inferred_reqs</span> <span class="o">=</span> <span class="n">infer_pip_requirements</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="p">),</span> <span class="n">FLAVOR_NAME</span><span class="p">,</span> <span class="n">fallback</span><span class="o">=</span><span class="n">default_reqs</span><span class="p">)</span>
            <span class="n">default_reqs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">inferred_reqs</span><span class="p">)</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">default_reqs</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">default_reqs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conda_env</span><span class="p">,</span> <span class="n">pip_requirements</span><span class="p">,</span> <span class="n">pip_constraints</span> <span class="o">=</span> <span class="n">_process_pip_requirements</span><span class="p">(</span>
            <span class="n">default_reqs</span><span class="p">,</span> <span class="n">pip_requirements</span><span class="p">,</span> <span class="n">extra_pip_requirements</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">conda_env</span><span class="p">,</span> <span class="n">pip_requirements</span><span class="p">,</span> <span class="n">pip_constraints</span> <span class="o">=</span> <span class="n">_process_conda_env</span><span class="p">(</span><span class="n">conda_env</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_CONDA_ENV_FILE_NAME</span><span class="p">)</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">yaml</span><span class="o">.</span><span class="n">safe_dump</span><span class="p">(</span><span class="n">conda_env</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">pip_constraints</span><span class="p">:</span>
        <span class="n">write_to</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_CONSTRAINTS_FILE_NAME</span><span class="p">)),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pip_constraints</span><span class="p">))</span>

    <span class="n">write_to</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_REQUIREMENTS_FILE_NAME</span><span class="p">)),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pip_requirements</span><span class="p">))</span>

    <span class="n">_PythonEnv</span><span class="o">.</span><span class="n">current</span><span class="p">()</span><span class="o">.</span><span class="n">to_yaml</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_PYTHON_ENV_FILE_NAME</span><span class="p">)))</span></div>


<span class="k">def</span> <span class="nf">_get_transformers_model_metadata</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract metadata about the underlying Transformers model, such as the model class name</span>
<span class="sd">    and the repository id.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: A SentenceTransformer model instance.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A dictionary containing metadata about the Transformers model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">sentence_transformers.models</span> <span class="kn">import</span> <span class="n">Transformer</span>

    <span class="c1"># NB: We assume the SentenceTransformer model contains only up to one Transformer model.</span>
    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">Transformer</span><span class="p">):</span>
            <span class="n">model_instance</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">auto_model</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="n">_TRANSFORMER_SOURCE_MODEL_NAME_KEY</span><span class="p">:</span> <span class="n">_get_transformers_model_name</span><span class="p">(</span>
                    <span class="n">model_instance</span><span class="o">.</span><span class="n">name_or_path</span>
                <span class="p">),</span>
                <span class="n">_TRANSFORMER_MODEL_TYPE_KEY</span><span class="p">:</span> <span class="n">model_instance</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
            <span class="p">}</span>
    <span class="k">return</span> <span class="p">{}</span>


<span class="k">def</span> <span class="nf">_get_transformers_model_name</span><span class="p">(</span><span class="n">model_name_or_path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract the Transformers model name from name_or_path attribute of a Transformer model.</span>

<span class="sd">    Normally the name_or_path attribute just points to the model name, but in Sentence</span>
<span class="sd">    Transformers &lt; 2.3.0, the library loads the Transformers model after local snapshot</span>
<span class="sd">    download, so the name_or_path attribute points to the local filepath.</span>
<span class="sd">    https://github.com/UKPLab/sentence-transformers/commit/9db0f205adcf315d16961fea7e9e6906cb950d43</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">m</span> <span class="o">:=</span> <span class="n">_LOCAL_SNAPSHOT_PATH_PATTERN</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">model_name_or_path</span><span class="p">):</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">return</span> <span class="n">model_name_or_path</span>


<div class="viewcode-block" id="log_model"><a class="viewcode-back" href="../../python_api/mlflow.sentence_transformers.html#mlflow.sentence_transformers.log_model">[docs]</a><span class="nd">@experimental</span>
<span class="nd">@docstring_version_compatibility_warning</span><span class="p">(</span><span class="n">integration_name</span><span class="o">=</span><span class="n">FLAVOR_NAME</span><span class="p">)</span>
<span class="nd">@format_docstring</span><span class="p">(</span><span class="n">LOG_MODEL_PARAM_DOCS</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">package_name</span><span class="o">=</span><span class="n">FLAVOR_NAME</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">log_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">artifact_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">task</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">inference_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">code_paths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">registered_model_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">signature</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelSignature</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_example</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelInputExample</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">await_registration_for</span><span class="o">=</span><span class="n">DEFAULT_AWAIT_MAX_SLEEP_SECONDS</span><span class="p">,</span>
    <span class="n">pip_requirements</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_pip_requirements</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">conda_env</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">example_no_conversion</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    .. note::</span>

<span class="sd">        Logging Sentence Transformers models with custom code (i.e. models that require</span>
<span class="sd">        ``trust_remote_code=True``) is supported in MLflow 2.12.0 and above.</span>

<span class="sd">    Log a ``sentence_transformers`` model as an MLflow artifact for the current run.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        # An example of using log_model for a sentence-transformers model and architecture:</span>

<span class="sd">        from sentence_transformers import SentenceTransformer</span>
<span class="sd">        import mlflow</span>

<span class="sd">        model = SentenceTransformer(&quot;all-MiniLM-L6-v2&quot;)</span>
<span class="sd">        data = &quot;MLflow is awesome!&quot;</span>
<span class="sd">        signature = mlflow.models.infer_signature(</span>
<span class="sd">            model_input=data,</span>
<span class="sd">            model_output=model.encode(data),</span>
<span class="sd">        )</span>

<span class="sd">        with mlflow.start_run():</span>
<span class="sd">            mlflow.sentence_transformers.log_model(</span>
<span class="sd">                model=model,</span>
<span class="sd">                artifact_path=&quot;sbert_model&quot;,</span>
<span class="sd">                signature=signature,</span>
<span class="sd">                input_example=data,</span>
<span class="sd">            )</span>



<span class="sd">    Args:</span>
<span class="sd">        model: A trained ``sentence-transformers`` model.</span>
<span class="sd">        artifact_path: Local path destination for the serialized model to be saved.</span>
<span class="sd">        task: MLflow inference task type for ``sentence-transformers`` model. Candidate task type</span>
<span class="sd">            is `llm/v1/embeddings`.</span>
<span class="sd">        inference_config:</span>
<span class="sd">            A dict of valid overrides that can be applied to a ``sentence-transformer`` model</span>
<span class="sd">            instance during inference.</span>
<span class="sd">            These arguments are used exclusively for the case of loading the model as a ``pyfunc``</span>
<span class="sd">            Model or for use in Spark.</span>
<span class="sd">            These values are not applied to a returned model from a call to</span>
<span class="sd">            ``mlflow.sentence_transformers.load_model()``</span>
<span class="sd">        code_paths: {{ code_paths }}</span>
<span class="sd">        registered_model_name: This argument may change or be removed in a</span>
<span class="sd">            future release without warning. If given, create a model</span>
<span class="sd">            version under ``registered_model_name``, also creating a</span>
<span class="sd">            registered model if one with the given name does not exist.</span>
<span class="sd">        signature: an instance of the :py:class:`ModelSignature &lt;mlflow.models.ModelSignature&gt;`</span>
<span class="sd">            class that describes the model&#39;s inputs and outputs. If not specified but an</span>
<span class="sd">            ``input_example`` is supplied, a signature will be automatically inferred</span>
<span class="sd">            based on the supplied input example and model. If both ``signature`` and</span>
<span class="sd">            ``input_example`` are not specified or the automatic signature inference</span>
<span class="sd">            fails, a default signature will be adopted. To prevent a signature from being</span>
<span class="sd">            adopted, set ``signature`` to ``False``. To manually infer a model signature,</span>
<span class="sd">            call :py:func:`infer_signature() &lt;mlflow.models.infer_signature&gt;` on datasets</span>
<span class="sd">            with valid model inputs and valid model outputs.</span>
<span class="sd">        input_example: {{ input_example }}</span>
<span class="sd">        await_registration_for: Number of seconds to wait for the model version to finish</span>
<span class="sd">            being created and is in ``READY`` status. By default, the function</span>
<span class="sd">            waits for five minutes. Specify 0 or None to skip waiting.</span>
<span class="sd">        pip_requirements: {{ pip_requirements }}</span>
<span class="sd">        extra_pip_requirements: {{ extra_pip_requirements }}</span>
<span class="sd">        conda_env: {{ conda_env }}</span>
<span class="sd">        metadata: {{ metadata }}</span>
<span class="sd">        example_no_conversion: {{ example_no_conversion }}</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">task</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="n">_verify_task_and_update_metadata</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">metadata</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Model</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="n">artifact_path</span><span class="p">,</span>
        <span class="n">flavor</span><span class="o">=</span><span class="n">mlflow</span><span class="o">.</span><span class="n">sentence_transformers</span><span class="p">,</span>
        <span class="n">registered_model_name</span><span class="o">=</span><span class="n">registered_model_name</span><span class="p">,</span>
        <span class="n">await_registration_for</span><span class="o">=</span><span class="n">await_registration_for</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">inference_config</span><span class="o">=</span><span class="n">inference_config</span><span class="p">,</span>
        <span class="n">conda_env</span><span class="o">=</span><span class="n">conda_env</span><span class="p">,</span>
        <span class="n">code_paths</span><span class="o">=</span><span class="n">code_paths</span><span class="p">,</span>
        <span class="n">signature</span><span class="o">=</span><span class="n">signature</span><span class="p">,</span>
        <span class="n">input_example</span><span class="o">=</span><span class="n">input_example</span><span class="p">,</span>
        <span class="n">pip_requirements</span><span class="o">=</span><span class="n">pip_requirements</span><span class="p">,</span>
        <span class="n">extra_pip_requirements</span><span class="o">=</span><span class="n">extra_pip_requirements</span><span class="p">,</span>
        <span class="n">example_no_conversion</span><span class="o">=</span><span class="n">example_no_conversion</span><span class="p">,</span>
    <span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_get_load_kwargs</span><span class="p">():</span>
    <span class="kn">import</span> <span class="nn">sentence_transformers</span>

    <span class="n">load_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="c1"># The trust_remote_code is supported since Sentence Transformers 2.3.0</span>
    <span class="k">if</span> <span class="n">Version</span><span class="p">(</span><span class="n">sentence_transformers</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">Version</span><span class="p">(</span><span class="s2">&quot;2.3.0&quot;</span><span class="p">):</span>
        <span class="c1"># Always set trust_remote_code=True because we save the entire repository files in</span>
        <span class="c1"># the model artifacts, so there is no risk of running untrusted code unless the logged</span>
        <span class="c1"># artifact is modified by a malicious actor, which is much more broader security</span>
        <span class="c1"># concern that even cannot be prevented by setting trust_remote_code=False.</span>
        <span class="n">load_kwargs</span><span class="p">[</span><span class="s2">&quot;trust_remote_code&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="n">load_kwargs</span>


<span class="k">def</span> <span class="nf">_load_pyfunc</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">model_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>  <span class="c1"># noqa: D417</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load PyFunc implementation for SentenceTransformer. Called by ``pyfunc.load_model``.</span>

<span class="sd">    Args:</span>
<span class="sd">        path: Local filesystem path to the MLflow Model with the ``sentence_transformer`` flavor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">sentence_transformers</span>

    <span class="n">load_kwargs</span> <span class="o">=</span> <span class="n">_get_load_kwargs</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">sentence_transformers</span><span class="o">.</span><span class="n">SentenceTransformer</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs</span><span class="p">)</span>
    <span class="n">model_config</span> <span class="o">=</span> <span class="n">model_config</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">task</span> <span class="o">=</span> <span class="n">model_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;task&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_SentenceTransformerModelWrapper</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">task</span><span class="p">)</span>


<div class="viewcode-block" id="load_model"><a class="viewcode-back" href="../../python_api/mlflow.sentence_transformers.html#mlflow.sentence_transformers.load_model">[docs]</a><span class="nd">@experimental</span>
<span class="nd">@docstring_version_compatibility_warning</span><span class="p">(</span><span class="n">integration_name</span><span class="o">=</span><span class="n">FLAVOR_NAME</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="n">model_uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">dst_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load a ``sentence_transformers`` object from a local file or a run.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_uri: The location, in URI format, of the MLflow model. For example:</span>

<span class="sd">            - ``/Users/me/path/to/local/model``</span>
<span class="sd">            - ``relative/path/to/local/model``</span>
<span class="sd">            - ``s3://my_bucket/path/to/model``</span>
<span class="sd">            - ``runs:/&lt;mlflow_run_id&gt;/run-relative/path/to/model``</span>
<span class="sd">            - ``mlflow-artifacts:/path/to/model``</span>

<span class="sd">            For more information about supported URI schemes, see</span>
<span class="sd">            `Referencing Artifacts &lt;https://www.mlflow.org/docs/latest/tracking.html#</span>
<span class="sd">            artifact-locations&gt;`_.</span>
<span class="sd">        dst_path: The local filesystem path to utilize for downloading the model artifact.</span>
<span class="sd">            This directory must already exist if provided. If unspecified, a local output</span>
<span class="sd">            path will be created.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A ``sentence_transformers`` model instance</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">import</span> <span class="nn">sentence_transformers</span>

    <span class="n">model_uri</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">model_uri</span><span class="p">)</span>

    <span class="n">local_model_path</span> <span class="o">=</span> <span class="n">_download_artifact_from_uri</span><span class="p">(</span><span class="n">artifact_uri</span><span class="o">=</span><span class="n">model_uri</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="n">dst_path</span><span class="p">)</span>

    <span class="n">local_model_dir</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">local_model_path</span><span class="p">)</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">SENTENCE_TRANSFORMERS_DATA_PATH</span><span class="p">)</span>

    <span class="n">flavor_config</span> <span class="o">=</span> <span class="n">_get_flavor_configuration_from_uri</span><span class="p">(</span><span class="n">model_uri</span><span class="p">,</span> <span class="n">FLAVOR_NAME</span><span class="p">,</span> <span class="n">_logger</span><span class="p">)</span>

    <span class="n">_add_code_from_conf_to_system_path</span><span class="p">(</span><span class="n">local_model_path</span><span class="p">,</span> <span class="n">flavor_config</span><span class="p">)</span>

    <span class="n">load_kwargs</span> <span class="o">=</span> <span class="n">_get_load_kwargs</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">sentence_transformers</span><span class="o">.</span><span class="n">SentenceTransformer</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">local_model_dir</span><span class="p">),</span> <span class="o">**</span><span class="n">load_kwargs</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_get_default_signature</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates a default signature for the ``sentence_transformers`` flavor to be applied if not</span>
<span class="sd">    set or overridden by supplying the `signature` argument to `log_model` or `save_model`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">ModelSignature</span><span class="p">(</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">)]),</span>
        <span class="n">outputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s2">&quot;float64&quot;</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])]),</span>
    <span class="p">)</span>


<span class="k">class</span> <span class="nc">_SentenceTransformerModelWrapper</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">=</span> <span class="n">task</span>

    <span class="k">def</span> <span class="nf">get_raw_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the underlying model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentences</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            sentences: Model input data.</span>
<span class="sd">            params: Additional parameters to pass to the model for inference.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Model predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># When the input is a single string or a dictionary, it is transformed into a DataFrame</span>
        <span class="c1"># with one column and row, but the encode function does not accept DataFrame input</span>
        <span class="n">convert_output_to_llm_v1_format</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span> <span class="o">==</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
            <span class="c1"># Wrap the output to OpenAI format only when the input is dict `{&quot;input&quot;: ... }`</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="ow">and</span> <span class="nb">list</span><span class="p">(</span><span class="n">sentences</span><span class="o">.</span><span class="n">columns</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">_LLM_V1_EMBEDDING_INPUT_KEY</span><span class="p">:</span>
                <span class="n">convert_output_to_llm_v1_format</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">sentences</span> <span class="o">=</span> <span class="n">sentences</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">sentences</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="nb">list</span><span class="p">:</span>
                <span class="n">sentences</span> <span class="o">=</span> <span class="n">sentences</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># The encode API has additional parameters that we can add as kwargs.</span>
        <span class="c1"># See https://www.sbert.net/docs/package_reference/SentenceTransformer.html#sentence_transformers.SentenceTransformer.encode</span>
        <span class="k">if</span> <span class="n">params</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">output_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
                    <span class="s2">&quot;Received invalid parameter value for `params` argument&quot;</span>
                <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">convert_output_to_llm_v1_format</span><span class="p">:</span>
            <span class="n">output_data</span> <span class="o">=</span> <span class="n">postprocess_output_for_llm_v1_embedding_task</span><span class="p">(</span>
                <span class="n">sentences</span><span class="p">,</span> <span class="n">output_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">tokenizer</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">output_data</span>
</pre></div>

              </div>
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../../',
      VERSION:'2.17.1.dev0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../../_static/clippy.svg";</script>
  <script type="text/javascript" src="../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>


<!DOCTYPE html>
<!-- source: docs/source/python_api/mlflow.langchain.rst -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mlflow.langchain</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/python_api/mlflow.langchain.html">
  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    

    

  
    

  

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="MLflow 2.17.1.dev0 documentation" href="../index.html"/>
        <link rel="up" title="Python API" href="index.html"/>
        <link rel="next" title="mlflow.lightgbm" href="/mlflow.lightgbm.html"/>
        <link rel="prev" title="mlflow.keras" href="/mlflow.keras.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../_static/jquery.js"></script>
<script type="text/javascript" src="../_static/underscore.js"></script>
<script type="text/javascript" src="../_static/doctools.js"></script>
<script type="text/javascript" src="../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="../_static/runllm.js"></script>

<body class="wy-body-for-nav" role="document">
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <ul>
  <li class="menu-toggle">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
    <a href="../index.html" class="wy-nav-top-logo"
      ><img src="../_static/MLflow-logo-final-black.png" alt="MLflow"
    /></a>
    <span class="version">2.17.1.dev0</span>
  </li>
</ul>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home"><img src="../_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Python API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="mlflow.html">mlflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.html#mlflow-tracing-apis">MLflow Tracing APIs</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.artifacts.html">mlflow.artifacts</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.autogen.html">mlflow.autogen</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.catboost.html">mlflow.catboost</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.client.html">mlflow.client</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.config.html">mlflow.config</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.data.html">mlflow.data</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.deployments.html">mlflow.deployments</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.diviner.html">mlflow.diviner</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.dspy.html">mlflow.dspy</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.entities.html">mlflow.entities</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.environment_variables.html">mlflow.environment_variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.fastai.html">mlflow.fastai</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.gateway.html">mlflow.gateway</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.gluon.html">mlflow.gluon</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.h2o.html">mlflow.h2o</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.johnsnowlabs.html">mlflow.johnsnowlabs</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.keras.html">mlflow.keras</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">mlflow.langchain</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.lightgbm.html">mlflow.lightgbm</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.llama_index.html">mlflow.llama_index</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.metrics.html">mlflow.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.mleap.html">mlflow.mleap</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.models.html">mlflow.models</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.onnx.html">mlflow.onnx</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.openai.html">mlflow.openai</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.paddle.html">mlflow.paddle</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pmdarima.html">mlflow.pmdarima</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.projects.html">mlflow.projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.promptflow.html">mlflow.promptflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.prophet.html">mlflow.prophet</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pyfunc.html">mlflow.pyfunc</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pyspark.ml.html">mlflow.pyspark.ml</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pytorch.html">mlflow.pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.recipes.html">mlflow.recipes</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.sagemaker.html">mlflow.sagemaker</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.sentence_transformers.html">mlflow.sentence_transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.server.html">mlflow.server</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.shap.html">mlflow.shap</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.sklearn.html">mlflow.sklearn</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.spacy.html">mlflow.spacy</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.spark.html">mlflow.spark</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.statsmodels.html">mlflow.statsmodels</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.system_metrics.html">mlflow.system_metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.tensorflow.html">mlflow.tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.tracing.html">mlflow.tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.transformers.html">mlflow.transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.types.html">mlflow.types</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.utils.html">mlflow.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.xgboost.html">mlflow.xgboost</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#log-levels">Log Levels</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rest-api.html">REST API</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="index.html">Python API</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>mlflow.langchain</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/python_api/mlflow.langchain.rst" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <div class="section" id="module-mlflow.langchain">
<span id="mlflow-langchain"></span><h1>mlflow.langchain<a class="headerlink" href="#module-mlflow.langchain" title="Permalink to this headline"> </a></h1>
<p>The <code class="docutils literal notranslate"><span class="pre">mlflow.langchain</span></code> module provides an API for logging and loading LangChain models.
This module exports multivariate LangChain models in the langchain flavor and univariate
LangChain models in the pyfunc flavor:</p>
<dl class="simple">
<dt>LangChain (native) format</dt><dd><p>This is the main flavor that can be accessed with LangChain APIs.</p>
</dd>
<dt><a class="reference internal" href="mlflow.pyfunc.html#module-mlflow.pyfunc" title="mlflow.pyfunc"><code class="xref py py-mod docutils literal notranslate"><span class="pre">mlflow.pyfunc</span></code></a></dt><dd><p>Produced for use by generic pyfunc-based deployment tools and for batch inference.</p>
</dd>
</dl>
<dl class="py function">
<dt id="mlflow.langchain.autolog">
<code class="sig-prename descclassname"><span class="pre">mlflow.langchain.</span></code><code class="sig-name descname"><span class="pre">autolog</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_input_examples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_model_signatures</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_models</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_datasets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_inputs_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclusive</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable_for_unsupported_versions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">registered_model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extra_tags</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extra_model_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_traces</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/langchain.html#autolog"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.langchain.autolog" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Autologging is known to be compatible with the following package versions: <code class="docutils literal notranslate"><span class="pre">0.1.0</span></code> &lt;= <code class="docutils literal notranslate"><span class="pre">langchain</span></code> &lt;= <code class="docutils literal notranslate"><span class="pre">0.3.3</span></code>. Autologging may not succeed when used with package versions outside of this range.</p>
</div>
<p>Enables (or disables) and configures autologging from Langchain to MLflow.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_input_examples</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, input examples from inference data are collected and
logged along with Langchain model artifacts during inference. If
<code class="docutils literal notranslate"><span class="pre">False</span></code>, input examples are not logged.
Note: Input examples are MLflow model attributes
and are only collected if <code class="docutils literal notranslate"><span class="pre">log_models</span></code> is also <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>log_model_signatures</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>,
<a class="reference internal" href="mlflow.models.html#mlflow.models.ModelSignature" title="mlflow.models.ModelSignature"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelSignatures</span></code></a>
describing model inputs and outputs are collected and logged along
with Langchain model artifacts during inference. If <code class="docutils literal notranslate"><span class="pre">False</span></code>,
signatures are not logged.
Note: Model signatures are MLflow model attributes
and are only collected if <code class="docutils literal notranslate"><span class="pre">log_models</span></code> is also <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>log_models</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, langchain models are logged as MLflow model artifacts.
If <code class="docutils literal notranslate"><span class="pre">False</span></code>, langchain models are not logged.
Input examples and model signatures, which are attributes of MLflow models,
are also omitted when <code class="docutils literal notranslate"><span class="pre">log_models</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>log_datasets</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, dataset information is logged to MLflow Tracking
if applicable. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, dataset information is not logged.</p></li>
<li><p><strong>log_inputs_outputs</strong> – <strong>Deprecated</strong> The legacy parameter used for logging inference
inputs and outputs. This argument will be removed in a future version of MLflow.
The alternative is to use <code class="docutils literal notranslate"><span class="pre">log_traces</span></code> which logs traces for Langchain models,
including inputs and outputs for each stage.
If <code class="docutils literal notranslate"><span class="pre">True</span></code>, inference data and results are combined into a single
pandas DataFrame and logged to MLflow Tracking as an artifact.
If <code class="docutils literal notranslate"><span class="pre">False</span></code>, inference data and results are not logged.
Default to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>disable</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, disables the Langchain autologging integration. If <code class="docutils literal notranslate"><span class="pre">False</span></code>,
enables the Langchain autologging integration.</p></li>
<li><p><strong>exclusive</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, autologged content is not logged to user-created fluent runs.
If <code class="docutils literal notranslate"><span class="pre">False</span></code>, autologged content is logged to the active fluent run,
which may be user-created.</p></li>
<li><p><strong>disable_for_unsupported_versions</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, disable autologging for versions of
langchain that have not been tested against this version of the MLflow
client or are incompatible.</p></li>
<li><p><strong>silent</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, suppress all event logs and warnings from MLflow during Langchain
autologging. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, show all events and warnings during Langchain
autologging.</p></li>
<li><p><strong>registered_model_name</strong> – If given, each time a model is trained, it is registered as a
new model version of the registered model with this name.
The registered model is created if it does not already exist.</p></li>
<li><p><strong>extra_tags</strong> – A dictionary of extra tags to set on each managed run created by autologging.</p></li>
<li><p><strong>extra_model_classes</strong> – A list of langchain classes to log in addition to the default classes.
We do not guarantee classes specified in this list can be logged as a model, but tracing
will be supported. Note that all classes within the list must be subclasses of Runnable,
and we only patch <cite>invoke</cite>, <cite>batch</cite>, and <cite>stream</cite> methods for tracing.</p></li>
<li><p><strong>log_traces</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, traces are logged for Langchain models by using
MlflowLangchainTracer as a callback during inference. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, no traces are
collected during inference. Default to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="mlflow.langchain.get_default_conda_env">
<code class="sig-prename descclassname"><span class="pre">mlflow.langchain.</span></code><code class="sig-name descname"><span class="pre">get_default_conda_env</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/langchain.html#get_default_conda_env"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.langchain.get_default_conda_env" title="Permalink to this definition"> </a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The default Conda environment for MLflow Models produced by calls to
<a class="reference internal" href="#mlflow.langchain.save_model" title="mlflow.langchain.save_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">save_model()</span></code></a> and <a class="reference internal" href="#mlflow.langchain.log_model" title="mlflow.langchain.log_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">log_model()</span></code></a>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="mlflow.langchain.get_default_pip_requirements">
<code class="sig-prename descclassname"><span class="pre">mlflow.langchain.</span></code><code class="sig-name descname"><span class="pre">get_default_pip_requirements</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/langchain.html#get_default_pip_requirements"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.langchain.get_default_pip_requirements" title="Permalink to this definition"> </a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A list of default pip requirements for MLflow Models produced by this flavor.
Calls to <a class="reference internal" href="#mlflow.langchain.save_model" title="mlflow.langchain.save_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">save_model()</span></code></a> and <a class="reference internal" href="#mlflow.langchain.log_model" title="mlflow.langchain.log_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">log_model()</span></code></a> produce a pip environment
that, at a minimum, contains these requirements.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="mlflow.langchain.load_model">
<code class="sig-prename descclassname"><span class="pre">mlflow.langchain.</span></code><code class="sig-name descname"><span class="pre">load_model</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_uri</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dst_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/langchain.html#load_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.langchain.load_model" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The ‘langchain’ MLflow Models integration is known to be compatible with <code class="docutils literal notranslate"><span class="pre">0.0.354</span></code> &lt;= <code class="docutils literal notranslate"><span class="pre">langchain</span></code> &lt;= <code class="docutils literal notranslate"><span class="pre">0.3.3</span></code>. MLflow Models integrations with langchain may not succeed when used with package versions outside of this range.</p>
</div>
<p>Load a LangChain model from a local file or a run.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_uri</strong> – <p>The location, in URI format, of the MLflow model. For example:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">/Users/me/path/to/local/model</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">relative/path/to/local/model</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">s3://my_bucket/path/to/model</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">runs:/&lt;mlflow_run_id&gt;/run-relative/path/to/model</span></code></p></li>
</ul>
<p>For more information about supported URI schemes, see
<a class="reference external" href="https://www.mlflow.org/docs/latest/tracking.html#artifact-locations">Referencing Artifacts</a>.</p>
</p></li>
<li><p><strong>dst_path</strong> – The local filesystem path to which to download the model artifact.
This directory must already exist. If unspecified, a local output
path will be created.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A LangChain model instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="mlflow.langchain.log_model">
<code class="sig-prename descclassname"><span class="pre">mlflow.langchain.</span></code><code class="sig-name descname"><span class="pre">log_model</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lc_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">artifact_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conda_env</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">code_paths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">registered_model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">signature</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">mlflow.models.signature.ModelSignature</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_example</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pandas.core.frame.DataFrame</span><span class="p"><span class="pre">,</span> </span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">,</span> </span><span class="pre">csr_matrix</span><span class="p"><span class="pre">,</span> </span><span class="pre">csc_matrix</span><span class="p"><span class="pre">,</span> </span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">bytes</span><span class="p"><span class="pre">,</span> </span><span class="pre">tuple</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">await_registration_for</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">300</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pip_requirements</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extra_pip_requirements</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loader_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persist_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">example_no_conversion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">streamable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resources</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/langchain.html#log_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.langchain.log_model" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The ‘langchain’ MLflow Models integration is known to be compatible with <code class="docutils literal notranslate"><span class="pre">0.0.354</span></code> &lt;= <code class="docutils literal notranslate"><span class="pre">langchain</span></code> &lt;= <code class="docutils literal notranslate"><span class="pre">0.3.3</span></code>. MLflow Models integrations with langchain may not succeed when used with package versions outside of this range.</p>
</div>
<p>Log a LangChain model as an MLflow artifact for the current run.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lc_model</strong> – <p>A LangChain model, which could be a
<a class="reference external" href="https://python.langchain.com/docs/modules/chains/">Chain</a>,
<a class="reference external" href="https://python.langchain.com/docs/modules/agents/">Agent</a>, or
<a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/retrievers/">retriever</a>
or a path containing the <cite>LangChain model code &lt;https://github.com/mlflow/mlflow/blob/master/examples/langchain/chain_as_code_driver.py&gt;</cite>
for the above types. When using model as path, make sure to set the model
by using <a class="reference internal" href="mlflow.models.html#mlflow.models.set_model" title="mlflow.models.set_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.models.set_model()</span></code></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: Using model as path may change or be removed in a future
release without warning.</p>
</div>
</p></li>
<li><p><strong>artifact_path</strong> – Run-relative artifact path.</p></li>
<li><p><strong>conda_env</strong> – <p>Either a dictionary representation of a Conda environment or the path to a conda
environment yaml file. If provided, this describes the environment this model should be run in.
At a minimum, it should specify the dependencies contained in <a class="reference internal" href="#mlflow.langchain.get_default_conda_env" title="mlflow.langchain.get_default_conda_env"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_default_conda_env()</span></code></a>.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a conda environment with pip requirements inferred by
<a class="reference internal" href="mlflow.models.html#mlflow.models.infer_pip_requirements" title="mlflow.models.infer_pip_requirements"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.models.infer_pip_requirements()</span></code></a> is added
to the model. If the requirement inference fails, it falls back to using
<a class="reference internal" href="#mlflow.langchain.get_default_pip_requirements" title="mlflow.langchain.get_default_pip_requirements"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_default_pip_requirements()</span></code></a>. pip requirements from <code class="docutils literal notranslate"><span class="pre">conda_env</span></code> are written to a pip
<code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code> file and the full conda environment is written to <code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code>.
The following is an <em>example</em> dictionary representation of a conda environment:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;mlflow-env&quot;</span><span class="p">,</span>
    <span class="s2">&quot;channels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;conda-forge&quot;</span><span class="p">],</span>
    <span class="s2">&quot;dependencies&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;python=3.8.15&quot;</span><span class="p">,</span>
        <span class="p">{</span>
            <span class="s2">&quot;pip&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="s2">&quot;langchain==x.y.z&quot;</span>
            <span class="p">],</span>
        <span class="p">},</span>
    <span class="p">],</span>
<span class="p">}</span>
</pre></div>
</div>
</p></li>
<li><p><strong>code_paths</strong> – <p>A list of local filesystem paths to Python file dependencies (or directories
containing file dependencies). These files are <em>prepended</em> to the system path when the model
is loaded. Files declared as dependencies for a given model should have relative
imports declared from a common root path if multiple files are defined with import dependencies
between them to avoid import errors when loading the model.</p>
<p>For a detailed explanation of <code class="docutils literal notranslate"><span class="pre">code_paths</span></code> functionality, recommended usage patterns and
limitations, see the
<a class="reference external" href="https://mlflow.org/docs/latest/model/dependencies.html?highlight=code_paths#saving-extra-code-with-an-mlflow-model">code_paths usage guide</a>.</p>
</p></li>
<li><p><strong>registered_model_name</strong> – This argument may change or be removed in a
future release without warning. If given, create a model
version under <code class="docutils literal notranslate"><span class="pre">registered_model_name</span></code>, also creating a
registered model if one with the given name does not exist.</p></li>
<li><p><strong>signature</strong> – <p><a class="reference internal" href="mlflow.models.html#mlflow.models.ModelSignature" title="mlflow.models.ModelSignature"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelSignature</span></code></a>
describes model input and output
<a class="reference internal" href="mlflow.types.html#mlflow.types.Schema" title="mlflow.types.Schema"><code class="xref py py-class docutils literal notranslate"><span class="pre">Schema</span></code></a>.
If not specified, the model signature would be set according to
<cite>lc_model.input_keys</cite> and <cite>lc_model.output_keys</cite> as columns names, and
<cite>DataType.string</cite> as the column type.
Alternatively, you can explicitly specify the model signature.
The model signature can be <a class="reference internal" href="mlflow.models.html#mlflow.models.infer_signature" title="mlflow.models.infer_signature"><code class="xref py py-func docutils literal notranslate"><span class="pre">inferred</span></code></a> from datasets with valid model input
(e.g. the training dataset with target column omitted) and valid model
output (e.g. model predictions generated on the training dataset),
for example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlflow.models</span> <span class="kn">import</span> <span class="n">infer_signature</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">input_str</span><span class="p">)</span>
<span class="n">input_columns</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">input_key</span><span class="p">}</span> <span class="k">for</span> <span class="n">input_key</span> <span class="ow">in</span> <span class="n">chain</span><span class="o">.</span><span class="n">input_keys</span>
<span class="p">]</span>
<span class="n">signature</span> <span class="o">=</span> <span class="n">infer_signature</span><span class="p">(</span><span class="n">input_columns</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</pre></div>
</div>
</p></li>
<li><p><strong>input_example</strong> – one or several instances of valid model input. The input example is used
as a hint of what data to feed the model. It will be converted to a Pandas
DataFrame and then serialized to json using the Pandas split-oriented
format, or a numpy array where the example will be serialized to json
by converting it to a list. Bytes are base64-encoded. When the <code class="docutils literal notranslate"><span class="pre">signature</span></code> parameter is
<code class="docutils literal notranslate"><span class="pre">None</span></code>, the input example is used to infer a model signature.</p></li>
<li><p><strong>await_registration_for</strong> – Number of seconds to wait for the model version
to finish being created and is in <code class="docutils literal notranslate"><span class="pre">READY</span></code> status.
By default, the function waits for five minutes.
Specify 0 or None to skip waiting.</p></li>
<li><p><strong>pip_requirements</strong> – Either an iterable of pip requirement strings
(e.g. <code class="docutils literal notranslate"><span class="pre">[&quot;langchain&quot;,</span> <span class="pre">&quot;-r</span> <span class="pre">requirements.txt&quot;,</span> <span class="pre">&quot;-c</span> <span class="pre">constraints.txt&quot;]</span></code>) or the string path to
a pip requirements file on the local filesystem (e.g. <code class="docutils literal notranslate"><span class="pre">&quot;requirements.txt&quot;</span></code>). If provided, this
describes the environment this model should be run in. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a default list of requirements
is inferred by <a class="reference internal" href="mlflow.models.html#mlflow.models.infer_pip_requirements" title="mlflow.models.infer_pip_requirements"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.models.infer_pip_requirements()</span></code></a> from the current software environment.
If the requirement inference fails, it falls back to using <a class="reference internal" href="#mlflow.langchain.get_default_pip_requirements" title="mlflow.langchain.get_default_pip_requirements"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_default_pip_requirements()</span></code></a>.
Both requirements and constraints are automatically parsed and written to <code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code> and
<code class="docutils literal notranslate"><span class="pre">constraints.txt</span></code> files, respectively, and stored as part of the model. Requirements are also
written to the <code class="docutils literal notranslate"><span class="pre">pip</span></code> section of the model’s conda environment (<code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code>) file.</p></li>
<li><p><strong>extra_pip_requirements</strong> – <p>Either an iterable of pip
requirement strings
(e.g. <code class="docutils literal notranslate"><span class="pre">[&quot;pandas&quot;,</span> <span class="pre">&quot;-r</span> <span class="pre">requirements.txt&quot;,</span> <span class="pre">&quot;-c</span> <span class="pre">constraints.txt&quot;]</span></code>) or the string path to
a pip requirements file on the local filesystem (e.g. <code class="docutils literal notranslate"><span class="pre">&quot;requirements.txt&quot;</span></code>). If provided, this
describes additional pip requirements that are appended to a default set of pip requirements
generated automatically based on the user’s current software environment. Both requirements and
constraints are automatically parsed and written to <code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code> and <code class="docutils literal notranslate"><span class="pre">constraints.txt</span></code>
files, respectively, and stored as part of the model. Requirements are also written to the <code class="docutils literal notranslate"><span class="pre">pip</span></code>
section of the model’s conda environment (<code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code>) file.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The following arguments can’t be specified at the same time:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">conda_env</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pip_requirements</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">extra_pip_requirements</span></code></p></li>
</ul>
</div>
<p><a class="reference external" href="https://github.com/mlflow/mlflow/blob/master/examples/pip_requirements/pip_requirements.py">This example</a> demonstrates how to specify pip requirements using
<code class="docutils literal notranslate"><span class="pre">pip_requirements</span></code> and <code class="docutils literal notranslate"><span class="pre">extra_pip_requirements</span></code>.</p>
</p></li>
<li><p><strong>metadata</strong> – Custom metadata dictionary passed to the model and stored in the MLmodel file.</p></li>
<li><p><strong>loader_fn</strong> – <p>A function that’s required for models containing objects that aren’t natively
serialized by LangChain.
This function takes a string <cite>persist_dir</cite> as an argument and returns the
specific object that the model needs. Depending on the model,
this could be a retriever, vectorstore, requests_wrapper, embeddings, or
database. For RetrievalQA Chain and retriever models, the object is a
(<a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/retrievers/">retriever</a>).
For APIChain models, it’s a
(<a class="reference external" href="https://python.langchain.com/docs/modules/agents/tools/integrations/requests">requests_wrapper</a>).
For HypotheticalDocumentEmbedder models, it’s an
(<a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/text_embedding/">embeddings</a>).
For SQLDatabaseChain models, it’s a
(<a class="reference external" href="https://python.langchain.com/docs/modules/agents/toolkits/sql_database">database</a>).</p>
</p></li>
<li><p><strong>persist_dir</strong> – <p>The directory where the object is stored. The <cite>loader_fn</cite>
takes this string as the argument to load the object.
This is optional for models containing objects that aren’t natively
serialized by LangChain. MLflow logs the content in this directory as
artifacts in the subdirectory named <cite>persist_dir_data</cite>.</p>
<p>Here is the code snippet for logging a RetrievalQA chain with <cite>loader_fn</cite>
and <cite>persist_dir</cite>:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In langchain_community &gt;= 0.0.27, loading pickled data requires providing the
<code class="docutils literal notranslate"><span class="pre">allow_dangerous_deserialization</span></code> argument.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">qa</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="o">.</span><span class="n">from_llm</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">OpenAI</span><span class="p">(),</span> <span class="n">retriever</span><span class="o">=</span><span class="n">db</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">())</span>


<span class="k">def</span> <span class="nf">load_retriever</span><span class="p">(</span><span class="n">persist_directory</span><span class="p">):</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">()</span>
    <span class="n">vectorstore</span> <span class="o">=</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">load_local</span><span class="p">(</span>
        <span class="n">persist_directory</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="c1"># you may need to add the line below</span>
        <span class="c1"># for langchain_community &gt;= 0.0.27</span>
        <span class="n">allow_dangerous_deserialization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">vectorstore</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">()</span>


<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
    <span class="n">logged_model</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">langchain</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">qa</span><span class="p">,</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;retrieval_qa&quot;</span><span class="p">,</span>
        <span class="n">loader_fn</span><span class="o">=</span><span class="n">load_retriever</span><span class="p">,</span>
        <span class="n">persist_dir</span><span class="o">=</span><span class="n">persist_dir</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>See a complete example in examples/langchain/retrieval_qa_chain.py.</p>
</p></li>
<li><p><strong>example_no_conversion</strong> – This parameter is deprecated and will be removed in a future
release. It’s no longer used and can be safely removed. Input examples are
not converted anymore.</p></li>
<li><p><strong>run_id</strong> – run_id to associate with this model version. If specified, we resume the
run and log the model to that run. Otherwise, a new run is created.
Default to None.</p></li>
<li><p><strong>model_config</strong> – <p>The model configuration to apply to the model if saving model from code. This
configuration is available during model loading.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This parameter may change or be removed in a future
release without warning.</p>
</div>
</p></li>
<li><p><strong>streamable</strong> – A boolean value indicating if the model supports streaming prediction. If
True, the model must implement <cite>stream</cite> method. If None, If None, streamable is
set to True if the model implements <cite>stream</cite> method. Default to <cite>None</cite>.</p></li>
<li><p><strong>resources</strong> – <dl class="simple">
<dt>A list of model resources or a resources.yaml file containing a list of</dt><dd><p>resources required to serve the model.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This parameter may change or be removed in a future
release without warning.</p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="mlflow.models.html#mlflow.models.model.ModelInfo" title="mlflow.models.model.ModelInfo"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelInfo</span></code></a> instance that contains the
metadata of the logged model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="mlflow.langchain.save_model">
<code class="sig-prename descclassname"><span class="pre">mlflow.langchain.</span></code><code class="sig-name descname"><span class="pre">save_model</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lc_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conda_env</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">code_paths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlflow_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">signature</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">mlflow.models.signature.ModelSignature</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_example</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pandas.core.frame.DataFrame</span><span class="p"><span class="pre">,</span> </span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">,</span> </span><span class="pre">csr_matrix</span><span class="p"><span class="pre">,</span> </span><span class="pre">csc_matrix</span><span class="p"><span class="pre">,</span> </span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">bytes</span><span class="p"><span class="pre">,</span> </span><span class="pre">tuple</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pip_requirements</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extra_pip_requirements</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loader_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persist_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">example_no_conversion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">streamable</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/langchain.html#save_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.langchain.save_model" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The ‘langchain’ MLflow Models integration is known to be compatible with <code class="docutils literal notranslate"><span class="pre">0.0.354</span></code> &lt;= <code class="docutils literal notranslate"><span class="pre">langchain</span></code> &lt;= <code class="docutils literal notranslate"><span class="pre">0.3.3</span></code>. MLflow Models integrations with langchain may not succeed when used with package versions outside of this range.</p>
</div>
<p>Save a LangChain model to a path on the local file system.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lc_model</strong> – <p>A LangChain model, which could be a
<a class="reference external" href="https://python.langchain.com/docs/modules/chains/">Chain</a>,
<a class="reference external" href="https://python.langchain.com/docs/modules/agents/">Agent</a>,
<a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/retrievers/">retriever</a>,
or <a class="reference external" href="https://python.langchain.com/docs/modules/chains/foundational/sequential_chains#using-lcel">RunnableSequence</a>,
or a path containing the <cite>LangChain model code &lt;https://github.com/mlflow/mlflow/blob/master/examples/langchain/chain_as_code_driver.py&gt;</cite>
for the above types. When using model as path, make sure to set the model
by using <a class="reference internal" href="mlflow.models.html#mlflow.models.set_model" title="mlflow.models.set_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.models.set_model()</span></code></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: Using model as path may change or be removed in a future
release without warning.</p>
</div>
</p></li>
<li><p><strong>path</strong> – Local path where the serialized model (as YAML) is to be saved.</p></li>
<li><p><strong>conda_env</strong> – <p>Either a dictionary representation of a Conda environment or the path to a conda
environment yaml file. If provided, this describes the environment this model should be run in.
At a minimum, it should specify the dependencies contained in <a class="reference internal" href="#mlflow.langchain.get_default_conda_env" title="mlflow.langchain.get_default_conda_env"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_default_conda_env()</span></code></a>.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a conda environment with pip requirements inferred by
<a class="reference internal" href="mlflow.models.html#mlflow.models.infer_pip_requirements" title="mlflow.models.infer_pip_requirements"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.models.infer_pip_requirements()</span></code></a> is added
to the model. If the requirement inference fails, it falls back to using
<a class="reference internal" href="#mlflow.langchain.get_default_pip_requirements" title="mlflow.langchain.get_default_pip_requirements"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_default_pip_requirements()</span></code></a>. pip requirements from <code class="docutils literal notranslate"><span class="pre">conda_env</span></code> are written to a pip
<code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code> file and the full conda environment is written to <code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code>.
The following is an <em>example</em> dictionary representation of a conda environment:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;mlflow-env&quot;</span><span class="p">,</span>
    <span class="s2">&quot;channels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;conda-forge&quot;</span><span class="p">],</span>
    <span class="s2">&quot;dependencies&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;python=3.8.15&quot;</span><span class="p">,</span>
        <span class="p">{</span>
            <span class="s2">&quot;pip&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="s2">&quot;langchain==x.y.z&quot;</span>
            <span class="p">],</span>
        <span class="p">},</span>
    <span class="p">],</span>
<span class="p">}</span>
</pre></div>
</div>
</p></li>
<li><p><strong>code_paths</strong> – <p>A list of local filesystem paths to Python file dependencies (or directories
containing file dependencies). These files are <em>prepended</em> to the system path when the model
is loaded. Files declared as dependencies for a given model should have relative
imports declared from a common root path if multiple files are defined with import dependencies
between them to avoid import errors when loading the model.</p>
<p>For a detailed explanation of <code class="docutils literal notranslate"><span class="pre">code_paths</span></code> functionality, recommended usage patterns and
limitations, see the
<a class="reference external" href="https://mlflow.org/docs/latest/model/dependencies.html?highlight=code_paths#saving-extra-code-with-an-mlflow-model">code_paths usage guide</a>.</p>
</p></li>
<li><p><strong>mlflow_model</strong> – <a class="reference internal" href="mlflow.models.html#mlflow.models.Model" title="mlflow.models.Model"><code class="xref py py-mod docutils literal notranslate"><span class="pre">mlflow.models.Model</span></code></a> this flavor is being added to.</p></li>
<li><p><strong>signature</strong> – <p><a class="reference internal" href="mlflow.models.html#mlflow.models.ModelSignature" title="mlflow.models.ModelSignature"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelSignature</span></code></a>
describes model input and output <a class="reference internal" href="mlflow.types.html#mlflow.types.Schema" title="mlflow.types.Schema"><code class="xref py py-class docutils literal notranslate"><span class="pre">Schema</span></code></a>.
If not specified, the model signature would be set according to
<cite>lc_model.input_keys</cite> and <cite>lc_model.output_keys</cite> as columns names, and
<cite>DataType.string</cite> as the column type.
Alternatively, you can explicitly specify the model signature.
The model signature can be <a class="reference internal" href="mlflow.models.html#mlflow.models.infer_signature" title="mlflow.models.infer_signature"><code class="xref py py-func docutils literal notranslate"><span class="pre">inferred</span></code></a>
from datasets with valid model input (e.g. the training dataset with target
column omitted) and valid model output (e.g. model predictions generated on
the training dataset), for example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlflow.models</span> <span class="kn">import</span> <span class="n">infer_signature</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">input_str</span><span class="p">)</span>
<span class="n">input_columns</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">input_key</span><span class="p">}</span> <span class="k">for</span> <span class="n">input_key</span> <span class="ow">in</span> <span class="n">chain</span><span class="o">.</span><span class="n">input_keys</span>
<span class="p">]</span>
<span class="n">signature</span> <span class="o">=</span> <span class="n">infer_signature</span><span class="p">(</span><span class="n">input_columns</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</pre></div>
</div>
</p></li>
<li><p><strong>input_example</strong> – one or several instances of valid model input. The input example is used
as a hint of what data to feed the model. It will be converted to a Pandas
DataFrame and then serialized to json using the Pandas split-oriented
format, or a numpy array where the example will be serialized to json
by converting it to a list. Bytes are base64-encoded. When the <code class="docutils literal notranslate"><span class="pre">signature</span></code> parameter is
<code class="docutils literal notranslate"><span class="pre">None</span></code>, the input example is used to infer a model signature.</p></li>
<li><p><strong>pip_requirements</strong> – Either an iterable of pip requirement strings
(e.g. <code class="docutils literal notranslate"><span class="pre">[&quot;langchain&quot;,</span> <span class="pre">&quot;-r</span> <span class="pre">requirements.txt&quot;,</span> <span class="pre">&quot;-c</span> <span class="pre">constraints.txt&quot;]</span></code>) or the string path to
a pip requirements file on the local filesystem (e.g. <code class="docutils literal notranslate"><span class="pre">&quot;requirements.txt&quot;</span></code>). If provided, this
describes the environment this model should be run in. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a default list of requirements
is inferred by <a class="reference internal" href="mlflow.models.html#mlflow.models.infer_pip_requirements" title="mlflow.models.infer_pip_requirements"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.models.infer_pip_requirements()</span></code></a> from the current software environment.
If the requirement inference fails, it falls back to using <a class="reference internal" href="#mlflow.langchain.get_default_pip_requirements" title="mlflow.langchain.get_default_pip_requirements"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_default_pip_requirements()</span></code></a>.
Both requirements and constraints are automatically parsed and written to <code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code> and
<code class="docutils literal notranslate"><span class="pre">constraints.txt</span></code> files, respectively, and stored as part of the model. Requirements are also
written to the <code class="docutils literal notranslate"><span class="pre">pip</span></code> section of the model’s conda environment (<code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code>) file.</p></li>
<li><p><strong>extra_pip_requirements</strong> – <p>Either an iterable of pip
requirement strings
(e.g. <code class="docutils literal notranslate"><span class="pre">[&quot;pandas&quot;,</span> <span class="pre">&quot;-r</span> <span class="pre">requirements.txt&quot;,</span> <span class="pre">&quot;-c</span> <span class="pre">constraints.txt&quot;]</span></code>) or the string path to
a pip requirements file on the local filesystem (e.g. <code class="docutils literal notranslate"><span class="pre">&quot;requirements.txt&quot;</span></code>). If provided, this
describes additional pip requirements that are appended to a default set of pip requirements
generated automatically based on the user’s current software environment. Both requirements and
constraints are automatically parsed and written to <code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code> and <code class="docutils literal notranslate"><span class="pre">constraints.txt</span></code>
files, respectively, and stored as part of the model. Requirements are also written to the <code class="docutils literal notranslate"><span class="pre">pip</span></code>
section of the model’s conda environment (<code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code>) file.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The following arguments can’t be specified at the same time:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">conda_env</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pip_requirements</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">extra_pip_requirements</span></code></p></li>
</ul>
</div>
<p><a class="reference external" href="https://github.com/mlflow/mlflow/blob/master/examples/pip_requirements/pip_requirements.py">This example</a> demonstrates how to specify pip requirements using
<code class="docutils literal notranslate"><span class="pre">pip_requirements</span></code> and <code class="docutils literal notranslate"><span class="pre">extra_pip_requirements</span></code>.</p>
</p></li>
<li><p><strong>metadata</strong> – Custom metadata dictionary passed to the model and stored in the MLmodel file.</p></li>
<li><p><strong>loader_fn</strong> – <p>A function that’s required for models containing objects that aren’t natively
serialized by LangChain.
This function takes a string <cite>persist_dir</cite> as an argument and returns the
specific object that the model needs. Depending on the model,
this could be a retriever, vectorstore, requests_wrapper, embeddings, or
database. For RetrievalQA Chain and retriever models, the object is a
(<a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/retrievers/">retriever</a>).
For APIChain models, it’s a
(<a class="reference external" href="https://python.langchain.com/docs/modules/agents/tools/integrations/requests">requests_wrapper</a>).
For HypotheticalDocumentEmbedder models, it’s an
(<a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/text_embedding/">embeddings</a>).
For SQLDatabaseChain models, it’s a
(<a class="reference external" href="https://python.langchain.com/docs/modules/agents/toolkits/sql_database">database</a>).</p>
</p></li>
<li><p><strong>persist_dir</strong> – <p>The directory where the object is stored. The <cite>loader_fn</cite>
takes this string as the argument to load the object.
This is optional for models containing objects that aren’t natively
serialized by LangChain. MLflow logs the content in this directory as
artifacts in the subdirectory named <cite>persist_dir_data</cite>.</p>
<p>Here is the code snippet for logging a RetrievalQA chain with <cite>loader_fn</cite>
and <cite>persist_dir</cite>:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In langchain_community &gt;= 0.0.27, loading pickled data requires providing the
<code class="docutils literal notranslate"><span class="pre">allow_dangerous_deserialization</span></code> argument.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">qa</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="o">.</span><span class="n">from_llm</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">OpenAI</span><span class="p">(),</span> <span class="n">retriever</span><span class="o">=</span><span class="n">db</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">())</span>


<span class="k">def</span> <span class="nf">load_retriever</span><span class="p">(</span><span class="n">persist_directory</span><span class="p">):</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">()</span>
    <span class="n">vectorstore</span> <span class="o">=</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">load_local</span><span class="p">(</span>
        <span class="n">persist_directory</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="c1"># you may need to add the line below</span>
        <span class="c1"># for langchain_community &gt;= 0.0.27</span>
        <span class="n">allow_dangerous_deserialization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">vectorstore</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">()</span>


<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
    <span class="n">logged_model</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">langchain</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">qa</span><span class="p">,</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;retrieval_qa&quot;</span><span class="p">,</span>
        <span class="n">loader_fn</span><span class="o">=</span><span class="n">load_retriever</span><span class="p">,</span>
        <span class="n">persist_dir</span><span class="o">=</span><span class="n">persist_dir</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>See a complete example in examples/langchain/retrieval_qa_chain.py.</p>
</p></li>
<li><p><strong>example_no_conversion</strong> – This parameter is deprecated and will be removed in a future
release. It’s no longer used and can be safely removed. Input examples are
not converted anymore.</p></li>
<li><p><strong>model_config</strong> – <p>The model configuration to apply to the model if saving model from code. This
configuration is available during model loading.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This parameter may change or be removed in a future
release without warning.</p>
</div>
</p></li>
<li><p><strong>streamable</strong> – A boolean value indicating if the model supports streaming prediction. If
True, the model must implement <cite>stream</cite> method. If None, streamable is
set to True if the model implements <cite>stream</cite> method. Default to <cite>None</cite>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>


              </div>
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="mlflow.keras.html" class="btn btn-neutral" title="mlflow.keras" accesskey="p"><span class="db-icon db-icon-chevron-left"></span> Previous</a>
      
      
        <a href="mlflow.lightgbm.html" class="btn btn-neutral" title="mlflow.lightgbm" accesskey="n">Next <span class="db-icon db-icon-chevron-right"></span></a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../',
      VERSION:'2.17.1.dev0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../_static/clippy.svg";</script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>
{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"docsSidebar":[{"type":"link","label":"MLflow","href":"/","className":"sidebar-top-level-category","docId":"index","unlisted":false},{"type":"category","label":"Getting Started","className":"sidebar-top-level-category","items":[{"type":"link","label":"Quickstart","href":"/getting-started/intro-quickstart/","docId":"getting-started/intro-quickstart/index","unlisted":false},{"type":"link","label":"How to Run Tutorials","href":"/getting-started/running-notebooks/","docId":"getting-started/running-notebooks/index","unlisted":false},{"type":"link","label":"Databricks Community Edition","href":"/getting-started/community-edition/","docId":"getting-started/community-edition/index","unlisted":false},{"type":"category","label":"More Tutorials","items":[{"type":"link","label":"Hyperparameter Tuning Tutorial","href":"/getting-started/quickstart-2/","docId":"getting-started/quickstart-2/index","unlisted":false},{"type":"category","label":"Model Registry Tutorial","items":[{"type":"link","label":"Tutorial Overview","href":"/getting-started/registering-first-model/","docId":"getting-started/registering-first-model/index","unlisted":false},{"type":"link","label":"Register a Model","href":"/getting-started/registering-first-model/step1-register-model/","docId":"getting-started/registering-first-model/step1-register-model/index","unlisted":false},{"type":"link","label":"Explore the Registered Model","href":"/getting-started/registering-first-model/step2-explore-registered-model/","docId":"getting-started/registering-first-model/step2-explore-registered-model/index","unlisted":false},{"type":"link","label":"Load a Registered Model","href":"/getting-started/registering-first-model/step3-load-model/","docId":"getting-started/registering-first-model/step3-load-model/index","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"5 Minute Tracking Server Overview","href":"/getting-started/tracking-server-overview/","docId":"getting-started/tracking-server-overview/index","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true,"href":"/getting-started/"},{"type":"category","label":"Machine Learning ðŸ§ ","className":"sidebar-top-level-category","collapsed":false,"items":[{"type":"category","label":"LLM / GenAI","items":[{"type":"link","label":"Overview","href":"/llms/","docId":"llms/index","unlisted":false},{"type":"category","label":"Integrations","items":[{"type":"category","label":"OpenAI","items":[{"type":"link","label":"MLflow OpenAI Flavor","href":"/llms/openai/","docId":"llms/openai/index","unlisted":false},{"type":"link","label":"Tutorials","href":"/llms/openai/notebooks/","docId":"llms/openai/notebooks/index","unlisted":false},{"type":"link","label":"Autologging","href":"/llms/openai/autologging/","docId":"llms/openai/autologging/index","unlisted":false},{"type":"link","label":"Detailed Guide","href":"/llms/openai/guide/","docId":"llms/openai/guide/index","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/llms/openai/"},{"type":"category","label":"LangChain","items":[{"type":"link","label":"MLflow Langchain Autologging","href":"/llms/langchain/autologging","docId":"llms/langchain/autologging","unlisted":false},{"type":"link","label":"LangChain within MLflow (Experimental)","href":"/llms/langchain/guide/","docId":"llms/langchain/guide/index","unlisted":false},{"type":"link","label":"MLflow LangChain Flavor","href":"/llms/langchain/","docId":"llms/langchain/index","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/llms/langchain/"},{"type":"link","label":"DSPy","href":"/llms/dspy/","docId":"llms/dspy/index","unlisted":false},{"type":"link","label":"LlamaIndex","href":"/llms/llama-index/","docId":"llms/llama-index/index","unlisted":false},{"type":"category","label":"Transformers","items":[{"type":"link","label":"Overview","href":"/llms/transformers/","docId":"llms/transformers/index","unlisted":false},{"type":"link","label":"Tutorials","href":"/llms/transformers/tutorials/","docId":"llms/transformers/tutorials/index","unlisted":false},{"type":"link","label":"Detailed Guide","href":"/llms/transformers/guide/","docId":"llms/transformers/guide/index","unlisted":false},{"type":"link","label":"Task","href":"/llms/transformers/task/","docId":"llms/transformers/task/index","unlisted":false},{"type":"link","label":"Storage Optimization","href":"/llms/transformers/large-models/","docId":"llms/transformers/large-models/index","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/llms/transformers/"},{"type":"category","label":"Sentence Transformers","items":[{"type":"link","label":"Overview","href":"/llms/sentence-transformers/","docId":"llms/sentence-transformers/index","unlisted":false},{"type":"link","label":"Tutorials","href":"/llms/sentence-transformers/tutorials/","docId":"llms/sentence-transformers/tutorials/index","unlisted":false},{"type":"link","label":"Detailed Guides","href":"/llms/sentence-transformers/guide/","docId":"llms/sentence-transformers/guide/index","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/llms/sentence-transformers/"},{"type":"link","href":"/tracing/integrations/","label":"More"}],"collapsed":true,"collapsible":true},{"type":"link","label":"Tracing (Observability)","href":"/tracing/"},{"type":"link","label":"Evaluation","href":"/llms/llm-evaluate/"},{"type":"category","label":"ChatModel","items":[{"type":"link","label":"What is ChatModel?","href":"/llms/chat-model-intro/","docId":"llms/chat-model-intro/index","unlisted":false},{"type":"link","label":"Advanced Guide","href":"/llms/chat-model-guide/","docId":"llms/chat-model-guide/index","unlisted":false},{"type":"link","label":"More Customization","href":"/llms/custom-pyfunc-for-llms/","docId":"llms/custom-pyfunc-for-llms/index","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"RAG","items":[{"type":"link","label":"What is RAG?","href":"/llms/rag/","docId":"llms/rag/index","unlisted":false},{"type":"link","label":"Explore RAG Tutorials","href":"/llms/rag/notebooks/","docId":"llms/rag/notebooks/index","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"Prompt Engineering","href":"/llms/prompt-engineering/","docId":"llms/prompt-engineering/index","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/llms/"},{"type":"category","label":"Deep Learning","items":[{"type":"link","label":"Overview","href":"/deep-learning/","docId":"deep-learning/index","unlisted":false},{"type":"category","label":"Pytorch","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"PyTorch within MLflow","href":"/deep-learning/pytorch/guide/","docId":"deep-learning/pytorch/guide/index","unlisted":false}],"href":"/deep-learning/pytorch/"},{"type":"link","label":"Keras","href":"/deep-learning/keras/","docId":"deep-learning/keras/index","unlisted":false},{"type":"category","label":"Tensorflow","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Tensorflow within MLflow","href":"/deep-learning/tensorflow/guide/","docId":"deep-learning/tensorflow/guide/index","unlisted":false}],"href":"/deep-learning/tensorflow/"}],"collapsed":true,"collapsible":true,"href":"/deep-learning/"},{"type":"category","label":"Traditional ML","items":[{"type":"link","label":"Overview","href":"/traditional-ml/","docId":"traditional-ml/index","unlisted":false},{"type":"category","label":"Hyperparameter Tuning with MLflow and Optuna","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Full Notebooks","href":"/traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/","docId":"traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/index","unlisted":false},{"type":"link","label":"The Parent-Child relationship with runs","href":"/traditional-ml/hyperparameter-tuning-with-child-runs/part1-child-runs/","docId":"traditional-ml/hyperparameter-tuning-with-child-runs/part1-child-runs/index","unlisted":false},{"type":"link","label":"Logging plots with MLflow","href":"/traditional-ml/hyperparameter-tuning-with-child-runs/part2-logging-plots/","docId":"traditional-ml/hyperparameter-tuning-with-child-runs/part2-logging-plots/index","unlisted":false}],"href":"/traditional-ml/hyperparameter-tuning-with-child-runs/"},{"type":"category","label":"Building Custom Python Function Models with MLflow","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Models, Flavors, and PyFuncs in MLflow","href":"/traditional-ml/creating-custom-pyfunc/part1-named-flavors/","docId":"traditional-ml/creating-custom-pyfunc/part1-named-flavors/index","unlisted":false},{"type":"link","label":"Understanding PyFunc in MLflow","href":"/traditional-ml/creating-custom-pyfunc/part2-pyfunc-components/","docId":"traditional-ml/creating-custom-pyfunc/part2-pyfunc-components/index","unlisted":false},{"type":"link","label":"Full Notebooks","href":"/traditional-ml/creating-custom-pyfunc/notebooks/","docId":"traditional-ml/creating-custom-pyfunc/notebooks/index","unlisted":false}],"href":"/traditional-ml/creating-custom-pyfunc/"},{"type":"link","label":"Serving Multiple Models on a Single Endpoint with a Custom PyFunc Model","href":"/traditional-ml/serving-multiple-models-with-pyfunc/","docId":"traditional-ml/serving-multiple-models-with-pyfunc/index","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/traditional-ml/"}],"collapsible":true},{"type":"category","label":"Build ðŸ”¨ ","className":"sidebar-top-level-category","collapsed":false,"items":[{"type":"category","label":"MLflow Tracking","items":[{"type":"link","label":"Overview","href":"/tracking/","docId":"tracking/index","unlisted":false},{"type":"link","href":"/getting-started/intro-quickstart/","label":"Quickstart"},{"type":"link","label":"Auto Logging","href":"/tracking/autolog/","docId":"tracking/autolog/index","unlisted":false},{"type":"category","label":"Tracking Server","items":[{"type":"link","label":"Artifact Store","href":"/tracking/artifacts-stores/","docId":"tracking/artifacts-stores/index","unlisted":false},{"type":"link","label":"Backend Store","href":"/tracking/backend-stores/","docId":"tracking/backend-stores/index","unlisted":false},{"type":"category","label":"Tutorials","items":[{"type":"link","label":"Tracking Experiments with a Local Database","href":"/tracking/tutorials/local-database/","docId":"tracking/tutorials/local-database/index","unlisted":false},{"type":"link","label":"Remote Experiment Tracking with MLflow Tracking Server","href":"/tracking/tutorials/remote-server/","docId":"tracking/tutorials/remote-server/index","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true,"href":"/tracking/server/"},{"type":"category","label":"Searching Runs & Experiments","items":[{"type":"link","label":"Search Runs","href":"/search-runs/","docId":"search-runs/index","unlisted":false},{"type":"link","label":"Search Experiments","href":"/search-experiments/","docId":"search-experiments/index","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"System Metrics","href":"/system-metrics/","docId":"system-metrics/index","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/tracking/"},{"type":"category","label":"MLflow Model","items":[{"type":"link","label":"Overview","href":"/model/","docId":"model/index","unlisted":false},{"type":"link","label":"Model Signature","href":"/model/signatures/","docId":"model/signatures/index","unlisted":false},{"type":"link","label":"Dependency Management","href":"/model/dependencies/","docId":"model/dependencies/index","unlisted":false},{"type":"link","label":"Models From Code","href":"/model/models-from-code/","docId":"model/models-from-code/index","unlisted":false},{"type":"link","label":"Custom Python Model","href":"/model/python_model","docId":"model/python_model","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"MLflow Recipes","href":"/recipes/","docId":"recipes/index","unlisted":false}],"collapsible":true},{"type":"category","label":"Evaluate & Monitor ðŸ“Š","className":"sidebar-top-level-category","collapsed":false,"items":[{"type":"link","label":"MLflow Evaluation","href":"/model-evaluation/","docId":"model-evaluation/index","unlisted":false},{"type":"category","label":"MLflow Tracing (Observability)","items":[{"type":"link","label":"Overview","href":"/tracing/","docId":"tracing/index","unlisted":false},{"type":"link","label":"Data Structure","href":"/tracing/tracing-schema","docId":"tracing/tracing-schema","unlisted":false},{"type":"category","label":"Integrations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"OpenAI","href":"/tracing/integrations/openai","docId":"tracing/integrations/openai","unlisted":false},{"type":"link","label":"LangChain","href":"/tracing/integrations/langchain","docId":"tracing/integrations/langchain","unlisted":false},{"type":"link","label":"LangGraph","href":"/tracing/integrations/langgraph","docId":"tracing/integrations/langgraph","unlisted":false},{"type":"link","label":"LlamaIndex","href":"/tracing/integrations/llama_index","docId":"tracing/integrations/llama_index","unlisted":false},{"type":"link","label":"Bedrock","href":"/tracing/integrations/bedrock","docId":"tracing/integrations/bedrock","unlisted":false},{"type":"link","label":"DSPy","href":"/tracing/integrations/dspy","docId":"tracing/integrations/dspy","unlisted":false},{"type":"link","label":"AutoGen","href":"/tracing/integrations/autogen","docId":"tracing/integrations/autogen","unlisted":false},{"type":"link","label":"CrewAI","href":"/tracing/integrations/crewai","docId":"tracing/integrations/crewai","unlisted":false},{"type":"link","label":"Anthropic","href":"/tracing/integrations/anthropic","docId":"tracing/integrations/anthropic","unlisted":false},{"type":"link","label":"LiteLLM","href":"/tracing/integrations/litellm","docId":"tracing/integrations/litellm","unlisted":false},{"type":"link","label":"Swarm","href":"/tracing/integrations/swarm","docId":"tracing/integrations/swarm","unlisted":false},{"type":"link","label":"Gemini","href":"/tracing/integrations/gemini","docId":"tracing/integrations/gemini","unlisted":false},{"type":"link","label":"Ollama","href":"/tracing/integrations/ollama","docId":"tracing/integrations/ollama","unlisted":false},{"type":"link","label":"Mistral","href":"/tracing/integrations/mistral","docId":"tracing/integrations/mistral","unlisted":false},{"type":"link","label":"Groq","href":"/tracing/integrations/groq","docId":"tracing/integrations/groq","unlisted":false},{"type":"link","label":"Instructor","href":"/tracing/integrations/instructor","docId":"tracing/integrations/instructor","unlisted":false},{"type":"link","label":"Add New Integration","href":"/tracing/integrations/contribute","docId":"tracing/integrations/contribute","unlisted":false}],"href":"/tracing/integrations/"},{"type":"category","label":"APIs","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Manual Tracing","href":"/tracing/api/manual-instrumentation","docId":"tracing/api/manual-instrumentation","unlisted":false},{"type":"link","label":"Query Traces","href":"/tracing/api/search","docId":"tracing/api/search","unlisted":false},{"type":"link","label":"How-to Guide","href":"/tracing/api/how-to","docId":"tracing/api/how-to","unlisted":false},{"type":"link","label":"Low-level Client APIs","href":"/tracing/api/client","docId":"tracing/api/client","unlisted":false}],"href":"/tracing/api/"},{"type":"link","label":"Production Monitoring","href":"/tracing/production","docId":"tracing/production","unlisted":false},{"type":"link","label":"Session","href":"/tracing/session","docId":"tracing/session","unlisted":false},{"type":"link","label":"FAQ","href":"/tracing/faq","docId":"tracing/faq","unlisted":false},{"type":"category","label":"Tutorials","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Tracing 101","href":"/tracing/tutorials/concept","docId":"tracing/tutorials/concept","unlisted":false}],"href":"/tracing/tutorials/"},{"type":"link","label":"ui","href":"/tracing/ui","docId":"tracing/ui","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/tracing/"},{"type":"link","label":"MLflow Dataset","href":"/dataset/","docId":"dataset/index","unlisted":false}],"collapsible":true},{"type":"category","label":"Deploy ðŸš€","className":"sidebar-top-level-category","collapsed":false,"items":[{"type":"link","label":"MLflow Model Registry","href":"/model-registry/","docId":"model-registry/index","unlisted":false},{"type":"category","label":"MLflow Serving","items":[{"type":"link","label":"Overview","href":"/deployment/","docId":"deployment/index","unlisted":false},{"type":"link","label":"Deploy MLflow Model as a Local Inference Server","href":"/deployment/deploy-model-locally/","docId":"deployment/deploy-model-locally/index","unlisted":false},{"type":"link","label":"Deploy MLflow Model to Amazon SageMaker","href":"/deployment/deploy-model-to-sagemaker/","docId":"deployment/deploy-model-to-sagemaker/index","unlisted":false},{"type":"category","label":"Deploy MLflow Model to Kubernetes","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Develop ML model with MLflow and deploy to Kubernetes","href":"/deployment/deploy-model-to-kubernetes/tutorial/","docId":"deployment/deploy-model-to-kubernetes/tutorial/index","unlisted":false}],"href":"/deployment/deploy-model-to-kubernetes/"}],"collapsed":true,"collapsible":true},{"type":"link","label":"MLflow AI Gateway","href":"/llms/deployments/","docId":"llms/deployments/index","unlisted":false}],"collapsible":true},{"type":"category","label":"Team Collaboration ðŸ‘¥","className":"sidebar-top-level-category","collapsed":true,"items":[{"type":"link","href":"/tracking/#tracking-setup","label":"Self-Hosting"},{"type":"link","href":"/#running-mlflow-anywhere","label":"Managed Services"},{"type":"link","label":"Access Control","href":"/auth/","docId":"auth/index","unlisted":false},{"type":"link","label":"MLflow Projects","href":"/projects/","docId":"projects/index","unlisted":false}],"collapsible":true},{"type":"category","label":"API References","className":"sidebar-top-level-category","collapsed":true,"items":[{"type":"link","label":"Python API","href":"https://mlflow.org/docs/latest/api_reference/python_api/index.html"},{"type":"link","label":"Java API","href":"https://mlflow.org/docs/latest/api_reference/java_api/index.html"},{"type":"link","label":"R API","href":"https://mlflow.org/docs/latest/api_reference/R-api/index.html"},{"type":"link","label":"REST API","href":"https://mlflow.org/docs/latest/api_reference/rest-api/index.html"},{"type":"link","label":"CLI","href":"https://mlflow.org/docs/latest/api_reference/cli.html"}],"collapsible":true},{"type":"category","label":"More","collapsed":true,"className":"sidebar-top-level-category","items":[{"type":"link","label":"Contributing","href":"https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md"},{"type":"link","label":"MLflow Blogs","href":"https://mlflow.org/blog/index.html"},{"type":"link","label":"MLflow Plugins","href":"/plugins/","docId":"plugins/index","unlisted":false}],"collapsible":true}]},"docs":{"auth/index":{"id":"auth/index","title":"MLflow Authentication","description":"This feature is still experimental and may change in a future release without warning.","sidebar":"docsSidebar"},"community-model-flavors/index":{"id":"community-model-flavors/index","title":"Community Model Flavors","description":"Other useful MLflow flavors are developed and maintained by the"},"dataset/index":{"id":"dataset/index","title":"MLflow Dataset Tracking Tutorial","description":"The mlflow.data module is an integral part of the MLflow ecosystem, designed to enhance your machine learning workflow.","sidebar":"docsSidebar"},"deep-learning/index":{"id":"deep-learning/index","title":"Deep Learning","description":"The realm of deep learning has witnessed an unprecedented surge, revolutionizing numerous sectors with its ability to","sidebar":"docsSidebar"},"deep-learning/keras/index":{"id":"deep-learning/keras/index","title":"MLflow Keras 3.0 Integration","description":"Introduction","sidebar":"docsSidebar"},"deep-learning/pytorch/guide/index":{"id":"deep-learning/pytorch/guide/index","title":"PyTorch within MLflow","description":"In this guide we will walk you through how to use PyTorch within MLflow. We will demonstrate","sidebar":"docsSidebar"},"deep-learning/pytorch/index":{"id":"deep-learning/pytorch/index","title":"MLflow PyTorch Flavor","description":"Introduction","sidebar":"docsSidebar"},"deep-learning/tensorflow/guide/index":{"id":"deep-learning/tensorflow/guide/index","title":"Tensorflow within MLflow","description":"In this guide we will walk you through how to use Tensorflow within MLflow. We will demonstrate","sidebar":"docsSidebar"},"deep-learning/tensorflow/index":{"id":"deep-learning/tensorflow/index","title":"MLflow Tensorflow Integration","description":"Introduction","sidebar":"docsSidebar"},"deployment/deploy-model-locally/index":{"id":"deployment/deploy-model-locally/index","title":"Deploy MLflow Model as a Local Inference Server","description":"MLflow allows you to deploy your model locally using just a single command.","sidebar":"docsSidebar"},"deployment/deploy-model-to-kubernetes/index":{"id":"deployment/deploy-model-to-kubernetes/index","title":"Deploy MLflow Model to Kubernetes","description":"Using MLServer as the Inference Server","sidebar":"docsSidebar"},"deployment/deploy-model-to-kubernetes/tutorial/index":{"id":"deployment/deploy-model-to-kubernetes/tutorial/index","title":"Develop ML model with MLflow and deploy to Kubernetes","description":"This tutorial assumes that you have access to a Kubernetes cluster. However, you can also complete this tutorial on your local machine","sidebar":"docsSidebar"},"deployment/deploy-model-to-sagemaker/index":{"id":"deployment/deploy-model-to-sagemaker/index","title":"Deploy MLflow Model to Amazon SageMaker","description":"Amazon SageMaker is a fully managed service designed for scaling ML inference containers.","sidebar":"docsSidebar"},"deployment/index":{"id":"deployment/index","title":"MLflow Serving","description":"This page describes the toolset for deploying your in-house MLflow Model.For information on the","sidebar":"docsSidebar"},"docker/index":{"id":"docker/index","title":"Official MLflow Docker image","description":"The official MLflow Docker image is available on GitHub Container Registry at https://ghcr.io/mlflow/mlflow."},"getting-started/community-edition/index":{"id":"getting-started/community-edition/index","title":"Databricks Community Edition","description":"The Databricks Community Edition (CE) is a fully managed, Databricks-hosted version of the Databricks platform. While many of the enterprise features of the","sidebar":"docsSidebar"},"getting-started/index":{"id":"getting-started/index","title":"Getting Started with MLflow","description":"For those new to MLflow or seeking a refresher on its core functionalities, the","sidebar":"docsSidebar"},"getting-started/intro-quickstart/index":{"id":"getting-started/intro-quickstart/index","title":"MLflow Tracking Quickstart","description":"Welcome to MLflow!","sidebar":"docsSidebar"},"getting-started/intro-quickstart/notebooks/index":{"id":"getting-started/intro-quickstart/notebooks/index","title":"MLflow Tracking Quickstart Notebook","description":"Welcome to the MLflow Tracking Quickstart! The notebook-based companion to the quickstart guide is tailored to help you quickly"},"getting-started/logging-first-model/index":{"id":"getting-started/logging-first-model/index","title":"Tutorial Overview","description":"In this entry point tutorial to MLflow, we'll be covering the essential basics of core MLflow functionality associated"},"getting-started/logging-first-model/notebooks/index":{"id":"getting-started/logging-first-model/notebooks/index","title":"Logging Your First MLflow Model Notebook","description":"If you would like to view the full notebook:"},"getting-started/logging-first-model/step1-tracking-server/index":{"id":"getting-started/logging-first-model/step1-tracking-server/index","title":"Starting the MLflow Tracking Server","description":"Before diving into MLflow's rich features, let's set up the foundational components: the MLflow"},"getting-started/logging-first-model/step2-mlflow-client/index":{"id":"getting-started/logging-first-model/step2-mlflow-client/index","title":"Using the MLflow Client API","description":"In the previous section, we started an instance of the MLflow Tracking Server and the MLflow UI."},"getting-started/logging-first-model/step3-create-experiment/index":{"id":"getting-started/logging-first-model/step3-create-experiment/index","title":"Creating Experiments","description":"In the previous section, we became familiar with the MLflow Client and its search_experiments API."},"getting-started/logging-first-model/step4-experiment-search/index":{"id":"getting-started/logging-first-model/step4-experiment-search/index","title":"Searching Experiments","description":"In the last section, we created our first MLflow Experiment, providing custom tags so that we can find"},"getting-started/logging-first-model/step5-synthetic-data/index":{"id":"getting-started/logging-first-model/step5-synthetic-data/index","title":"Create a dataset about apples","description":"In order to produce some meaningful data (and a model) for us to log to MLflow, we'll need a dataset."},"getting-started/logging-first-model/step6-logging-a-run/index":{"id":"getting-started/logging-first-model/step6-logging-a-run/index","title":"Logging our first runs with MLflow","description":"In our previous segments, we worked through setting up our first MLflow Experiment and equipped it"},"getting-started/quickstart-2/index":{"id":"getting-started/quickstart-2/index","title":"Quickstart: Compare runs, choose a model, and deploy it to a REST API","description":"In this quickstart, you will:","sidebar":"docsSidebar"},"getting-started/registering-first-model/index":{"id":"getting-started/registering-first-model/index","title":"Tutorial Overview","description":"The MLflow Model Registry has several core components:","sidebar":"docsSidebar"},"getting-started/registering-first-model/step1-register-model/index":{"id":"getting-started/registering-first-model/step1-register-model/index","title":"Register a Model","description":"Throughout this tutorial we will leverage a local tracking server and model registry for simplicity.","sidebar":"docsSidebar"},"getting-started/registering-first-model/step2-explore-registered-model/index":{"id":"getting-started/registering-first-model/step2-explore-registered-model/index","title":"Explore the Registered Model","description":"Now that we've logged an experiment and registered the model associated with that experiment run,","sidebar":"docsSidebar"},"getting-started/registering-first-model/step3-load-model/index":{"id":"getting-started/registering-first-model/step3-load-model/index","title":"Load a Registered Model","description":"To perform inference on a registered model version, we need to load it into memory. There are many","sidebar":"docsSidebar"},"getting-started/running-notebooks/index":{"id":"getting-started/running-notebooks/index","title":"How to Run Tutorials","description":"This brief guide will walk you through some options that you have to run these tutorials and have a Tracking Server that is available to log the results to (as well","sidebar":"docsSidebar"},"getting-started/tracking-server-overview/index":{"id":"getting-started/tracking-server-overview/index","title":"5 Minute Tracking Server Overview","description":"In this guide we will walk you through how to view your MLflow experiment results with different types of","sidebar":"docsSidebar"},"index":{"id":"index","title":"MLflow: A Tool for Managing the Machine Learning Lifecycle","description":"MLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in","sidebar":"docsSidebar"},"introduction/index":{"id":"introduction/index","title":"MLflow Overview","description":"Stepping into the world of Machine Learning (ML) is an exciting journey, but it often comes with"},"llms/chat-model-guide/index":{"id":"llms/chat-model-guide/index","title":"Tutorial: Custom GenAI Models using ChatModel","description":"The rapidly evolving landscape of Generative Artificial Intelligence (GenAI) presents exciting opportunities and integration challenges.","sidebar":"docsSidebar"},"llms/chat-model-intro/index":{"id":"llms/chat-model-intro/index","title":"Tutorial: Getting Started with ChatModel","description":"MLflow's ChatModel class provides a standardized way to create production-ready conversational AI models.","sidebar":"docsSidebar"},"llms/custom-pyfunc-for-llms/index":{"id":"llms/custom-pyfunc-for-llms/index","title":"Deploying Advanced LLMs with Custom PyFuncs in MLflow","description":"Advanced Large Language Models (LLMs) such as the MPT-7B instruct transformer are intricate and have requirements that don't align with","sidebar":"docsSidebar"},"llms/custom-pyfunc-for-llms/notebooks/index":{"id":"llms/custom-pyfunc-for-llms/notebooks/index","title":"Custom PyFuncs for Advanced LLMs with MLflow - Notebooks","description":"If you'd like to delve deeper into the notebooks in this guide, they can be viewed or downloaded directly below."},"llms/deployments/guides/index":{"id":"llms/deployments/guides/index","title":"Getting Started with MLflow Deployments for LLMs","description":"MLflow provides a robust framework for deploying and managing machine learning models. In this tutorial, we will explore how to set up an"},"llms/deployments/guides/step1-create-deployments/index":{"id":"llms/deployments/guides/step1-create-deployments/index","title":"Configuring and Starting the gateway server","description":"Step 1: Install"},"llms/deployments/guides/step2-query-deployments/index":{"id":"llms/deployments/guides/step2-query-deployments/index","title":"Querying endpoints in the MLflow Deployment Server","description":"Now that the deployment server is operational, it's time to send it some data. You can interact with the"},"llms/deployments/index":{"id":"llms/deployments/index","title":"MLflow AI Gateway (Experimental)","description":"MLflow AI Gateway does not support Windows.","sidebar":"docsSidebar"},"llms/deployments/uc_integration/index":{"id":"llms/deployments/uc_integration/index","title":"Unity Catalog Integration","description":"This example illustrates the use of the Unity Catalog (UC) integration with the MLflow AI Gateway."},"llms/dspy/index":{"id":"llms/dspy/index","title":"MLflow DSPy Flavor","description":"The dspy flavor is under active development and is marked as Experimental. Public APIs are","sidebar":"docsSidebar"},"llms/index":{"id":"llms/index","title":"LLM / GenAI","description":"LLMs (Large Language Models) have become essential in machine learning, enabling tasks like natural language understanding and code generation. However, fully leveraging their potential often involves complex processes of managing many moving pieces such as prompts, LLM providers, frameworks, knowledge base, tools, and more.","sidebar":"docsSidebar"},"llms/langchain/autologging":{"id":"llms/langchain/autologging","title":"MLflow Langchain Autologging","description":"MLflow LangChain flavor supports autologging, a powerful feature that allows you to log crucial details about the LangChain model and execution without the need for explicit logging statements. MLflow LangChain autologging covers various aspects of the model, including traces, models, signatures and more.","sidebar":"docsSidebar"},"llms/langchain/guide/index":{"id":"llms/langchain/guide/index","title":"LangChain within MLflow (Experimental)","description":"The langchain flavor is currently under active development and is marked as Experimental. Public APIs are evolving, and new features are being added to enhance its functionality.","sidebar":"docsSidebar"},"llms/langchain/index":{"id":"llms/langchain/index","title":"MLflow LangChain Flavor","description":"The langchain flavor is under active development and is marked as Experimental. Public APIs are","sidebar":"docsSidebar"},"llms/llama-index/index":{"id":"llms/llama-index/index","title":"MLflow LlamaIndex Flavor","description":"The llama_index flavor is under active development and is marked as Experimental. Public APIs are","sidebar":"docsSidebar"},"llms/llm-evaluate/index":{"id":"llms/llm-evaluate/index","title":"MLflow LLM Evaluation","description":"LLM evaluation involves assessing how well a model performs on a task. MLflow provides a simple API to evaluate your LLMs with popular metrics."},"llms/llm-evaluate/notebooks/index":{"id":"llms/llm-evaluate/notebooks/index","title":"LLM Evaluation Examples","description":"The notebooks listed below contain step-by-step tutorials on how to use MLflow to evaluate LLMs."},"llms/llm-tracking/index":{"id":"llms/llm-tracking/index","title":"MLflow's LLM Tracking Capabilities","description":"MLflow's LLM Tracking system is an enhancement to the existing MLflow Tracking system, offerring additional capabilities for monitoring,"},"llms/openai/autologging/index":{"id":"llms/openai/autologging/index","title":"MLflow OpenAI Autologging","description":"The OpenAI flavor for MLflow supports autologging to ensure that experimentation, testing, and validation of your ideas can be captured dynamically without","sidebar":"docsSidebar"},"llms/openai/guide/index":{"id":"llms/openai/guide/index","title":"OpenAI within MLflow","description":"The openai flavor is under active development and is marked as Experimental. Public APIs may change and new features are","sidebar":"docsSidebar"},"llms/openai/index":{"id":"llms/openai/index","title":"MLflow OpenAI Flavor","description":"The openai flavor is under active development and is marked as Experimental. Public APIs are","sidebar":"docsSidebar"},"llms/openai/notebooks/index":{"id":"llms/openai/notebooks/index","title":"MLflow OpenAI Flavor - Tutorials and Guides","description":"Below, you will find a number of guides that focus on different ways that you can leverage the power of the openai library, leveraging MLflow's","sidebar":"docsSidebar"},"llms/prompt-engineering/index":{"id":"llms/prompt-engineering/index","title":"Prompt Engineering UI (Experimental)","description":"Starting in MLflow 2.7, the MLflow Tracking UI provides a best-in-class experience for prompt","sidebar":"docsSidebar"},"llms/rag/index":{"id":"llms/rag/index","title":"Retrieval Augmented Generation (RAG)","description":"Retrieval Augmented Generation (RAG) is a powerful and efficient approach to natural","sidebar":"docsSidebar"},"llms/rag/notebooks/index":{"id":"llms/rag/notebooks/index","title":"RAG Tutorials","description":"You can find a list of tutorials for RAG below. These tutorials are designed to help you","sidebar":"docsSidebar"},"llms/sentence-transformers/guide/index":{"id":"llms/sentence-transformers/guide/index","title":"Sentence Transformers within MLflow","description":"The sentence_transformers flavor is in active development and is marked as Experimental. Public APIs may change and new features are","sidebar":"docsSidebar"},"llms/sentence-transformers/index":{"id":"llms/sentence-transformers/index","title":"MLflow Sentence-Transformers Flavor","description":"The sentence-transformers flavor is under active development and is marked as Experimental. Public APIs are subject to change,","sidebar":"docsSidebar"},"llms/sentence-transformers/tutorials/index":{"id":"llms/sentence-transformers/tutorials/index","title":"MLflow Sentence Transformers Flavor - Tutorials and Guides","description":"Below, you will find a number of guides that focus on different ways that you can leverage the power of the sentence-transformers library, leveraging MLflow's","sidebar":"docsSidebar"},"llms/transformers/guide/index":{"id":"llms/transformers/guide/index","title":"ðŸ¤— Transformers within MLflow","description":"The transformers flavor is in active development and is marked as Experimental. Public APIs may change and new features are","sidebar":"docsSidebar"},"llms/transformers/index":{"id":"llms/transformers/index","title":"MLflow Transformers Flavor","description":"The transformers flavor is in active development and is marked as Experimental. Public APIs may change and new features are","sidebar":"docsSidebar"},"llms/transformers/large-models/index":{"id":"llms/transformers/large-models/index","title":"Working with Large Models in MLflow Transformers flavor","description":"The features described in this guide are intended for advanced users familiar with Transformers and MLflow. Please understand the limitations and potential risks associated with these features before use.","sidebar":"docsSidebar"},"llms/transformers/task/index":{"id":"llms/transformers/task/index","title":"Tasks in MLflow Transformers Flavor","description":"This page provides an overview of how to use the task parameter in the MLflow Transformers flavor to control","sidebar":"docsSidebar"},"llms/transformers/tutorials/index":{"id":"llms/transformers/tutorials/index","title":"MLflow Transformers Flavor - Tutorials and Guides","description":"Below, you will find a number of guides that focus on different use cases using transformers that leverage MLflow's","sidebar":"docsSidebar"},"model-evaluation/index":{"id":"model-evaluation/index","title":"Model Evaluation","description":"Harnessing the Power of Automation","sidebar":"docsSidebar"},"model-registry/index":{"id":"model-registry/index","title":"MLflow Model Registry","description":"The MLflow Model Registry component is a centralized model store, set of APIs, and UI, to","sidebar":"docsSidebar"},"model/dependencies/index":{"id":"model/dependencies/index","title":"Managing Dependencies in MLflow Models","description":"MLflow Model is a standard format that packages a machine learning model with its dependencies and other metadata.","sidebar":"docsSidebar"},"model/index":{"id":"model/index","title":"MLflow Models","description":"An MLflow Model is a standard format for packaging machine learning models that can be used in a","sidebar":"docsSidebar"},"model/models-from-code/index":{"id":"model/models-from-code/index","title":"Models From Code","description":"Models from Code is available in MLflow 2.12.2 and above. If you are using a version earlier than what supports this feature,","sidebar":"docsSidebar"},"model/python_model":{"id":"model/python_model","title":"MLflow PythonModel Guide","description":"Introduction to MLflow PythonModel","sidebar":"docsSidebar"},"model/signatures/index":{"id":"model/signatures/index","title":"MLflow Model Signatures and Input Examples Guide","description":"Introduction to Model Signatures and Input Examples \\","sidebar":"docsSidebar"},"new-features/index":{"id":"new-features/index","title":"New Features","description":"<NewFeatureCard"},"plugins/index":{"id":"plugins/index","title":"MLflow Plugins","description":"As a framework-agnostic tool for machine learning, the MLflow Python API provides developer APIs for","sidebar":"docsSidebar"},"projects/index":{"id":"projects/index","title":"MLflow Projects","description":"An MLflow Project is a format for packaging data science code in a reusable and reproducible way,","sidebar":"docsSidebar"},"quickstart_drilldown/index":{"id":"quickstart_drilldown/index","title":"Quickstart options and troubleshooting","description":"{/ Eventually, these H2s will probably all be separate articles. For now, I'm"},"recipes/index":{"id":"recipes/index","title":"MLflow Recipes","description":"MLflow Recipes (previously known as MLflow Pipelines) is a framework that enables data scientists","sidebar":"docsSidebar"},"search-experiments/index":{"id":"search-experiments/index","title":"Search Experiments","description":"and MlflowClient.search_experiments()","sidebar":"docsSidebar"},"search-runs/index":{"id":"search-runs/index","title":"Search Runs","description":"This guide will walk you through how to search your MLflow runs through the MLflow UI and Python API.","sidebar":"docsSidebar"},"system-metrics/index":{"id":"system-metrics/index","title":"System Metrics","description":"MLflow allows users to log system metrics including CPU stats, GPU stats, memory usage, network traffic, and","sidebar":"docsSidebar"},"tracing/api/client":{"id":"tracing/api/client","title":"(Advanced) Low-level Client APIs","description":"The MlflowClient class provides a set of low-level APIS for fine-grained control over creating, manipulating, and retrieving traces.","sidebar":"docsSidebar"},"tracing/api/how-to":{"id":"tracing/api/how-to","title":"Tracing SDK How-to Guides","description":"Render Trace inside Jupyter Notebook","sidebar":"docsSidebar"},"tracing/api/index":{"id":"tracing/api/index","title":"MLflow Tracing SDK","description":"","sidebar":"docsSidebar"},"tracing/api/manual-instrumentation":{"id":"tracing/api/manual-instrumentation","title":"Manual Tracing","description":"In addition to the Auto Tracing integrations, you can instrument your Python code using the MLflow Tracing SDK. This is especially useful when you need to instrument your custom Python code.","sidebar":"docsSidebar"},"tracing/api/search":{"id":"tracing/api/search","title":"Query Traces","description":"This page describes how to query traces logged to MLflow.","sidebar":"docsSidebar"},"tracing/faq":{"id":"tracing/faq","title":"FAQ","description":"Q: I cannot open my trace in the MLflow UI. What should I do?","sidebar":"docsSidebar"},"tracing/index":{"id":"tracing/index","title":"MLflow Tracing for LLM Observability","description":"MLflow Tracing is a feature that enables LLM observability in your apps. MLflow automatically logs traces for LangChain, LlamaIndex, and more.","sidebar":"docsSidebar"},"tracing/integrations/anthropic":{"id":"tracing/integrations/anthropic","title":"Tracing Anthropic","description":"OpenAI Tracing via autolog","sidebar":"docsSidebar"},"tracing/integrations/autogen":{"id":"tracing/integrations/autogen","title":"Tracing AutoGenðŸ¤–","description":"AutoGen Tracing via autolog","sidebar":"docsSidebar"},"tracing/integrations/bedrock":{"id":"tracing/integrations/bedrock","title":"Tracing Amazon Bedrock with MLflow","description":"MLflow supports automatic tracing for Amazon Bedrock, a fully managed service on AWS that provides high-performing","sidebar":"docsSidebar"},"tracing/integrations/contribute":{"id":"tracing/integrations/contribute","title":"Contributing to MLflow Tracing","description":"Welcome to the MLflow Tracing contribution guide! This step-by-step resource will assist you in implementing additional GenAI library integrations for tracing into MLflow.","sidebar":"docsSidebar"},"tracing/integrations/crewai":{"id":"tracing/integrations/crewai","title":"Tracing CrewAI","description":"CrewAI Tracing via autolog","sidebar":"docsSidebar"},"tracing/integrations/dspy":{"id":"tracing/integrations/dspy","title":"Tracing DSPyðŸ§©","description":"DSPy Tracing via autolog","sidebar":"docsSidebar"},"tracing/integrations/gemini":{"id":"tracing/integrations/gemini","title":"Tracing Gemini","description":"OpenAI Tracing via autolog","sidebar":"docsSidebar"},"tracing/integrations/groq":{"id":"tracing/integrations/groq","title":"Tracing Groq","description":"Groq tracing via autolog","sidebar":"docsSidebar"},"tracing/integrations/index":{"id":"tracing/integrations/index","title":"Auto Tracing Integrations","description":"MLflow Tracing is integrated with various GenAI libraries and provide one-line automatic tracing experience for each library (and the combination of them!). Click on the icon below to see detailed examples to integrate MLflow with your favorite library.","sidebar":"docsSidebar"},"tracing/integrations/instructor":{"id":"tracing/integrations/instructor","title":"Tracing Instructor","description":"Instructor Tracing via autolog","sidebar":"docsSidebar"},"tracing/integrations/langchain":{"id":"tracing/integrations/langchain","title":"Tracing LangChainðŸ¦œâ›“ï¸","description":"LangChain Tracing via autolog","sidebar":"docsSidebar"},"tracing/integrations/langgraph":{"id":"tracing/integrations/langgraph","title":"Tracing LangGraphðŸ¦œðŸ•¸ï¸","description":"LangChain Tracing via autolog","sidebar":"docsSidebar"},"tracing/integrations/litellm":{"id":"tracing/integrations/litellm","title":"Tracing LiteLLMðŸš„","description":"LiteLLM Tracing via autolog","sidebar":"docsSidebar"},"tracing/integrations/llama_index":{"id":"tracing/integrations/llama_index","title":"Tracing LlamaIndexðŸ¦™","description":"LlamaIndex Tracing via autolog","sidebar":"docsSidebar"},"tracing/integrations/mistral":{"id":"tracing/integrations/mistral","title":"Tracing Mistral","description":"Mistral tracing via autolog","sidebar":"docsSidebar"},"tracing/integrations/ollama":{"id":"tracing/integrations/ollama","title":"Tracing Ollama","description":"Ollama Tracing via autolog","sidebar":"docsSidebar"},"tracing/integrations/openai":{"id":"tracing/integrations/openai","title":"Tracing OpenAI","description":"OpenAI Tracing via autolog","sidebar":"docsSidebar"},"tracing/integrations/swarm":{"id":"tracing/integrations/swarm","title":"Tracing OpenAI SwarmðŸ","description":"OpenAI Tracing via autolog","sidebar":"docsSidebar"},"tracing/production":{"id":"tracing/production","title":"Tracing in Production","description":"Machine learning projects don't conclude with their initial launch. Ongoing monitoring and incremental enhancements are critical for long-term success. MLflow Tracing offers observability for your production application, supporting the iterative process of continuous improvement.","sidebar":"docsSidebar"},"tracing/session":{"id":"tracing/session","title":"Tracing Multi-turn Conversation Sessions","description":"In conversational AI applications, it is common that users interact with the model multiple times within a single conversation session. Since each interaction generates a trace in the typical MLflow setup, it is useful to group these traces together to analyze the conversation as a whole. You can achieve this by attaching the session ID as a tag to each trace.","sidebar":"docsSidebar"},"tracing/tracing-schema":{"id":"tracing/tracing-schema","title":"Trace Data Structure","description":"This document provides a detailed view of the schema for traces and its ingredients. MLflow traces are compatible to OpenTelemetry specs,","sidebar":"docsSidebar"},"tracing/tutorials/concept":{"id":"tracing/tutorials/concept","title":"Tracing 101","description":"A good companion to the explanations in this guide is the Tracing Schema guide which will show how MLflow Tracing constructs the","sidebar":"docsSidebar"},"tracing/tutorials/index":{"id":"tracing/tutorials/index","title":"MLflow Tracing Tutorials","description":"Explore the comprehensive collection of tutorials, including end-to-end guides, debugging techniques, evaluation, and production monitoring best practices.","sidebar":"docsSidebar"},"tracing/ui":{"id":"tracing/ui","title":"ui","description":"","sidebar":"docsSidebar"},"tracking/artifacts-stores/index":{"id":"tracking/artifacts-stores/index","title":"Artifact Stores","description":"The artifact store is a core component in MLflow Tracking where MLflow stores (typically large) artifacts","sidebar":"docsSidebar"},"tracking/autolog/index":{"id":"tracking/autolog/index","title":"Automatic Logging with MLflow Tracking","description":"Auto logging is a powerful feature that allows you to log metrics, parameters, and models without the need for explicit log statements. All you need to do is to","sidebar":"docsSidebar"},"tracking/backend-stores/index":{"id":"tracking/backend-stores/index","title":"Backend Stores","description":"The backend store is a core component in MLflow Tracking where MLflow stores metadata for","sidebar":"docsSidebar"},"tracking/index":{"id":"tracking/index","title":"MLflow Tracking","description":"The MLflow Tracking is an API and UI for logging parameters, code versions, metrics, and output files","sidebar":"docsSidebar"},"tracking/server/index":{"id":"tracking/server/index","title":"MLflow Tracking Server","description":"MLflow tracking server is a stand-alone HTTP server that serves multiple REST API endpoints for tracking runs/experiments.","sidebar":"docsSidebar"},"tracking/tracking-api/index":{"id":"tracking/tracking-api/index","title":"MLflow Tracking APIs","description":"MLflow Tracking provides Python, R, Java, or REST API to log your experiment data and models."},"tracking/tutorials/local-database/index":{"id":"tracking/tutorials/local-database/index","title":"Tracking Experiments with a Local Database","description":"In this tutorial, you will learn how to use a local database to track your experiment metadata with MLflow. By default, MLflow Tracking logs run data to local files,","sidebar":"docsSidebar"},"tracking/tutorials/remote-server/index":{"id":"tracking/tutorials/remote-server/index","title":"Remote Experiment Tracking with MLflow Tracking Server","description":"In this tutorial, you will learn how to set up MLflow Tracking environment for team development using the MLflow Tracking Server.","sidebar":"docsSidebar"},"traditional-ml/creating-custom-pyfunc/index":{"id":"traditional-ml/creating-custom-pyfunc/index","title":"Building Custom Python Function Models with MLflow","description":"MLflow offers a wide range of pre-defined model flavors, but there are instances where you'd want to go","sidebar":"docsSidebar"},"traditional-ml/creating-custom-pyfunc/notebooks/index":{"id":"traditional-ml/creating-custom-pyfunc/notebooks/index","title":"Custom PyFuncs with MLflow - Notebooks","description":"If you would like to view the notebooks in this guide in their entirety, each notebook can viewed or downloaded directly below.","sidebar":"docsSidebar"},"traditional-ml/creating-custom-pyfunc/part1-named-flavors/index":{"id":"traditional-ml/creating-custom-pyfunc/part1-named-flavors/index","title":"Models, Flavors, and PyFuncs in MLflow","description":"In the MLflow ecosystem, \"flavors\" play a pivotal role in model management. Essentially, a \"flavor\" is a designated wrapper for specific machine","sidebar":"docsSidebar"},"traditional-ml/creating-custom-pyfunc/part2-pyfunc-components/index":{"id":"traditional-ml/creating-custom-pyfunc/part2-pyfunc-components/index","title":"Understanding PyFunc in MLflow","description":"In the realm of MLflow, while named flavors offer specific functionalities tailored to popular frameworks, there are situations and","sidebar":"docsSidebar"},"traditional-ml/hyperparameter-tuning-with-child-runs/index":{"id":"traditional-ml/hyperparameter-tuning-with-child-runs/index","title":"Hyperparameter Tuning with MLflow and Optuna","description":"In this guide, we venture into a frequent use case of MLflow Tracking: hyperparameter tuning.","sidebar":"docsSidebar"},"traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/index":{"id":"traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/index","title":"Hyperparameter tuning with MLflow and child runs - Notebooks","description":"If you would like to view the notebooks in this guide in their entirety, each notebook can be either viewed or downloaded below.","sidebar":"docsSidebar"},"traditional-ml/hyperparameter-tuning-with-child-runs/part1-child-runs/index":{"id":"traditional-ml/hyperparameter-tuning-with-child-runs/part1-child-runs/index","title":"Understanding Parent and Child Runs in MLflow","description":"Introduction","sidebar":"docsSidebar"},"traditional-ml/hyperparameter-tuning-with-child-runs/part2-logging-plots/index":{"id":"traditional-ml/hyperparameter-tuning-with-child-runs/part2-logging-plots/index","title":"Leveraging Visualizations and MLflow for In-depth Model Analysis","description":"Introduction","sidebar":"docsSidebar"},"traditional-ml/index":{"id":"traditional-ml/index","title":"Traditional ML","description":"In the dynamic landscape of machine learning, traditional techniques remain foundational, playing pivotal roles across various industries","sidebar":"docsSidebar"},"traditional-ml/serving-multiple-models-with-pyfunc/index":{"id":"traditional-ml/serving-multiple-models-with-pyfunc/index","title":"Serving Multiple Models on a Single Endpoint with a Custom PyFunc Model","description":"This tutorial addresses a common scenario in machine learning: serving multiple models through a","sidebar":"docsSidebar"},"tutorials-and-examples/index":{"id":"tutorials-and-examples/index","title":"Tutorials and Examples","description":"Below, you can find a number of tutorials and examples for various MLflow use cases."}}}}
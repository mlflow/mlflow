{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/","tagsPath":"/tags","isLast":true,"routePriority":-1,"sidebarFilePath":"/Users/serena.ruan/Documents/repos/mlflow/docs/sidebars.ts","contentPath":"/Users/serena.ruan/Documents/repos/mlflow/docs/docs","contentPathLocalized":"/Users/serena.ruan/Documents/repos/mlflow/docs/i18n/en/docusaurus-plugin-content-docs/current","docs":[{"id":"auth/index","title":"MLflow Authentication","description":"This feature is still experimental and may change in a future release without warning.","source":"@site/docs/auth/index.mdx","sourceDirName":"auth","slug":"/auth/","permalink":"/auth/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":18,"frontMatter":{"sidebar_position":18},"sidebar":"docsSidebar","previous":{"title":"MLflow AI Gateway","permalink":"/llms/deployments/"},"next":{"title":"MLflow Projects","permalink":"/projects/"}},{"id":"community-model-flavors/index","title":"Community Model Flavors","description":"Other useful MLflow flavors are developed and maintained by the","source":"@site/docs/community-model-flavors/index.mdx","sourceDirName":"community-model-flavors","slug":"/community-model-flavors/","permalink":"/community-model-flavors/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":27,"frontMatter":{"sidebar_position":27}},{"id":"dataset/index","title":"MLflow Dataset Tracking Tutorial","description":"The mlflow.data module is an integral part of the MLflow ecosystem, designed to enhance your machine learning workflow.","source":"@site/docs/dataset/index.mdx","sourceDirName":"dataset","slug":"/dataset/","permalink":"/dataset/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"sidebar_label":"MLflow Dataset"},"sidebar":"docsSidebar","previous":{"title":"ui","permalink":"/tracing/ui"},"next":{"title":"MLflow Model Registry","permalink":"/model-registry/"}},{"id":"deep-learning/index","title":"Deep Learning","description":"The realm of deep learning has witnessed an unprecedented surge, revolutionizing numerous sectors with its ability to","source":"@site/docs/deep-learning/index.mdx","sourceDirName":"deep-learning","slug":"/deep-learning/","permalink":"/deep-learning/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_position":0,"sidebar_label":"Overview"},"sidebar":"docsSidebar","previous":{"title":"Prompt Engineering","permalink":"/llms/prompt-engineering/"},"next":{"title":"Overview","permalink":"/deep-learning/"}},{"id":"deep-learning/keras/index","title":"MLflow Keras 3.0 Integration","description":"Introduction","source":"@site/docs/deep-learning/keras/index.mdx","sourceDirName":"deep-learning/keras","slug":"/deep-learning/keras/","permalink":"/deep-learning/keras/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"sidebar_label":"Keras"},"sidebar":"docsSidebar","previous":{"title":"PyTorch within MLflow","permalink":"/deep-learning/pytorch/guide/"},"next":{"title":"Tensorflow","permalink":"/deep-learning/tensorflow/"}},{"id":"deep-learning/pytorch/guide/index","title":"PyTorch within MLflow","description":"In this guide we will walk you through how to use PyTorch within MLflow. We will demonstrate","source":"@site/docs/deep-learning/pytorch/guide/index.mdx","sourceDirName":"deep-learning/pytorch/guide","slug":"/deep-learning/pytorch/guide/","permalink":"/deep-learning/pytorch/guide/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Pytorch","permalink":"/deep-learning/pytorch/"},"next":{"title":"Keras","permalink":"/deep-learning/keras/"}},{"id":"deep-learning/pytorch/index","title":"MLflow PyTorch Flavor","description":"Introduction","source":"@site/docs/deep-learning/pytorch/index.mdx","sourceDirName":"deep-learning/pytorch","slug":"/deep-learning/pytorch/","permalink":"/deep-learning/pytorch/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"sidebar_label":"Pytorch"},"sidebar":"docsSidebar","previous":{"title":"Overview","permalink":"/deep-learning/"},"next":{"title":"PyTorch within MLflow","permalink":"/deep-learning/pytorch/guide/"}},{"id":"deep-learning/tensorflow/guide/index","title":"Tensorflow within MLflow","description":"In this guide we will walk you through how to use Tensorflow within MLflow. We will demonstrate","source":"@site/docs/deep-learning/tensorflow/guide/index.mdx","sourceDirName":"deep-learning/tensorflow/guide","slug":"/deep-learning/tensorflow/guide/","permalink":"/deep-learning/tensorflow/guide/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Tensorflow","permalink":"/deep-learning/tensorflow/"},"next":{"title":"Overview","permalink":"/traditional-ml/"}},{"id":"deep-learning/tensorflow/index","title":"MLflow Tensorflow Integration","description":"Introduction","source":"@site/docs/deep-learning/tensorflow/index.mdx","sourceDirName":"deep-learning/tensorflow","slug":"/deep-learning/tensorflow/","permalink":"/deep-learning/tensorflow/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"sidebar_label":"Tensorflow"},"sidebar":"docsSidebar","previous":{"title":"Keras","permalink":"/deep-learning/keras/"},"next":{"title":"Tensorflow within MLflow","permalink":"/deep-learning/tensorflow/guide/"}},{"id":"deployment/deploy-model-locally/index","title":"Deploy MLflow Model as a Local Inference Server","description":"MLflow allows you to deploy your model locally using just a single command.","source":"@site/docs/deployment/deploy-model-locally/index.mdx","sourceDirName":"deployment/deploy-model-locally","slug":"/deployment/deploy-model-locally/","permalink":"/deployment/deploy-model-locally/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"docsSidebar","previous":{"title":"Overview","permalink":"/deployment/"},"next":{"title":"Deploy MLflow Model to Amazon SageMaker","permalink":"/deployment/deploy-model-to-sagemaker/"}},{"id":"deployment/deploy-model-to-kubernetes/index","title":"Deploy MLflow Model to Kubernetes","description":"Using MLServer as the Inference Server","source":"@site/docs/deployment/deploy-model-to-kubernetes/index.mdx","sourceDirName":"deployment/deploy-model-to-kubernetes","slug":"/deployment/deploy-model-to-kubernetes/","permalink":"/deployment/deploy-model-to-kubernetes/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"docsSidebar","previous":{"title":"Deploy MLflow Model to Amazon SageMaker","permalink":"/deployment/deploy-model-to-sagemaker/"},"next":{"title":"Develop ML model with MLflow and deploy to Kubernetes","permalink":"/deployment/deploy-model-to-kubernetes/tutorial/"}},{"id":"deployment/deploy-model-to-kubernetes/tutorial/index","title":"Develop ML model with MLflow and deploy to Kubernetes","description":"This tutorial assumes that you have access to a Kubernetes cluster. However, you can also complete this tutorial on your local machine","source":"@site/docs/deployment/deploy-model-to-kubernetes/tutorial/index.mdx","sourceDirName":"deployment/deploy-model-to-kubernetes/tutorial","slug":"/deployment/deploy-model-to-kubernetes/tutorial/","permalink":"/deployment/deploy-model-to-kubernetes/tutorial/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Deploy MLflow Model to Kubernetes","permalink":"/deployment/deploy-model-to-kubernetes/"},"next":{"title":"MLflow AI Gateway","permalink":"/llms/deployments/"}},{"id":"deployment/deploy-model-to-sagemaker/index","title":"Deploy MLflow Model to Amazon SageMaker","description":"Amazon SageMaker is a fully managed service designed for scaling ML inference containers.","source":"@site/docs/deployment/deploy-model-to-sagemaker/index.mdx","sourceDirName":"deployment/deploy-model-to-sagemaker","slug":"/deployment/deploy-model-to-sagemaker/","permalink":"/deployment/deploy-model-to-sagemaker/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Deploy MLflow Model as a Local Inference Server","permalink":"/deployment/deploy-model-locally/"},"next":{"title":"Deploy MLflow Model to Kubernetes","permalink":"/deployment/deploy-model-to-kubernetes/"}},{"id":"deployment/index","title":"MLflow Serving","description":"This page describes the toolset for deploying your in-house MLflow Model.For information on the","source":"@site/docs/deployment/index.mdx","sourceDirName":"deployment","slug":"/deployment/","permalink":"/deployment/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_position":0,"sidebar_label":"Overview"},"sidebar":"docsSidebar","previous":{"title":"MLflow Model Registry","permalink":"/model-registry/"},"next":{"title":"Deploy MLflow Model as a Local Inference Server","permalink":"/deployment/deploy-model-locally/"}},{"id":"docker/index","title":"Official MLflow Docker image","description":"The official MLflow Docker image is available on GitHub Container Registry at https://ghcr.io/mlflow/mlflow.","source":"@site/docs/docker/index.mdx","sourceDirName":"docker","slug":"/docker/","permalink":"/docker/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":26,"frontMatter":{"sidebar_position":26}},{"id":"getting-started/community-edition/index","title":"Databricks Community Edition","description":"The Databricks Community Edition (CE) is a fully managed, Databricks-hosted version of the Databricks platform. While many of the enterprise features of the","source":"@site/docs/getting-started/community-edition/index.mdx","sourceDirName":"getting-started/community-edition","slug":"/getting-started/community-edition/","permalink":"/getting-started/community-edition/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"How to Run Tutorials","permalink":"/getting-started/running-notebooks/"},"next":{"title":"Hyperparameter Tuning Tutorial","permalink":"/getting-started/quickstart-2/"}},{"id":"getting-started/index","title":"Getting Started with MLflow","description":"For those new to MLflow or seeking a refresher on its core functionalities, the","source":"@site/docs/getting-started/index.mdx","sourceDirName":"getting-started","slug":"/getting-started/","permalink":"/getting-started/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"docsSidebar","previous":{"title":"MLflow","permalink":"/"},"next":{"title":"Quickstart","permalink":"/getting-started/intro-quickstart/"}},{"id":"getting-started/intro-quickstart/index","title":"MLflow Tracking Quickstart","description":"Welcome to MLflow!","source":"@site/docs/getting-started/intro-quickstart/index.mdx","sourceDirName":"getting-started/intro-quickstart","slug":"/getting-started/intro-quickstart/","permalink":"/getting-started/intro-quickstart/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Getting Started with MLflow","permalink":"/getting-started/"},"next":{"title":"How to Run Tutorials","permalink":"/getting-started/running-notebooks/"}},{"id":"getting-started/intro-quickstart/notebooks/index","title":"MLflow Tracking Quickstart Notebook","description":"Welcome to the MLflow Tracking Quickstart! The notebook-based companion to the quickstart guide is tailored to help you quickly","source":"@site/docs/getting-started/intro-quickstart/notebooks/index.mdx","sourceDirName":"getting-started/intro-quickstart/notebooks","slug":"/getting-started/intro-quickstart/notebooks/","permalink":"/getting-started/intro-quickstart/notebooks/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"getting-started/logging-first-model/index","title":"Tutorial Overview","description":"In this entry point tutorial to MLflow, we'll be covering the essential basics of core MLflow functionality associated","source":"@site/docs/getting-started/logging-first-model/index.mdx","sourceDirName":"getting-started/logging-first-model","slug":"/getting-started/logging-first-model/","permalink":"/getting-started/logging-first-model/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"sidebar-position":3}},{"id":"getting-started/logging-first-model/notebooks/index","title":"Logging Your First MLflow Model Notebook","description":"If you would like to view the full notebook:","source":"@site/docs/getting-started/logging-first-model/notebooks/index.mdx","sourceDirName":"getting-started/logging-first-model/notebooks","slug":"/getting-started/logging-first-model/notebooks/","permalink":"/getting-started/logging-first-model/notebooks/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7}},{"id":"getting-started/logging-first-model/step1-tracking-server/index","title":"Starting the MLflow Tracking Server","description":"Before diving into MLflow's rich features, let's set up the foundational components: the MLflow","source":"@site/docs/getting-started/logging-first-model/step1-tracking-server/index.mdx","sourceDirName":"getting-started/logging-first-model/step1-tracking-server","slug":"/getting-started/logging-first-model/step1-tracking-server/","permalink":"/getting-started/logging-first-model/step1-tracking-server/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1}},{"id":"getting-started/logging-first-model/step2-mlflow-client/index","title":"Using the MLflow Client API","description":"In the previous section, we started an instance of the MLflow Tracking Server and the MLflow UI.","source":"@site/docs/getting-started/logging-first-model/step2-mlflow-client/index.mdx","sourceDirName":"getting-started/logging-first-model/step2-mlflow-client","slug":"/getting-started/logging-first-model/step2-mlflow-client/","permalink":"/getting-started/logging-first-model/step2-mlflow-client/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2}},{"id":"getting-started/logging-first-model/step3-create-experiment/index","title":"Creating Experiments","description":"In the previous section, we became familiar with the MLflow Client and its search_experiments API.","source":"@site/docs/getting-started/logging-first-model/step3-create-experiment/index.mdx","sourceDirName":"getting-started/logging-first-model/step3-create-experiment","slug":"/getting-started/logging-first-model/step3-create-experiment/","permalink":"/getting-started/logging-first-model/step3-create-experiment/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3}},{"id":"getting-started/logging-first-model/step4-experiment-search/index","title":"Searching Experiments","description":"In the last section, we created our first MLflow Experiment, providing custom tags so that we can find","source":"@site/docs/getting-started/logging-first-model/step4-experiment-search/index.mdx","sourceDirName":"getting-started/logging-first-model/step4-experiment-search","slug":"/getting-started/logging-first-model/step4-experiment-search/","permalink":"/getting-started/logging-first-model/step4-experiment-search/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4}},{"id":"getting-started/logging-first-model/step5-synthetic-data/index","title":"Create a dataset about apples","description":"In order to produce some meaningful data (and a model) for us to log to MLflow, we'll need a dataset.","source":"@site/docs/getting-started/logging-first-model/step5-synthetic-data/index.mdx","sourceDirName":"getting-started/logging-first-model/step5-synthetic-data","slug":"/getting-started/logging-first-model/step5-synthetic-data/","permalink":"/getting-started/logging-first-model/step5-synthetic-data/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5}},{"id":"getting-started/logging-first-model/step6-logging-a-run/index","title":"Logging our first runs with MLflow","description":"In our previous segments, we worked through setting up our first MLflow Experiment and equipped it","source":"@site/docs/getting-started/logging-first-model/step6-logging-a-run/index.mdx","sourceDirName":"getting-started/logging-first-model/step6-logging-a-run","slug":"/getting-started/logging-first-model/step6-logging-a-run/","permalink":"/getting-started/logging-first-model/step6-logging-a-run/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6}},{"id":"getting-started/quickstart-2/index","title":"Quickstart: Compare runs, choose a model, and deploy it to a REST API","description":"In this quickstart, you will:","source":"@site/docs/getting-started/quickstart-2/index.mdx","sourceDirName":"getting-started/quickstart-2","slug":"/getting-started/quickstart-2/","permalink":"/getting-started/quickstart-2/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Databricks Community Edition","permalink":"/getting-started/community-edition/"},"next":{"title":"Tutorial Overview","permalink":"/getting-started/registering-first-model/"}},{"id":"getting-started/registering-first-model/index","title":"Tutorial Overview","description":"The MLflow Model Registry has several core components:","source":"@site/docs/getting-started/registering-first-model/index.mdx","sourceDirName":"getting-started/registering-first-model","slug":"/getting-started/registering-first-model/","permalink":"/getting-started/registering-first-model/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Hyperparameter Tuning Tutorial","permalink":"/getting-started/quickstart-2/"},"next":{"title":"Register a Model","permalink":"/getting-started/registering-first-model/step1-register-model/"}},{"id":"getting-started/registering-first-model/step1-register-model/index","title":"Register a Model","description":"Throughout this tutorial we will leverage a local tracking server and model registry for simplicity.","source":"@site/docs/getting-started/registering-first-model/step1-register-model/index.mdx","sourceDirName":"getting-started/registering-first-model/step1-register-model","slug":"/getting-started/registering-first-model/step1-register-model/","permalink":"/getting-started/registering-first-model/step1-register-model/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Tutorial Overview","permalink":"/getting-started/registering-first-model/"},"next":{"title":"Explore the Registered Model","permalink":"/getting-started/registering-first-model/step2-explore-registered-model/"}},{"id":"getting-started/registering-first-model/step2-explore-registered-model/index","title":"Explore the Registered Model","description":"Now that we've logged an experiment and registered the model associated with that experiment run,","source":"@site/docs/getting-started/registering-first-model/step2-explore-registered-model/index.mdx","sourceDirName":"getting-started/registering-first-model/step2-explore-registered-model","slug":"/getting-started/registering-first-model/step2-explore-registered-model/","permalink":"/getting-started/registering-first-model/step2-explore-registered-model/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Register a Model","permalink":"/getting-started/registering-first-model/step1-register-model/"},"next":{"title":"Load a Registered Model","permalink":"/getting-started/registering-first-model/step3-load-model/"}},{"id":"getting-started/registering-first-model/step3-load-model/index","title":"Load a Registered Model","description":"To perform inference on a registered model version, we need to load it into memory. There are many","source":"@site/docs/getting-started/registering-first-model/step3-load-model/index.mdx","sourceDirName":"getting-started/registering-first-model/step3-load-model","slug":"/getting-started/registering-first-model/step3-load-model/","permalink":"/getting-started/registering-first-model/step3-load-model/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Explore the Registered Model","permalink":"/getting-started/registering-first-model/step2-explore-registered-model/"},"next":{"title":"5 Minute Tracking Server Overview","permalink":"/getting-started/tracking-server-overview/"}},{"id":"getting-started/running-notebooks/index","title":"How to Run Tutorials","description":"This brief guide will walk you through some options that you have to run these tutorials and have a Tracking Server that is available to log the results to (as well","source":"@site/docs/getting-started/running-notebooks/index.mdx","sourceDirName":"getting-started/running-notebooks","slug":"/getting-started/running-notebooks/","permalink":"/getting-started/running-notebooks/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"docsSidebar","previous":{"title":"Quickstart","permalink":"/getting-started/intro-quickstart/"},"next":{"title":"Databricks Community Edition","permalink":"/getting-started/community-edition/"}},{"id":"getting-started/tracking-server-overview/index","title":"5 Minute Tracking Server Overview","description":"In this guide we will walk you through how to view your MLflow experiment results with different types of","source":"@site/docs/getting-started/tracking-server-overview/index.mdx","sourceDirName":"getting-started/tracking-server-overview","slug":"/getting-started/tracking-server-overview/","permalink":"/getting-started/tracking-server-overview/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Load a Registered Model","permalink":"/getting-started/registering-first-model/step3-load-model/"},"next":{"title":"LLM / GenAI","permalink":"/llms/"}},{"id":"index","title":"MLflow: A Tool for Managing the Machine Learning Lifecycle","description":"MLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in","source":"@site/docs/index.mdx","sourceDirName":".","slug":"/","permalink":"/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_label":"MLflow","sidebar_position":1},"sidebar":"docsSidebar","next":{"title":"Getting Started with MLflow","permalink":"/getting-started/"}},{"id":"introduction/index","title":"MLflow Overview","description":"Stepping into the world of Machine Learning (ML) is an exciting journey, but it often comes with","source":"@site/docs/introduction/index.mdx","sourceDirName":"introduction","slug":"/introduction/","permalink":"/introduction/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2}},{"id":"llms/chat-model-guide/index","title":"Tutorial: Custom GenAI Models using ChatModel","description":"The rapidly evolving landscape of Generative Artificial Intelligence (GenAI) presents exciting opportunities and integration challenges.","source":"@site/docs/llms/chat-model-guide/index.mdx","sourceDirName":"llms/chat-model-guide","slug":"/llms/chat-model-guide/","permalink":"/llms/chat-model-guide/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"What is ChatModel?","permalink":"/llms/chat-model-intro/"},"next":{"title":"More Customization","permalink":"/llms/custom-pyfunc-for-llms/"}},{"id":"llms/chat-model-intro/index","title":"Tutorial: Getting Started with ChatModel","description":"MLflow's ChatModel class provides a standardized way to create production-ready conversational AI models.","source":"@site/docs/llms/chat-model-intro/index.mdx","sourceDirName":"llms/chat-model-intro","slug":"/llms/chat-model-intro/","permalink":"/llms/chat-model-intro/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Detailed Guides","permalink":"/llms/sentence-transformers/guide/"},"next":{"title":"Advanced Guide","permalink":"/llms/chat-model-guide/"}},{"id":"llms/custom-pyfunc-for-llms/index","title":"Deploying Advanced LLMs with Custom PyFuncs in MLflow","description":"Advanced Large Language Models (LLMs) such as the MPT-7B instruct transformer are intricate and have requirements that don't align with","source":"@site/docs/llms/custom-pyfunc-for-llms/index.mdx","sourceDirName":"llms/custom-pyfunc-for-llms","slug":"/llms/custom-pyfunc-for-llms/","permalink":"/llms/custom-pyfunc-for-llms/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Advanced Guide","permalink":"/llms/chat-model-guide/"},"next":{"title":"What is RAG?","permalink":"/llms/rag/"}},{"id":"llms/custom-pyfunc-for-llms/notebooks/index","title":"Custom PyFuncs for Advanced LLMs with MLflow - Notebooks","description":"If you'd like to delve deeper into the notebooks in this guide, they can be viewed or downloaded directly below.","source":"@site/docs/llms/custom-pyfunc-for-llms/notebooks/index.mdx","sourceDirName":"llms/custom-pyfunc-for-llms/notebooks","slug":"/llms/custom-pyfunc-for-llms/notebooks/","permalink":"/llms/custom-pyfunc-for-llms/notebooks/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"llms/deployments/guides/index","title":"Getting Started with MLflow Deployments for LLMs","description":"MLflow provides a robust framework for deploying and managing machine learning models. In this tutorial, we will explore how to set up an","source":"@site/docs/llms/deployments/guides/index.mdx","sourceDirName":"llms/deployments/guides","slug":"/llms/deployments/guides/","permalink":"/llms/deployments/guides/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"llms/deployments/guides/step1-create-deployments/index","title":"Configuring and Starting the gateway server","description":"Step 1: Install","source":"@site/docs/llms/deployments/guides/step1-create-deployments/index.mdx","sourceDirName":"llms/deployments/guides/step1-create-deployments","slug":"/llms/deployments/guides/step1-create-deployments/","permalink":"/llms/deployments/guides/step1-create-deployments/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"llms/deployments/guides/step2-query-deployments/index","title":"Querying endpoints in the MLflow Deployment Server","description":"Now that the deployment server is operational, it's time to send it some data. You can interact with the","source":"@site/docs/llms/deployments/guides/step2-query-deployments/index.mdx","sourceDirName":"llms/deployments/guides/step2-query-deployments","slug":"/llms/deployments/guides/step2-query-deployments/","permalink":"/llms/deployments/guides/step2-query-deployments/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"llms/deployments/index","title":"MLflow AI Gateway (Experimental)","description":"MLflow AI Gateway does not support Windows.","source":"@site/docs/llms/deployments/index.mdx","sourceDirName":"llms/deployments","slug":"/llms/deployments/","permalink":"/llms/deployments/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Develop ML model with MLflow and deploy to Kubernetes","permalink":"/deployment/deploy-model-to-kubernetes/tutorial/"},"next":{"title":"Access Control","permalink":"/auth/"}},{"id":"llms/deployments/uc_integration/index","title":"Unity Catalog Integration","description":"This example illustrates the use of the Unity Catalog (UC) integration with the MLflow AI Gateway.","source":"@site/docs/llms/deployments/uc_integration/index.mdx","sourceDirName":"llms/deployments/uc_integration","slug":"/llms/deployments/uc_integration/","permalink":"/llms/deployments/uc_integration/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"llms/dspy/index","title":"MLflow DSPy Flavor","description":"The dspy flavor is under active development and is marked as Experimental. Public APIs are","source":"@site/docs/llms/dspy/index.mdx","sourceDirName":"llms/dspy","slug":"/llms/dspy/","permalink":"/llms/dspy/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"MLflow LangChain Flavor","permalink":"/llms/langchain/"},"next":{"title":"LlamaIndex","permalink":"/llms/llama-index/"}},{"id":"llms/index","title":"LLM / GenAI","description":"LLMs (Large Language Models) have become essential in machine learning, enabling tasks like natural language understanding and code generation. However, fully leveraging their potential often involves complex processes of managing many moving pieces such as prompts, LLM providers, frameworks, knowledge base, tools, and more.","source":"@site/docs/llms/index.mdx","sourceDirName":"llms","slug":"/llms/","permalink":"/llms/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"docsSidebar","previous":{"title":"5 Minute Tracking Server Overview","permalink":"/getting-started/tracking-server-overview/"},"next":{"title":"Overview","permalink":"/llms/"}},{"id":"llms/langchain/autologging","title":"MLflow Langchain Autologging","description":"MLflow LangChain flavor supports autologging, a powerful feature that allows you to log crucial details about the LangChain model and execution without the need for explicit logging statements. MLflow LangChain autologging covers various aspects of the model, including traces, models, signatures and more.","source":"@site/docs/llms/langchain/autologging.mdx","sourceDirName":"llms/langchain","slug":"/llms/langchain/autologging","permalink":"/llms/langchain/autologging","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"MLflow LangChain Flavor","permalink":"/llms/langchain/"},"next":{"title":"LangChain within MLflow (Experimental)","permalink":"/llms/langchain/guide/"}},{"id":"llms/langchain/guide/index","title":"LangChain within MLflow (Experimental)","description":"The langchain flavor is currently under active development and is marked as Experimental. Public APIs are evolving, and new features are being added to enhance its functionality.","source":"@site/docs/llms/langchain/guide/index.mdx","sourceDirName":"llms/langchain/guide","slug":"/llms/langchain/guide/","permalink":"/llms/langchain/guide/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"MLflow Langchain Autologging","permalink":"/llms/langchain/autologging"},"next":{"title":"MLflow LangChain Flavor","permalink":"/llms/langchain/"}},{"id":"llms/langchain/index","title":"MLflow LangChain Flavor","description":"The langchain flavor is under active development and is marked as Experimental. Public APIs are","source":"@site/docs/llms/langchain/index.mdx","sourceDirName":"llms/langchain","slug":"/llms/langchain/","permalink":"/llms/langchain/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Detailed Guide","permalink":"/llms/openai/guide/"},"next":{"title":"MLflow Langchain Autologging","permalink":"/llms/langchain/autologging"}},{"id":"llms/llama-index/index","title":"MLflow LlamaIndex Flavor","description":"The llama_index flavor is under active development and is marked as Experimental. Public APIs are","source":"@site/docs/llms/llama-index/index.mdx","sourceDirName":"llms/llama-index","slug":"/llms/llama-index/","permalink":"/llms/llama-index/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"DSPy","permalink":"/llms/dspy/"},"next":{"title":"Overview","permalink":"/llms/transformers/"}},{"id":"llms/llm-evaluate/index","title":"MLflow LLM Evaluation","description":"LLM evaluation involves assessing how well a model performs on a task. MLflow provides a simple API to evaluate your LLMs with popular metrics.","source":"@site/docs/llms/llm-evaluate/index.mdx","sourceDirName":"llms/llm-evaluate","slug":"/llms/llm-evaluate/","permalink":"/llms/llm-evaluate/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"description":"LLM evaluation involves assessing how well a model performs on a task. MLflow provides a simple API to evaluate your LLMs with popular metrics."}},{"id":"llms/llm-evaluate/notebooks/index","title":"LLM Evaluation Examples","description":"The notebooks listed below contain step-by-step tutorials on how to use MLflow to evaluate LLMs.","source":"@site/docs/llms/llm-evaluate/notebooks/index.mdx","sourceDirName":"llms/llm-evaluate/notebooks","slug":"/llms/llm-evaluate/notebooks/","permalink":"/llms/llm-evaluate/notebooks/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"llms/llm-tracking/index","title":"MLflow's LLM Tracking Capabilities","description":"MLflow's LLM Tracking system is an enhancement to the existing MLflow Tracking system, offerring additional capabilities for monitoring,","source":"@site/docs/llms/llm-tracking/index.mdx","sourceDirName":"llms/llm-tracking","slug":"/llms/llm-tracking/","permalink":"/llms/llm-tracking/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"llms/openai/autologging/index","title":"MLflow OpenAI Autologging","description":"The OpenAI flavor for MLflow supports autologging to ensure that experimentation, testing, and validation of your ideas can be captured dynamically without","source":"@site/docs/llms/openai/autologging/index.mdx","sourceDirName":"llms/openai/autologging","slug":"/llms/openai/autologging/","permalink":"/llms/openai/autologging/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_label":"Autologging","sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Tutorials","permalink":"/llms/openai/notebooks/"},"next":{"title":"Detailed Guide","permalink":"/llms/openai/guide/"}},{"id":"llms/openai/guide/index","title":"OpenAI within MLflow","description":"The openai flavor is under active development and is marked as Experimental. Public APIs may change and new features are","source":"@site/docs/llms/openai/guide/index.mdx","sourceDirName":"llms/openai/guide","slug":"/llms/openai/guide/","permalink":"/llms/openai/guide/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_label":"Detailed Guide","sidebar_position":3},"sidebar":"docsSidebar","previous":{"title":"Autologging","permalink":"/llms/openai/autologging/"},"next":{"title":"MLflow LangChain Flavor","permalink":"/llms/langchain/"}},{"id":"llms/openai/index","title":"MLflow OpenAI Flavor","description":"The openai flavor is under active development and is marked as Experimental. Public APIs are","source":"@site/docs/llms/openai/index.mdx","sourceDirName":"llms/openai","slug":"/llms/openai/","permalink":"/llms/openai/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_position":0},"sidebar":"docsSidebar","previous":{"title":"Overview","permalink":"/llms/"},"next":{"title":"MLflow OpenAI Flavor","permalink":"/llms/openai/"}},{"id":"llms/openai/notebooks/index","title":"MLflow OpenAI Flavor - Tutorials and Guides","description":"Below, you will find a number of guides that focus on different ways that you can leverage the power of the openai library, leveraging MLflow's","source":"@site/docs/llms/openai/notebooks/index.mdx","sourceDirName":"llms/openai/notebooks","slug":"/llms/openai/notebooks/","permalink":"/llms/openai/notebooks/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_label":"Tutorials","sidebar_position":1},"sidebar":"docsSidebar","previous":{"title":"MLflow OpenAI Flavor","permalink":"/llms/openai/"},"next":{"title":"Autologging","permalink":"/llms/openai/autologging/"}},{"id":"llms/prompt-engineering/index","title":"Prompt Engineering UI (Experimental)","description":"Starting in MLflow 2.7, the MLflow Tracking UI provides a best-in-class experience for prompt","source":"@site/docs/llms/prompt-engineering/index.mdx","sourceDirName":"llms/prompt-engineering","slug":"/llms/prompt-engineering/","permalink":"/llms/prompt-engineering/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Explore RAG Tutorials","permalink":"/llms/rag/notebooks/"},"next":{"title":"Overview","permalink":"/deep-learning/"}},{"id":"llms/rag/index","title":"Retrieval Augmented Generation (RAG)","description":"Retrieval Augmented Generation (RAG) is a powerful and efficient approach to natural","source":"@site/docs/llms/rag/index.mdx","sourceDirName":"llms/rag","slug":"/llms/rag/","permalink":"/llms/rag/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"More Customization","permalink":"/llms/custom-pyfunc-for-llms/"},"next":{"title":"Explore RAG Tutorials","permalink":"/llms/rag/notebooks/"}},{"id":"llms/rag/notebooks/index","title":"RAG Tutorials","description":"You can find a list of tutorials for RAG below. These tutorials are designed to help you","source":"@site/docs/llms/rag/notebooks/index.mdx","sourceDirName":"llms/rag/notebooks","slug":"/llms/rag/notebooks/","permalink":"/llms/rag/notebooks/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"sidebar_label":"Explore RAG Tutorials"},"sidebar":"docsSidebar","previous":{"title":"What is RAG?","permalink":"/llms/rag/"},"next":{"title":"Prompt Engineering","permalink":"/llms/prompt-engineering/"}},{"id":"llms/sentence-transformers/guide/index","title":"Sentence Transformers within MLflow","description":"The sentence_transformers flavor is in active development and is marked as Experimental. Public APIs may change and new features are","source":"@site/docs/llms/sentence-transformers/guide/index.mdx","sourceDirName":"llms/sentence-transformers/guide","slug":"/llms/sentence-transformers/guide/","permalink":"/llms/sentence-transformers/guide/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"sidebar_label":"Detailed Guides"},"sidebar":"docsSidebar","previous":{"title":"Tutorials","permalink":"/llms/sentence-transformers/tutorials/"},"next":{"title":"What is ChatModel?","permalink":"/llms/chat-model-intro/"}},{"id":"llms/sentence-transformers/index","title":"MLflow Sentence-Transformers Flavor","description":"The sentence-transformers flavor is under active development and is marked as Experimental. Public APIs are subject to change,","source":"@site/docs/llms/sentence-transformers/index.mdx","sourceDirName":"llms/sentence-transformers","slug":"/llms/sentence-transformers/","permalink":"/llms/sentence-transformers/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_position":0,"sidebar_label":"Overview"},"sidebar":"docsSidebar","previous":{"title":"Storage Optimization","permalink":"/llms/transformers/large-models/"},"next":{"title":"Overview","permalink":"/llms/sentence-transformers/"}},{"id":"llms/sentence-transformers/tutorials/index","title":"MLflow Sentence Transformers Flavor - Tutorials and Guides","description":"Below, you will find a number of guides that focus on different ways that you can leverage the power of the sentence-transformers library, leveraging MLflow's","source":"@site/docs/llms/sentence-transformers/tutorials/index.mdx","sourceDirName":"llms/sentence-transformers/tutorials","slug":"/llms/sentence-transformers/tutorials/","permalink":"/llms/sentence-transformers/tutorials/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"sidebar_label":"Tutorials"},"sidebar":"docsSidebar","previous":{"title":"Overview","permalink":"/llms/sentence-transformers/"},"next":{"title":"Detailed Guides","permalink":"/llms/sentence-transformers/guide/"}},{"id":"llms/transformers/guide/index","title":"ðŸ¤— Transformers within MLflow","description":"The transformers flavor is in active development and is marked as Experimental. Public APIs may change and new features are","source":"@site/docs/llms/transformers/guide/index.mdx","sourceDirName":"llms/transformers/guide","slug":"/llms/transformers/guide/","permalink":"/llms/transformers/guide/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_label":"Detailed Guide","sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Tutorials","permalink":"/llms/transformers/tutorials/"},"next":{"title":"Task","permalink":"/llms/transformers/task/"}},{"id":"llms/transformers/index","title":"MLflow Transformers Flavor","description":"The transformers flavor is in active development and is marked as Experimental. Public APIs may change and new features are","source":"@site/docs/llms/transformers/index.mdx","sourceDirName":"llms/transformers","slug":"/llms/transformers/","permalink":"/llms/transformers/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_position":0,"sidebar_label":"Overview"},"sidebar":"docsSidebar","previous":{"title":"LlamaIndex","permalink":"/llms/llama-index/"},"next":{"title":"Overview","permalink":"/llms/transformers/"}},{"id":"llms/transformers/large-models/index","title":"Working with Large Models in MLflow Transformers flavor","description":"The features described in this guide are intended for advanced users familiar with Transformers and MLflow. Please understand the limitations and potential risks associated with these features before use.","source":"@site/docs/llms/transformers/large-models/index.mdx","sourceDirName":"llms/transformers/large-models","slug":"/llms/transformers/large-models/","permalink":"/llms/transformers/large-models/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"sidebar_label":"Storage Optimization"},"sidebar":"docsSidebar","previous":{"title":"Task","permalink":"/llms/transformers/task/"},"next":{"title":"Overview","permalink":"/llms/sentence-transformers/"}},{"id":"llms/transformers/task/index","title":"Tasks in MLflow Transformers Flavor","description":"This page provides an overview of how to use the task parameter in the MLflow Transformers flavor to control","source":"@site/docs/llms/transformers/task/index.mdx","sourceDirName":"llms/transformers/task","slug":"/llms/transformers/task/","permalink":"/llms/transformers/task/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"sidebar_label":"Task"},"sidebar":"docsSidebar","previous":{"title":"Detailed Guide","permalink":"/llms/transformers/guide/"},"next":{"title":"Storage Optimization","permalink":"/llms/transformers/large-models/"}},{"id":"llms/transformers/tutorials/index","title":"MLflow Transformers Flavor - Tutorials and Guides","description":"Below, you will find a number of guides that focus on different use cases using transformers that leverage MLflow's","source":"@site/docs/llms/transformers/tutorials/index.mdx","sourceDirName":"llms/transformers/tutorials","slug":"/llms/transformers/tutorials/","permalink":"/llms/transformers/tutorials/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"sidebar_label":"Tutorials"},"sidebar":"docsSidebar","previous":{"title":"Overview","permalink":"/llms/transformers/"},"next":{"title":"Detailed Guide","permalink":"/llms/transformers/guide/"}},{"id":"model-evaluation/index","title":"Model Evaluation","description":"Harnessing the Power of Automation","source":"@site/docs/model-evaluation/index.mdx","sourceDirName":"model-evaluation","slug":"/model-evaluation/","permalink":"/model-evaluation/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7},"sidebar":"docsSidebar","previous":{"title":"MLflow Recipes","permalink":"/recipes/"},"next":{"title":"Overview","permalink":"/tracing/"}},{"id":"model-registry/index","title":"MLflow Model Registry","description":"The MLflow Model Registry component is a centralized model store, set of APIs, and UI, to","source":"@site/docs/model-registry/index.mdx","sourceDirName":"model-registry","slug":"/model-registry/","permalink":"/model-registry/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":15,"frontMatter":{"sidebar_position":15,"toc_max_heading_level":4},"sidebar":"docsSidebar","previous":{"title":"MLflow Dataset","permalink":"/dataset/"},"next":{"title":"Overview","permalink":"/deployment/"}},{"id":"model/dependencies/index","title":"Managing Dependencies in MLflow Models","description":"MLflow Model is a standard format that packages a machine learning model with its dependencies and other metadata.","source":"@site/docs/model/dependencies/index.mdx","sourceDirName":"model/dependencies","slug":"/model/dependencies/","permalink":"/model/dependencies/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_label":"Dependency Management","sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Model Signature","permalink":"/model/signatures/"},"next":{"title":"Models From Code","permalink":"/model/models-from-code/"}},{"id":"model/index","title":"MLflow Models","description":"An MLflow Model is a standard format for packaging machine learning models that can be used in a","source":"@site/docs/model/index.mdx","sourceDirName":"model","slug":"/model/","permalink":"/model/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_label":"Overview","sidebar_position":0},"sidebar":"docsSidebar","previous":{"title":"System Metrics","permalink":"/system-metrics/"},"next":{"title":"Model Signature","permalink":"/model/signatures/"}},{"id":"model/models-from-code/index","title":"Models From Code","description":"Models from Code is available in MLflow 2.12.2 and above. If you are using a version earlier than what supports this feature,","source":"@site/docs/model/models-from-code/index.mdx","sourceDirName":"model/models-from-code","slug":"/model/models-from-code/","permalink":"/model/models-from-code/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"docsSidebar","previous":{"title":"Dependency Management","permalink":"/model/dependencies/"},"next":{"title":"Custom Python Model","permalink":"/model/python_model"}},{"id":"model/python_model","title":"MLflow PythonModel Guide","description":"Introduction to MLflow PythonModel","source":"@site/docs/model/python_model.mdx","sourceDirName":"model","slug":"/model/python_model","permalink":"/model/python_model","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_label":"Custom Python Model","sidebar_position":4},"sidebar":"docsSidebar","previous":{"title":"Models From Code","permalink":"/model/models-from-code/"},"next":{"title":"MLflow Recipes","permalink":"/recipes/"}},{"id":"model/signatures/index","title":"MLflow Model Signatures and Input Examples Guide","description":"Introduction to Model Signatures and Input Examples \\","source":"@site/docs/model/signatures/index.mdx","sourceDirName":"model/signatures","slug":"/model/signatures/","permalink":"/model/signatures/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_label":"Model Signature","sidebar_position":1},"sidebar":"docsSidebar","previous":{"title":"Overview","permalink":"/model/"},"next":{"title":"Dependency Management","permalink":"/model/dependencies/"}},{"id":"new-features/index","title":"New Features","description":"<NewFeatureCard","source":"@site/docs/new-features/index.mdx","sourceDirName":"new-features","slug":"/new-features/","permalink":"/new-features/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"hide_table_of_contents":true}},{"id":"plugins/index","title":"MLflow Plugins","description":"As a framework-agnostic tool for machine learning, the MLflow Python API provides developer APIs for","source":"@site/docs/plugins/index.mdx","sourceDirName":"plugins","slug":"/plugins/","permalink":"/plugins/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":17,"frontMatter":{"sidebar_position":17},"sidebar":"docsSidebar","previous":{"title":"MLflow Projects","permalink":"/projects/"}},{"id":"projects/index","title":"MLflow Projects","description":"An MLflow Project is a format for packaging data science code in a reusable and reproducible way,","source":"@site/docs/projects/index.mdx","sourceDirName":"projects","slug":"/projects/","permalink":"/projects/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":13,"frontMatter":{"sidebar_position":13},"sidebar":"docsSidebar","previous":{"title":"Access Control","permalink":"/auth/"},"next":{"title":"MLflow Plugins","permalink":"/plugins/"}},{"id":"quickstart_drilldown/index","title":"Quickstart options and troubleshooting","description":"{/ Eventually, these H2s will probably all be separate articles. For now, I'm","source":"@site/docs/quickstart_drilldown/index.mdx","sourceDirName":"quickstart_drilldown","slug":"/quickstart_drilldown/","permalink":"/quickstart_drilldown/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"sidebar_custom_props":{"hide":true}}},{"id":"recipes/index","title":"MLflow Recipes","description":"MLflow Recipes (previously known as MLflow Pipelines) is a framework that enables data scientists","source":"@site/docs/recipes/index.mdx","sourceDirName":"recipes","slug":"/recipes/","permalink":"/recipes/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":16,"frontMatter":{"sidebar_position":16},"sidebar":"docsSidebar","previous":{"title":"Custom Python Model","permalink":"/model/python_model"},"next":{"title":"MLflow Evaluation","permalink":"/model-evaluation/"}},{"id":"search-experiments/index","title":"Search Experiments","description":"and MlflowClient.search_experiments()","source":"@site/docs/search-experiments/index.mdx","sourceDirName":"search-experiments","slug":"/search-experiments/","permalink":"/search-experiments/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":21,"frontMatter":{"sidebar_position":21},"sidebar":"docsSidebar","previous":{"title":"Search Runs","permalink":"/search-runs/"},"next":{"title":"System Metrics","permalink":"/system-metrics/"}},{"id":"search-runs/index","title":"Search Runs","description":"This guide will walk you through how to search your MLflow runs through the MLflow UI and Python API.","source":"@site/docs/search-runs/index.mdx","sourceDirName":"search-runs","slug":"/search-runs/","permalink":"/search-runs/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":20,"frontMatter":{"sidebar_position":20},"sidebar":"docsSidebar","previous":{"title":"Remote Experiment Tracking with MLflow Tracking Server","permalink":"/tracking/tutorials/remote-server/"},"next":{"title":"Search Experiments","permalink":"/search-experiments/"}},{"id":"system-metrics/index","title":"System Metrics","description":"MLflow allows users to log system metrics including CPU stats, GPU stats, memory usage, network traffic, and","source":"@site/docs/system-metrics/index.mdx","sourceDirName":"system-metrics","slug":"/system-metrics/","permalink":"/system-metrics/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":12,"frontMatter":{"sidebar_position":12},"sidebar":"docsSidebar","previous":{"title":"Search Experiments","permalink":"/search-experiments/"},"next":{"title":"Overview","permalink":"/model/"}},{"id":"tracing/api/client","title":"(Advanced) Low-level Client APIs","description":"The MlflowClient class provides a set of low-level APIS for fine-grained control over creating, manipulating, and retrieving traces.","source":"@site/docs/tracing/api/client.mdx","sourceDirName":"tracing/api","slug":"/tracing/api/client","permalink":"/tracing/api/client","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"sidebar_label":"Low-level Client APIs"},"sidebar":"docsSidebar","previous":{"title":"How-to Guide","permalink":"/tracing/api/how-to"},"next":{"title":"Production Monitoring","permalink":"/tracing/production"}},{"id":"tracing/api/how-to","title":"Tracing SDK How-to Guides","description":"Render Trace inside Jupyter Notebook","source":"@site/docs/tracing/api/how-to.mdx","sourceDirName":"tracing/api","slug":"/tracing/api/how-to","permalink":"/tracing/api/how-to","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"sidebar_label":"How-to Guide"},"sidebar":"docsSidebar","previous":{"title":"Query Traces","permalink":"/tracing/api/search"},"next":{"title":"Low-level Client APIs","permalink":"/tracing/api/client"}},{"id":"tracing/api/index","title":"MLflow Tracing SDK","description":"","source":"@site/docs/tracing/api/index.mdx","sourceDirName":"tracing/api","slug":"/tracing/api/","permalink":"/tracing/api/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"sidebar_label":"APIs"},"sidebar":"docsSidebar","previous":{"title":"Add New Integration","permalink":"/tracing/integrations/contribute"},"next":{"title":"Manual Tracing","permalink":"/tracing/api/manual-instrumentation"}},{"id":"tracing/api/manual-instrumentation","title":"Manual Tracing","description":"In addition to the Auto Tracing integrations, you can instrument your Python code using the MLflow Tracing SDK. This is especially useful when you need to instrument your custom Python code.","source":"@site/docs/tracing/api/manual-instrumentation.mdx","sourceDirName":"tracing/api","slug":"/tracing/api/manual-instrumentation","permalink":"/tracing/api/manual-instrumentation","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"sidebar_label":"Manual Tracing"},"sidebar":"docsSidebar","previous":{"title":"APIs","permalink":"/tracing/api/"},"next":{"title":"Query Traces","permalink":"/tracing/api/search"}},{"id":"tracing/api/search","title":"Query Traces","description":"This page describes how to query traces logged to MLflow.","source":"@site/docs/tracing/api/search.mdx","sourceDirName":"tracing/api","slug":"/tracing/api/search","permalink":"/tracing/api/search","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"sidebar_label":"Query Traces"},"sidebar":"docsSidebar","previous":{"title":"Manual Tracing","permalink":"/tracing/api/manual-instrumentation"},"next":{"title":"How-to Guide","permalink":"/tracing/api/how-to"}},{"id":"tracing/faq","title":"FAQ","description":"Q: I cannot open my trace in the MLflow UI. What should I do?","source":"@site/docs/tracing/faq.mdx","sourceDirName":"tracing","slug":"/tracing/faq","permalink":"/tracing/faq","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7,"sidebar_label":"FAQ"},"sidebar":"docsSidebar","previous":{"title":"Session","permalink":"/tracing/session"},"next":{"title":"Tutorials","permalink":"/tracing/tutorials/"}},{"id":"tracing/index","title":"MLflow Tracing for LLM Observability","description":"MLflow Tracing is a feature that enables LLM observability in your apps. MLflow automatically logs traces for LangChain, LlamaIndex, and more.","source":"@site/docs/tracing/index.mdx","sourceDirName":"tracing","slug":"/tracing/","permalink":"/tracing/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"description":"MLflow Tracing is a feature that enables LLM observability in your apps. MLflow automatically logs traces for LangChain, LlamaIndex, and more.","sidebar_position":1,"sidebar_label":"Overview"},"sidebar":"docsSidebar","previous":{"title":"MLflow Evaluation","permalink":"/model-evaluation/"},"next":{"title":"Overview","permalink":"/tracing/"}},{"id":"tracing/integrations/anthropic","title":"Tracing Anthropic","description":"OpenAI Tracing via autolog","source":"@site/docs/tracing/integrations/anthropic.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/anthropic","permalink":"/tracing/integrations/anthropic","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_position":8,"sidebar_label":"Anthropic"},"sidebar":"docsSidebar","previous":{"title":"CrewAI","permalink":"/tracing/integrations/crewai"},"next":{"title":"LiteLLM","permalink":"/tracing/integrations/litellm"}},{"id":"tracing/integrations/autogen","title":"Tracing AutoGenðŸ¤–","description":"AutoGen Tracing via autolog","source":"@site/docs/tracing/integrations/autogen.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/autogen","permalink":"/tracing/integrations/autogen","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"sidebar_label":"AutoGen"},"sidebar":"docsSidebar","previous":{"title":"DSPy","permalink":"/tracing/integrations/dspy"},"next":{"title":"CrewAI","permalink":"/tracing/integrations/crewai"}},{"id":"tracing/integrations/bedrock","title":"Tracing Amazon Bedrock with MLflow","description":"MLflow supports automatic tracing for Amazon Bedrock, a fully managed service on AWS that provides high-performing","source":"@site/docs/tracing/integrations/bedrock.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/bedrock","permalink":"/tracing/integrations/bedrock","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4.5,"frontMatter":{"sidebar_position":4.5,"sidebar_label":"Bedrock"},"sidebar":"docsSidebar","previous":{"title":"LlamaIndex","permalink":"/tracing/integrations/llama_index"},"next":{"title":"DSPy","permalink":"/tracing/integrations/dspy"}},{"id":"tracing/integrations/contribute","title":"Contributing to MLflow Tracing","description":"Welcome to the MLflow Tracing contribution guide! This step-by-step resource will assist you in implementing additional GenAI library integrations for tracing into MLflow.","source":"@site/docs/tracing/integrations/contribute.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/contribute","permalink":"/tracing/integrations/contribute","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":100,"frontMatter":{"sidebar_position":100,"sidebar_label":"Add New Integration"},"sidebar":"docsSidebar","previous":{"title":"Instructor","permalink":"/tracing/integrations/instructor"},"next":{"title":"APIs","permalink":"/tracing/api/"}},{"id":"tracing/integrations/crewai","title":"Tracing CrewAI","description":"CrewAI Tracing via autolog","source":"@site/docs/tracing/integrations/crewai.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/crewai","permalink":"/tracing/integrations/crewai","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7,"sidebar_label":"CrewAI"},"sidebar":"docsSidebar","previous":{"title":"AutoGen","permalink":"/tracing/integrations/autogen"},"next":{"title":"Anthropic","permalink":"/tracing/integrations/anthropic"}},{"id":"tracing/integrations/dspy","title":"Tracing DSPyðŸ§©","description":"DSPy Tracing via autolog","source":"@site/docs/tracing/integrations/dspy.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/dspy","permalink":"/tracing/integrations/dspy","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"sidebar_label":"DSPy"},"sidebar":"docsSidebar","previous":{"title":"Bedrock","permalink":"/tracing/integrations/bedrock"},"next":{"title":"AutoGen","permalink":"/tracing/integrations/autogen"}},{"id":"tracing/integrations/gemini","title":"Tracing Gemini","description":"OpenAI Tracing via autolog","source":"@site/docs/tracing/integrations/gemini.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/gemini","permalink":"/tracing/integrations/gemini","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":9,"frontMatter":{"sidebar_position":9,"sidebar_label":"Gemini"},"sidebar":"docsSidebar","previous":{"title":"Swarm","permalink":"/tracing/integrations/swarm"},"next":{"title":"Ollama","permalink":"/tracing/integrations/ollama"}},{"id":"tracing/integrations/groq","title":"Tracing Groq","description":"Groq tracing via autolog","source":"@site/docs/tracing/integrations/groq.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/groq","permalink":"/tracing/integrations/groq","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":11,"frontMatter":{"sidebar_position":11,"sidebar_label":"Groq"},"sidebar":"docsSidebar","previous":{"title":"Mistral","permalink":"/tracing/integrations/mistral"},"next":{"title":"Instructor","permalink":"/tracing/integrations/instructor"}},{"id":"tracing/integrations/index","title":"Auto Tracing Integrations","description":"MLflow Tracing is integrated with various GenAI libraries and provide one-line automatic tracing experience for each library (and the combination of them!). Click on the icon below to see detailed examples to integrate MLflow with your favorite library.","source":"@site/docs/tracing/integrations/index.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/","permalink":"/tracing/integrations/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"sidebar_label":"Integrations"},"sidebar":"docsSidebar","previous":{"title":"Data Structure","permalink":"/tracing/tracing-schema"},"next":{"title":"OpenAI","permalink":"/tracing/integrations/openai"}},{"id":"tracing/integrations/instructor","title":"Tracing Instructor","description":"Instructor Tracing via autolog","source":"@site/docs/tracing/integrations/instructor.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/instructor","permalink":"/tracing/integrations/instructor","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":12,"frontMatter":{"sidebar_position":12,"sidebar_label":"Instructor"},"sidebar":"docsSidebar","previous":{"title":"Groq","permalink":"/tracing/integrations/groq"},"next":{"title":"Add New Integration","permalink":"/tracing/integrations/contribute"}},{"id":"tracing/integrations/langchain","title":"Tracing LangChainðŸ¦œâ›“ï¸","description":"LangChain Tracing via autolog","source":"@site/docs/tracing/integrations/langchain.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/langchain","permalink":"/tracing/integrations/langchain","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"sidebar_label":"LangChain"},"sidebar":"docsSidebar","previous":{"title":"OpenAI","permalink":"/tracing/integrations/openai"},"next":{"title":"LangGraph","permalink":"/tracing/integrations/langgraph"}},{"id":"tracing/integrations/langgraph","title":"Tracing LangGraphðŸ¦œðŸ•¸ï¸","description":"LangChain Tracing via autolog","source":"@site/docs/tracing/integrations/langgraph.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/langgraph","permalink":"/tracing/integrations/langgraph","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"sidebar_label":"LangGraph"},"sidebar":"docsSidebar","previous":{"title":"LangChain","permalink":"/tracing/integrations/langchain"},"next":{"title":"LlamaIndex","permalink":"/tracing/integrations/llama_index"}},{"id":"tracing/integrations/litellm","title":"Tracing LiteLLMðŸš„","description":"LiteLLM Tracing via autolog","source":"@site/docs/tracing/integrations/litellm.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/litellm","permalink":"/tracing/integrations/litellm","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_position":8,"sidebar_label":"LiteLLM"},"sidebar":"docsSidebar","previous":{"title":"Anthropic","permalink":"/tracing/integrations/anthropic"},"next":{"title":"Swarm","permalink":"/tracing/integrations/swarm"}},{"id":"tracing/integrations/llama_index","title":"Tracing LlamaIndexðŸ¦™","description":"LlamaIndex Tracing via autolog","source":"@site/docs/tracing/integrations/llama_index.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/llama_index","permalink":"/tracing/integrations/llama_index","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"sidebar_label":"LlamaIndex"},"sidebar":"docsSidebar","previous":{"title":"LangGraph","permalink":"/tracing/integrations/langgraph"},"next":{"title":"Bedrock","permalink":"/tracing/integrations/bedrock"}},{"id":"tracing/integrations/mistral","title":"Tracing Mistral","description":"Mistral tracing via autolog","source":"@site/docs/tracing/integrations/mistral.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/mistral","permalink":"/tracing/integrations/mistral","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":10.5,"frontMatter":{"sidebar_position":10.5,"sidebar_label":"Mistral"},"sidebar":"docsSidebar","previous":{"title":"Ollama","permalink":"/tracing/integrations/ollama"},"next":{"title":"Groq","permalink":"/tracing/integrations/groq"}},{"id":"tracing/integrations/ollama","title":"Tracing Ollama","description":"Ollama Tracing via autolog","source":"@site/docs/tracing/integrations/ollama.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/ollama","permalink":"/tracing/integrations/ollama","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"sidebar_position":10,"sidebar_label":"Ollama"},"sidebar":"docsSidebar","previous":{"title":"Gemini","permalink":"/tracing/integrations/gemini"},"next":{"title":"Mistral","permalink":"/tracing/integrations/mistral"}},{"id":"tracing/integrations/openai","title":"Tracing OpenAI","description":"OpenAI Tracing via autolog","source":"@site/docs/tracing/integrations/openai.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/openai","permalink":"/tracing/integrations/openai","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"sidebar_label":"OpenAI"},"sidebar":"docsSidebar","previous":{"title":"Integrations","permalink":"/tracing/integrations/"},"next":{"title":"LangChain","permalink":"/tracing/integrations/langchain"}},{"id":"tracing/integrations/swarm","title":"Tracing OpenAI SwarmðŸ","description":"OpenAI Tracing via autolog","source":"@site/docs/tracing/integrations/swarm.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/swarm","permalink":"/tracing/integrations/swarm","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_position":8,"sidebar_label":"Swarm"},"sidebar":"docsSidebar","previous":{"title":"LiteLLM","permalink":"/tracing/integrations/litellm"},"next":{"title":"Gemini","permalink":"/tracing/integrations/gemini"}},{"id":"tracing/production","title":"Tracing in Production","description":"Machine learning projects don't conclude with their initial launch. Ongoing monitoring and incremental enhancements are critical for long-term success. MLflow Tracing offers observability for your production application, supporting the iterative process of continuous improvement.","source":"@site/docs/tracing/production.mdx","sourceDirName":"tracing","slug":"/tracing/production","permalink":"/tracing/production","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"sidebar_label":"Production Monitoring"},"sidebar":"docsSidebar","previous":{"title":"Low-level Client APIs","permalink":"/tracing/api/client"},"next":{"title":"Session","permalink":"/tracing/session"}},{"id":"tracing/session","title":"Tracing Multi-turn Conversation Sessions","description":"In conversational AI applications, it is common that users interact with the model multiple times within a single conversation session. Since each interaction generates a trace in the typical MLflow setup, it is useful to group these traces together to analyze the conversation as a whole. You can achieve this by attaching the session ID as a tag to each trace.","source":"@site/docs/tracing/session.mdx","sourceDirName":"tracing","slug":"/tracing/session","permalink":"/tracing/session","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"sidebar_label":"Session"},"sidebar":"docsSidebar","previous":{"title":"Production Monitoring","permalink":"/tracing/production"},"next":{"title":"FAQ","permalink":"/tracing/faq"}},{"id":"tracing/tracing-schema","title":"Trace Data Structure","description":"This document provides a detailed view of the schema for traces and its ingredients. MLflow traces are compatible to OpenTelemetry specs,","source":"@site/docs/tracing/tracing-schema.mdx","sourceDirName":"tracing","slug":"/tracing/tracing-schema","permalink":"/tracing/tracing-schema","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"sidebar_label":"Data Structure"},"sidebar":"docsSidebar","previous":{"title":"Overview","permalink":"/tracing/"},"next":{"title":"Integrations","permalink":"/tracing/integrations/"}},{"id":"tracing/tutorials/concept","title":"Tracing 101","description":"A good companion to the explanations in this guide is the Tracing Schema guide which will show how MLflow Tracing constructs the","source":"@site/docs/tracing/tutorials/concept.mdx","sourceDirName":"tracing/tutorials","slug":"/tracing/tutorials/concept","permalink":"/tracing/tutorials/concept","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Tutorials","permalink":"/tracing/tutorials/"},"next":{"title":"ui","permalink":"/tracing/ui"}},{"id":"tracing/tutorials/index","title":"MLflow Tracing Tutorials","description":"Explore the comprehensive collection of tutorials, including end-to-end guides, debugging techniques, evaluation, and production monitoring best practices.","source":"@site/docs/tracing/tutorials/index.mdx","sourceDirName":"tracing/tutorials","slug":"/tracing/tutorials/","permalink":"/tracing/tutorials/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":9,"frontMatter":{"sidebar_position":9,"sidebar_label":"Tutorials"},"sidebar":"docsSidebar","previous":{"title":"FAQ","permalink":"/tracing/faq"},"next":{"title":"Tracing 101","permalink":"/tracing/tutorials/concept"}},{"id":"tracing/ui","title":"ui","description":"","source":"@site/docs/tracing/ui.mdx","sourceDirName":"tracing","slug":"/tracing/ui","permalink":"/tracing/ui","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Tracing 101","permalink":"/tracing/tutorials/concept"},"next":{"title":"MLflow Dataset","permalink":"/dataset/"}},{"id":"tracking/artifacts-stores/index","title":"Artifact Stores","description":"The artifact store is a core component in MLflow Tracking where MLflow stores (typically large) artifacts","source":"@site/docs/tracking/artifacts-stores/index.mdx","sourceDirName":"tracking/artifacts-stores","slug":"/tracking/artifacts-stores/","permalink":"/tracking/artifacts-stores/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"sidebar_label":"Artifact Store"},"sidebar":"docsSidebar","previous":{"title":"Tracking Server","permalink":"/tracking/server/"},"next":{"title":"Backend Store","permalink":"/tracking/backend-stores/"}},{"id":"tracking/autolog/index","title":"Automatic Logging with MLflow Tracking","description":"Auto logging is a powerful feature that allows you to log metrics, parameters, and models without the need for explicit log statements. All you need to do is to","source":"@site/docs/tracking/autolog/index.mdx","sourceDirName":"tracking/autolog","slug":"/tracking/autolog/","permalink":"/tracking/autolog/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_label":"Auto Logging","sidebar_position":1},"sidebar":"docsSidebar","previous":{"title":"Overview","permalink":"/tracking/"},"next":{"title":"Tracking Server","permalink":"/tracking/server/"}},{"id":"tracking/backend-stores/index","title":"Backend Stores","description":"The backend store is a core component in MLflow Tracking where MLflow stores metadata for","source":"@site/docs/tracking/backend-stores/index.mdx","sourceDirName":"tracking/backend-stores","slug":"/tracking/backend-stores/","permalink":"/tracking/backend-stores/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"sidebar_label":"Backend Store"},"sidebar":"docsSidebar","previous":{"title":"Artifact Store","permalink":"/tracking/artifacts-stores/"},"next":{"title":"Tracking Experiments with a Local Database","permalink":"/tracking/tutorials/local-database/"}},{"id":"tracking/index","title":"MLflow Tracking","description":"The MLflow Tracking is an API and UI for logging parameters, code versions, metrics, and output files","source":"@site/docs/tracking/index.mdx","sourceDirName":"tracking","slug":"/tracking/","permalink":"/tracking/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_label":"Overview","sidebar_position":0},"sidebar":"docsSidebar","previous":{"title":"Serving Multiple Models on a Single Endpoint with a Custom PyFunc Model","permalink":"/traditional-ml/serving-multiple-models-with-pyfunc/"},"next":{"title":"Overview","permalink":"/tracking/"}},{"id":"tracking/server/index","title":"MLflow Tracking Server","description":"MLflow tracking server is a stand-alone HTTP server that serves multiple REST API endpoints for tracking runs/experiments.","source":"@site/docs/tracking/server/index.mdx","sourceDirName":"tracking/server","slug":"/tracking/server/","permalink":"/tracking/server/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"sidebar_label":"Tracking Server"},"sidebar":"docsSidebar","previous":{"title":"Auto Logging","permalink":"/tracking/autolog/"},"next":{"title":"Artifact Store","permalink":"/tracking/artifacts-stores/"}},{"id":"tracking/tracking-api/index","title":"MLflow Tracking APIs","description":"MLflow Tracking provides Python, R, Java, or REST API to log your experiment data and models.","source":"@site/docs/tracking/tracking-api/index.mdx","sourceDirName":"tracking/tracking-api","slug":"/tracking/tracking-api/","permalink":"/tracking/tracking-api/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_label":"API Guides","sidebar_position":5}},{"id":"tracking/tutorials/local-database/index","title":"Tracking Experiments with a Local Database","description":"In this tutorial, you will learn how to use a local database to track your experiment metadata with MLflow. By default, MLflow Tracking logs run data to local files,","source":"@site/docs/tracking/tutorials/local-database/index.mdx","sourceDirName":"tracking/tutorials/local-database","slug":"/tracking/tutorials/local-database/","permalink":"/tracking/tutorials/local-database/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Backend Store","permalink":"/tracking/backend-stores/"},"next":{"title":"Remote Experiment Tracking with MLflow Tracking Server","permalink":"/tracking/tutorials/remote-server/"}},{"id":"tracking/tutorials/remote-server/index","title":"Remote Experiment Tracking with MLflow Tracking Server","description":"In this tutorial, you will learn how to set up MLflow Tracking environment for team development using the MLflow Tracking Server.","source":"@site/docs/tracking/tutorials/remote-server/index.mdx","sourceDirName":"tracking/tutorials/remote-server","slug":"/tracking/tutorials/remote-server/","permalink":"/tracking/tutorials/remote-server/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Tracking Experiments with a Local Database","permalink":"/tracking/tutorials/local-database/"},"next":{"title":"Search Runs","permalink":"/search-runs/"}},{"id":"traditional-ml/creating-custom-pyfunc/index","title":"Building Custom Python Function Models with MLflow","description":"MLflow offers a wide range of pre-defined model flavors, but there are instances where you'd want to go","source":"@site/docs/traditional-ml/creating-custom-pyfunc/index.mdx","sourceDirName":"traditional-ml/creating-custom-pyfunc","slug":"/traditional-ml/creating-custom-pyfunc/","permalink":"/traditional-ml/creating-custom-pyfunc/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Logging plots with MLflow","permalink":"/traditional-ml/hyperparameter-tuning-with-child-runs/part2-logging-plots/"},"next":{"title":"Models, Flavors, and PyFuncs in MLflow","permalink":"/traditional-ml/creating-custom-pyfunc/part1-named-flavors/"}},{"id":"traditional-ml/creating-custom-pyfunc/notebooks/index","title":"Custom PyFuncs with MLflow - Notebooks","description":"If you would like to view the notebooks in this guide in their entirety, each notebook can viewed or downloaded directly below.","source":"@site/docs/traditional-ml/creating-custom-pyfunc/notebooks/index.mdx","sourceDirName":"traditional-ml/creating-custom-pyfunc/notebooks","slug":"/traditional-ml/creating-custom-pyfunc/notebooks/","permalink":"/traditional-ml/creating-custom-pyfunc/notebooks/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"sidebar_label":"Full Notebooks"},"sidebar":"docsSidebar","previous":{"title":"Understanding PyFunc in MLflow","permalink":"/traditional-ml/creating-custom-pyfunc/part2-pyfunc-components/"},"next":{"title":"Serving Multiple Models on a Single Endpoint with a Custom PyFunc Model","permalink":"/traditional-ml/serving-multiple-models-with-pyfunc/"}},{"id":"traditional-ml/creating-custom-pyfunc/part1-named-flavors/index","title":"Models, Flavors, and PyFuncs in MLflow","description":"In the MLflow ecosystem, \"flavors\" play a pivotal role in model management. Essentially, a \"flavor\" is a designated wrapper for specific machine","source":"@site/docs/traditional-ml/creating-custom-pyfunc/part1-named-flavors/index.mdx","sourceDirName":"traditional-ml/creating-custom-pyfunc/part1-named-flavors","slug":"/traditional-ml/creating-custom-pyfunc/part1-named-flavors/","permalink":"/traditional-ml/creating-custom-pyfunc/part1-named-flavors/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"docsSidebar","previous":{"title":"Building Custom Python Function Models with MLflow","permalink":"/traditional-ml/creating-custom-pyfunc/"},"next":{"title":"Understanding PyFunc in MLflow","permalink":"/traditional-ml/creating-custom-pyfunc/part2-pyfunc-components/"}},{"id":"traditional-ml/creating-custom-pyfunc/part2-pyfunc-components/index","title":"Understanding PyFunc in MLflow","description":"In the realm of MLflow, while named flavors offer specific functionalities tailored to popular frameworks, there are situations and","source":"@site/docs/traditional-ml/creating-custom-pyfunc/part2-pyfunc-components/index.mdx","sourceDirName":"traditional-ml/creating-custom-pyfunc/part2-pyfunc-components","slug":"/traditional-ml/creating-custom-pyfunc/part2-pyfunc-components/","permalink":"/traditional-ml/creating-custom-pyfunc/part2-pyfunc-components/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Models, Flavors, and PyFuncs in MLflow","permalink":"/traditional-ml/creating-custom-pyfunc/part1-named-flavors/"},"next":{"title":"Full Notebooks","permalink":"/traditional-ml/creating-custom-pyfunc/notebooks/"}},{"id":"traditional-ml/hyperparameter-tuning-with-child-runs/index","title":"Hyperparameter Tuning with MLflow and Optuna","description":"In this guide, we venture into a frequent use case of MLflow Tracking: hyperparameter tuning.","source":"@site/docs/traditional-ml/hyperparameter-tuning-with-child-runs/index.mdx","sourceDirName":"traditional-ml/hyperparameter-tuning-with-child-runs","slug":"/traditional-ml/hyperparameter-tuning-with-child-runs/","permalink":"/traditional-ml/hyperparameter-tuning-with-child-runs/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"docsSidebar","previous":{"title":"Overview","permalink":"/traditional-ml/"},"next":{"title":"Full Notebooks","permalink":"/traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/"}},{"id":"traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/index","title":"Hyperparameter tuning with MLflow and child runs - Notebooks","description":"If you would like to view the notebooks in this guide in their entirety, each notebook can be either viewed or downloaded below.","source":"@site/docs/traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/index.mdx","sourceDirName":"traditional-ml/hyperparameter-tuning-with-child-runs/notebooks","slug":"/traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/","permalink":"/traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"sidebar_label":"Full Notebooks"},"sidebar":"docsSidebar","previous":{"title":"Hyperparameter Tuning with MLflow and Optuna","permalink":"/traditional-ml/hyperparameter-tuning-with-child-runs/"},"next":{"title":"The Parent-Child relationship with runs","permalink":"/traditional-ml/hyperparameter-tuning-with-child-runs/part1-child-runs/"}},{"id":"traditional-ml/hyperparameter-tuning-with-child-runs/part1-child-runs/index","title":"Understanding Parent and Child Runs in MLflow","description":"Introduction","source":"@site/docs/traditional-ml/hyperparameter-tuning-with-child-runs/part1-child-runs/index.mdx","sourceDirName":"traditional-ml/hyperparameter-tuning-with-child-runs/part1-child-runs","slug":"/traditional-ml/hyperparameter-tuning-with-child-runs/part1-child-runs/","permalink":"/traditional-ml/hyperparameter-tuning-with-child-runs/part1-child-runs/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"sidebar_label":"The Parent-Child relationship with runs"},"sidebar":"docsSidebar","previous":{"title":"Full Notebooks","permalink":"/traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/"},"next":{"title":"Logging plots with MLflow","permalink":"/traditional-ml/hyperparameter-tuning-with-child-runs/part2-logging-plots/"}},{"id":"traditional-ml/hyperparameter-tuning-with-child-runs/part2-logging-plots/index","title":"Leveraging Visualizations and MLflow for In-depth Model Analysis","description":"Introduction","source":"@site/docs/traditional-ml/hyperparameter-tuning-with-child-runs/part2-logging-plots/index.mdx","sourceDirName":"traditional-ml/hyperparameter-tuning-with-child-runs/part2-logging-plots","slug":"/traditional-ml/hyperparameter-tuning-with-child-runs/part2-logging-plots/","permalink":"/traditional-ml/hyperparameter-tuning-with-child-runs/part2-logging-plots/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"sidebar_label":"Logging plots with MLflow"},"sidebar":"docsSidebar","previous":{"title":"The Parent-Child relationship with runs","permalink":"/traditional-ml/hyperparameter-tuning-with-child-runs/part1-child-runs/"},"next":{"title":"Building Custom Python Function Models with MLflow","permalink":"/traditional-ml/creating-custom-pyfunc/"}},{"id":"traditional-ml/index","title":"Traditional ML","description":"In the dynamic landscape of machine learning, traditional techniques remain foundational, playing pivotal roles across various industries","source":"@site/docs/traditional-ml/index.mdx","sourceDirName":"traditional-ml","slug":"/traditional-ml/","permalink":"/traditional-ml/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_position":0,"sidebar_label":"Overview"},"sidebar":"docsSidebar","previous":{"title":"Tensorflow within MLflow","permalink":"/deep-learning/tensorflow/guide/"},"next":{"title":"Overview","permalink":"/traditional-ml/"}},{"id":"traditional-ml/serving-multiple-models-with-pyfunc/index","title":"Serving Multiple Models on a Single Endpoint with a Custom PyFunc Model","description":"This tutorial addresses a common scenario in machine learning: serving multiple models through a","source":"@site/docs/traditional-ml/serving-multiple-models-with-pyfunc/index.mdx","sourceDirName":"traditional-ml/serving-multiple-models-with-pyfunc","slug":"/traditional-ml/serving-multiple-models-with-pyfunc/","permalink":"/traditional-ml/serving-multiple-models-with-pyfunc/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"docsSidebar","previous":{"title":"Full Notebooks","permalink":"/traditional-ml/creating-custom-pyfunc/notebooks/"},"next":{"title":"Overview","permalink":"/tracking/"}},{"id":"tutorials-and-examples/index","title":"Tutorials and Examples","description":"Below, you can find a number of tutorials and examples for various MLflow use cases.","source":"@site/docs/tutorials-and-examples/index.mdx","sourceDirName":"tutorials-and-examples","slug":"/tutorials-and-examples/","permalink":"/tutorials-and-examples/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":28,"frontMatter":{"sidebar_position":28}}],"drafts":[],"sidebars":{"docsSidebar":[{"type":"doc","id":"index","className":"sidebar-top-level-category"},{"type":"category","label":"Getting Started","className":"sidebar-top-level-category","items":[{"type":"doc","id":"getting-started/intro-quickstart/index","label":"Quickstart","translatable":true},{"type":"doc","id":"getting-started/running-notebooks/index"},{"type":"doc","id":"getting-started/community-edition/index"},{"type":"category","label":"More Tutorials","items":[{"type":"doc","label":"Hyperparameter Tuning Tutorial","id":"getting-started/quickstart-2/index","translatable":true},{"type":"category","label":"Model Registry Tutorial","items":[{"type":"doc","id":"getting-started/registering-first-model/index"},{"type":"doc","label":"Register a Model","id":"getting-started/registering-first-model/step1-register-model/index"},{"type":"doc","label":"Explore the Registered Model","id":"getting-started/registering-first-model/step2-explore-registered-model/index"},{"type":"doc","label":"Load a Registered Model","id":"getting-started/registering-first-model/step3-load-model/index"}],"collapsed":true,"collapsible":true},{"type":"doc","id":"getting-started/tracking-server-overview/index"}],"collapsed":true,"collapsible":true}],"link":{"type":"doc","id":"getting-started/index"},"collapsed":true,"collapsible":true},{"type":"category","label":"Machine Learning ðŸ§ ","className":"sidebar-top-level-category","collapsed":false,"items":[{"type":"category","label":"LLM / GenAI","items":[{"type":"doc","label":"Overview","id":"llms/index","translatable":true},{"type":"category","label":"Integrations","items":[{"type":"category","label":"OpenAI","items":[{"type":"doc","id":"llms/openai/index"},{"type":"doc","label":"Tutorials","id":"llms/openai/notebooks/index"},{"type":"doc","label":"Autologging","id":"llms/openai/autologging/index"},{"type":"doc","label":"Detailed Guide","id":"llms/openai/guide/index"}],"link":{"type":"doc","id":"llms/openai/index"},"collapsed":true,"collapsible":true},{"type":"category","label":"LangChain","items":[{"type":"doc","id":"llms/langchain/autologging"},{"type":"doc","label":"LangChain within MLflow (Experimental)","id":"llms/langchain/guide/index"},{"type":"doc","id":"llms/langchain/index"}],"link":{"type":"doc","id":"llms/langchain/index"},"collapsed":true,"collapsible":true},{"type":"doc","id":"llms/dspy/index","label":"DSPy","translatable":true},{"type":"doc","id":"llms/llama-index/index","label":"LlamaIndex","translatable":true},{"type":"category","label":"Transformers","items":[{"type":"doc","id":"llms/transformers/index","label":"Overview"},{"type":"doc","label":"Tutorials","id":"llms/transformers/tutorials/index"},{"type":"doc","label":"Detailed Guide","id":"llms/transformers/guide/index"},{"type":"doc","label":"Task","id":"llms/transformers/task/index"},{"type":"doc","label":"Storage Optimization","id":"llms/transformers/large-models/index"}],"link":{"type":"doc","id":"llms/transformers/index"},"collapsed":true,"collapsible":true},{"type":"category","label":"Sentence Transformers","items":[{"type":"doc","id":"llms/sentence-transformers/index","label":"Overview"},{"type":"doc","label":"Tutorials","id":"llms/sentence-transformers/tutorials/index"},{"type":"doc","label":"Detailed Guides","id":"llms/sentence-transformers/guide/index"}],"link":{"type":"doc","id":"llms/sentence-transformers/index"},"collapsed":true,"collapsible":true},{"type":"link","href":"/tracing/integrations/","label":"More"}],"collapsed":true,"collapsible":true},{"type":"link","label":"Tracing (Observability)","href":"/tracing/"},{"type":"link","label":"Evaluation","href":"/llms/llm-evaluate/"},{"type":"category","label":"ChatModel","items":[{"type":"doc","id":"llms/chat-model-intro/index","label":"What is ChatModel?","translatable":true},{"type":"doc","id":"llms/chat-model-guide/index","label":"Advanced Guide","translatable":true},{"type":"doc","id":"llms/custom-pyfunc-for-llms/index","label":"More Customization","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"RAG","items":[{"type":"doc","id":"llms/rag/index","label":"What is RAG?","translatable":true},{"type":"doc","id":"llms/rag/notebooks/index"}],"collapsed":true,"collapsible":true},{"type":"doc","label":"Prompt Engineering","id":"llms/prompt-engineering/index","translatable":true}],"link":{"type":"doc","id":"llms/index"},"collapsed":true,"collapsible":true},{"type":"category","label":"Deep Learning","items":[{"type":"doc","id":"deep-learning/index","label":"Overview"},{"type":"category","label":"Pytorch","collapsible":true,"collapsed":true,"items":[{"type":"doc","label":"PyTorch within MLflow","id":"deep-learning/pytorch/guide/index"}],"link":{"type":"doc","id":"deep-learning/pytorch/index"}},{"type":"doc","label":"Keras","id":"deep-learning/keras/index"},{"type":"category","label":"Tensorflow","collapsible":true,"collapsed":true,"items":[{"type":"doc","label":"Tensorflow within MLflow","id":"deep-learning/tensorflow/guide/index"}],"link":{"type":"doc","id":"deep-learning/tensorflow/index"}}],"link":{"type":"doc","id":"deep-learning/index"},"collapsed":true,"collapsible":true},{"type":"category","label":"Traditional ML","items":[{"type":"doc","id":"traditional-ml/index","label":"Overview"},{"type":"category","label":"Hyperparameter Tuning with MLflow and Optuna","collapsible":true,"collapsed":true,"items":[{"type":"doc","label":"Full Notebooks","id":"traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/index"},{"type":"doc","label":"The Parent-Child relationship with runs","id":"traditional-ml/hyperparameter-tuning-with-child-runs/part1-child-runs/index"},{"type":"doc","label":"Logging plots with MLflow","id":"traditional-ml/hyperparameter-tuning-with-child-runs/part2-logging-plots/index"}],"link":{"type":"doc","id":"traditional-ml/hyperparameter-tuning-with-child-runs/index"}},{"type":"category","label":"Building Custom Python Function Models with MLflow","collapsible":true,"collapsed":true,"items":[{"type":"doc","label":"Models, Flavors, and PyFuncs in MLflow","id":"traditional-ml/creating-custom-pyfunc/part1-named-flavors/index"},{"type":"doc","label":"Understanding PyFunc in MLflow","id":"traditional-ml/creating-custom-pyfunc/part2-pyfunc-components/index"},{"type":"doc","label":"Full Notebooks","id":"traditional-ml/creating-custom-pyfunc/notebooks/index"}],"link":{"type":"doc","id":"traditional-ml/creating-custom-pyfunc/index"}},{"type":"doc","label":"Serving Multiple Models on a Single Endpoint with a Custom PyFunc Model","id":"traditional-ml/serving-multiple-models-with-pyfunc/index"}],"link":{"type":"doc","id":"traditional-ml/index"},"collapsed":true,"collapsible":true}],"collapsible":true},{"type":"category","label":"Build ðŸ”¨ ","className":"sidebar-top-level-category","collapsed":false,"items":[{"type":"category","label":"MLflow Tracking","items":[{"type":"doc","id":"tracking/index"},{"type":"link","href":"/getting-started/intro-quickstart/","label":"Quickstart"},{"type":"doc","id":"tracking/autolog/index"},{"type":"category","label":"Tracking Server","items":[{"type":"doc","id":"tracking/artifacts-stores/index"},{"type":"doc","id":"tracking/backend-stores/index"},{"type":"category","label":"Tutorials","items":[{"type":"doc","label":"Tracking Experiments with a Local Database","id":"tracking/tutorials/local-database/index"},{"type":"doc","label":"Remote Experiment Tracking with MLflow Tracking Server","id":"tracking/tutorials/remote-server/index"}],"collapsed":true,"collapsible":true}],"link":{"type":"doc","id":"tracking/server/index"},"collapsed":true,"collapsible":true},{"type":"category","label":"Searching Runs & Experiments","items":[{"type":"doc","id":"search-runs/index"},{"type":"doc","id":"search-experiments/index"}],"collapsed":true,"collapsible":true},{"type":"doc","id":"system-metrics/index"}],"link":{"type":"doc","id":"tracking/index"},"collapsed":true,"collapsible":true},{"type":"category","label":"MLflow Model","items":[{"type":"doc","id":"model/index","label":"Overview"},{"type":"doc","label":"Model Signature","id":"model/signatures/index"},{"type":"doc","label":"Dependency Management","id":"model/dependencies/index"},{"type":"doc","label":"Models From Code","id":"model/models-from-code/index"},{"type":"doc","id":"model/python_model","label":"Custom Python Model"}],"collapsed":true,"collapsible":true},{"type":"doc","id":"recipes/index"}],"collapsible":true},{"type":"category","label":"Evaluate & Monitor ðŸ“Š","className":"sidebar-top-level-category","collapsed":false,"items":[{"type":"doc","id":"model-evaluation/index","label":"MLflow Evaluation","translatable":true},{"type":"category","label":"MLflow Tracing (Observability)","items":[{"type":"doc","id":"tracing/index","label":"Overview"},{"type":"doc","id":"tracing/tracing-schema","label":"Data Structure"},{"type":"category","label":"Integrations","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"tracing/integrations/openai","label":"OpenAI"},{"type":"doc","id":"tracing/integrations/langchain","label":"LangChain"},{"type":"doc","id":"tracing/integrations/langgraph","label":"LangGraph"},{"type":"doc","id":"tracing/integrations/llama_index","label":"LlamaIndex"},{"type":"doc","id":"tracing/integrations/bedrock","label":"Bedrock"},{"type":"doc","id":"tracing/integrations/dspy","label":"DSPy"},{"type":"doc","id":"tracing/integrations/autogen","label":"AutoGen"},{"type":"doc","id":"tracing/integrations/crewai","label":"CrewAI"},{"type":"doc","id":"tracing/integrations/anthropic","label":"Anthropic"},{"type":"doc","id":"tracing/integrations/litellm","label":"LiteLLM"},{"type":"doc","id":"tracing/integrations/swarm","label":"Swarm"},{"type":"doc","id":"tracing/integrations/gemini","label":"Gemini"},{"type":"doc","id":"tracing/integrations/ollama","label":"Ollama"},{"type":"doc","id":"tracing/integrations/mistral","label":"Mistral"},{"type":"doc","id":"tracing/integrations/groq","label":"Groq"},{"type":"doc","id":"tracing/integrations/instructor","label":"Instructor"},{"type":"doc","id":"tracing/integrations/contribute","label":"Add New Integration"}],"link":{"type":"doc","id":"tracing/integrations/index"}},{"type":"category","label":"APIs","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"tracing/api/manual-instrumentation","label":"Manual Tracing"},{"type":"doc","id":"tracing/api/search","label":"Query Traces"},{"type":"doc","id":"tracing/api/how-to","label":"How-to Guide"},{"type":"doc","id":"tracing/api/client","label":"Low-level Client APIs"}],"link":{"type":"doc","id":"tracing/api/index"}},{"type":"doc","id":"tracing/production","label":"Production Monitoring"},{"type":"doc","id":"tracing/session","label":"Session"},{"type":"doc","id":"tracing/faq","label":"FAQ"},{"type":"category","label":"Tutorials","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"tracing/tutorials/concept"}],"link":{"type":"doc","id":"tracing/tutorials/index"}},{"type":"doc","id":"tracing/ui"}],"link":{"type":"doc","id":"tracing/index"},"collapsed":true,"collapsible":true},{"type":"doc","id":"dataset/index","label":"MLflow Dataset","translatable":true}],"collapsible":true},{"type":"category","label":"Deploy ðŸš€","className":"sidebar-top-level-category","collapsed":false,"items":[{"type":"doc","id":"model-registry/index"},{"type":"category","label":"MLflow Serving","items":[{"type":"doc","id":"deployment/index","label":"Overview"},{"type":"doc","label":"Deploy MLflow Model as a Local Inference Server","id":"deployment/deploy-model-locally/index"},{"type":"doc","label":"Deploy MLflow Model to Amazon SageMaker","id":"deployment/deploy-model-to-sagemaker/index"},{"type":"category","label":"Deploy MLflow Model to Kubernetes","collapsible":true,"collapsed":true,"items":[{"type":"doc","label":"Develop ML model with MLflow and deploy to Kubernetes","id":"deployment/deploy-model-to-kubernetes/tutorial/index"}],"link":{"type":"doc","id":"deployment/deploy-model-to-kubernetes/index"}}],"collapsed":true,"collapsible":true},{"type":"doc","id":"llms/deployments/index","label":"MLflow AI Gateway","translatable":true}],"collapsible":true},{"type":"category","label":"Team Collaboration ðŸ‘¥","className":"sidebar-top-level-category","collapsed":true,"items":[{"type":"link","href":"/tracking/#tracking-setup","label":"Self-Hosting"},{"type":"link","href":"/#running-mlflow-anywhere","label":"Managed Services"},{"type":"doc","id":"auth/index","label":"Access Control","translatable":true},{"type":"doc","id":"projects/index","label":"MLflow Projects","translatable":true}],"collapsible":true},{"type":"category","label":"API References","className":"sidebar-top-level-category","collapsed":true,"items":[{"type":"link","label":"Python API","href":"https://mlflow.org/docs/latest/api_reference/python_api/index.html"},{"type":"link","label":"Java API","href":"https://mlflow.org/docs/latest/api_reference/java_api/index.html"},{"type":"link","label":"R API","href":"https://mlflow.org/docs/latest/api_reference/R-api/index.html"},{"type":"link","label":"REST API","href":"https://mlflow.org/docs/latest/api_reference/rest-api/index.html"},{"type":"link","label":"CLI","href":"https://mlflow.org/docs/latest/api_reference/cli.html"}],"collapsible":true},{"type":"category","label":"More","collapsed":true,"className":"sidebar-top-level-category","items":[{"type":"link","label":"Contributing","href":"https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md"},{"type":"link","label":"MLflow Blogs","href":"https://mlflow.org/blog/index.html"},{"type":"doc","id":"plugins/index"}],"collapsible":true}]}}]}},"docusaurus-plugin-content-blog":{"default":{"blogSidebarTitle":"Recent posts","blogPosts":[],"blogListPaginated":[],"blogTags":{},"blogTagsListPath":"/blog/tags"}},"docusaurus-plugin-content-pages":{"default":null},"docusaurus-plugin-debug":{},"docusaurus-theme-classic":{},"docusaurus-theme-search-algolia":{},"docusaurus-plugin-client-redirects":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}
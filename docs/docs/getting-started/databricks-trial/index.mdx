---
sidebar_position: 2
---

# Databricks Free Trial

The [Databricks Free Trial](https://docs.databricks.com/en/getting-started/free-trial.html) offers an opportunity to experience a fully managed, hosted version of the Databricks platform. 
Most Databricks features, including full MLflow functionality are available during the trial period, allowing you to explore the platform with trial credits.

To get started with Databricks Free Trial, visit the [Databricks Trial Signup Page](http://signup.databricks.com)
and follow the instructions outlined there. It takes about 5 minutes to set up, and you'll have and you'll have access to a nearly fully functional Databricks Workspace for logging your tutorial experiments, runs, and artifacts.

Once you log in to the Databricks Workspace, you will see a landing page like this:

<figure>
  ![Databricks Trial Landing Page](/images/tutorials/introductory/lighthouse/landing-page.png)
  <figcaption style={{ textAlign: "center" }}>Databricks Landing Page</figcaption>
</figure>

In order to get to the MLflow UI, you can navigate to it by clicking on the "Experiments" link on the left-hand side (denoted by the laboratory beaker icon).
When you get to the MLflow UI on Databricks for the first time, you'll see this:

<figure>
  ![Databricks Trial MLflow UI](/images/tutorials/introductory/lighthouse/experiments-page.png)
    <figcaption style={{ textAlign: "center" }}>Databricks MLflow UI</figcaption>
</figure>

## Decisions about where to run your Notebook

With a Databricks managed instance of MLflow, you have two options for running the tutorial notebooks:

<details>
  <summary>**Expand to learn about Importing Notebooks directly into Databricks Workspace**</summary>

  Once you're at the main page of the Databricks Workspace, you can import any of the notebooks within this tutorial by navigating to the "Workspace" tab on the left.
  Click that link to expand the file navigation pane. From there, navigate to `Users/<you>` and you can right click to bring up the "Import" option.
  The below image shows what the import dialog should look like if you're going to directly import a notebook from the MLflow documentation website:
  
  ![Databricks Workspace import Notebook from MLflow docs website](/images/tutorials/introductory/lighthouse/import-notebook.png)

  At this point, you can simply just run the tutorial.
  
  Any calls to MLflow for creating experiments, initiating runs, logging metadata, and saving artifacts will be fully managed for you and your logging history will appear within the MLflow UI.
</details>

<details>
  <summary>**Expand to learn about Running Notebooks locally and using Databricks Workspace as a remote tracking server**</summary>

  In order to stay within the comfortable confines of your local machine and still have the use of the managed MLflow Tracking Server,
  you can authenticate via a Personal Access Token (PAT). 
  Generate a PAT by following [this guide](https://docs.databricks.com/en/dev-tools/auth/pat.html).

  Afterward, connect to the Databricks Workspace by calling `mlflow.login()` in your notebook.

  ```python
  import mlflow

  mlflow.login()
  ```
  This command will ask you about the Databricks host and PAT. Fill your workspace's url and PAT.
  Once logged in, you will simply have to set your MLflow Tracking URI to the Workspace that you just logged in to:
  
  ```python
  mlflow.set_tracking_uri("databricks")
  ```
</details>

At this point, you're ready to go! You can run any of the tutorials locally and they will log to the managed MLflow Tracking Server.

---
sidebar_position: 2
---

# Databricks Free Trial

The [Databricks Free Trial](https://docs.databricks.com/en/getting-started/free-trial.html) offers an opportunity to try a fully managed, Databricks-hosted version of the Databricks platform. 
The vast majority of Databricks features including full MLflow functionalities are available within free trial credits and trial time period.

To get started with Databricks Free Trial, please visit the [Databricks Trial Signup Page](http://signup.databricks.com)
and follow the instructions outlined there. It takes about 5 minutes to get started, and you'll have a (mostly) fully functional Databricks Workspace that you
can use to log your tutorial experiments, runs, and artifacts to.

Once you log in to the Databricks Workspace, you will see a landing page like this:

<figure>
  ![Databricks Trial Landing Page](/images/tutorials/introductory/lighthouse/landing-page.png)
  <figcaption style={{ textAlign: "center" }}>Databricks Landing Page</figcaption>
</figure>

In order to get to the MLflow UI, you can navigate to it by clicking on the "Experiments" link on the left-hand side (denoted by the laboratory beaker icon).
When you get to the MLflow UI on Databricks for the first time, you'll see this:

<figure>
  ![Databricks Trial MLflow UI](/images/tutorials/introductory/lighthouse/experiments-page.png)
    <figcaption style={{ textAlign: "center" }}>Databricks MLflow UI</figcaption>
</figure>

## Decisions about where to run your Notebook

With a Databricks managed instance of MLflow, you have two options for running the tutorial notebooks:

<details>
  <summary>**Expand to learn about Importing Notebooks directly into Databricks Workspace**</summary>

  Once you're at the main page of the Databricks Workspace, you can import any of the notebooks within this tutorial by navigating to the "Workspace" tab on the left.
  Click that link to expand the file navigation pane. From there, navigate to `Users/<you>` and you can right click to bring up the "Import" option.
  The below image shows what the import dialog should look like if you're going to directly import a notebook from the MLflow documentation website:
  
  ![Databricks Workspace import Notebook from MLflow docs website](/images/tutorials/introductory/lighthouse/import-notebook.png)

  At this point, you can simply just run the tutorial.
  
  Any calls to MLflow for creating experiments, initiating runs, logging metadata, and saving artifacts will be fully managed for you and your logging history will appear within the MLflow UI.
</details>

<details>
  <summary>**Expand to learn about Running Notebooks locally and using Databricks Workspace as a remote tracking server**</summary>

  In order to stay within the comfortable confines of your local machine and still have the use of the managed MLflow Tracking Server,
  you can authenticate through Personal Access Token (PAT). 
  Generate PAT by following [this guide](https://docs.databricks.com/en/dev-tools/auth/pat.html) and configure the `.databrickscfg` file with the following format:
  ```
  [DEFAULT]
  host = https://dbc-xxxxxxx-xxxx.cloud.databricks.com  # Replace with your Workspace URL
  token = REPLACE_ME # Replace with your copied PAT
  ```

  Then, you can connect to the Databricks Workspace by calling `mlflow.login()` in your notebook.

  ```python
  import mlflow

  mlflow.login()
  ```

  After the login process is done, you will simply have to set your MLflow Tracking URI to the instance that you just logged in to.
  
  It's made fairly easy for you:
  
  ```python
  mlflow.set_tracking_uri("databricks")
  ```
</details>

At this point, you're ready to go! You can run any of the tutorials locally and they will log to the managed MLflow Tracking Server.

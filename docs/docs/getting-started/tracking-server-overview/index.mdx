import { APILink } from "@site/src/components/APILink";

# 5 Minute Tracking Server Overview

In this guide we will walk you through how to view your MLflow experiment results with different types of
tracking server configurations. At a high level, there are 3 ways to view your MLflow experiments:

- **[Method 1]** Start your own MLflow server.
- **[Method 2]** Use a free hosted tracking server - Databricks Free Trial.
- **[Method 3]** Use production Databricks/AzureML.

To choose among these 3 methods, here is our recommendation:

- If you have privacy concerns (data/model/tech stack), use **Method 1 - start your own server**.
- If you are a student or an individual researcher, or if you are developing in cloud-based notebooks (e.g., Google
  Colab), use **Method 2 - free hosted tracking server**.
- Enterprise users, or if you want to serve or deploy your model for a production use-case, please use
  **Method 3 - production Databricks/AzureML**.

Overall **Method 2 - free hosted tracking server** is the simplest way to get started with MLflow, but please
pick the method that best suits your needs.

## Method 1: Start Your Own MLflow Server

**Disclaimier**: This part of guide is not suitable for running in a cloud-provided IPython environment
(e.g., Collab, Databricks). Please follow the guide below in your local machine (laptop/desktop).

A hosted tracking server is the simplest way to store and view MLflow experiments, but it is not suitable for
every user. For example, you may not want to expose your data and model to others in your cloud provider account. In this case,
you can use a local hosted MLflow server to store and view your experiments. To do so, there are two steps:

- Start your MLflow server.
- Connect MLflow session to the local MLflow server IP by <APILink fn="mlflow.set_tracking_uri" />.

### Start a Local MLflow Server

If you don't have MLflow installed, please run the command below to install it:

```bash
$ pip install mlflow
```

The installation of MLflow includes the MLflow CLI tool, so you can start a local MLflow server with UI
by running the command below in your terminal:

```bash
$ mlflow ui
```

It will generate logs with the IP address, for example:

```bash
(mlflow) [master][~/Documents/mlflow_team/mlflow]$ mlflow ui
[2023-10-25 19:39:12 -0700] [50239] [INFO] Starting gunicorn 20.1.0
[2023-10-25 19:39:12 -0700] [50239] [INFO] Listening at: http://127.0.0.1:5000 (50239)
```

Opening the URL of the MLflow tracking server in your browser will bring you to the MLflow UI. The image below is from the open source version of the MLflow UI,
which is a bit different from the MLflow UI on Databricks Workspaces. Below is a screenshot of the landing page:

<div className="center-div" style={{ width: 800, maxWidth: "100%" }}>
  ![Landing page of OSS MLflow server](/images/quickstart/tracking-server-overview/mlflow-localhost-landing-page.png)
</div>

:::note
It's also possible to deploy your own MLflow server on cloud platforms, but it is out of the scope of this guide.
:::

### Connect MLflow Session to Your Server

Now that the server is spun up, let's connect our MLflow session to the local server. This is very
similar to how we connect to a remote hosted tracking provider such as the Databricks platform.

```python
mlflow.set_tracking_uri("http://localhost:5000")
```

Next, let's try logging some dummy metrics. We can view these test metrics on the local hosted UI:

```python
mlflow.set_experiment("check-localhost-connection")

with mlflow.start_run():
    mlflow.log_metric("foo", 1)
    mlflow.log_metric("bar", 2)
```

Putting it together you can copy the following code to your editor and save it as _log_mlflow_with_localhost.py_:

```python
import mlflow

mlflow.set_tracking_uri("http://localhost:5000")
mlflow.set_experiment("check-localhost-connection")

with mlflow.start_run():
    mlflow.log_metric("foo", 1)
    mlflow.log_metric("bar", 2)
```

Then execute it by:

```bash
$ python log_mlflow_with_localhost.py
```

### View Experiment on Your MLflow Server

Now let's view your experiment on the local server. Open the URL in your browser, which is _http://localhost:5000_
in our case. In the UI, inside the left sidebar you should see the experiment with name
_"check-localhost-connection"_. Clicking on this experiment name should bring you to the experiment view, similar to what is shown below.

<div className="center-div" style={{ width: 800, maxWidth: "100%" }}>
  ![Experiment view of OSS MLflow server](/images/quickstart/tracking-server-overview/mlflow-localhost-experiment-view.png)
</div>

Clicking on the run (_"clumsy-steed-426"_ in this example, yours will be different) will bring you to the run view, similar as below.

<div className="center-div" style={{ width: 800, maxWidth: "100%" }}>
  ![Run view of OSS MLflow server](/images/quickstart/tracking-server-overview/mlflow-localhost-run-view.png)
</div>

### Conclusion

That's all about how to start your own MLflow server and view your experiments. Please see the pros and cons
of this method below:

- **Pros**

  - You have full control of your data and model, which is good for privacy concerns.
  - No subscription is required.
  - Unlimited quota of experiments/runs.
  - You can even customize your UI by forking the MLflow repo and modify the UI code.

- **Cons**

  - Requires manual setup and maintenance.
  - Team collaboration is harder than using a hosted tracking server.
  - Not suitable for cloud-based notebook, e.g., Google Colab.
  - Requires extra port forwarding if you deploy your server on cloud VM.
  - No serving support.

## Method 2: Use Free Hosted Tracking Server (Databricks Free Trial)

**Notice**: This part of guide can be directly executed in cloud-based notebook, e.g., Google Colab or
Databricks Notebook.

The [Databricks Free Trial](https://docs.databricks.com/en/getting-started/free-trial.html) offers an opportunity to experience a fully managed, hosted version of the Databricks platform. 
Databricks Free Trial users can access nearly full functionlities of the Databricks platform for free. 
You can use a Databricks Workspace to store and view your MLflow experiments without being charged within the free trial period.

To use Databricks Free Trial to store and view your MLflow experiments, basically you need to:

- Sign up for Databricks Free Trial.
- Generate a Personal Access Token (PAT)
- Set up Databricks workspace authentication in your dev environment.
- Connect to your Databricks Workspace in your MLflow experiment session.

Then the experiment results will be automatically sent to your Databricks Workspace, where you can view it in
MLflow experiment UI. Now let's look at the code.

### Signup for Databricks Free Trial

If you don't have an account of the Databricks Free Trial yet, you can create one
[here](http://signup.databricks.com). The full process should take no longer than 5 minutes.

### Generate a PAT
To create a PAT for your Databricks workspace user, follow the steps here:

1. In your Databricks workspace, click your Databricks username in the top bar, and then select Settings from the drop down.

2. Click **Developer**.

3. Next to Access tokens, click **Manage**.

4. Click **Generate new token**.

5. Enter a comment that helps you to identify this token in the future.

6. Set the token's lifetime in days. By default, the maximum token lifetime for a workspace is 730 days.

7. Click **Generate**.

8. Copy the displayed token to a secure location, and then click **Done**.

### Install Dependencies
Run the following command in your dev environment to install dependencies.

```bash
%pip install -q mlflow[databricks]
```

### Set Up Authentication of Databricks Workspace

To set up Databricks Workspace authentication, we can use the API <APILink fn="mlflow.login" />, which will prompt you for required information:

- **Databricks Host**: Use https://community.cloud.databricks.com/
- **Token**: Your personal access token for your Databricks Workspace.

If the authentication succeeds, you should see a message "Successfully signed in Databricks!".

```python
import mlflow

mlflow.login()
```

```
2025/02/19 12:25:04 INFO mlflow.utils.credentials: No valid Databricks credentials found, please enter your credentials...
Databricks Host (should begin with https://):  https://<your workspace host>.cloud.databricks.com/
Token:  ········
2025/02/19 12:26:24 INFO mlflow.utils.credentials: Successfully connected to MLflow hosted tracking server! Host: https://<your workspace host>.cloud.databricks.com.
```

### Connect MLflow Session to Databricks Workspace

We have set up the credentials, now we need to tell MLflow to send the data into Databricks Workspace.
To do so, we will use `mlflow.set_tracking_uri("databricks")` to port MLflow to Databricks Workspace. Basically
it is the command below. Please note that you need to always use _"databricks"_ as the keyword.

```python
mlflow.set_tracking_uri("databricks")
```

Now you are ready to go! Let's try starting an MLflow experiment and log some dummy metrics and view it in the UI.

```python
mlflow.set_experiment("/Users/<your email>/check-databricks-connection")

with mlflow.start_run():
    mlflow.log_metric("foo", 1)
    mlflow.log_metric("bar", 2)
```

```
2025/02/19 12:26:33 INFO mlflow.tracking.fluent: Experiment with name '/Users/<your email>/check-databricks-ce-connection' does not exist. Creating a new experiment.
```

### View Your Experiment on Databricks Workspace

Now let's navigate to your Databricks Workspace to view the experiment result. Log in to your
Databricks Workspace, and click on top left to select machine learning
in the drop down list. Then click on the experiment icon. See the screenshot below:

<div className="center-div" style={{ width: 800, maxWidth: "100%" }}>
  ![Landing page of Databricks MLflow server](/images/quickstart/tracking-server-overview/databricks-lighthouse-landing-page.png)
</div>

In the "Experiments" view, you should be able to find the experiment "check-databricks-connection", similar to

<div className="center-div" style={{ width: 800, maxWidth: "100%" }}>
  ![Experiment view of Databricks MLflow server](/images/quickstart/tracking-server-overview/databricks-lighthouse-experiment-view.png)
</div>

Clicking on the run name, in our example it is "skillful-jay-111" (it's a randomly generated name, you will see
a different name in your Databricks console), will bring you to the run view, similar to

<div className="center-div" style={{ width: 800, maxWidth: "100%" }}>
  ![Run view of Databricks MLflow server](/images/quickstart/tracking-server-overview/databricks-lighthouse-run-view.png)
</div>

In the run view, you will see your dummy metrics _"foo"_ and _"bar"_ are logged successfully.

### Conclusion

That's all about how to use the Databricks Free Trial as the tracking server. Please see the pros and cons
of this method below:

- **Pros**

  - Effortless setup.
  - Free within free trial credits and periods.
  - Good for collaboration, e.g., you can share your MLflow experiment with your teammates easily.
  - Compatible for developing on cloud-based notebook, e.g., Google Colab.
  - Compatible for developing on cloud VM.

- **Cons**

  - Has quota limit and time limit.

## Method 3: Use Production Hosted Tracking Server

If you are an enterprise user and willing to productionize your model, you can use a production platform like
Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks
MLflow server, and you can register your model then serve your model by a few clicks. 

The method of using production Databricks is the same as using Databricks Free Trial, you only need to
change the host to be the production workspace. For example, `https://dbc-1234567-123.cloud.databricks.com`.
For more information about how Databricks power your Machine Learning workflow, please refer to the [doc
here](https://docs.databricks.com/en/machine-learning/index.html).

To use AzureML as the tracking server, please read
[the doc here](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow-cli-runs?view=azureml-api-2&tabs=interactive%2Ccli)

### Conclusion

That's all about how to use a production platform as the tracking server. Please see the pros and cons
of this method below:

- **Pros**

  - Effortless setup.
  - Good for collaboration, e.g., you can share your MLflow experiment with your teammates easily.
  - Compatible for developing on cloud-based notebook, e.g., Google Colab.
  - Compatible for developing on cloud VM.
  - Seamless model registration/serving support.
  - Higher quota than the Databricks Free Trial (pay as you go).

- **Cons**

  - Not free.
  - Need to manage a billing account.

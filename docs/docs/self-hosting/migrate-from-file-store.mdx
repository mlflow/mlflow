---
title: Migrate from File Store
---

# Migrate from File Store to Database

MLflow's default backend store changed from file-based storage (`./mlruns`) to SQLite database in MLflow 3.6. If you have existing data in a file-based backend, you can migrate it to a database using the built-in migration command.

## Prerequisites

- MLflow 3.x or later installed
- Access to the `mlruns` directory (or wherever your FileStore data lives)

## Quick Start

```bash
mlflow migrate-filestore --source ./mlruns --target sqlite:///mlflow.db
```

This reads all data from the `./mlruns` directory and writes it to a new SQLite database at `mlflow.db`.

## What Gets Migrated

The migration tool transfers **all metadata** stored in the file-based backend:

| Category       | Entities                                              |
| -------------- | ----------------------------------------------------- |
| Experiments    | Experiments, experiment tags                          |
| Runs           | Runs, params, metrics, latest metrics, tags           |
| Datasets       | Datasets, inputs, input tags                          |
| Run I/O        | Model inputs (run → model), model outputs (run → model) |
| Traces         | Trace info, trace tags, trace request metadata        |
| Assessments    | Assessments (feedback, expectations)                  |
| Logged Models  | Logged models, tags                                   |
| Model Registry | Registered models, model versions, tags, aliases      |

### What Is NOT Migrated

- **Artifacts** (model files, images, etc.) — these stay in their original location. The database stores the same artifact URIs that point to the existing files.
- **Trace spans** — stored as artifact files, not in the database.

## Options

| Option                     | Description                                                      |
| -------------------------- | ---------------------------------------------------------------- |
| `--source`                 | Path to the directory containing FileStore data.                 |
| `--target`                 | SQLite URI for the target database (e.g. `sqlite:///mlflow.db`). |
| `--progress/--no-progress` | Show or hide per-experiment progress messages (default: on).     |

The `--source` can point to either:

- A directory containing an `mlruns/` subdirectory
- The `mlruns` directory itself

## Step-by-Step Guide

### 1. Stop the MLflow server

If you're running a tracking server, stop it before migrating.

### 2. Back up your data

```bash
cp -r ./mlruns ./mlruns.backup
```

### 3. Run the migration

```bash
mlflow migrate-filestore --source ./mlruns --target sqlite:///mlflow.db
```

The command prints progress for each experiment and model:

```
Source: ./mlruns
Target: sqlite:///mlflow.db

Initializing database schema...
[1/5] Migrating experiment 123456789...
[2/5] Migrating experiment 234567890...
[3/5] Migrating experiment 345678901...
[4/5] Migrating experiment 456789012...
[5/5] Migrating experiment 567890123...
[1/3] Migrating model my_model...
[2/3] Migrating model other_model...
[3/3] Migrating model prompt_qa...

Migration completed successfully!

==================================================
Migration summary:
==================================================
  entity                       migrated      in DB
  ------------------------- ---------- ----------
  experiments                        5          5
  runs                              42         42
  metrics                         1200       1200
  ...
==================================================
  source: ./mlruns
  target: sqlite:///mlflow.db
==================================================

To start a server with the migrated data:
  mlflow server --backend-store-uri sqlite:///mlflow.db
```

The migration is atomic — all data is committed in a single transaction at the end. If any error occurs, the entire migration is rolled back and the database remains empty, so you can safely re-run the command after fixing the issue. Entity types that don't exist in your FileStore (e.g., traces if you never used tracing) are automatically skipped.

### 4. Start the server with the new database

```bash
mlflow server --backend-store-uri sqlite:///mlflow.db
```

### 5. Verify

Open the MLflow UI and confirm your experiments, runs, and models are present.

## Important Notes

- **Target database must be empty.** The migration tool refuses to write to a database that already contains data to prevent conflicts. If the target file already exists, you will be prompted to overwrite it.
- **Original IDs are preserved.** Experiment IDs, run UUIDs, and all timestamps are kept exactly as they were in the file store.
- **Deleted items are included.** Experiments and runs in the `.trash` directory are migrated with their `deleted` lifecycle stage preserved.
- **SQLite only.** The initial version supports SQLite as the target database. FileStore generates large experiment IDs that exceed the 32-bit integer limit enforced by PostgreSQL and MySQL, but SQLite handles them natively.
- **Atomic migration.** The entire migration runs in a single transaction. If any error occurs, everything is rolled back and the database stays empty — no partial data is left behind.

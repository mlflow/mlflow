---
title: Migrate from File Store
---

# Migrate from File Store to Database

If you have existing data in a file-based backend (`./mlruns`), you can migrate it to a database using the built-in migration command.

## Prerequisites

MLflow 3.10 or later installed. Run the following command to upgrade if needed:

```bash
pip install 'mlflow>=3.10'
```

## Quick Start

```bash
mlflow migrate-filestore --source /path/to/mlruns --target sqlite:///path/to/mlflow.db
```

This reads all data from the specified directory and writes it to the specified SQLite database.

## What Gets Migrated

The migration tool transfers **all metadata** stored in the file-based backend:

| Category       | Entities                                                 |
| -------------- | -------------------------------------------------------- |
| Experiments    | Experiments, experiment tags                             |
| Runs           | Runs, params, metrics, latest metrics, tags              |
| Datasets       | Datasets, inputs, input tags                             |
| Run I/O        | Model inputs (run → model), model outputs (run → model)  |
| Traces         | Trace info, trace tags, trace request metadata           |
| Assessments    | Assessments (feedback, expectations)                     |
| Logged Models  | Logged models, tags                                      |
| Model Registry | Registered models, model versions, tags, aliases         |
| Prompts        | Prompts (stored as registered models and model versions) |

### What Is NOT Migrated

- **Artifacts** (model files, images, etc.) stay in their original location. The database stores the same artifact URIs that point to the existing files.
- **Trace spans** are stored as artifact files, not in the database.

## Step-by-Step Guide

### 1. Stop the MLflow server

If you're running a tracking server, stop it before migrating.

### 2. Run the migration

```bash
mlflow migrate-filestore --source /path/to/mlruns --target sqlite:///path/to/mlflow.db
```

The command prints progress for each experiment and registered model, followed by a summary of migrated entity counts and actual database row counts.

The migration is atomic. If any error occurs, the entire migration is rolled back and the database remains empty, so you can safely re-run the command after fixing the issue.

### 3. Start the server with the new database

```bash
mlflow server --backend-store-uri sqlite:///path/to/mlflow.db
```

### 4. Verify

Open the MLflow UI and confirm your experiments, runs, and models are present.

## Lossless Migration

The migration tool preserves your data exactly as it was in the FileStore. No timestamps are altered.

- **All IDs** (experiment, run, trace, model, etc.) are preserved as-is. Internal linkage IDs for dataset inputs and run I/O are generated because FileStore does not persist them.
- **All timestamps** (`creation_time`, `start_time`, `end_time`, `last_update_time`) retain their original millisecond precision.
- **Deleted items are included.** Experiments and runs in the `.trash` directory are migrated with their `deleted` lifecycle stage preserved.
- **Artifact URIs** remain unchanged, pointing to the same files on disk.

### Comparison with `mlflow-export-import`

|                                  | `mlflow migrate-filestore`      | [`mlflow-export-import`](https://github.com/mlflow/mlflow-export-import) |
| -------------------------------- | ------------------------------- | ------------------------------------------------------------------------ |
| **Use case**                     | Migrate FileStore to a database | Recreate data between MLflow servers                                     |
| **Preserves IDs and timestamps** | Yes                             | No (regenerated on import)                                               |
| **Requires a running server**    | No                              | Yes (both source and target)                                             |
| **Target**                       | SQLite                          | Any MLflow server                                                        |

## Important Notes

- **Target database must be empty.** The migration tool refuses to write to a database that already contains data to prevent conflicts. If the target file already exists, you will be prompted to overwrite it.
- **SQLite only.** The migration tool only supports SQLite as the target database. FileStore generates large experiment IDs that exceed the 32-bit integer limit enforced by PostgreSQL and MySQL, but SQLite handles them natively.

If you run into issues or have feedback (e.g., support for PostgreSQL/MySQL), please comment on [GitHub issue #18534](https://github.com/mlflow/mlflow/issues/18534).

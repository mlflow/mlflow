---
sidebar_label: MLflow 3.0
sidebar_position: 1
---

import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";
import { APILink } from "@site/src/components/APILink";
import { CardGroup, PageCard } from "@site/src/components/Card";

# MLflow 3.0

Discover the next generation of MLflow, designed to streamline your AI experimentation and accelerate your journey from idea to production. MLflow 3.0 brings cutting-edge support for GenAI workflows, enabling seamless integration of generative AI models into your projects.

## What is MLflow 3.0?

MLflow 3.0 delivers best-in-class experiment tracking, observability, and performance evaluation for machine learning models, AI applications, and generative AI agents!
MLflow 3.0 introduces a variety of exciting improvements, including:
- Centrally track and analyze the performance of your models and generative AI applications **across all environments**, from interactive queries in a development notebook through production batch or real-time serving deployments.
- Gain insights into model performance with **comprehensive metrics and lineage tracking**, enabling better decision-making for production readiness.
- Streamline the handling of model artifacts and evaluation results with a **cohesive structure** that improves observability and traceability.

Model Tracking helps you create and evaluate different model/agent configurations in your experiments, <APILink fn="mlflow.entities.LoggedModel">LoggedModel</APILink> helps you find the best ones for production usage, and tracing helps enhance observability in your model or GenAI applications.


## Model Tracking with LoggedModel

In MLflow 3.0, we introduce a refined architecture along with revamped APIs and UI, tailored to enhance deep learning and generative AI workflows. 
In deep learning, training often generates multiple model checkpoints, where the best candidates are further evaluated before production deployment. 
With GenAI agents, there are multiple rounds of offline evaluation via batch jobs and interactive queries from human beta testers. 

We are introducing a new first-class object, the Logged Model entity, into MLflow Tracking to streamline these processes. As your deep learning jobs create and evaluate models, 
or you define and evaluate your GenAI agents in code, they will be automatically stored as MLflow Logged Models in your MLflow Experiment. 

Every deep learning checkpoint is stored as a Logged Model with direct links to its own metrics. There is no longer any need to carefully log evaluation metrics for each checkpoint
at its epoch all within the same Run, or to later query all metrics at a certain epoch just to retrieve metrics for one checkpoint. 
Similarly, each GenAI agent consolidates its evaluation metrics from both offline jobs and online interactions if you use managed MLflow with Databricks. 
This feature removes the need to query Runs for traces from different environments (batch jobs, different notebook sessions etc.) to gain a full understanding of the agentâ€™s performance.

Specifically, you will be able to:
- View Logged Models alongside key information, including code and weights as artifacts and configurable parameters that affect model behavior
- Holistically track all performance metrics related to your logged models with links to training and evaluation jobs
- Search for and rank existing models based on a set of certain criteria, such as performance metrics on training or evaluation datasets

Simple example:

```python
import mlflow


class MyModel(mlflow.pyfunc.PythonModel):
    @mlflow.trace
    def predict(self, model_input: list[str]):
        return ",".join(model_input)


with mlflow.start_run():
    model_info = mlflow.pyfunc.log_model(
        python_model=MyModel(), name="my_model", input_example=["a", "b", "c"]
    )

print(f"LoggedModel model id: {model_info.model_id}")

pyfunc_model = mlflow.pyfunc.load_model(model_info.model_uri)
pyfunc_model.predict(["x", "y", "z"])
traces = mlflow.search_traces(model_id=model_info.model_id)
print(traces)

#                          request_id                                              trace   timestamp_ms  ...                                              spans                                               tags assessments
# 0  af5da8c78a6f49c793f57ebb19dcb6c7  Trace(request_id=af5da8c78a6f49c793f57ebb19dcb...  1742781867233  ...  [{'name': 'predict', 'context': {'span_id': '0...  {'mlflow.artifactLocation': 'file:///Users/ser...          []
```

## MLflow 3.0 Showcases

Explore the examples below to see how MLflow 3.0's powerful features can be applied across various domains.

<CardGroup>
  <PageCard headerText="Deep Learning with MLflow 3.0" link="/mlflow-3/deep-learning" text="Learn how to leverage MLflow 3.0 to identify the best models in deep learning workflows." />
  <PageCard headerText="GenAI with MLflow 3.0" link="/mlflow-3/genai-agent" text="Discover how to log, evaluate, and trace GenAI agents using MLflow 3.0." />
</CardGroup>

## Migration Guide

MLflow 3.0 introduces some key API changes while also removes some outdated features. This guide will help you transition smoothly to the latest version.

### Key changes

- `mlflow.<flavor>.log_model` API usage: `artifact_path` parameter is deprecated, use **`name`** instead
<Tabs>
    <TabItem label="MLflow 2.x" value="mlflow_2" default>
        ```python
        with mlflow.start_run():
            mlflow.pyfunc.log_model(artifact_path="model", python_model=python_model, ...)
        ```
    </TabItem>
    <TabItem label="MLflow 3.0" value="mlflow_3">
        Pass `name` when logging a model. This allows you to later search for LoggedModels using this name.
        ```python
        with mlflow.start_run():
            mlflow.pyfunc.log_model(name="python_model", python_model=python_model, ...)
        ```
    </TabItem>
</Tabs>

- Model artifacts storage location change: In MLflow 2.x, [model artifacts](../model/#storage-format) are stored as run artifacts. 
Since MLflow 3.0, those artifacts will be stored into models artifacts location. Note: this impacts the behavior of <APILink fn="mlflow.client.MlflowClient.list_artifacts">``list_artifacts``</APILink> API.

### Removed Features

- MLflow Recipes
- Flavors: the following model flavors are no longer supported
    - fastai
    - h2o
    - mleap
- AI gateway client APIs: use deployments APIs instead


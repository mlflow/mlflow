---
sidebar_position: 0
---

import Link from "@docusaurus/Link";
import { APILink } from "@site/src/components/APILink";
import { CardGroup, PageCard } from "@site/src/components/Card";

# MLflow OpenAI Flavor

:::warning attention
The `openai` flavor is under active development and is marked as Experimental. Public APIs are
subject to change, and new features may be added as the flavor evolves.
:::

## Introduction

**OpenAI's GPT Models** represent a significant leap in natural language processing (NLP) capabilities.
The Generative Pre-trained Transformer (GPT) models are renowned for
their ability to generate human-like text, comprehend complex queries, summarize extensive documents,
and much more. [OpenAI](https://openai.com) has been at the forefront of NLP technology, offering models that are
versatile and widely applicable in various domains.

Leveraging MLflow's robust experiment tracking and model management framework, the integration with
OpenAI's [GPT-based models](https://platform.openai.com/docs/models) enables practitioners to efficiently utilize these advanced NLP tools in their
projects. From simple text generation to complex conversational AI applications, the MLflow-OpenAI
integration brings a new level of ease and effectiveness to managing these powerful models.

The integration includes:

- **Text Analysis and Generation**: Utilizing models like GPT-3.5 and GPT-4 for diverse text-related tasks.
- **Conversational AI**: Exploring the capabilities of the Chat Completions API for interactive, context-aware applications.
- **Embeddings Generation**: Corpus and text embeddings generation capabilities for advanced document retrieval use cases.

## Autologging Support for the OpenAI integration

If you'd like to learn more about autologging support for OpenAI within MLflow, please visit the [OpenAI Autologging](/llms/openai/autologging) page.

## Tracing with the OpenAI flavor

MLflow's OpenAI flavor includes an integrated automated tracing feature with the use of the <APILink fn="mlflow.openai.autolog" /> API. To learn more about
how to log your development usage of the OpenAI SDK, please visit the [guide to autologging tracing](/llms/tracing#automatic-tracing) for this flavor.

## What makes this Integration so Special?

The combination of MLflow's experiment tracking and model management with OpenAI's cutting-edge NLP models unlocks new potential for AI applications.
This MLflow flavor for OpenAI simplifies the process of:

- **Developing** an application that leverages the power of OpenAI's models. By simplifying the process of keeping track of the highly iterative and creative process of prompt engineering, [MLflow prompt engineering](/llms/prompt-engineering) makes sure that you never lose track of a great idea.
- **Auditing and Reviewing** your most promising experiments. The [MLflow tracking service](/tracking) means that you can easily share the results of your work and get peer review of your work.
- **Customizing** the interface to your application. Whether you want to allow creative control with exposing parameters such as _temperature_ or to relax cost controls by exposing _max_tokens_, MLflow allows you to configure default values and restrict the ability to modify the parameters used for inference.
- **Tagging and annotating** particular runs with [tags](/tracking/tracking-api#adding-tags-to-runs) during the iterative prompt engineering phase to flag particularly promising ideas that you and others can revisit later for inspiration, further testing, or deployment.

### The Elephant in the Room: Prompt Engineering

In other fields of applied ML, the process of iterating over hypotheses is time-consuming, tedious, and lends itself to developing habits of meticulously
recording every step of the feature refinement and training process. With the advent of generative AI and the latent power of state-of-the-art LLMs such as
those offered by OpenAI, the process of refining the performance of a solution is much shorter. In the span of an hour, you could easily craft and test
a dozen prompts.

While this speed and ease of use is remarkably empowering, it generally leads to the dreaded realization after a few hours of experimentation that you can't
remember which of the dozens of prompts that you created hours ago was the one that created the best results that you remember seeing.

This is where MLflow comes in. With MLflow, you can easily track the prompts that you use, the results that you get, and the artifacts that you generate.

The figure below shows a fun take on this problem that MLflow helps to solve.

<figure className="center-div" style={{ width: "80%", textAlign: "center" }}>
  ![MLflow OpenAI Prompt Engineering](/images/tutorials/llms/prompt-engineering.png)
  <figcaption>Prompt Engineering for space flight with MLflow</figcaption>
</figure>

By logging each of the prompts that are used throughout testing, not only can you easily reproduce the results that you get, but you can also share those
results with others so that they can evaluate the subjective quality of the results. Without tracking in place, you're forced to come up with a solution for
recording the various parameters, prompts, test inputs, and results.

You could save all of that time and effort by using MLflow with OpenAI, giving you more time to come up with fun prompts.

## Features

With the MLflow OpenAI flavor, users can:

- **Save** and **log** applications using OpenAI models within MLflow using <APILink fn="mlflow.openai.save_model" /> and <APILink fn="mlflow.openai.log_model" />.
- Seamlessly track detailed experiments, including **parameters**, **prompts**, and **artifacts** associated with model runs.
- [Deploy](/deployment) OpenAI models for various NLP applications with ease.
- Utilize <APILink fn="mlflow.pyfunc.PythonModel">`mlflow.pyfunc.PythonModel`</APILink> for flexible Python function inference, enabling custom and innovative ML solutions.

### What can you do with OpenAI and MLflow?

The integration of OpenAI's advanced NLP models with MLflow's robust model management capabilities opens up a vast array of potential real-world applications. Here are some powerful and impactful use cases:

- **Automated Customer Support**: Develop sophisticated chatbots that understand and respond to customer inquiries in a human-like manner, significantly improving customer service efficiency and satisfaction.
- **Content Generation and Curation**: Automatically generate high-quality, contextually relevant content for articles, blogs, or social media posts. Curate content by summarizing and categorizing large volumes of text data, enhancing content management strategies.
- **Language Translation Services**: Create advanced translation tools that not only convert text from one language to another but also capture nuances, idioms, and cultural context, bridging communication gaps more effectively.
- **Sentiment Analysis for Market Research**: Analyze customer feedback, social media posts, or product reviews to gauge public sentiment about brands, products, or services, providing valuable insights for marketing and product development teams.
- **Personalized Education and Training Tools**: Develop AI-driven educational platforms that can adapt content and teaching styles to individual learning preferences, making education more engaging and effective.
- **Legal and Compliance Document Analysis**: Automate the review and analysis of legal documents, contracts, and compliance materials, increasing accuracy and reducing the time and resources required for legal workflows.
- **Healthcare Assistance and Research**: Assist in medical research by summarizing and analyzing medical literature, patient records, or clinical trial data, contributing to faster and more informed decision-making in healthcare.
- **Financial Analysis and Forecasting**: Leverage NLP models to analyze financial reports, market trends, and news articles, providing deeper insights and predictions for investment strategies and economic forecasting.

With MLflow's integration, these applications not only benefit from the linguistic prowess of OpenAI's models but also gain from streamlined
[tracking](/tracking), [version control](/model-registry), and [deployment](/deployment) processes.
This synergy empowers developers and businesses to build sophisticated, AI-driven solutions that address complex challenges and create new opportunities in various industries.

### Deployment Made Easy

Deploying OpenAI models becomes a breeze with MLflow. Functions like <APILink fn="mlflow.openai.load_model" /> and <APILink fn="mlflow.pyfunc.load_model" /> facilitate easy model serving.
Discover more about [deploying models with MLflow](/deployment), explore the <Link to="/api_reference/cli.html#mlflow-deployments" target="_blank">deployments API</Link>,
and learn about <Link to="/api_reference/cli.html#mlflow-models-serve" target="_blank">starting a local model serving endpoint</Link> to fully leverage the deployment capabilities of MLflow.

## Getting Started with the MLflow OpenAI Flavor - Tutorials and Guides


<CardGroup>
  <PageCard headerText="MLflow OpenAI Tutorials and Guides" link="/llms/openai/tutorials/index.html" text="Learn different ways that you can leverage the power of the OpenAI library, leveraging MLflow's APIs for tracking, inference, and tracing capabilities." />
</CardGroup>

## [Detailed Documentation](/llms/openai/guide)

To learn more about the details of the MLflow flavor for OpenAI, delve into the comprehensive guide below.

<Link className="button button--primary" to="/llms/openai/guide">
  <span>View the Comprehensive Guide</span>
</Link>

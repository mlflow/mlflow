---
sidebar_position: 5
pagination_next: tracing/index
---

import { Card, LogoCard, CardGroup, PageCard, SmallLogoCard } from "@site/src/components/Card";
import { APILink } from "@site/src/components/APILink";

# MLflow for GenAI

MLflow is built specifically to help developers build complex, production-grade GenAI applications that create business value by delivering **high‑quality (accurate) answers at the optimal cost and latency**.

## Key challenges

:::note 
See the [developer workflow](/llms/eval-workflow) to learn more.
:::

MLflow addresses the 2 inherent challenges in delivering high-quality generative AI:


<CardGroup>
  <PageCard
    headerText="Outputs are plain language 🗣️"
    
    text={[
      "LLMs speak in free‑form text, so judging accuracy is tough — there's rarely one perfect wording — so humans often need to look and decide.",
    ]}
    isBoldHeader={true}
  />
  <PageCard
    headerText="LLMs are non-deterministic 🎲"
    text={[
      "Even if you change nothing in the app, the same prompt can yield different responses — making issues hard to debug - so developers must track both accuracy and *consistency*.",
    ]}
    isBoldHeader={true}
  />
</CardGroup>

## How MLflow Helps

:::note 
See the [developer workflow](/llms/eval-workflow) to learn more.
:::

<CardGroup singleColumn={true}>
  <PageCard
    headerText="Tracing"
    icon="fa-search"
    text={[
      "Capture every user request and response plus each step in your app’s logic — retrievals, tool calls, LLM calls, etc — with a one‑line import. Jump straight to all the details you need to diagnose and fix any issue fast." 
    ]}
    isBoldHeader={true}
  />
  <PageCard
    headerText="Evaluation Metrics"
    icon="fa-chart-line"
    text={[
      "Use or build LLM‑based scorers that mimic human expert judgment on quality, so you can see how prompt or code tweaks affect quality without a full human review — and run those same scorers on live traffic to monitor quality continuously."
    ]}
    isBoldHeader={true}
  />
  <PageCard
    headerText="Human Labeling Workflows"
    icon="fa-users"
    text={[
      "Let users and domain experts label tough cases in a simple UI, turning their feedback into better evaluation metrics and training data."
    ]}
    isBoldHeader={true}
  />
  <PageCard
    headerText="Production Monitoring"
    icon="fa-tachometer-alt"
    text={[
      "Turn your quality metrics into live dashboards and alerts that surface quality regressions the moment they appear. Additionally, track latency and cost so you can similarly identify operational issues."
    ]}
    isBoldHeader={true}
  />
  <PageCard
    headerText="Iterative Evaluation"
    icon="fa-sync"
    text={[
      "Rapidly test many prompt or code versions offline against historical traffic, then ship only the top‑scoring versions to lift overall quality."
    ]}
    isBoldHeader={true}
  />
  <PageCard
    headerText="User Behavior Insights"
    icon="fa-lightbulb"
    text={[
      "Mine user sessions and feedback to uncover what users want and where they struggle, and feed those insights into your next iteration."
    ]}
    isBoldHeader={true}
  />
</CardGroup>



## Getting started

## <span style={{color: "red"}}>TODO: add this - what are the key things we shuold have ppl do? prob just point to our getting started section??</span>


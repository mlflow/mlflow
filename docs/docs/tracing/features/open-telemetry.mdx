---
sidebar_label: Open Telemetry Export
sidebar_position: 8
---

import { CardGroup, SmallLogoCard } from "@site/src/components/Card";


# Open Telemetry Collector

Traces generated by MLflow are compatible with the [OpenTelemetry trace specs](https://opentelemetry.io/docs/specs/otel/trace/api/#span).
Therefore, MLflow traces can be exported to various observability solutions that support OpenTelemetry.


By default, MLflow exports traces to the MLflow Tracking Server. To enable exporting traces to an OpenTelemetry Collector, set the `OTEL_EXPORTER_OTLP_ENDPOINT` environment variable (or `OTEL_EXPORTER_OTLP_TRACES_ENDPOINT`) to the target URL of the OpenTelemetry Collector **before starting any trace**.

```python
import mlflow
import os

# Set the endpoint of the OpenTelemetry Collector
os.environ["OTEL_EXPORTER_OTLP_TRACES_ENDPOINT"] = "http://localhost:4317/v1/traces"
# Optionally, set the service name to group traces
os.environ["OTEL_SERVICE_NAME"] = "<your-service-name>"

# Trace will be exported to the OTel collector at http://localhost:4317/v1/traces
with mlflow.start_span(name="foo") as span:
    span.set_inputs({"a": 1})
    span.set_outputs({"b": 2})
```



:::warning
MLflow only exports traces to a single destination. When the `OTEL_EXPORTER_OTLP_ENDPOINT` environment variable is configured, MLflow will **not** export traces to the MLflow Tracking Server and you will not see traces in the MLflow UI.

Similarly, if you deploy the model to the [Databricks Model Serving with tracing enabled](https://docs.databricks.com/en/mlflow/mlflow-tracing.html#use-mlflow-tracing-in-production), using the OpenTelemetry Collector will result in traces not being recorded in the Inference Table.
:::

Click on the following icons to learn more about how to set up OpenTelemetry Collector for your specific observability platform.

<CardGroup isSmall>

    <SmallLogoCard link="https://docs.datadoghq.com/opentelemetry/">
        <span>![Datadog Logo](/images/logos/datadog-logo.png)</span>
    </SmallLogoCard>
    <SmallLogoCard link="https://docs.newrelic.com/docs/opentelemetry/get-started/apm-monitoring/opentelemetry-apm-intro/#review-settings">
        <span>![NewRelic Logo](/images/logos/new-relic-logo.png)</span>
    </SmallLogoCard>
    <SmallLogoCard link="https://signoz.io/docs/instrumentation/opentelemetry-python/">
        <span>![Signoz Logo](/images/logos/signoz-logo.svg)</span>
    </SmallLogoCard>
    <SmallLogoCard link="https://docs.splunk.com/observability/en/gdi/get-data-in/get-data-in.html">
        <span>![Splunk Logo](/images/logos/splunk-logo.png)</span>
    </SmallLogoCard>
    <SmallLogoCard ink="https://grafana.com/docs/grafana-cloud/send-data/otlp/send-data-otlp/">
        <span>![Grafana Logo](/images/logos/grafana-logo.png)</span>
    </SmallLogoCard>
    <SmallLogoCard link="https://docs.lightstep.com/docs/collector-home-page">
        <span>![ServiceNow Logo](/images/logos/servicenow-logo.avif)</span>
    </SmallLogoCard>

</CardGroup>


### Configurations

MLflow uses the standard OTLP Exporter for exporting traces to OpenTelemetry Collector instances. Thereby, you can use [all of the configurations](https://opentelemetry.io/docs/languages/sdk-configuration/otlp-exporter/) supported by OpenTelemetry. The following example configures the OTLP Exporter to use HTTP protocol instead of the default gRPC and sets custom headers:

```bash
export OTEL_EXPORTER_OTLP_TRACES_ENDPOINT="http://localhost:4317/v1/traces"
export OTEL_EXPORTER_OTLP_TRACES_PROTOCOL="http/protobuf"
export OTEL_EXPORTER_OTLP_TRACES_HEADERS="api_key=12345"
```

---
sidebar_position: 2
sidebar_label: Query Traces
---

import { APILink } from "@site/src/components/APILink";
import { Card, CardGroup, SmallLogoCard } from "@site/src/components/Card";
import TOCInline from "@theme/TOCInline";
import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";

# Query Traces

This page describes how to query traces logged to MLflow.

## Client vs High-Level API

MLflow provides two APIs for searching and retrieving traces:

- **<APILink fn="mlflow.client.MlflowClient.search_traces">`MlflowClient.search_traces()`</APILink>**: Query traces using experiment IDs, filter strings, and other parameters. This API returns **a list of <APILink fn="mlflow.entities.Trace">`Trace`</APILink> objects** that matches with the given search criteria.

- **<APILink fn="mlflow.search_traces" />**: A higher-level API that supports the same filtering functionalities as the client APIs, but instead returns a pre-formatted **Pandas DataFrame** with each row representing a trace, simplifying the process of creating an evaluation dataset for [MLflow LLM Evaluation](/llms/llm-evaluate).

The following screenshot shows example of the returned traces from these APIs:

![Search Traces Output](/images/llms/tracing/search-traces.png)

## Example Usage of Search Traces

First, create several traces using the following code:

```python
import time
import mlflow
from mlflow.entities import SpanType


# Define methods to be traced
@mlflow.trace(span_type=SpanType.TOOL, attributes={"time": "morning"})
def morning_greeting(name: str):
    time.sleep(1)
    mlflow.update_current_trace(tags={"person": name})
    return f"Good morning {name}."


@mlflow.trace(span_type=SpanType.TOOL, attributes={"time": "evening"})
def evening_greeting(name: str):
    time.sleep(1)
    mlflow.update_current_trace(tags={"person": name})
    return f"Good evening {name}."


@mlflow.trace(span_type=SpanType.TOOL)
def goodbye():
    raise Exception("Cannot say goodbye")


# Execute the methods within different experiments
morning_experiment = mlflow.set_experiment("Morning Experiment")
morning_greeting("Tom")

# Get the timestamp in milliseconds
morning_time = int(time.time() * 1000)

evening_experiment = mlflow.set_experiment("Evening Experiment")
experiment_ids = [morning_experiment.experiment_id, evening_experiment.experiment_id]
evening_greeting("Mary")
goodbye()
```

The code above creates the following traces:

| Experiment         | Name               | Tags.person | Status  |
| ------------------ | ------------------ | ----------- | ------- |
| Morning Experiment | `morning_greeting` | `Tom`       | `OK`    |
| Evening Experiment | `evening_greeting` | `Mary`      | `OK`    |
| Evening Experiment | `goodbye`          | `N/A`       | `ERROR` |

Searching the traces with <APILink fn="mlflow.client.MlflowClient.search_traces">`MlflowClient.search_traces()`</APILink> gives you a list of <APILink fn="mlflow.entities.Trace">`Trace`</APILink> objects.

```python
from mlflow import MlflowClient

client = MlflowClient()

client.search_traces(experiment_ids=[morning_experiment.experiment_id])
# [Trace #1]
```

The <APILink fn="mlflow.search_traces" /> fluent API returns a Pandas DataFrame instead.

```python
mlflow.search_traces(experiment_ids=[morning_experiment.experiment_id])
#     request_id     status          ...    response
# 0   [trace #1 ID]  TraceStatus.OK  ...    Good morning Tom.

# If an experiment ID is not specified, MLflow uses the current active experiment ("Evening Experiment")
mlflow.search_traces()
#     request_id     status          ...    response
# 0   [trace #2 ID]  TraceStatus.OK  ...    Good evening Tom.
# 1   [trace #3 ID]  TraceStatus.OK  ...    NA
```

:::note

<APILink fn="mlflow.client.MlflowClient.search_traces">`MlflowClient.search_traces()`</APILink> requires experiment IDs to be specified for searching traces from, whereas <APILink fn="mlflow.search_traces" /> does not require it and defaults to the current active experiment.

:::

## DataFrame Schema

The pandas DataFrame returned by the <APILink fn="mlflow.search_traces" /> API consists of the following columns by default:

- **request_id**: A primary identifier of a trace
- **trace**: A trace object.
- **timestamp_ms**: The start time of the trace in milliseconds.
- **status**: The status of the trace.
- **execution_time_ms**: The duration of the trace in milliseconds.
- **request**: The input to the traced logic.
- **response**: The output of the traced logic.
- **request_metadata**: Key-value pairs associated with the trace.
- **spans**: Spans in the trace.
- **tags**: Tags associated with the trace.

Furthermore, you can extract span fields into additional columns using the [extract_fields](#extract-specific-fields) parameter.

## Filtering Traces

The `filter_string` argument in the search APIs provides a flexible way to query traces using a SQL-like Domain-Specific Language (DSL). The syntax supports searching traces with various metadata and allows for combining multiple conditions.

:::note
The `filter_string` argument is supported in both client and fluent APIs and there is no syntax difference. The example below uses client API for demonstration purpose only.
:::

### Filter Traces by Name

Search for traces by name using the `trace.name` key:

```python
client.search_traces(
    experiment_ids=experiment_ids,
    filter_string="trace.name = 'morning_greeting'",
)
# [Trace #1]
```

### Filter Traces by Timestamp

Search traces created after a specific timestamp:

```python
client.search_traces(
    experiment_ids=experiment_ids,
    filter_string=f"trace.timestamp > {morning_time}",
)
# [Trace #2, Trace #3]
```

### Filter Traces by Tags

Filter traces by specific tag values using `tag.[tag name]`:

```python
client.search_traces(
    experiment_ids=experiment_ids,
    filter_string="tag.person = 'Tom'",
)
# [Trace #1]
```

The timestamp is recorded as a UNIX timestamp in milliseconds.

### Filter Traces by Status

Search for traces by their status:

```python
client.search_traces(
    experiment_ids=experiment_ids,
    filter_string="trace.status = 'OK'",
)
# [Trace #1, Trace #2]
```

Trace status must be one of `["OK", "ERROR", "IN_PROGRESS"]`.

### Combine Multiple Conditions

The `filter_string` DSL allows you to combine multiple filters together by using `AND`.

```python
client.search_traces(
    experiment_ids=experiment_ids,
    filter_string=f"attributes.status = 'OK' AND attributes.timestamp > {morning_time}",
)
# [Trace #2]
```

## Order Traces

The `order_by` argument allows you to sort traces based on one or more fields. Each `order_by` clause follows the format `[attribute name] [ASC or DESC]`.

```python
client.search_traces(
    experiment_ids=experiment_ids,
    order_by=["timestamp DESC"],
)
# [Trace #3, Trace #2, Trace #1]
```

## Extract Specific Fields

The <APILink fn="mlflow.search_traces" /> API allows you to extract specific fields from spans with `extract_fields` argument. The span fields can be specifie in the format of `span_name.[inputs|outputs]` or `span_name.[inputs|outputs].field_name`:

```python
traces = mlflow.search_traces(
    extract_fields=[
        # Extract the "name" field in the "morning_greeting" span inputs.
        "morning_greeting.inputs.name",
        # Extract the all output fields in the "morning_greeting" span.
        "morning_greeting.outputs",
    ],
    experiment_ids=[morning_experiment.experiment_id],
)

print(traces)
```

The output Pandas DataFrame contains the additional columns for the extracted span fields:

```text
    request_id                              ...     morning_greeting.inputs.name   morning_greeting.outputs
0   053adf2f5f5e4ad68d432e06e254c8a4        ...     'Tom'                          'Good morning Tom.'
```

This feature is particularly useful for building an evaluation dataset for your application. You can convert the returned Pandas DataFrame into an MLflow LLM evaluation dataset format by renaming fields, and evaluate your language model using the [mlflow.evaluate()](/llms/llm-evaluate) API.

```python
eval_data = traces.rename(
    columns={
        "morning_greeting.inputs.name": "inputs",
        "morning_greeting.outputs": "ground_truth",
    }
)
results = mlflow.evaluate(
    model,
    eval_data,
    targets="ground_truth",
    model_type="question-answering",
)
```

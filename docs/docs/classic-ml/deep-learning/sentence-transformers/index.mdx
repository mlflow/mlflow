---
sidebar_position: 2
sidebar_label: Sentence Transformers
---

import { CardGroup, PageCard } from "@site/src/components/Card";
import FeatureHighlights from "@site/src/components/FeatureHighlights";
import TilesGrid from "@site/src/components/TilesGrid";
import TileCard from "@site/src/components/TileCard";
import { Package, Sparkles, Search, Box, Zap, GitBranch, BookOpen } from "lucide-react";

# MLflow Sentence Transformers Flavor

The MLflow Sentence Transformers flavor provides integration with the [Sentence Transformers](https://www.sbert.net/) library for generating semantic embeddings from text.

## Key Features

<FeatureHighlights
  features={[
    {
      icon: Package,
      title: "Model Logging",
      description: "Save and version sentence transformer models with full metadata",
    },
    {
      icon: Sparkles,
      title: "Embedding Generation",
      description: "Deploy models as embeddings services with standardized interfaces",
    },
    {
      icon: Search,
      title: "Semantic Task Support",
      description: "Handle semantic search, similarity, classification, and clustering tasks",
    },
    {
      icon: Box,
      title: "PyFunc Integration",
      description: "Serve models with MLflow's generic Python function interface",
    },
    {
      icon: Zap,
      title: "Autologging",
      description: "Automatic tracking of training metrics and parameters",
    },
  ]}
/>

## Installation

```bash
pip install mlflow[sentence-transformers]
```

## Basic Usage

### Logging and Loading Models

```python
import mlflow
from sentence_transformers import SentenceTransformer

# Load and log a model
model = SentenceTransformer("all-MiniLM-L6-v2")

with mlflow.start_run():
    model_info = mlflow.sentence_transformers.log_model(
        model=model,
        name="model",
        input_example=["Sample text for inference"],
    )

# Load as native sentence transformer
loaded_model = mlflow.sentence_transformers.load_model(model_info.model_uri)
embeddings = loaded_model.encode(["Hello world", "MLflow is great"])

# Load as PyFunc
pyfunc_model = mlflow.pyfunc.load_model(model_info.model_uri)
result = pyfunc_model.predict(["Hello world", "MLflow is great"])
```

### Model Signatures

Define explicit signatures for production deployments:

```python
from mlflow.models import infer_signature

sample_texts = [
    "MLflow makes ML development easier",
    "Sentence transformers create embeddings",
]
sample_embeddings = model.encode(sample_texts)

signature = infer_signature(sample_texts, sample_embeddings)

with mlflow.start_run():
    mlflow.sentence_transformers.log_model(
        model=model,
        name="model",
        signature=signature,
        input_example=sample_texts,
    )
```

## Semantic Search

Build semantic search systems with tracking:

```python
import mlflow
import pandas as pd
from sentence_transformers import SentenceTransformer, util

documents = [
    "Machine learning is a subset of artificial intelligence",
    "Deep learning uses neural networks with multiple layers",
    "MLflow helps manage the machine learning lifecycle",
]

with mlflow.start_run():
    model = SentenceTransformer("all-MiniLM-L6-v2")

    # Log model parameters
    mlflow.log_params(
        {
            "model_name": "all-MiniLM-L6-v2",
            "embedding_dimension": model.get_sentence_embedding_dimension(),
            "corpus_size": len(documents),
        }
    )

    # Encode corpus
    corpus_embeddings = model.encode(documents, convert_to_tensor=True)

    # Save corpus
    corpus_df = pd.DataFrame({"documents": documents})
    corpus_df.to_csv("corpus.csv", index=False)
    mlflow.log_artifact("corpus.csv")

    # Semantic search
    query = "What tools help with ML development?"
    query_embedding = model.encode(query, convert_to_tensor=True)
    results = util.semantic_search(query_embedding, corpus_embeddings, top_k=3)[0]

    # Log model
    mlflow.sentence_transformers.log_model(
        model=model,
        name="search_model",
        input_example=[query],
    )
```

## Fine-tuning

Track fine-tuning experiments:

```python
from sentence_transformers import InputExample, losses
from torch.utils.data import DataLoader

train_examples = [
    InputExample(texts=["Python programming", "Coding in Python"], label=0.9),
    InputExample(texts=["Machine learning model", "ML algorithm"], label=0.8),
    InputExample(texts=["Software development", "Cooking recipes"], label=0.1),
]

with mlflow.start_run():
    model = SentenceTransformer("all-MiniLM-L6-v2")

    # Log training parameters
    mlflow.log_params(
        {
            "base_model": "all-MiniLM-L6-v2",
            "num_epochs": 3,
            "batch_size": 16,
            "learning_rate": 2e-5,
        }
    )

    # Fine-tune
    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)
    train_loss = losses.CosineSimilarityLoss(model)

    model.fit(
        train_objectives=[(train_dataloader, train_loss)],
        epochs=3,
        warmup_steps=100,
    )

    # Log fine-tuned model
    mlflow.sentence_transformers.log_model(
        model=model,
        name="fine_tuned_model",
    )
```

## Batch Processing

Optimize batch processing for large datasets:

```python
import time

with mlflow.start_run():
    model = SentenceTransformer("all-MiniLM-L6-v2")

    large_dataset = [f"Document {i}: Sample text" for i in range(1000)]

    # Configure batch processing
    batch_config = {
        "batch_size": 32,
        "convert_to_numpy": True,
        "normalize_embeddings": True,
    }
    mlflow.log_params(batch_config)

    # Process in batches
    start_time = time.time()
    embeddings = model.encode(
        large_dataset,
        batch_size=batch_config["batch_size"],
        convert_to_numpy=batch_config["convert_to_numpy"],
        normalize_embeddings=batch_config["normalize_embeddings"],
    )
    processing_time = time.time() - start_time

    # Log performance metrics
    mlflow.log_metrics(
        {
            "processing_time_seconds": processing_time,
            "documents_per_second": len(large_dataset) / processing_time,
            "embedding_dimension": embeddings.shape[1],
        }
    )
```

## Model Comparison

Compare multiple models systematically:

```python
models_to_compare = [
    "all-MiniLM-L6-v2",
    "all-mpnet-base-v2",
    "paraphrase-albert-small-v2",
]

with mlflow.start_run(run_name="model_comparison"):
    results = []

    for model_name in models_to_compare:
        with mlflow.start_run(run_name=f"eval_{model_name}", nested=True):
            model = SentenceTransformer(model_name)

            # Evaluate speed
            test_texts = ["Sample text"] * 100
            start_time = time.time()
            embeddings = model.encode(test_texts)
            encoding_time = time.time() - start_time

            results.append(
                {
                    "model": model_name,
                    "texts_per_second": len(test_texts) / encoding_time,
                    "embedding_dimension": model.get_sentence_embedding_dimension(),
                }
            )

            mlflow.log_metrics(
                {
                    "texts_per_second": len(test_texts) / encoding_time,
                    "embedding_dimension": model.get_sentence_embedding_dimension(),
                }
            )

    # Log comparison
    results_df = pd.DataFrame(results)
    results_df.to_csv("comparison.csv", index=False)
    mlflow.log_artifact("comparison.csv")
```

## Tutorials

### Quickstart

<CardGroup>
  <PageCard
    headerText="Sentence Transformers Quickstart"
    link="/ml/deep-learning/sentence-transformers/tutorials/quickstart/sentence-transformers-quickstart/"
    text="Learn the basics of using Sentence Transformers with MLflow"
  />
</CardGroup>

### Advanced Tutorials

<CardGroup>
  <PageCard
    headerText="Semantic Similarity"
    link="/ml/deep-learning/sentence-transformers/tutorials/semantic-similarity/semantic-similarity-sentence-transformers/"
    text="Determine similarity scores between sentences using embeddings"
  />
  <PageCard
    headerText="Semantic Search"
    link="/ml/deep-learning/sentence-transformers/tutorials/semantic-search/semantic-search-sentence-transformers/"
    text="Find the most similar embeddings within a corpus of text"
  />
  <PageCard
    headerText="Paraphrase Mining"
    link="/ml/deep-learning/sentence-transformers/tutorials/paraphrase-mining/paraphrase-mining-sentence-transformers/"
    text="Identify semantically similar sentences in a text corpus"
  />
</CardGroup>

## Learn More

<TilesGrid>
  <TileCard
    icon={Package}
    title="Model Registry"
    description="Version and manage Sentence Transformer models"
    href="/ml/model-registry"
  />
  <TileCard
    icon={GitBranch}
    title="MLflow Tracking"
    description="Track experiments, parameters, and metrics"
    href="/ml/tracking"
  />
  <TileCard
    icon={BookOpen}
    title="Sentence Transformers Library"
    description="Official documentation for the Sentence Transformers library"
    href="https://www.sbert.net/"
  />
</TilesGrid>

---
sidebar_position: 2
sidebar_label: Keras
---

import { APILink } from "@site/src/components/APILink";
import Link from "@docusaurus/Link";
import { CardGroup, PageCard } from "@site/src/components/Card";

# MLflow Keras 3.0 Integration

**Keras 3.0** represents a revolutionary leap in deep learning accessibility and flexibility. As a high-level neural networks API, Keras empowers everyone from machine learning beginners to seasoned researchers to build, train, and deploy sophisticated models with unprecedented ease.

What makes Keras 3.0 truly special is its **multi-backend architecture**. Unlike previous versions, Keras 3.0 can seamlessly run on top of TensorFlow, JAX, and PyTorch - giving you the freedom to choose the best backend for your specific use case without changing your code.

<details>
  <summary>Why Keras 3.0 is a Game Changer</summary>

#### Multi-Backend Freedom

- ğŸ”§ **TensorFlow**: Production-ready ecosystem with robust deployment options
- âš¡ **JAX**: High-performance computing with automatic differentiation and JIT compilation
- ğŸ”¬ **PyTorch**: Research-friendly interface with dynamic computation graphs
- ğŸ”„ **Seamless Switching**: Change backends without rewriting your model code

#### Universal Design Philosophy

- ğŸ¯ **Beginner-Friendly**: Simple, intuitive APIs that make deep learning accessible
- ğŸš€ **Research-Ready**: Advanced features for cutting-edge experimentation
- ğŸ—ï¸ **Production-Proven**: Battle-tested in enterprise environments worldwide
- ğŸ“š **Comprehensive**: From basic neural networks to complex architectures

</details>

## Why MLflow + Keras 3.0?

The combination of MLflow's experiment tracking capabilities with Keras 3.0's flexibility creates a powerful synergy for deep learning practitioners:

- ğŸ“Š **One-Line Setup**: Enable comprehensive experiment tracking with just `mlflow.tensorflow.autolog()` - no configuration required
- ğŸ”„ **Multi-Backend Consistency**: Track experiments consistently across TensorFlow, JAX, and PyTorch backends
- âš™ï¸ **Zero-Code Integration**: Your existing Keras training code works unchanged - autologging captures everything automatically
- ğŸ› ï¸ **Advanced Customization**: When you need more control, use the <APILink fn="mlflow.keras.callback.MlflowCallback" /> API for specialized logging requirements
- ğŸ”¬ **Complete Reproducibility**: Every parameter, metric, and artifact is captured automatically for perfect experiment reproduction
- ğŸ‘¥ **Effortless Collaboration**: Share comprehensive experiment results through MLflow's intuitive UI without any manual logging

## Key Features

### One-Line Autologging Magic

The easiest way to get started with MLflow and Keras is through **autologging** - just add one line of code and MLflow automatically captures everything you need:

```python
import mlflow

mlflow.tensorflow.autolog()  # That's it! ğŸ‰

# Your existing Keras code works unchanged
model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10)
```

<details>
  <summary>What Gets Automatically Logged</summary>

#### Metrics

- ğŸ“Š **Training & Validation Loss**: Automatic tracking of loss functions across epochs
- ğŸ¯ **Custom Metrics**: Any metrics you specify (accuracy, F1-score, etc.) are logged automatically
- ğŸ›‘ **Early Stopping Metrics**: When using `EarlyStopping`, MLflow logs `stopped_epoch`, `restored_epoch`, and restoration details

#### Parameters

- âš™ï¸ **Training Configuration**: All `fit()` parameters including batch size, epochs, and validation split
- ğŸ§  **Optimizer Details**: Optimizer name, learning rate, epsilon, and other hyperparameters
- ğŸ›‘ **Callback Parameters**: Early stopping settings like `min_delta`, `patience`, and `restore_best_weights`

#### Artifacts

- ğŸ“‹ **Model Summary**: Complete architecture overview logged at training start
- ğŸ¤– **MLflow Model**: Full Keras model saved for easy deployment and inference
- ğŸ“Š **TensorBoard Logs**: Complete training history for detailed visualization

#### Smart Run Management

- ğŸš€ **Automatic Run Creation**: If no run exists, MLflow creates one automatically
- ğŸ”„ **Flexible Run Handling**: Works with existing runs or creates new ones as needed
- â¹ï¸ **Intelligent Run Ending**: Automatically closes runs when training completes

</details>

### Advanced Logging with MlflowCallback

For users who need more control, MLflow's Keras integration also provides the powerful `MlflowCallback` that offers fine-grained customization:

<details>
  <summary>Advanced Callback Capabilities</summary>

- ğŸ“‹ **Custom Parameter Logging**: Selectively log specific parameters and hyperparameters
- ğŸ“ˆ **Granular Metrics Tracking**: Log metrics at custom intervals (per batch, per epoch, or custom frequencies)
- â±ï¸ **Flexible Logging Frequency**: Choose between epoch-based or batch-based logging to match your monitoring needs
- ğŸ›ï¸ **Custom Callback Extensions**: Subclass the callback to implement specialized logging for your unique requirements
- ğŸ·ï¸ **Advanced Artifact Management**: Control exactly which artifacts get saved and when
- ğŸ” **Performance Monitoring**: Add custom tracking for training time, memory usage, and convergence patterns

</details>

### Multi-Backend Support

Run the same MLflow tracking code across different Keras backends:

```python
# Switch backends without changing your MLflow code
os.environ["KERAS_BACKEND"] = "tensorflow"  # or "jax" or "torch"
```

### Advanced Experiment Management

<details>
  <summary>Enterprise-Grade ML Operations</summary>

- ğŸ“ **Model Versioning**: Track different model architectures and their performance over time
- ğŸ¯ **Hyperparameter Optimization**: Log and compare results from hyperparameter sweeps with tools like Optuna
- ğŸ“¦ **Artifact Management**: Store model checkpoints, training plots, and custom visualizations
- ğŸ‘¥ **Collaborative Development**: Share experiment results with team members through MLflow's UI
- ğŸ”„ **Reproducibility**: Capture exact environments and dependencies for perfect experiment reproduction
- ğŸ“Š **Performance Analytics**: Detailed insights into training dynamics and model behavior

</details>

## Real-World Applications

The MLflow-Keras 3.0 integration excels in scenarios such as:

- ğŸ–¼ï¸ **Computer Vision Projects**: Track CNN architectures, data augmentation strategies, and training dynamics for image classification, object detection, and segmentation tasks
- ğŸ“ **Natural Language Processing**: Log transformer models, tokenization strategies, and sequence-to-sequence performance for text generation and understanding
- ğŸ”¬ **Research Experiments**: Maintain detailed records of ablation studies, architecture comparisons, and novel technique validation
- ğŸ­ **Production Pipelines**: Version control models from experimentation through deployment with full lineage tracking
- ğŸ“ **Educational Projects**: Demonstrate clear progression from simple perceptrons to complex deep architectures
- ğŸ“Š **Time Series Analysis**: Track LSTM, GRU, and transformer models for forecasting and anomaly detection

## Get Started in 5 Minutes

Ready to supercharge your Keras workflow with MLflow? Our comprehensive quickstart tutorial walks you through everything from basic logging to advanced callback customization using a practical MNIST classification example.

<CardGroup>
  <PageCard
    headerText="Get Started with Keras 3.0 + MLflow"
    link="/ml/deep-learning/keras/quickstart/quickstart-keras"
    text="Master the fundamentals through a hands-on MNIST tutorial covering automatic logging, custom callbacks, multi-backend experimentation, and advanced tracking techniques."
  />
</CardGroup>

## What You'll Master

In our comprehensive tutorial, you'll discover how to:

<details>
  <summary>Complete Learning Path</summary>

#### Foundation Skills

- ğŸš€ Set up MLflow tracking for Keras 3.0 workflows across TensorFlow, JAX, and PyTorch backends
- âš¡ Enable comprehensive autologging with a single line of code: `mlflow.tensorflow.autolog()`
- ğŸ“Š Use `MlflowCallback` for advanced experiment logging and customization
- ğŸ“ˆ Implement custom logging strategies for both batch-level and epoch-level tracking
- ğŸ›ï¸ Create specialized callback subclasses for advanced logging requirements

#### Advanced Techniques

- ğŸ“Š Visualize and compare training results in the MLflow UI with custom metrics
- ğŸ”„ Switch between backends while maintaining consistent experiment tracking
- ğŸ¯ Optimize hyperparameters while automatically logging all trial results
- ğŸ“¦ Package and version your models for seamless deployment

#### Production Readiness

- ğŸ­ Apply enterprise-grade tracking to your production deep learning projects
- ğŸ‘¥ Set up collaborative workflows for team-based model development
- ğŸ” Monitor model performance and training dynamics at scale
- ğŸ“‹ Implement model governance and approval workflows

</details>

To learn more about the nuances of the `keras` flavor in MLflow, delve into the comprehensive guide below.

<Link className="button button--primary" to="/ml/deep-learning/keras/guide">
  <span>View the Comprehensive Guide</span>
</Link>

Whether you're building your first neural network or optimizing complex architectures for production, the MLflow-Keras 3.0 integration provides the foundation for organized, reproducible, and scalable deep learning experimentation that grows with your needs.

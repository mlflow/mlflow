---
sidebar_position: 2
sidebar_label: TensorFlow
---

import FeatureHighlights from "@site/src/components/FeatureHighlights";
import TilesGrid from "@site/src/components/TilesGrid";
import TileCard from "@site/src/components/TileCard";
import { Zap, GitBranch, Package, BookOpen } from "lucide-react";
import { APILink } from "@site/src/components/APILink";

# MLflow TensorFlow Integration

## Introduction

**TensorFlow** is an end-to-end open source platform for machine learning developed by Google. It provides a comprehensive ecosystem for building and deploying ML models, from research prototypes to production systems. TensorFlow's Keras API offers an intuitive interface for building neural networks while its powerful backend enables efficient computation across CPUs, GPUs, and TPUs.

MLflow's TensorFlow integration provides experiment tracking, model versioning, and deployment capabilities for deep learning workflows.

## Why MLflow + TensorFlow?

<FeatureHighlights
  features={[
    {
      icon: Zap,
      title: "Autologging",
      description: "Enable comprehensive experiment tracking with one line: mlflow.tensorflow.autolog() automatically logs metrics, parameters, and models.",
    },
    {
      icon: GitBranch,
      title: "Experiment Tracking",
      description: "Track training metrics, hyperparameters, model architectures, and artifacts across all TensorFlow experiments.",
    },
    {
      icon: Package,
      title: "Model Registry",
      description: "Version, stage, and deploy TensorFlow models with MLflow's model registry and serving infrastructure.",
    },
    {
      icon: BookOpen,
      title: "Reproducibility",
      description: "Capture model states, training configurations, and environments for reproducible experiments.",
    },
  ]}
/>

## Autologging

Enable comprehensive autologging with a single line:

```python
import mlflow
import numpy as np
import tensorflow as tf
from tensorflow import keras

# Enable autologging
mlflow.tensorflow.autolog()

# Prepare sample data
data = np.random.uniform(size=[20, 28, 28, 3])
label = np.random.randint(2, size=20)

# Define model
model = keras.Sequential(
    [
        keras.Input([28, 28, 3]),
        keras.layers.Conv2D(8, 2),
        keras.layers.MaxPool2D(2),
        keras.layers.Flatten(),
        keras.layers.Dense(2),
        keras.layers.Softmax(),
    ]
)

model.compile(
    loss=keras.losses.SparseCategoricalCrossentropy(),
    optimizer=keras.optimizers.Adam(0.001),
    metrics=[keras.metrics.SparseCategoricalAccuracy()],
)

# Training with automatic logging
with mlflow.start_run():
    model.fit(data, label, batch_size=5, epochs=2)
```

Autologging captures training metrics, model parameters, optimizer configuration, and model artifacts automatically. Requires TensorFlow >= 2.3.0 and the `model.fit()` Keras API.

Configure autologging behavior:

```python
mlflow.tensorflow.autolog(
    log_models=True,
    log_input_examples=True,
    log_model_signatures=True,
    log_every_n_steps=1,
)
```

## Manual Logging with Keras Callback

For more control, use <APILink fn="mlflow.tensorflow.MlflowCallback" />:

```python
import mlflow
from tensorflow import keras

# Define and compile your model
model = keras.Sequential([...])
model.compile(...)

# Create an MLflow run and add the callback
with mlflow.start_run() as run:
    model.fit(
        data,
        labels,
        batch_size=32,
        epochs=10,
        callbacks=[mlflow.tensorflow.MlflowCallback(run)],
    )
```

### Custom Callback

Create custom logging logic by subclassing `keras.callbacks.Callback`:

```python
from tensorflow import keras
import math
import mlflow


class CustomMlflowCallback(keras.callbacks.Callback):
    def on_epoch_begin(self, epoch, logs=None):
        mlflow.log_metric("current_epoch", epoch)

    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        # Log metrics in log scale
        for k, v in logs.items():
            if v > 0:
                mlflow.log_metric(f"log_{k}", math.log(v), step=epoch)
            mlflow.log_metric(k, v, step=epoch)

    def on_train_end(self, logs=None):
        # Log final model weights statistics
        weights = self.model.get_weights()
        mlflow.log_metric("total_parameters", sum(w.size for w in weights))
```

## Model Logging

Save TensorFlow models with <APILink fn="mlflow.tensorflow.log_model" />:

```python
import mlflow
import tensorflow as tf
from tensorflow import keras

# Define model
model = keras.Sequential(
    [
        keras.Input([28, 28, 3]),
        keras.layers.Conv2D(8, 2),
        keras.layers.MaxPool2D(2),
        keras.layers.Flatten(),
        keras.layers.Dense(2),
        keras.layers.Softmax(),
    ]
)

# Train model (code omitted for brevity)

# Log the model to MLflow
model_info = mlflow.tensorflow.log_model(model, name="model")

# Later, load the model for inference
loaded_model = mlflow.tensorflow.load_model(model_info.model_uri)
predictions = loaded_model.predict(tf.random.uniform([1, 28, 28, 3]))
```

### Model Formats

By default, models are saved in TensorFlow SavedModel format. Alternative formats:

```python
# Save in H5 format
mlflow.tensorflow.log_model(
    model, name="model", keras_model_kwargs={"save_format": "h5"}
)

# Save in native Keras format
mlflow.tensorflow.log_model(
    model, name="model", keras_model_kwargs={"save_format": "keras"}
)
```

### Model Signatures

Add signatures for better model understanding and validation:

```python
import mlflow
from mlflow.models import infer_signature
import numpy as np

# Sample input data
sample_input = np.random.uniform(size=[2, 28, 28, 3])

# Get predictions
sample_output = model.predict(sample_input)

# Infer signature from data
signature = infer_signature(sample_input, sample_output)

# Log model with inferred signature
model_info = mlflow.tensorflow.log_model(model, name="model", signature=signature)
```

## Hyperparameter Optimization

Track hyperparameter tuning with MLflow:

```python
import mlflow
import tensorflow as tf
from tensorflow import keras
import optuna


def create_model(trial):
    learning_rate = trial.suggest_float("learning_rate", 1e-5, 1e-1, log=True)
    units = trial.suggest_int("units", 32, 512)
    dropout = trial.suggest_float("dropout", 0.1, 0.5)

    model = keras.Sequential(
        [
            keras.layers.Input(shape=(28, 28, 3)),
            keras.layers.Flatten(),
            keras.layers.Dense(units, activation="relu"),
            keras.layers.Dropout(dropout),
            keras.layers.Dense(10, activation="softmax"),
        ]
    )

    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
        loss="sparse_categorical_crossentropy",
        metrics=["accuracy"],
    )

    return model


def objective(trial):
    with mlflow.start_run(nested=True):
        params = {
            "learning_rate": trial.params["learning_rate"],
            "units": trial.params["units"],
            "dropout": trial.params["dropout"],
        }
        mlflow.log_params(params)

        model = create_model(trial)
        history = model.fit(
            x_train, y_train, validation_data=(x_val, y_val), epochs=5, verbose=0
        )

        val_accuracy = max(history.history["val_accuracy"])
        mlflow.log_metric("val_accuracy", val_accuracy)

        mlflow.tensorflow.log_model(model, name="model")

        return val_accuracy


# Main experiment run
with mlflow.start_run(run_name="hyperparameter_optimization"):
    mlflow.log_params(
        {
            "optimization_framework": "optuna",
            "n_trials": 20,
            "direction": "maximize",
            "metric": "val_accuracy",
        }
    )

    study = optuna.create_study(direction="maximize")
    study.optimize(objective, n_trials=20)

    mlflow.log_params({f"best_{k}": v for k, v in study.best_params.items()})
    mlflow.log_metric("best_val_accuracy", study.best_value)

    final_model = create_model(study.best_trial)
    final_model.fit(x_train, y_train, epochs=10)
    mlflow.tensorflow.log_model(final_model, name="best_model")
```

## Model Registry Integration

Register TensorFlow models for version control and deployment:

```python
import mlflow
from tensorflow import keras
from mlflow import MlflowClient

client = MlflowClient()

with mlflow.start_run():
    # Create model for demonstration
    model = keras.Sequential(
        [
            keras.layers.Conv2D(32, 3, activation="relu", input_shape=(224, 224, 3)),
            keras.layers.MaxPooling2D(2),
            keras.layers.Flatten(),
            keras.layers.Dense(10, activation="softmax"),
        ]
    )

    # Log model to registry
    model_info = mlflow.tensorflow.log_model(
        model, name="tensorflow_model", registered_model_name="ImageClassifier"
    )

    # Tag for tracking
    mlflow.set_tags(
        {"model_type": "cnn", "dataset": "imagenet", "framework": "tensorflow"}
    )

# Transition to production
client.transition_model_version_stage(
    name="ImageClassifier",
    version=model_info.registered_model_version,
    stage="Production",
)
```

## Deployment

Deploy TensorFlow models locally:

```bash
mlflow models serve -m models:/<model_id> -p 5000
```

Test your deployed model:

```python
import requests
import json

# Prepare test data
test_data = {"inputs": sample_input.tolist()}

# Make prediction request
response = requests.post(
    "http://localhost:5000/invocations",
    data=json.dumps(test_data),
    headers={"Content-Type": "application/json"},
)

predictions = response.json()
print("Predictions:", predictions)
```

## Learn More

<TilesGrid>
  <TileCard
    icon={Package}
    title="Model Registry"
    description="Version and manage TensorFlow models"
    href="/ml/model-registry"
  />
  <TileCard
    icon={GitBranch}
    title="MLflow Tracking"
    description="Track experiments, parameters, and metrics"
    href="/ml/tracking"
  />
</TilesGrid>

import Link from "@docusaurus/Link";
import { APILink } from "@site/src/components/APILink";
import { Table } from "@site/src/components/Table";

# Backend Stores

The backend store is a core component in [MLflow Tracking](/ml/tracking) where MLflow stores metadata for
[Runs](/ml/tracking#runs), models and experiments such as:

- Model ID
- Run ID
- Start & end time
- Parameters
- Metrics
- Code version (only if you launch runs from an [MLflow Project](/ml/projects)).
- Source file name (only if you launch runs from an [MLflow Project](/ml/projects)).

Note that large model artifacts such as model weight files are stored in [artifact store](/ml/tracking/artifact-stores).

## Configure Backend Store

By default, MLflow stores metadata in local files in the `./mlruns` directory, but MLflow can store metadata to databases as well.
You can configure the location by passing the desired **tracking URI** to MLflow, via either of the following methods:

- Set the `MLFLOW_TRACKING_URI` environment variable.
- Call <APILink fn="mlflow.set_tracking_uri" /> in your code.
- If you are running a [Tracking Server](/ml/tracking#tracking_server), you can set the `tracking_uri` option when starting the server, like `mlflow server --backend-store-uri sqlite:///mydb.sqlite`

Continue to the next section for the supported format of tracking URLs.
Also visit [this guidance](/ml/tracking#tracking_setup) for how to set up the backend store properly for your workflow.

## Supported Store Types

MLflow supports the following types of tracking URI for backend stores:

- Local file path (specified as `file:/my/local/dir`), where data is just directly stored locally to a system disk where your code is executing.
- A Database, encoded as `<dialect>+<driver>://<username>:<password>@<host>:<port>/<database>`. MLflow supports the dialects `mysql`, `mssql`, `sqlite`, and `postgresql`. For more details, see [SQLAlchemy database uri](https://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls).
- HTTP server (specified as `https://my-server:5000`), which is a server hosting an [MLflow tracking server](/ml/tracking#tracking_server).
- Databricks workspace (specified as `databricks` or as `databricks://<profileName>`, a [Databricks CLI profile](https://github.com/databricks/databricks-cli#installation)).
  Refer to Access the MLflow tracking server from outside Databricks [[AWS]](http://docs.databricks.com/applications/mlflow/access-hosted-tracking-server.html)
  [[Azure]](http://docs.microsoft.com/azure/databricks/applications/mlflow/access-hosted-tracking-server), or [the quickstart](/ml/tracking/quickstart) to
  easily get started with hosted MLflow on the Databricks Free Trial.

:::warning database-requirements
**Database-Backed Store Requirements**

When using database-backed stores, please note:

- **Model Registry Integration**: [Model Registry](/ml/model-registry) functionality requires a database-backed store. See [this FAQ](/ml/tracking#tracking-with-model-registry) for more information.

- **Schema Migrations**: `mlflow server` will fail against a database with an out-of-date schema. Always run `mlflow db upgrade [db_uri]` to upgrade your database schema before starting the server. Schema migrations can result in database downtime and may take longer on larger databases. **Always backup your database before running migrations.**
:::

:::note parameter-limits
In Sep 2023, we increased the max length for params recorded in a Run from 500 to 8k (but we limit param value max length to 6000 internally).
[mlflow/2d6e25af4d3e_increase_max_param_val_length](https://github.com/mlflow/mlflow/blob/master/mlflow/store/db_migrations/versions/2d6e25af4d3e_increase_max_param_val_length.py)
is a non-invertible migration script that increases the cap in existing database to 8k. Please be careful if you want to upgrade and backup your database before upgrading.
:::

## Deletion Behavior

In order to allow MLflow Runs to be restored, Run metadata and artifacts are not automatically removed
from the backend store or artifact store when a Run is deleted. The <Link to="/api_reference/cli.html" target="_blank">mlflow gc</Link> CLI is provided
for permanently removing Run metadata and artifacts for deleted runs.

## SQLAlchemy Options

You can inject some [SQLAlchemy connection pooling options](https://docs.sqlalchemy.org/en/latest/core/pooling.html) using environment variables.

<Table>
  <thead>
    <tr>
      <th>MLflow Environment Variable</th>
      <th>SQLAlchemy QueuePool Option</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>`MLFLOW_SQLALCHEMYSTORE_POOL_SIZE`</td>
      <td>`pool_size`</td>
    </tr>
    <tr>
      <td>`MLFLOW_SQLALCHEMYSTORE_POOL_RECYCLE`</td>
      <td>`pool_recycle`</td>
    </tr>
    <tr>
      <td>`MLFLOW_SQLALCHEMYSTORE_MAX_OVERFLOW`</td>
      <td>`max_overflow`</td>
    </tr>
  </tbody>
</Table>

## MySQL SSL Options

When connecting to a MySQL database that requires SSL certificates, you can set the following environment variables:

```bash
# Path to SSL CA certificate file
export MLFLOW_MYSQL_SSL_CA=/path/to/ca.pem

# Path to SSL client certificate file (if needed)
export MLFLOW_MYSQL_SSL_CERT=/path/to/client-cert.pem

# Path to SSL client key file (if needed)
export MLFLOW_MYSQL_SSL_KEY=/path/to/client-key.pem
```

Then start the MLflow server with your MySQL URI:

```bash
mlflow server --backend-store-uri="mysql+pymysql://username@hostname:port/database" --default-artifact-root=s3://your-bucket --host=0.0.0.0 --port=5000
```

These environment variables will be used to configure the SSL connection to the MySQL server.

## File Store Performance

MLflow will automatically try to use [LibYAML](https://pyyaml.org/wiki/LibYAML) bindings if they are already installed.
However, if you notice any performance issues when using _file store_ backend, it could mean LibYAML is not installed on your system.
On Linux or Mac you can easily install it using your system package manager:

```bash
# On Ubuntu/Debian
apt-get install libyaml-cpp-dev libyaml-dev

# On macOS using Homebrew
brew install yaml-cpp libyaml
```

After installing LibYAML, you need to reinstall PyYAML:

```bash
# Reinstall PyYAML
pip --no-cache-dir install --force-reinstall -I pyyaml
```

---
sidebar_label: Pickle-Free Model format
sidebar_position: 5
---

import { APILink } from "@site/src/components/APILink";

# Pickle-Free Model format

Saving models with Python's `pickle` or `cloudpickle` rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization. MLflow supports safer **pickle-free** saving formats for several model flavors. Prefer these formats when possible.

## Pickle-free format for Scikit-learn model

When saving a scikit-learn model, set param `serialization_format="skops"` to use the **skops** format for safe deserialization of scikit-learn models. The `skops` format does not rely on Python's pickle and avoids arbitrary code execution when loading.

```python
import mlflow
import mlflow.sklearn
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier

X, y = load_iris(return_X_y=True)
model = DecisionTreeClassifier().fit(X, y)

with mlflow.start_run():
    mlflow.sklearn.log_model(
        model,
        "model",
        serialization_format="skops",
    )
```

For some scikit-learn model that contains custom or third-party types, you need to set `skops_trusted_types` mark a list of classes as trusted types.

```python
# Add an example that contains custom type, e.g. a pipeline with a custom transformer.
```

See <APILink fn="mlflow.sklearn.log_model" /> and <APILink fn="mlflow.sklearn.save_model" /> for full parameters.

## Pickle-free format for PyTorch model

When saving a pytorch model, saving with **export_model=True** uses `torch.export.save` and stores the model as a traced graph instead of pickle serialization format.

Requirements:

- `torch` >= 2.4
- An **input_example** is required (and only `Tensor` type input are supported for the exported model)
- Not supported for `torch.jit.ScriptModule` models

```python
import mlflow
import mlflow.pytorch
import torch
from torch import nn
from mlflow.models import infer_signature

model = nn.Linear(10, 2)
input_example = torch.randn(1, 10)
signature = infer_signature(input_example.numpy(), model(input_example).detach().numpy())

with mlflow.start_run():
    mlflow.pytorch.log_model(
        model,
        "model",
        export_model=True,
        input_example=input_example,
        signature=signature,
    )
```

See <APILink fn="mlflow.pytorch.log_model" /> and <APILink fn="mlflow.pytorch.save_model" /> for details.

## Pickle-free format for DSPy model

DSPy models can be save with param `use_dspy_model_save=True` to use the DSPy built-in `dspy.Module.save` method instead of pickle format. This option requires **dspy >= 3.1.0**.

```python
import mlflow
import mlflow.dspy
import dspy

# Build and compile your DSPy model
model = dspy.Module(...)  # your module
# ... compile, etc.

with mlflow.start_run():
    mlflow.dspy.log_model(
        model,
        "model",
        use_dspy_model_save=True,
    )
```

See <APILink fn="mlflow.dspy.log_model" /> and <APILink fn="mlflow.dspy.save_model" /> for full parameters.

## Pickle-free format for LightGBM model

For LightGBM models that are the scikit-learn model types (e.g., `LGBMClassifier`, `LGBMRegressor`), you can use the **skops** format. This does not apply to `lightgbm.Booster` instances, which use a native format.

```python
import mlflow
import mlflow.lightgbm
from lightgbm import LGBMClassifier
from sklearn.datasets import load_iris

X, y = load_iris(return_X_y=True)
model = LGBMClassifier(objective="multiclass", random_state=42).fit(X, y)

with mlflow.start_run():
    mlflow.lightgbm.log_model(
        model,
        "model",
        serialization_format="skops",
    )
```

See <APILink fn="mlflow.lightgbm.log_model" /> and <APILink fn="mlflow.lightgbm.save_model" /> for details.

## Pickle-free format for LangChain model

LangChain model supports saving as **Models-From-Code** artifacts, which avoids pickle entirely. For details and examples, see [Models From Code](/ml/model/models-from-code).

## Pickle-free format for custom Python model

Custom Python model supports saving as **Models-From-Code** artifacts, which avoids pickle entirely. For details and examples, see [Models From Code](/ml/model/models-from-code).


## Global configuration to force MLflow pickle-free model loading

You can disallow MLflow model loading with `pickle` or `cloudpickle` globally by setting the environment variable as follows:

```bash
export MLFLOW_ALLOW_PICKLE_DESERIALIZATION=false
```

When set to `false`, loading a model that was saved with `pickle` or `cloudpickle` will raise an error unless you use a pickle-free saving option when logging the model. The default is `true` for backward compatibility.


## Summary

| Flavor | Pickle-free option | Notes |
|--------|--------------------|-------|
| Scikit-learn | `serialization_format="skops"` | Use `skops_trusted_types` when needed. |
| PyTorch | `export_model=True` | Requires `input_example`, torch >= 2.4; not for ScriptModule. |
| DSPy | `use_dspy_model_save=True` | Requires dspy >= 3.1.0. |
| LightGBM | `serialization_format="skops"` | Only for lightGBM model of sklearn type |
| LangChain | Models From Code | Pickle saving emits warnings. |
| Custom Python model | Models From Code | Pickle saving emits warnings. |

# Scikit-learn with MLflow

This guide covers how to use scikit-learn with MLflow for experiment tracking and hyperparameter tuning.

## Quick Start

Get started with scikit-learn and MLflow in just a few lines of code:

```python
import mlflow
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split

# Enable autologging
mlflow.sklearn.autolog()

# Load and prepare data
wine = load_wine()
X_train, X_test, y_train, y_test = train_test_split(
    wine.data, wine.target, test_size=0.2, random_state=42
)

# Train model - MLflow automatically logs everything!
with mlflow.start_run():
    model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)
    model.fit(X_train, y_train)

    # Evaluation metrics are automatically captured
    train_score = model.score(X_train, y_train)
    test_score = model.score(X_test, y_test)

    print(f"Train accuracy: {train_score:.3f}, Test accuracy: {test_score:.3f}")
```

Autologging captures all model parameters, training metrics, the trained model, and model signatures.

:::tip Tracking Server Setup
Running locally? MLflow stores experiments in the current directory by default. For team collaboration or remote tracking, **[set up a tracking server](/tracking/tracking-server/self-host)**.
:::

## Autologging

Enable autologging to automatically track scikit-learn experiments:

```python
import mlflow
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split

# Load data
cancer = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
    cancer.data, cancer.target, test_size=0.2, random_state=42
)

# Enable autologging
mlflow.sklearn.autolog()

with mlflow.start_run():
    model = GradientBoostingClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    # Model scoring is automatically captured
    train_score = model.score(X_train, y_train)
    test_score = model.score(X_test, y_test)
```

## Hyperparameter Tuning

### Grid Search

MLflow automatically creates child runs for hyperparameter tuning:

```python
import mlflow
from sklearn.datasets import load_digits
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV, train_test_split

# Load data
digits = load_digits()
X_train, X_test, y_train, y_test = train_test_split(
    digits.data, digits.target, test_size=0.2, random_state=42
)

# Enable autologging
mlflow.sklearn.autolog(max_tuning_runs=10)

# Define parameter grid
param_grid = {
    "n_estimators": [50, 100, 200],
    "max_depth": [5, 10, 15, None],
    "min_samples_split": [2, 5, 10],
}

with mlflow.start_run(run_name="RF Hyperparameter Tuning"):
    rf = RandomForestClassifier(random_state=42)
    grid_search = GridSearchCV(rf, param_grid, cv=5, scoring="accuracy", n_jobs=-1)
    grid_search.fit(X_train, y_train)

    best_score = grid_search.score(X_test, y_test)
    print(f"Best params: {grid_search.best_params_}")
    print(f"Best CV score: {grid_search.best_score_:.3f}")
    print(f"Test score: {best_score:.3f}")
```

### Optuna Integration

For advanced hyperparameter optimization:

```python
import mlflow
import optuna
from sklearn.datasets import load_breast_cancer
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split

# Load data
cancer = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
    cancer.data, cancer.target, test_size=0.2, random_state=42
)

mlflow.sklearn.autolog()


def objective(trial):
    params = {
        "n_estimators": trial.suggest_int("n_estimators", 50, 200),
        "max_depth": trial.suggest_int("max_depth", 3, 10),
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3),
    }

    with mlflow.start_run(nested=True):
        model = GradientBoostingClassifier(**params, random_state=42)
        model.fit(X_train, y_train)
        accuracy = model.score(X_test, y_test)
        return accuracy


with mlflow.start_run():
    study = optuna.create_study(direction="maximize")
    study.optimize(objective, n_trials=20)

    mlflow.log_params({f"best_{k}": v for k, v in study.best_params.items()})
    mlflow.log_metric("best_accuracy", study.best_value)
```

:::note Nested Runs
The `nested=True` parameter creates child runs for each trial under the parent run, enabling hierarchical organization of hyperparameter tuning experiments. Learn more about **[hierarchical runs](/ml/tracking/tracking-api#hierarchical-runs-with-parent-child-relationships)**.
:::

## Adding Custom Metrics

Extend autologging with custom evaluation metrics:

```python
import mlflow
from sklearn.datasets import load_breast_cancer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score, precision_score, recall_score
from sklearn.model_selection import train_test_split

# Load data
cancer = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
    cancer.data, cancer.target, test_size=0.2, random_state=42
)

mlflow.sklearn.autolog()

with mlflow.start_run():
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    # Add custom metrics
    y_pred = model.predict(X_test)

    mlflow.log_metrics(
        {
            "custom_f1": f1_score(y_test, y_pred, average="weighted"),
            "custom_precision": precision_score(y_test, y_pred, average="weighted"),
            "custom_recall": recall_score(y_test, y_pred, average="weighted"),
        }
    )
```

## Learn More

import TilesGrid from "@site/src/components/TilesGrid";
import TileCard from "@site/src/components/TileCard";
import { BarChart3, Rocket, Database } from "lucide-react";

<TilesGrid>
  <TileCard
    icon={Database}
    iconSize={48}
    title="Model Registry"
    description="Register and manage scikit-learn model versions with aliases for deployment workflows."
    href="/model-registry"
    linkText="Model registry guide →"
    containerHeight={64}
  />
  <TileCard
    icon={Rocket}
    iconSize={48}
    title="Model Deployment"
    description="Deploy scikit-learn models to production using MLflow's serving capabilities and cloud integrations."
    href="/deployment"
    linkText="Deployment guide →"
    containerHeight={64}
  />
  <TileCard
    icon={BarChart3}
    iconSize={48}
    title="Model Evaluation"
    description="Evaluate scikit-learn models using MLflow's comprehensive evaluation framework with built-in metrics."
    href="/ml/evaluation"
    linkText="Evaluation guide →"
    containerHeight={64}
  />
</TilesGrid>

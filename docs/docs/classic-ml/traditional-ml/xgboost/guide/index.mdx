import { APILink } from "@site/src/components/APILink";
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import TilesGrid from "@site/src/components/TilesGrid";
import TileCard from "@site/src/components/TileCard";
import { BarChart3, Rocket } from "lucide-react";

# XGBoost with MLflow

This guide covers how to use XGBoost with MLflow for experiment tracking, model management, and deployment. It covers both the native XGBoost API and scikit-learn compatible interface.

## Autologging

Enable autologging to automatically track XGBoost experiments:

```python
import mlflow
import mlflow.xgboost
import xgboost as xgb
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split

# Enable autologging for XGBoost
mlflow.xgboost.autolog()

# Load sample data
data = load_diabetes()
X_train, X_test, y_train, y_test = train_test_split(
    data.data, data.target, test_size=0.2, random_state=42
)

# Prepare DMatrix format
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Define training parameters
params = {
    "objective": "reg:squarederror",
    "max_depth": 6,
    "learning_rate": 0.1,
    "subsample": 0.8,
    "colsample_bytree": 0.8,
    "random_state": 42,
}

# Train model - MLflow automatically logs everything
with mlflow.start_run():
    model = xgb.train(
        params=params,
        dtrain=dtrain,
        num_boost_round=100,
        evals=[(dtrain, "train"), (dtest, "test")],
        early_stopping_rounds=10,
        verbose_eval=False,
    )
```

Autologging captures:

- All parameters and training configuration
- Training and validation metrics per iteration
- Feature importance plots for multiple types (weight, gain, cover, total_gain) with both visualizations and JSON artifacts
- The trained model with serialization format
- Early stopping metrics and best iteration information

## API Support

MLflow supports both native XGBoost API and scikit-learn compatible estimators:

<Tabs>
  <TabItem value="native" label="Native XGBoost API" default>

```python
import mlflow
import xgboost as xgb

mlflow.xgboost.autolog()

dtrain = xgb.DMatrix(X_train, label=y_train)
model = xgb.train(params, dtrain, num_boost_round=100)
```

  </TabItem>
  <TabItem value="sklearn" label="Scikit-learn API">

```python
import mlflow
from xgboost import XGBClassifier

mlflow.sklearn.autolog()

model = XGBClassifier(n_estimators=100, max_depth=6)
model.fit(X_train, y_train)
```

  </TabItem>
</Tabs>

## Manual Logging

For more control, you can manually log parameters, metrics, and models:

```python
import mlflow
import mlflow.xgboost
import xgboost as xgb
from sklearn.metrics import accuracy_score
from mlflow.models import infer_signature

with mlflow.start_run():
    params = {
        "objective": "binary:logistic",
        "max_depth": 6,
        "learning_rate": 0.1,
    }

    mlflow.log_params(params)

    dtrain = xgb.DMatrix(X_train, label=y_train)
    dtest = xgb.DMatrix(X_test, label=y_test)

    model = xgb.train(
        params=params,
        dtrain=dtrain,
        num_boost_round=100,
        evals=[(dtest, "test")],
    )

    # Log metrics
    y_pred = model.predict(dtest)
    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))
    mlflow.log_metric("accuracy", accuracy)

    # Log model
    signature = infer_signature(X_train, y_pred)
    mlflow.xgboost.log_model(model, name="model", signature=signature)
```

## Hyperparameter Optimization

MLflow automatically creates child runs for hyperparameter tuning with GridSearchCV:

```python
import mlflow
from sklearn.model_selection import GridSearchCV
from xgboost import XGBClassifier

mlflow.sklearn.autolog()

param_grid = {
    "n_estimators": [50, 100],
    "max_depth": [3, 6],
    "learning_rate": [0.01, 0.1],
}

with mlflow.start_run():
    model = XGBClassifier(random_state=42)
    grid_search = GridSearchCV(model, param_grid, cv=5, scoring="roc_auc")
    grid_search.fit(X_train, y_train)
```

You can also use Optuna for more advanced hyperparameter optimization:

```python
import mlflow
import optuna
from xgboost import XGBClassifier

mlflow.xgboost.autolog()


def objective(trial):
    params = {
        "n_estimators": trial.suggest_int("n_estimators", 50, 200),
        "max_depth": trial.suggest_int("max_depth", 3, 10),
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3),
    }

    with mlflow.start_run(nested=True):
        model = XGBClassifier(**params, random_state=42)
        model.fit(X_train, y_train)
        accuracy = model.score(X_test, y_test)
        return accuracy


study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=20)
```

## Model Management

### Saving Models

Log models with specific serialization formats:

```python
import mlflow.xgboost
from mlflow.models import infer_signature

signature = infer_signature(X_train, model.predict(xgb.DMatrix(X_train)))

with mlflow.start_run():
    mlflow.xgboost.log_model(
        xgb_model=model,
        name="model",
        signature=signature,
        model_format="json",  # Recommended: json, ubj, or xgb
    )
```

### Loading Models

```python
# Load as native XGBoost model
model = mlflow.xgboost.load_model(f"runs:/{run_id}/model")

# Load as PyFunc for generic interface
pyfunc_model = mlflow.pyfunc.load_model(f"runs:/{run_id}/model")

# Load from model registry
model = mlflow.pyfunc.load_model("models:/XGBoostModel@champion")
```

## Model Registry

Register models to the MLflow Model Registry for version control and deployment:

```python
from mlflow import MlflowClient

# Register model during logging
with mlflow.start_run():
    mlflow.xgboost.log_model(
        xgb_model=model,
        name="model",
        registered_model_name="XGBoostModel",
        signature=signature,
    )

# Set alias for deployment
client = MlflowClient()
client.set_registered_model_alias(
    name="XGBoostModel",
    alias="champion",
    version=1,
)
```

## Model Serving

Serve models using MLflow's built-in serving:

```bash
mlflow models serve -m "models:/XGBoostModel@champion" -p 5000
```

Make predictions via REST API:

```python
import requests

data = {"inputs": [[1.2, 0.8, 3.4, 2.1]]}
response = requests.post(
    "http://localhost:5000/invocations",
    headers={"Content-Type": "application/json"},
    json=data,
)
predictions = response.json()
```

## Autolog Configuration

Customize autologging behavior with additional options:

```python
mlflow.xgboost.autolog(
    importance_types=["weight", "gain", "cover"],
    log_input_examples=True,
    log_model_signatures=True,
    log_models=True,
    log_datasets=True,
    model_format="json",
    registered_model_name="XGBoostModel",
    extra_tags={"team": "data-science", "project": "churn-prediction"},
)
```

Key configuration options:

- `importance_types`: Which feature importance metrics to log
- `log_input_examples`: Include sample inputs with the model
- `log_model_signatures`: Automatically infer and log model signatures
- `model_format`: Serialization format (json, ubj, or xgb)
- `registered_model_name`: Automatically register models to the Model Registry
- `extra_tags`: Add custom tags to all runs

## Learn More

<TilesGrid>
  <TileCard
    icon={BarChart3}
    iconSize={48}
    title="Model Evaluation"
    description="Evaluate XGBoost models using MLflow's comprehensive evaluation framework with built-in metrics and custom evaluators."
    href="/ml/evaluation"
    linkText="Learn about evaluation →"
    containerHeight={64}
  />
  <TileCard
    icon={Rocket}
    iconSize={48}
    title="Model Deployment"
    description="Deploy XGBoost models locally, to Kubernetes, AWS SageMaker, or other cloud platforms using MLflow's deployment tools."
    href="/ml/deployment"
    linkText="Learn about deployment →"
    containerHeight={64}
  />
</TilesGrid>

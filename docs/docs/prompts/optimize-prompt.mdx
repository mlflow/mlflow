---
sidebar_position: 5
sidebar_label: Optimize Prompts
---

import { APILink } from "@site/src/components/APILink";

# Optimize Prompts (Experimental)

MLflow allows you to plug your prompts into advanced prompt optimization techniques through MLflow's unified interface using the <APILink fn="mlflow.genai.optimize_prompt" /> API. 
This feature helps you improve your prompts automatically by leveraging evaluation metrics and labeled data.
Currently, DSPy's MIPROv2 algorithm is supported by this API.

## Overview

In order to use <APILink fn="mlflow.genai.optimize_prompt" /> API, you need to prepare the following:

1. An existing prompt registered in MLflow.
2. A set of <APILink fn="mlflow.genai.Scorer">Scorer</APILink> objects that evaluate the quality of the prompt.
3. A set of training data and optionally validation data containing inputs and expected outputs.

## Basic Usage

Here's a simple example of optimizing a question-answering prompt:

As a prerequisite, you need to install DSPy.

```bash
$ pip install dspy>=2.6.0
```

Then, run the following code to register the initial prompt and optimize it.
{/* TODO: Add multi-step agent example once Prompt Registry is released in the managed MLflow. */}

```python
import mlflow
from mlflow.genai.scorers import scorer
from mlflow.genai.optimize import OptimizerConfig, LLMParams

# Define a scorer function to evaluate prompt performance with the @scorer decorator
@scorer
def exact_match(expectations, outputs) -> bool:
    return expectations == outputs

# Register the initial prompt
initial_template="""
You are a mathematical calculation agent. Let's think step by step to answer the following question:

Question: {{question}}

Return the result in a JSON string in the format of {"answer": "xxx"}.
"""

prompt = mlflow.register_prompt(
    name="math",
    template=initial_template,
)

# The data can be a list of dictionaries, a pandas DataFrame, or an mlflow.genai.EvaluationDataset
# It needs to contain inputs and expectations where each row is a dictionary.
train_data = [
    {
        'inputs': {'question': 'Given that $y=3$, evaluate $(1+y)^y$.'},
        'expectations': {'answer': '64'}
    },
    {
        'inputs': {'question': 'The midpoint of the line segment between $(x,y)$ and $(-9,1)$ is $(3,-5)$. Find $(x,y)$.'},
        'expectations': {'answer': '(15,-11)'}
    },
    {
        'inputs': {'question': 'What is the value of $b$ if $5^b + 5^b + 5^b + 5^b + 5^b = 625^{(b-1)}$? Express your answer as a common fraction.'},
        'expectations': {'answer': '\\frac{5}{3}'}
    },
    {
        'inputs': {'question': 'Evaluate the expression $a^3\\cdot a^2$ if $a= 5$.'},
        'expectations': {'answer': '3125'}
    },
    {
        'inputs': {'question': 'Evaluate $\\lceil 8.8 \\rceil+\\lceil -8.8 \\rceil$.'},
        'expectations': {'answer': '17'}
    },
]

eval_data = [
    {
        'inputs': {'question': 'The sum of 27 consecutive positive integers is $3^7$. What is their median?'},
        'expectations': {'answer': '81'}
    },
    {
        'inputs': {'question': 'What is the value of $x$ if $x^2 - 10x + 25 = 0$?'},
        'expectations': {'answer': '5'}
    },
    {
        'inputs': {'question': 'If $a\\ast b = 2a+5b-ab$, what is the value of $3\\ast10$?'},
        'expectations': {'answer': '26'}
    },
    {
        'inputs': {'question': 'Given that $-4$ is a solution to $x^2 + bx -36 = 0$, what is the value of $b$?'},
        'expectations': {'answer': '-5'}
    },
]

# Optimize the prompt
result = mlflow.genai.optimize_prompt(
    target_llm_params=LLMParams(model_name="openai/gpt-4.1-mini"),
    prompt=prompt,
    train_data=train_data,
    eval_data=eval_data,
    scorers=[exact_match],
    optimizer_config=OptimizerConfig(
        num_instruction_candidates=8,
        max_few_show_examples=2,
    )
)

# The optimized prompt is automatically registered as a new version
print(result.prompt.uri)
```

After the optimization process is completed, you can visit the MLFlow Prompt Registry page and see the optimized prompt.

![Optimized Prompt](/images/llms/optimize-prompt/registered_prompt.png)

Note that the optimized prompt of <APILink fn="mlflow.genai.optimize_prompt" /> expects the output to be a JSON string.
Therefore, you need to parse the output using `json.loads` in your application.

```python
import mlflow
import json

def predict(question: str, prompt_uri: str) -> str:
    prompt = mlflow.load_prompt(prompt_uri)
    content = prompt.format(question=question)
    completion = openai.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "user", "content": content}],
        temperature=0.1,
    )

    return json.loads(completion.choices[0].message.content)["answer"]
```

## Configuration

You can customize the optimization process using `OptimizerConfig`, which includes the following parameters:

- `num_instruction_candidates`: The number of candidate instructions to try.
- `max_few_show_examples`: The maximum number of examples to show in few-shot demonstrations.
- `optimizer_llm`: The LLM to use for optimization.

See <APILink fn="mlflow.genai.OptimizerConfig" /> for more details.

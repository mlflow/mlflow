import TilesGrid from "@site/src/components/TilesGrid";
import TileCard from "@site/src/components/TileCard";
import TabsWrapper from "@site/src/components/TabsWrapper";
import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";
import FeatureHighlights from "@site/src/components/FeatureHighlights";
import { Shield, Globe, Zap, Settings, Users, Wrench, Play, Database, BarChart3 } from "lucide-react";

# MLflow AI Gateway

MLflow AI Gateway provides a unified interface for deploying and managing multiple LLM providers within your organization. It simplifies interactions with services like OpenAI, Anthropic, and others through a single, secure endpoint.

The gateway server excels in production environments where organizations need to manage multiple LLM providers securely while maintaining operational flexibility and developer productivity.

MLflow AI Gateway also offers passthrough endpoints, enabling requests to be forwarded in providers' native formats. This feature allows you to access and leverage the latest provider-specific capabilities as soon as they become available.

<FeatureHighlights features={[
  {
    icon: Globe,
    title: "Unified Interface",
    description: "Access multiple LLM providers through a single endpoint, eliminating the need to integrate with each provider individually."
  },
  {
    icon: Shield,
    title: "Centralized Security",
    description: "Store API keys in one secure location with request/response logging for audit trails and compliance."
  },
  {
    icon: Database,
    title: "Provider Abstraction",
    description: "Switch between OpenAI, Anthropic, Google, and other providers without changing your application code."
  },
  {
    icon: Zap,
    title: "Zero-Downtime Updates",
    description: "Add, remove, or modify endpoints dynamically without restarting the server or disrupting running applications."
  },
  {
    icon: BarChart3,
    title: "Cost Optimization",
    description: "Monitor usage across providers and optimize costs by routing requests to the most efficient models."
  },
  {
    icon: Users,
    title: "Team Collaboration",
    description: "Shared endpoint configurations and standardized access patterns across development teams."
  }
]} />

## Quick Start

Get your AI Gateway running in minutes:

<TabsWrapper>
<Tabs>
<TabItem value="install" label="1. Install" default>

Install MLflow with GenAI dependencies:

```bash
pip install 'mlflow[genai]'
```

</TabItem>
<TabItem value="start" label="2. Start Server">

Start the MLflow server with a SQL backend:

```bash
mlflow server --backend-store-uri sqlite:///mlflow.db --host 0.0.0.0 --port 5000
```

</TabItem>
<TabItem value="configure" label="3. Configure">

Navigate to the Gateway section at `http://localhost:5000/#/gateway` and create your first endpoint through the web interface. Select your provider, model, and configure your API key.

</TabItem>
<TabItem value="test" label="4. Test">

Test your endpoint using the unified MLflow API:

```bash
curl -X POST http://localhost:5000/gateway/my-endpoint/mlflow/invocations \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

</TabItem>
</Tabs>
</TabsWrapper>

## Next Steps

Ready to dive deeper? Start with the setup guide or explore the legacy YAML-based configuration:

<TilesGrid>
  <TileCard
    icon={Wrench}
    title="Setup Guide"
    description="Configure endpoints, API keys, and advanced routing features"
    href="./setup"
    linkText="Get started →"
  />
  <TileCard
    icon={Play}
    title="Query Guide"
    description="Learn how to call endpoints with unified and passthrough APIs"
    href="./query"
    linkText="View query guide →"
  />
  <TileCard
    icon={Settings}
    title="Gateway Server (Legacy)"
    description="YAML-based configuration for endpoints and routing"
    href="./legacy"
    linkText="View legacy docs →"
  />
</TilesGrid>

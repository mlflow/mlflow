import TilesGrid from "@site/src/components/TilesGrid";
import TileCard from "@site/src/components/TileCard";
import FeatureHighlights from "@site/src/components/FeatureHighlights";
import { Shield, Globe, Zap, Users, Wrench, Play, GitBranch, BarChart3 } from "lucide-react";

# MLflow AI Gateway

MLflow AI Gateway provides a unified interface for deploying and managing multiple LLM providers within your organization. It simplifies interactions with services like OpenAI, Anthropic, and others through a single, secure endpoint.

The gateway excels in production environments where organizations need to manage multiple LLM providers securely while maintaining operational flexibility. Advanced routing capabilities enable traffic splitting for A/B testing and automatic failover chains for high availability.

MLflow AI Gateway also offers passthrough endpoints, enabling requests to be forwarded in providers' native formats. This feature allows you to access provider-specific capabilities as soon as they become available.

<FeatureHighlights features={[
  {
    icon: Globe,
    title: "Unified Interface",
    description: "Access multiple LLM providers through a single endpoint, eliminating the need to integrate with each provider individually."
  },
  {
    icon: Shield,
    title: "Centralized Security",
    description: "Store API keys in one secure location with request/response logging for audit trails and compliance."
  },
  {
    icon: GitBranch,
    title: "Advanced Routing",
    description: "Traffic splitting for A/B testing and automatic fallbacks ensure high availability across providers."
  },
  {
    icon: Zap,
    title: "Zero-Downtime Updates",
    description: "Add, remove, or modify endpoints dynamically without restarting the server or disrupting running applications."
  },
  {
    icon: BarChart3,
    title: "Cost Optimization",
    description: "Monitor usage across providers and optimize costs by routing requests to the most efficient models."
  },
  {
    icon: Users,
    title: "Team Collaboration",
    description: "Shared endpoint configurations and standardized access patterns across development teams."
  }
]} />

## Quick Start

Get your AI Gateway running in minutes:

**1. Install MLflow with GenAI dependencies:**

```bash
pip install 'mlflow[genai]'
```

**2. Start the MLflow Tracking Server:**

```bash
mlflow server --port 5000
```

The AI Gateway runs within the MLflow Tracking Server itself and requires a SQL-based backend store with the FastAPI tracking server.

**3. Configure your first endpoint:**

Navigate to `http://localhost:5000/#/gateway` and create your first endpoint `my-chat-endpoint` through the web interface. Select your provider, model, and configure your API key. API keys are encrypted and stored securely in the MLflow backend.

![Create Endpoint](/images/genai/governance/ai-gateway/create-endpoint.png)

**4. Test your endpoint:**

```bash
curl -X POST http://localhost:5000/gateway/my-chat-endpoint/mlflow/invocations \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

## Next Steps

Ready to dive deeper? Start with the setup guide or explore the legacy YAML-based configuration:

<TilesGrid>
  <TileCard
    icon={Wrench}
    title="Setup Guide"
    description="Configure endpoints, API keys, and advanced routing features"
    href="./setup"
    linkText="Get started →"
  />
  <TileCard
    icon={GitBranch}
    title="Advanced Routing"
    description="Configure traffic splitting and fallbacks for high availability"
    href="./routing"
    linkText="Learn routing →"
  />
  <TileCard
    icon={Play}
    title="Query Guide"
    description="Learn how to call endpoints with unified and passthrough APIs"
    href="./query"
    linkText="View query guide →"
  />
</TilesGrid>

---
description: "Try MLflow GenAI features instantly with pre-populated demo data"
sidebar_position: 1
---

import Tabs from "@theme/Tabs"
import TabItem from "@theme/TabItem"
import TabsWrapper from "@site/src/components/TabsWrapper";
import ImageBox from "@site/src/components/ImageBox";
import TilesGrid from "@site/src/components/TilesGrid";
import TileCard from "@site/src/components/TileCard";

# Try the Demo

Experience MLflow GenAI features instantly with pre-populated demo data. The demo launches a local MLflow server with sample traces, evaluation runs, datasets, and prompts - no configuration required.

<ImageBox src="/images/demo/demo-overview.png" alt="Demo Overview" />

## Quickstart

Run this single command to start exploring:

```bash
uvx mlflow demo
```

:::tip No Installation Required
Using [`uvx`](https://docs.astral.sh/uv/getting-started/installation/) runs MLflow directly without installing it globally. If you prefer, you can also use `pip install mlflow` followed by `mlflow demo`.
:::

## What's Included

The demo populates an "MLflow Demo" experiment with sample data for key GenAI features:

<TabsWrapper>
<Tabs>
<TabItem value="traces" label="Traces" default>

<ImageBox src="/images/demo/demo-traces.png" alt="Demo Traces" />

### [Traces](/genai/tracing)

Observe your GenAI application's execution with detailed traces capturing inputs, outputs, latency, and token usage for every LLM call, retrieval, and tool invocation.

</TabItem>
<TabItem value="evaluation" label="Evaluation Runs">

<ImageBox src="/images/demo/demo-eval.png" alt="Demo Evaluation Runs" />

### [Evaluation Runs](/genai/eval-monitor)

Systematically measure quality with LLM judges and custom scorers. Compare versions side-by-side to track improvements and catch regressions.

</TabItem>
<TabItem value="datasets" label="Datasets">

<ImageBox src="/images/demo/demo-datasets.png" alt="Demo Datasets" />

### [Datasets](/genai/datasets)

Manage evaluation datasets for testing your GenAI applications. Create, version, and reuse datasets across evaluation runs to ensure consistent quality benchmarks.

</TabItem>
<TabItem value="prompts" label="Prompts">

<ImageBox src="/images/demo/demo-prompts.png" alt="Demo Prompts" />

### [Prompts](/genai/prompt-registry)

Version, compare, and manage prompts with full history tracking. Use aliases to manage lifecycle stages like development, staging, and production.

</TabItem>
</Tabs>
</TabsWrapper>

## Usage Options

<TabsWrapper>
<Tabs>
<TabItem value="standalone" label="New to MLflow" default>

For new users or quick exploration, the standalone mode is simplest:

```bash
uvx mlflow demo
```

Or if MLflow is already installed:

```bash
mlflow demo
```

**Options:**

- `--port PORT`: Run on a specific port (default: auto-selected)
- `--no-browser`: Don't open browser automatically
- `--refresh`: Delete existing demo data and regenerate it

</TabItem>
<TabItem value="existing" label="Familiar with MLflow">

If you already have an MLflow server running, you can add demo data to it:

```bash
mlflow demo --tracking-uri http://localhost:5000
```

This generates the demo data in your existing server's storage, creating the "MLflow Demo" experiment alongside your existing experiments.

:::info
If you want to remove the demo data after exploring the features, you can delete it using the cleanup option below.
:::

</TabItem>
</Tabs>
</TabsWrapper>

## Launch Demo from the UI

The MLflow home page includes a banner offering to generate demo data. Click **"Launch Demo"** to generate the demo data and navigate to the traces view, or click any of the individual feature cards to generate the demo and navigate directly to that feature.

<ImageBox src="/images/demo/demo-home.png" alt="Demo Home Page" />

## Cleanup

To remove the demo data, go to **Settings** and click **"Delete Demo Data"**. This removes all demo traces, runs, datasets, and prompts.

<ImageBox src="/images/demo/demo-settings.png" alt="Demo Settings" />

## Next Steps

After exploring the demo, continue your MLflow GenAI journey:

<TilesGrid>
  <TileCard
    title="Set Up Your Environment"
    description="Configure MLflow for your own projects"
    href="/genai/getting-started/connect-environment"
    linkText="Get started →"
  />
  <TileCard
    title="Start Tracing"
    description="Add observability to your GenAI app"
    href="/genai/tracing/quickstart"
    linkText="Start tracing →"
  />
  <TileCard
    title="Run Evaluations"
    description="Systematically test your application"
    href="/genai/eval-monitor/quickstart"
    linkText="Evaluate →"
  />
  <TileCard
    title="Manage Prompts"
    description="Version and iterate on prompts"
    href="/genai/prompt-registry/create-and-edit-prompts"
    linkText="Manage prompts →"
  />
</TilesGrid>

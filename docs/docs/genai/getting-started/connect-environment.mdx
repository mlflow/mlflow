---
description: "Learn how to setup the MLflow server for GenAI application development."
last_update:
  date: 2025-11-27
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import TabsWrapper from '@site/src/components/TabsWrapper';
import ImageBox from '@site/src/components/ImageBox';

# Set Up MLflow Server

MLflow is open source, and you can set up the MLflow server using either `pip` or `docker`.

Before you can leverage MLflow for your GenAI application development, you must first start the MLflow server.

## Prerequisites

**Python Environment**: Python 3.10+

## Start the MLflow Server

<TabsWrapper>
<Tabs>
<TabItem value="local" label="Local (pip)" default>

For the fastest setup, you can install the `mlflow` Python package via `pip` and start the MLflow server locally.

```bash
pip install --upgrade mlflow
mlflow ui --backend-store-uri sqlite:///mlflow.db --port 5000
```

</TabItem>

<TabItem value="docker" label="Local (docker)">

MLflow provides a Docker Compose file to start a local MLflow server with a postgres database and a minio server.

```bash
git clone https://github.com/mlflow/mlflow.git
cd docker-compose
cp .env.dev.example .env
docker compose up -d
```

Refer to the [instruction](https://github.com/mlflow/mlflow/tree/master/docker-compose/README.md) for more details, e.g., overriding the default environment variables.

</TabItem>

</Tabs>
</TabsWrapper>

This will start the server at port 5000 on your local machine and you can access the MLflow web UI at http://localhost:5000.

<ImageBox src="/images/quickstart/quickstart_ui_home.png" alt="MLflow UI Home" />

## Self-hosting

If you are looking to self-host the MLflow server, please see the [Self-Hosting Guide](/self-hosting) for more details.

:::info

If you are using MLflow on Databricks, please visit <ins>[this](https://docs.databricks.com/aws/en/mlflow3/genai/getting-started/)</ins> for environment setup instructions specific to Databricks.

:::

## Next Step

Now that you have started the MLflow server, let's start tracing your GenAI application.

Follow [this quickstart](/genai/tracing/quickstart) to send your GenAI application traces to the MLflow server.

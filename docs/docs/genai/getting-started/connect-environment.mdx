---
description: "Learn how to connect your development environment to MLflow for GenAI application development, whether using OSS MLflow or a managed offering."
last_update:
  date: 2025-05-18
---

import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";

# Connect Your Development Environment to MLflow

This guide shows you how to connect your development environment to an MLflow Experiment. You can run MLflow on your local machine, self-host the open source MLflow service, or use a managed offering, such as Databricks Managed MLflow.

:::note[MLflow Experiments]
An MLflow Experiment is the container for your GenAI application. Learn more about Experiments in the [MLflow documentation](/ml/tracking).
:::

## Prerequisites

<Tabs>
  <TabItem value="oss" label="OSS MLflow">

    - **Python Environment**: Python 3.8+ with pip installed
    - **Local or Remote Server**: Access to run MLflow tracking server

  </TabItem>
  <TabItem value="managed" label="Databricks">

    - **Databricks Workspace**: Access to a Databricks workspace

    :::note[Authentication Methods]
    This guide describes using a Databricks Personal Access Token. MLflow also works with the other [Databricks-supported authentication methods](https://docs.databricks.com/aws/en/dev-tools/auth).
    :::

  </TabItem>
</Tabs>

## Setup Instructions

<Tabs>
  <TabItem value="oss" label="OSS MLflow">

        ### Step 1: Install MLflow

        Install MLflow for local development:

        ```bash
        pip install --upgrade "mlflow>=3.1"
        ```

        ### Step 2: Start MLflow Tracking Server

        **Option A: Local Tracking (Default)**

        MLflow will automatically use local file storage if no tracking URI is specified:

        ```python
        import mlflow

        # Creates local mlruns directory for experiments
        mlflow.set_experiment("my-genai-experiment")
        ```

        **Option B: Remote Tracking Server**

        Start a remote MLflow tracking server:

        ```bash
        # Start MLflow server (in a separate terminal)
        mlflow server --host 0.0.0.0 --port 5000
        ```

        Then configure your client to use the remote server:

        ```python
        import mlflow

        # Connect to remote MLflow server
        mlflow.set_tracking_uri("http://localhost:5000")
        mlflow.set_experiment("my-genai-experiment")
        ```

        **Option C: Database Backend**

        For production use, configure MLflow with a database backend:

        ```bash
        # Example with PostgreSQL
        mlflow server \
            --backend-store-uri postgresql://user:password@localhost:5432/mlflow \
            --default-artifact-root s3://my-mlflow-bucket/artifacts \
            --host 0.0.0.0 \
            --port 5000
        ```

        ### Step 3: Configure Environment (Optional)

        For consistent configuration across your team, use environment variables:

        ```bash
        # .env file
        MLFLOW_TRACKING_URI=http://localhost:5000
        MLFLOW_EXPERIMENT_NAME=my-genai-experiment
        ```

        Load in your Python code:

        ```python
        import os
        from dotenv import load_dotenv
        import mlflow

        load_dotenv()

        # Set tracking URI and experiment
        mlflow.set_tracking_uri(os.getenv("MLFLOW_TRACKING_URI", "file:./mlruns"))
        mlflow.set_experiment(os.getenv("MLFLOW_EXPERIMENT_NAME", "default"))
        ```

        ### Step 4: Verify Your Connection

        Create a test file and run this code:

        ```python
        import mlflow

        # Print connection information
        print(f"MLflow Tracking URI: {mlflow.get_tracking_uri()}")
        print(f"Active Experiment: {mlflow.get_experiment_by_name('my-genai-experiment')}")

        # Test logging
        with mlflow.start_run():
            mlflow.log_param("test_param", "test_value")
            print("✓ Successfully connected to MLflow!")
        ```

        ### Step 5: Access MLflow UI

        Open your browser to view the MLflow UI:

        - **Local tracking**: `http://localhost:5000` (if running mlflow server)
        - **File-based tracking**: Run `mlflow ui` in your project directory, then go to `http://localhost:5000`

      </TabItem>

  <TabItem value="databricks-ide" label="Databricks - Local IDE">

    #### Step 1: Install MLflow

    Install MLflow with Databricks connectivity:

    ```bash
    pip install --upgrade "mlflow[databricks]>=3.1"
    ```

    #### Step 2: Create an MLflow Experiment

    1. Open your Databricks workspace
    2. Go to **Experiments** in the left sidebar under **Machine Learning**
    3. At the top of the Experiments page, click on **New GenAI Experiment**

    #### Step 3: Configure Authentication

    Choose one of the following authentication methods:

    **Option A: Environment Variables**

    1. In your MLflow Experiment, click **Generate API Key**
    2. Copy and run the generated code in your terminal:

    ```bash
    export DATABRICKS_TOKEN=<databricks-personal-access-token>
    export DATABRICKS_HOST=https://<workspace-name>.cloud.databricks.com
    export MLFLOW_TRACKING_URI=databricks
    export MLFLOW_EXPERIMENT_ID=<experiment-id>
    ```

    **Option B: .env File**

    1. In your MLflow Experiment, click **Generate API Key**
    2. Copy the generated code to a `.env` file in your project root:

    ```bash
    DATABRICKS_TOKEN=<databricks-personal-access-token>
    DATABRICKS_HOST=https://<workspace-name>.cloud.databricks.com
    MLFLOW_TRACKING_URI=databricks
    MLFLOW_EXPERIMENT_ID=<experiment-id>
    ```

    3. Install the `python-dotenv` package:

    ```bash
    pip install python-dotenv
    ```

    4. Load environment variables in your code:

    ```python
    # At the beginning of your Python script
    from dotenv import load_dotenv

    # Load environment variables from .env file
    load_dotenv()
    ```

    #### Step 4: Verify Your Connection

    Create a test file and run this code to verify your connection:

    ```python
    import mlflow

    # Test logging to verify connection
    print(f"MLflow Tracking URI: {mlflow.get_tracking_uri()}")
    with mlflow.start_run():
        print("✓ Successfully connected to MLflow!")
    ```

  </TabItem>
  <TabItem value="databricks-notebook" label="Databricks - Notebook">
    #### Step 1: Install MLflow

    Databricks runtimes include MLflow, but for the best experience with GenAI capabilities, update to the latest version:

    ```
    %pip install --upgrade "mlflow[databricks]>=3.1"
    dbutils.library.restartPython()
    ```

    #### Step 2: Create a Notebook

    Creating a Databricks Notebook will create an MLflow Experiment that is the container for your GenAI application. Learn more about Experiments in the [MLflow documentation](/ml/tracking).

    1. Open your Databricks workspace
    2. Go to **New** at the top of the left sidebar
    3. Click **Notebook**

    #### Step 3: Configure Authentication

    No additional authentication configuration is needed when working within a Databricks Notebook. The notebook automatically has access to your workspace and the associated MLflow Experiment.

    #### Step 4: Verify Your Connection

    Run this code in a notebook cell to verify your connection:

    ```python
    import mlflow

    # Test logging to verify connection
    print(f"MLflow Tracking URI: {mlflow.get_tracking_uri()}")
    with mlflow.start_run():
        print("✓ Successfully connected to MLflow!")
    ```

  </TabItem>
</Tabs>

## Next Steps

Now that your environment is connected to MLflow, try the other GenAI quickstarts:

- **Instrument your app with tracing**: Follow the [quickstart](/genai/tracing/quickstart/python-openai) to instrument your first GenAI app
- **Evaluate your app's quality**: Use the [evaluation quickstart](https://docs.databricks.com/aws/en/mlflow3/genai/getting-started/eval.html) to systematically test and improve your app's quality

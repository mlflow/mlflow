---
title: Track Application Versions with MLflow
description: Learn how to version GenAI applications using MLflow LoggedModel as a metadata hub, linking external code with traces and evaluations via mlflow.set_active_model().
---

import FeatureHighlights from "@site/src/components/FeatureHighlights";
import ConceptOverview from "@site/src/components/ConceptOverview";
import TilesGrid from "@site/src/components/TilesGrid";
import TileCard from "@site/src/components/TileCard";
import { APILink } from "@site/src/components/APILink";
import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";
import { GitBranch, Code2, Database, Settings, Eye, Target, Zap, BarChart3, PlayCircle } from "lucide-react";

# Track Application Versions with External Code Management

The production-ready approach to GenAI versioning: use MLflow's **<APILink fn="mlflow.entities.LoggedModel">LoggedModel</APILink>** as a metadata hub that links your git-managed code to traces, evaluations, and configurations. Perfect for teams that want systematic version control without vendor lock-in.

## Why This Approach Works for Production Teams

<FeatureHighlights features={[
  {
    icon: GitBranch,
    title: "Keep Code Where It Belongs",
    description: "Your application code stays in git where your team already works. MLflow tracks metadata and links to specific commits‚Äîno code duplication or vendor lock-in."
  },
  {
    icon: Database,
    title: "Automatic Context Linking",
    description: "Set an active model once, then every trace and evaluation automatically links to that version. No manual bookkeeping across your development workflow."
  },
  {
    icon: Eye,
    title: "Complete Version Visibility",
    description: "See exactly which code, configurations, and performance data belong to each version. Debug issues and reproduce results with complete confidence."
  },
  {
    icon: Target,
    title: "Production-Ready Patterns",
    description: "Designed for real development workflows with git, CI/CD, and team collaboration. Scale from individual experimentation to enterprise deployment."
  }
]} />

## How MLflow LoggedModel Works as a Metadata Hub

<ConceptOverview concepts={[
  {
    icon: Code2,
    title: "External Code References",
    description: "LoggedModel stores git commit hashes and configuration parameters, pointing to your externally managed code rather than duplicating it."
  },
  {
    icon: Settings,
    title: "Active Model Context",
    description: "mlflow.set_active_model() establishes version context so subsequent traces and evaluations automatically link to the correct application version."
  },
  {
    icon: Database,
    title: "Unified Metadata Hub",
    description: "Each LoggedModel version becomes a central reference linking code commits, configurations, traces, and evaluation results in one versioned entity."
  }
]} />

## Quick Start: Version Your Application in 5 Minutes

Transform your GenAI application into a systematically versioned system with automatic trace linking.

### Prerequisites

Install the required packages:

```bash
pip install --upgrade "mlflow>=3.1" openai>=1.0.0
```

:::note
MLflow includes GitPython as a core dependency, so `mlflow.utils.git_utils` functions work out of the box for git integration.
:::

### Step 1: Environment Setup

<Tabs>
  <TabItem value="oss" label="Open Source MLflow">
    ```python
    import os
    import mlflow

    # Configure MLflow tracking
    mlflow.set_tracking_uri("http://localhost:5000")  # Optional: use remote server
    mlflow.set_experiment("my_genai_app_versions")

    # Set LLM provider API key
    os.environ["OPENAI_API_KEY"] = "your-api-key-here"
    ```

  </TabItem>
  <TabItem value="databricks" label="Databricks">
    ```python
    import os
    import mlflow

    # Authentication (only needed outside Databricks notebooks)
    os.environ["DATABRICKS_HOST"] = "https://your-workspace.databricks.com"
    os.environ["DATABRICKS_TOKEN"] = "your-databricks-token"

    # Set LLM provider API key
    os.environ["OPENAI_API_KEY"] = "your-api-key-here"

    # Configure tracking
    mlflow.set_tracking_uri("http://127.0.0.1:5000")
    mlflow.set_experiment("my_genai_app_versions")
    ```

  </TabItem>
</Tabs>

### Step 2: Create Version-Controlled Application

Link your application to git commits for complete traceability:

```python
import mlflow
import openai

# Get current git commit using MLflow's built-in utilities
from mlflow.utils.git_utils import get_git_commit

git_commit = get_git_commit(".")
if git_commit:
    version_id = f"git-{git_commit[:8]}"  # Use short hash
else:
    version_id = "local-dev"  # Fallback if not in git repo

# Create versioned application context
app_name = "customer_support_agent"
model_name = f"{app_name}-{version_id}"

# Establish active model context - all traces will link here
active_model = mlflow.set_active_model(name=model_name)
print(f"‚úÖ Created version: {active_model.name} (ID: {active_model.model_id})")

# Log configuration parameters for this version
app_config = {
    "llm": "gpt-4o-mini",
    "temperature": 0.7,
    "max_tokens": 150,
    "retrieval_strategy": "vector_search_v3",
}

mlflow.log_model_params(model_id=active_model.model_id, params=app_config)
print(f"‚úÖ Logged configuration parameters")
```

### Step 3: Enable Automatic Trace Linking

All LLM calls now automatically link to your application version:

```python
# Enable automatic tracing
mlflow.openai.autolog()


def support_agent(user_query):
    """Customer support agent with automatic trace linking."""
    client = openai.OpenAI()
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You are a helpful customer support agent."},
            {"role": "user", "content": user_query},
        ],
        temperature=0.7,
        max_tokens=150,
    )
    return response.choices[0].message.content


# Test the agent - traces automatically link to your version
test_queries = [
    "How can I track my package?",
    "What's your return policy?",
    "I need help with my account login",
]

print("\nüîç Testing agent with automatic trace linking:")
for query in test_queries:
    response = support_agent(query)
    print(f"Query: {query}")
    print(f"Response: {response[:100]}...")
    print("‚úÖ Trace automatically linked to version\n")
```

**What happens automatically:**

- Every LLM call generates a detailed trace
- All traces link to your specific git commit
- Configuration parameters are preserved
- Version performance can be analyzed systematically

### Step 4: Inspect and Compare Versions

Retrieve version metadata and compare across iterations:

```python
# Fetch your LoggedModel version
logged_model = mlflow.get_logged_model(model_id=active_model.model_id)

print(f"\nüìä Version Information:")
print(f"Model ID: {logged_model.model_id}")
print(f"Name: {logged_model.name}")
print(f"Status: {logged_model.status}")

print(f"\n‚öôÔ∏è Configuration Parameters:")
for param, value in logged_model.params.items():
    print(f"  {param}: {value}")

# Find all versions of your application
from mlflow import search_logged_models
from datetime import datetime

all_versions = search_logged_models(
    experiment_ids=[logged_model.experiment_id],
    filter_string=f"name LIKE '{app_name}%'",
    output_format="list",
)

print(f"\nüìà All Application Versions:")
for version in all_versions:
    created = datetime.fromtimestamp(version.creation_timestamp / 1000)
    print(f"  - {version.name} (Created: {created.strftime('%Y-%m-%d %H:%M')})")
```

## Advanced Version Management Patterns

### Context Manager for Temporary Versions

Test different configurations without changing your active context:

```python
# Temporarily switch to a new version for testing
with mlflow.set_active_model(name=f"{app_name}-experiment-{version_id}") as test_model:
    # Log experimental parameters
    experimental_config = {
        "llm": "gpt-4o-mini",
        "temperature": 0.3,  # Lower temperature for consistency
        "max_tokens": 100,  # Shorter responses
        "system_prompt_version": "v2.1",
    }

    mlflow.log_model_params(model_id=test_model.model_id, params=experimental_config)

    # Test experimental agent
    experimental_response = support_agent("How do I reset my password?")
    print(f"Experimental response: {experimental_response}")
    # ‚úÖ This trace links to the experimental version

# Back to original version context automatically
print(f"Returned to original version: {active_model.name}")
```

### Link Evaluation Results to Versions

Systematically evaluate and compare application versions:

```python
import pandas as pd

# Prepare evaluation dataset
eval_data = pd.DataFrame(
    {"inputs": test_queries, "expected_categories": ["shipping", "returns", "account"]}
)

# Evaluate current version with automatic linking
results = mlflow.genai.evaluate(
    data=eval_data,
    scorers=[
        mlflow.metrics.toxicity(),
        mlflow.metrics.latency(),
        mlflow.metrics.flesch_kincaid_grade_level(),
    ],
    predict_fn=support_agent,
    model_id=active_model.model_id,  # Links evaluation to this version
)

print(f"‚úÖ Evaluation results linked to version {active_model.name}")
print(f"Toxicity score: {results.metrics['toxicity/v1/mean']:.3f}")
print(f"Average latency: {results.metrics['latency/mean']:.3f}ms")
```

## Production Integration Patterns

### CI/CD Integration

```python
# In your CI/CD pipeline
def create_production_version():
    """Create a production-ready version with CI metadata."""

    # Get CI environment information (prefer environment vars in CI)
    ci_commit = (
        os.environ.get("GITHUB_SHA", "")[:8] if os.environ.get("GITHUB_SHA") else None
    )

    # Fallback to MLflow's git utilities if not in CI
    if not ci_commit:
        from mlflow.utils.git_utils import get_git_commit

        git_commit = get_git_commit(".")
        ci_commit = git_commit[:8] if git_commit else "unknown"

    ci_branch = os.environ.get("GITHUB_REF_NAME", "unknown")
    ci_build = os.environ.get("GITHUB_RUN_NUMBER", "unknown")

    # Create production version
    prod_version = f"prod-{ci_commit}-build-{ci_build}"

    with mlflow.set_active_model(name=prod_version) as prod_model:
        # Log production configuration
        prod_config = {
            "deployment_env": "production",
            "git_commit": ci_commit,
            "git_branch": ci_branch,
            "build_number": ci_build,
            "llm": "gpt-4o-mini",
            "temperature": 0.3,
        }

        mlflow.log_model_params(model_id=prod_model.model_id, params=prod_config)

        # Run production validation tests
        validation_passed = run_production_tests()

        # Tag for deployment if validation passes
        if validation_passed:
            mlflow.set_tag("deployment_ready", "true")
            print(f"‚úÖ Version {prod_version} ready for deployment")

        return prod_model.model_id


# Use in deployment scripts
def deploy_validated_version():
    """Deploy the latest validated version."""
    validated_versions = search_logged_models(
        filter_string="tags.deployment_ready = 'true'",
        order_by=["creation_timestamp DESC"],
        output_format="list",
    )

    if validated_versions:
        latest_validated = validated_versions[0]
        print(f"Deploying version: {latest_validated.name}")
        # Deploy using model_id: latest_validated.model_id
    else:
        raise ValueError("No validated versions found for deployment")
```

This production-ready approach gives you complete version control with minimal overhead, keeping your code in git while providing comprehensive observability and systematic evaluation capabilities.

## Next Steps

<TilesGrid>
  <TileCard
    href="/genai/prompt-version-mgmt/version-tracking/compare-app-versions"
    title="Compare App Versions"
    description="Learn how to analyze performance differences between versions using trace-based comparison"
    icon={BarChart3}
  />
  <TileCard
    href="/genai/prompt-version-mgmt/version-tracking/quickstart"
    title="Version Tracking Quickstart"
    description="Get started quickly with a hands-on guide to version tracking in MLflow"
    icon={PlayCircle}
  />
</TilesGrid>

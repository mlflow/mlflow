{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MemAlign: Aligning LLM Judges with Human Feedback\n",
    "This notebook demonstrates how to use MemAlign to align an LLM judge with human preferences.\n",
    "\n",
    "MemAlign uses a dual-memory system:\n",
    "\n",
    "Semantic Memory: Distills general guidelines from human feedback patterns\n",
    "\n",
    "Episodic Memory: Retrieves similar past examples using embeddings for few-shot learning\n",
    "## What you'll learn:\n",
    "You'll learn how to create an LLM judge for evaluating responses and use human feedback to align the judge with human preferences, improving accuracy. MemAlign also offers unalignment which allows you to remove certain pieces of feedback from the judge's memory if, for instance, they are no longer useful or contain sensitive data you have to remove. Lastly, we'll register the judge to the experiment so that it is persisted and can be used in monitoring production traffic."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "First, let's import the required modules and set up the environment."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T05:42:18.787966Z",
     "start_time": "2026-02-06T05:42:01.973614Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install --upgrade \"mlflow>=3.9.0\" litellm dspy jinja2 tqdm databricks-agents",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow==3.9.0\r\n",
      "  Using cached mlflow-3.9.0-py3-none-any.whl.metadata (31 kB)\r\n",
      "Requirement already satisfied: litellm in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.81.0)\r\n",
      "Collecting litellm\r\n",
      "  Using cached litellm-1.81.8-py3-none-any.whl.metadata (30 kB)\r\n",
      "Requirement already satisfied: dspy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (3.1.2)\r\n",
      "Collecting dspy\r\n",
      "  Using cached dspy-3.1.3-py3-none-any.whl.metadata (8.4 kB)\r\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (3.1.6)\r\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.67.1)\r\n",
      "Collecting tqdm\r\n",
      "  Using cached tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\r\n",
      "Collecting databricks-agents\r\n",
      "  Using cached databricks_agents-1.9.3-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Collecting mlflow-skinny==3.9.0 (from mlflow==3.9.0)\r\n",
      "  Downloading mlflow_skinny-3.9.0-py3-none-any.whl.metadata (32 kB)\r\n",
      "Collecting mlflow-tracing==3.9.0 (from mlflow==3.9.0)\r\n",
      "  Using cached mlflow_tracing-3.9.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: Flask-CORS<7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (6.0.2)\r\n",
      "Requirement already satisfied: Flask<4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (3.1.2)\r\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (1.18.1)\r\n",
      "Requirement already satisfied: cryptography<47,>=43.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (46.0.3)\r\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (7.1.0)\r\n",
      "Requirement already satisfied: graphene<4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (3.4.3)\r\n",
      "Requirement already satisfied: gunicorn<24 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (23.0.0)\r\n",
      "Requirement already satisfied: huey<3,>=2.5.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (2.6.0)\r\n",
      "Requirement already satisfied: matplotlib<4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (3.10.8)\r\n",
      "Requirement already satisfied: numpy<3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (2.4.1)\r\n",
      "Requirement already satisfied: pandas<3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (2.3.3)\r\n",
      "Requirement already satisfied: pyarrow<23,>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (22.0.0)\r\n",
      "Requirement already satisfied: scikit-learn<2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (1.8.0)\r\n",
      "Requirement already satisfied: scipy<2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (1.17.0)\r\n",
      "Requirement already satisfied: skops<1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (0.13.0)\r\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow==3.9.0) (2.0.45)\r\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (6.2.4)\r\n",
      "Requirement already satisfied: click<9,>=7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (8.3.1)\r\n",
      "Requirement already satisfied: cloudpickle<4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (3.1.2)\r\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (0.78.0)\r\n",
      "Requirement already satisfied: fastapi<1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (0.128.0)\r\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (3.1.46)\r\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (8.7.1)\r\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (1.39.1)\r\n",
      "Requirement already satisfied: packaging<26 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (25.0)\r\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (6.33.4)\r\n",
      "Requirement already satisfied: pydantic<3,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (2.12.5)\r\n",
      "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (1.2.1)\r\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (6.0.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (2.32.5)\r\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (0.5.5)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (4.15.0)\r\n",
      "Requirement already satisfied: uvicorn<1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mlflow-skinny==3.9.0->mlflow==3.9.0) (0.40.0)\r\n",
      "Requirement already satisfied: aiohttp>=3.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from litellm) (3.13.3)\r\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from litellm) (0.14.0)\r\n",
      "Requirement already satisfied: httpx>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from litellm) (0.28.1)\r\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from litellm) (4.26.0)\r\n",
      "Requirement already satisfied: openai>=2.8.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from litellm) (2.15.0)\r\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from litellm) (0.12.0)\r\n",
      "Requirement already satisfied: tokenizers in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from litellm) (0.22.2)\r\n",
      "Requirement already satisfied: regex>=2023.10.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dspy) (2026.1.15)\r\n",
      "Requirement already satisfied: orjson>=3.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dspy) (3.11.5)\r\n",
      "Requirement already satisfied: optuna>=3.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dspy) (4.7.0)\r\n",
      "Requirement already satisfied: diskcache>=5.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dspy) (5.6.3)\r\n",
      "Requirement already satisfied: json-repair>=0.54.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dspy) (0.55.0)\r\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dspy) (9.1.2)\r\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dspy) (4.12.0)\r\n",
      "Requirement already satisfied: asyncer==0.0.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dspy) (0.0.8)\r\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dspy) (3.6.0)\r\n",
      "Collecting gepa==0.0.26 (from gepa[dspy]==0.0.26->dspy)\r\n",
      "  Using cached gepa-0.0.26-py3-none-any.whl.metadata (29 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2) (3.0.3)\r\n",
      "Collecting dataclasses-json (from databricks-agents)\r\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\r\n",
      "Collecting googleapis-common-protos (from databricks-agents)\r\n",
      "  Using cached googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: urllib3>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from databricks-agents) (2.6.3)\r\n",
      "Collecting whenever==0.7.3 (from databricks-agents)\r\n",
      "  Downloading whenever-0.7.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (11 kB)\r\n",
      "Collecting boto3>1 (from databricks-agents)\r\n",
      "  Using cached boto3-1.42.43-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting botocore (from databricks-agents)\r\n",
      "  Using cached botocore-1.42.43-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp>=3.10->litellm) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp>=3.10->litellm) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp>=3.10->litellm) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp>=3.10->litellm) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp>=3.10->litellm) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp>=3.10->litellm) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp>=3.10->litellm) (1.22.0)\r\n",
      "Requirement already satisfied: Mako in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from alembic!=1.10.0,<2->mlflow==3.9.0) (1.3.10)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio->dspy) (3.11)\r\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>1->databricks-agents)\r\n",
      "  Using cached jmespath-1.1.0-py3-none-any.whl.metadata (7.6 kB)\r\n",
      "Collecting s3transfer<0.17.0,>=0.16.0 (from boto3>1->databricks-agents)\r\n",
      "  Using cached s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from botocore->databricks-agents) (2.9.0.post0)\r\n",
      "Requirement already satisfied: cffi>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from cryptography<47,>=43.0.0->mlflow==3.9.0) (2.0.0)\r\n",
      "Requirement already satisfied: google-auth~=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow==3.9.0) (2.47.0)\r\n",
      "Collecting langchain-openai (from databricks-sdk[openai]>=0.58.0->databricks-agents)\r\n",
      "  Using cached langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Requirement already satisfied: blinker>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from Flask<4->mlflow==3.9.0) (1.9.0)\r\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from Flask<4->mlflow==3.9.0) (2.2.0)\r\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from Flask<4->mlflow==3.9.0) (3.1.5)\r\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from graphene<4->mlflow==3.9.0) (3.2.7)\r\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from graphene<4->mlflow==3.9.0) (3.2.0)\r\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx>=0.23.0->litellm) (2025.11.12)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx>=0.23.0->litellm) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.16.0)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.9.0->mlflow==3.9.0) (3.23.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (2025.9.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (0.37.0)\r\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (0.30.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib<4->mlflow==3.9.0) (1.3.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib<4->mlflow==3.9.0) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib<4->mlflow==3.9.0) (4.61.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib<4->mlflow==3.9.0) (1.4.9)\r\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib<4->mlflow==3.9.0) (12.1.0)\r\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib<4->mlflow==3.9.0) (3.3.1)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=2.8.0->litellm) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=2.8.0->litellm) (0.12.0)\r\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=2.8.0->litellm) (1.3.1)\r\n",
      "Requirement already satisfied: colorlog in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from optuna>=3.4.0->dspy) (6.10.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas<3->mlflow==3.9.0) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas<3->mlflow==3.9.0) (2025.3)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow==3.9.0) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow==3.9.0) (2.41.5)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow==3.9.0) (0.4.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow==3.9.0) (3.4.4)\r\n",
      "Requirement already satisfied: joblib>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn<2->mlflow==3.9.0) (1.5.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn<2->mlflow==3.9.0) (3.6.0)\r\n",
      "Requirement already satisfied: prettytable>=3.9 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from skops<1->mlflow==3.9.0) (3.17.0)\r\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->databricks-agents)\r\n",
      "  Using cached marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->databricks-agents)\r\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tokenizers->litellm) (1.3.2)\r\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow==3.9.0) (2.23)\r\n",
      "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow==3.9.0) (0.50.0)\r\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow==3.9.0) (0.0.4)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow==3.9.0) (4.0.12)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow==3.9.0) (0.4.2)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow==3.9.0) (4.9.1)\r\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (3.20.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (2026.1.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (1.2.0)\r\n",
      "Requirement already satisfied: shellingham in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (1.5.4)\r\n",
      "Requirement already satisfied: typer-slim in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (0.21.1)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.9.0->mlflow==3.9.0) (0.60b1)\r\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from prettytable>=3.9->skops<1->mlflow==3.9.0) (0.2.14)\r\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.1->botocore->databricks-agents) (1.17.0)\r\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->databricks-agents)\r\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "Collecting langchain-core<2.0.0,>=1.2.6 (from langchain-openai->databricks-sdk[openai]>=0.58.0->databricks-agents)\r\n",
      "  Using cached langchain_core-1.2.9-py3-none-any.whl.metadata (4.4 kB)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow==3.9.0) (5.0.2)\r\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.2.6->langchain-openai->databricks-sdk[openai]>=0.58.0->databricks-agents)\r\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.2.6->langchain-openai->databricks-sdk[openai]>=0.58.0->databricks-agents)\r\n",
      "  Using cached langsmith-0.6.9-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core<2.0.0,>=1.2.6->langchain-openai->databricks-sdk[openai]>=0.58.0->databricks-agents)\r\n",
      "  Using cached uuid_utils-0.14.0-cp39-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (4.9 kB)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow==3.9.0) (0.6.2)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.6->langchain-openai->databricks-sdk[openai]>=0.58.0->databricks-agents) (3.0.0)\r\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai->databricks-sdk[openai]>=0.58.0->databricks-agents)\r\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai->databricks-sdk[openai]>=0.58.0->databricks-agents)\r\n",
      "  Downloading zstandard-0.25.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.3 kB)\r\n",
      "Using cached mlflow-3.9.0-py3-none-any.whl (9.7 MB)\r\n",
      "Downloading mlflow_skinny-3.9.0-py3-none-any.whl (2.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/2.8 MB\u001B[0m \u001B[31m3.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached mlflow_tracing-3.9.0-py3-none-any.whl (1.4 MB)\r\n",
      "Using cached litellm-1.81.8-py3-none-any.whl (12.3 MB)\r\n",
      "Using cached dspy-3.1.3-py3-none-any.whl (312 kB)\r\n",
      "Using cached gepa-0.0.26-py3-none-any.whl (139 kB)\r\n",
      "Using cached tqdm-4.67.3-py3-none-any.whl (78 kB)\r\n",
      "Using cached databricks_agents-1.9.3-py3-none-any.whl (203 kB)\r\n",
      "Downloading whenever-0.7.3-cp313-cp313-macosx_11_0_arm64.whl (368 kB)\r\n",
      "Using cached boto3-1.42.43-py3-none-any.whl (140 kB)\r\n",
      "Using cached botocore-1.42.43-py3-none-any.whl (14.6 MB)\r\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\r\n",
      "Using cached googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\r\n",
      "Using cached jmespath-1.1.0-py3-none-any.whl (20 kB)\r\n",
      "Using cached marshmallow-3.26.2-py3-none-any.whl (50 kB)\r\n",
      "Using cached s3transfer-0.16.0-py3-none-any.whl (86 kB)\r\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\r\n",
      "Using cached langchain_openai-1.1.7-py3-none-any.whl (84 kB)\r\n",
      "Using cached langchain_core-1.2.9-py3-none-any.whl (496 kB)\r\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\r\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\r\n",
      "Using cached langsmith-0.6.9-py3-none-any.whl (319 kB)\r\n",
      "Using cached uuid_utils-0.14.0-cp39-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (601 kB)\r\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\r\n",
      "Downloading zstandard-0.25.0-cp313-cp313-macosx_11_0_arm64.whl (640 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m640.4/640.4 kB\u001B[0m \u001B[31m6.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: zstandard, whenever, uuid-utils, tqdm, mypy-extensions, marshmallow, jsonpatch, jmespath, googleapis-common-protos, gepa, typing-inspect, requests-toolbelt, botocore, s3transfer, langsmith, dataclasses-json, langchain-core, boto3, mlflow-tracing, mlflow-skinny, litellm, langchain-openai, mlflow, dspy, databricks-agents\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.67.1\r\n",
      "    Uninstalling tqdm-4.67.1:\r\n",
      "      Successfully uninstalled tqdm-4.67.1\r\n",
      "  Attempting uninstall: gepa\r\n",
      "    Found existing installation: gepa 0.0.24\r\n",
      "    Uninstalling gepa-0.0.24:\r\n",
      "      Successfully uninstalled gepa-0.0.24\r\n",
      "  Attempting uninstall: mlflow-tracing\r\n",
      "    Found existing installation: mlflow-tracing 3.9.0rc0\r\n",
      "    Uninstalling mlflow-tracing-3.9.0rc0:\r\n",
      "      Successfully uninstalled mlflow-tracing-3.9.0rc0\r\n",
      "  Attempting uninstall: mlflow-skinny\r\n",
      "    Found existing installation: mlflow-skinny 3.9.0rc0\r\n",
      "    Uninstalling mlflow-skinny-3.9.0rc0:\r\n",
      "      Successfully uninstalled mlflow-skinny-3.9.0rc0\r\n",
      "  Attempting uninstall: litellm\r\n",
      "    Found existing installation: litellm 1.81.0\r\n",
      "    Uninstalling litellm-1.81.0:\r\n",
      "      Successfully uninstalled litellm-1.81.0\r\n",
      "  Attempting uninstall: mlflow\r\n",
      "    Found existing installation: mlflow 3.9.0rc0\r\n",
      "    Uninstalling mlflow-3.9.0rc0:\r\n",
      "      Successfully uninstalled mlflow-3.9.0rc0\r\n",
      "  Attempting uninstall: dspy\r\n",
      "    Found existing installation: dspy 3.1.2\r\n",
      "    Uninstalling dspy-3.1.2:\r\n",
      "      Successfully uninstalled dspy-3.1.2\r\n",
      "Successfully installed boto3-1.42.43 botocore-1.42.43 databricks-agents-1.9.3 dataclasses-json-0.6.7 dspy-3.1.3 gepa-0.0.26 googleapis-common-protos-1.72.0 jmespath-1.1.0 jsonpatch-1.33 langchain-core-1.2.9 langchain-openai-1.1.7 langsmith-0.6.9 litellm-1.81.8 marshmallow-3.26.2 mlflow-3.9.0 mlflow-skinny-3.9.0 mlflow-tracing-3.9.0 mypy-extensions-1.1.0 requests-toolbelt-1.0.0 s3transfer-0.16.0 tqdm-4.67.3 typing-inspect-0.9.0 uuid-utils-0.14.0 whenever-0.7.3 zstandard-0.25.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m26.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:02:59.212029Z",
     "start_time": "2026-02-06T06:02:56.441297Z"
    }
   },
   "cell_type": "code",
   "source": "import os\n\nimport mlflow\nfrom mlflow.genai.judges import make_judge\nfrom mlflow.genai.judges.optimizers import MemAlignOptimizer\nfrom mlflow.entities import AssessmentSource, AssessmentSourceType",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austin.choi/PycharmProjects2/mlflow-gateway-databricks-app/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set up your provider and model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:02:59.317241Z",
     "start_time": "2026-02-06T06:02:59.230680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For example, to use OpenAI API, provide your API key below:\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\" # TODO: set your OpenAI API key\n",
    "mlflow.set_tracking_uri(\"\")\n",
    "mlflow.set_registry_uri(\"\")\n",
    "experiment_name = \"memalign-demo\"\n",
    "experiment = mlflow.set_experiment(experiment_name)\n",
    "experiment_id = experiment.experiment_id"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/05 23:02:59 INFO mlflow.tracking.fluent: Experiment with name 'memalign-demo-2' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 1: Create an LLM Judge\n",
    "We'll create a judge that evaluates whether customer service responses are helpful."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:03:03.104264Z",
     "start_time": "2026-02-06T06:03:03.082049Z"
    }
   },
   "source": [
    "JUDGE_NAME = \"helpfulness\"\n",
    "\n",
    "initial_judge = make_judge(\n",
    "    name=JUDGE_NAME,\n",
    "    instructions=(\n",
    "        \"Evaluate whether the customer support bot's response is helpful \"\n",
    "        \"given the user query.\\n\\n\"\n",
    "        \"User query: {{ inputs }}\\n\"\n",
    "        \"Assistant response: {{ outputs }}\\n\"\n",
    "    ),\n",
    "    feedback_value_type=bool,\n",
    "    model=\"openai:/gpt-5.2\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 2: Create Alignment Traces with Human Feedback\nMemAlign learns from traces that have human feedback attached. We'll create traces and log human feedback in a single step using a helper function.\n\nYou can either log feedback programmatically (like below) or with the MLflow UI (see [here](https://mlflow.org/docs/latest/genai/eval-monitor/scorers/llm-judge/alignment/#collecting-feedback-for-alignment)).\n## The tricky case: Factually correct but emotionally cold\nLLM judges often rate **factually correct responses as helpful**, even when they lack empathy. But in customer service, a cold transactional response to a frustrated user is unhelpful - it should acknowledge emotions first."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feedback_source = AssessmentSource(\n",
    "    source_type=AssessmentSourceType.HUMAN,\n",
    "    source_id=\"human_expert\",\n",
    ")\n",
    "\n",
    "def create_trace(inputs, outputs, feedback):\n",
    "    with mlflow.start_span(\"alignment_trace\") as span:\n",
    "        span.set_inputs({\"inputs\": inputs})\n",
    "        span.set_outputs({\"outputs\": outputs})\n",
    "        trace_id = span.trace_id\n",
    "\n",
    "    mlflow.flush_trace_async_logging()\n",
    "    mlflow.log_assessment(trace_id, feedback)\n",
    "    return mlflow.get_trace(trace_id)\n",
    "\n",
    "alignment_traces = [\n",
    "    create_trace(\n",
    "        inputs=\"What are your store hours?\",\n",
    "        outputs=\"We're open Monday to Friday, 9am to 6pm.\",\n",
    "        feedback=mlflow.entities.Feedback(\n",
    "            name=JUDGE_NAME,\n",
    "            value=True,\n",
    "            rationale=\"Direct, accurate answer to a simple question.\",\n",
    "            source=feedback_source,\n",
    "        ),\n",
    "    ),\n",
    "    create_trace(\n",
    "        inputs=\"Thanks for your help!\",\n",
    "        outputs=\"You're welcome! Let me know if you need anything else.\",\n",
    "        feedback=mlflow.entities.Feedback(\n",
    "            name=JUDGE_NAME,\n",
    "            value=True,\n",
    "            rationale=\"Warm, friendly acknowledgment.\",\n",
    "            source=feedback_source,\n",
    "        ),\n",
    "    ),\n",
    "    create_trace(\n",
    "        inputs=\"Can you help me track my order?\",\n",
    "        outputs=\"Figure it out yourself.\",\n",
    "        feedback=mlflow.entities.Feedback(\n",
    "            name=JUDGE_NAME,\n",
    "            value=False,\n",
    "            rationale=\"Rude and dismissive.\",\n",
    "            source=feedback_source,\n",
    "        ),\n",
    "    ),\n",
    "    create_trace(\n",
    "        inputs=\"I have a question about returns.\",\n",
    "        outputs=\"Whatever.\",\n",
    "        feedback=mlflow.entities.Feedback(\n",
    "            name=JUDGE_NAME,\n",
    "            value=False,\n",
    "            rationale=\"Dismissive and unprofessional.\",\n",
    "            source=feedback_source,\n",
    "        ),\n",
    "    ),\n",
    "    # Tricky: Factually correct with solution, but lacks empathy\n",
    "    create_trace(\n",
    "        inputs=\"The sweater I ordered looks completely different from what was shown on the website.\",\n",
    "        outputs=(\n",
    "            \"Product colors may vary slightly due to lighting and display settings. \"\n",
    "            \"You can initiate a return through your order history if needed.\"\n",
    "        ),\n",
    "        feedback=mlflow.entities.Feedback(\n",
    "            name=JUDGE_NAME,\n",
    "            value=False,\n",
    "            rationale=(\n",
    "                \"Response provides factual explanation and offers a solution (return option), \"\n",
    "                \"but fails to acknowledge the customer's disappointment. Should start with \"\n",
    "                \"'I'm sorry the product didn't meet your expectations' before explaining.\"\n",
    "            ),\n",
    "            source=feedback_source,\n",
    "        ),\n",
    "    ),\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Additional traces to evaluate judge performance (held out from alignment)\n",
    "test_traces = [\n",
    "    create_trace(\n",
    "        inputs=\"Do you offer gift wrapping?\",\n",
    "        outputs=\"Yes! You can select gift wrapping at checkout for $3.\",\n",
    "        feedback=mlflow.entities.Feedback(\n",
    "            name=JUDGE_NAME,\n",
    "            value=True,\n",
    "            rationale=\"Helpful and informative.\",\n",
    "            source=feedback_source,\n",
    "        ),\n",
    "    ),\n",
    "    create_trace(\n",
    "        inputs=\"I love your product!\",\n",
    "        outputs=\"Thank you so much! We're glad you're enjoying it.\",\n",
    "        feedback=mlflow.entities.Feedback(\n",
    "            name=JUDGE_NAME,\n",
    "            value=True,\n",
    "            rationale=\"Warm acknowledgment of positive feedback.\",\n",
    "            source=feedback_source,\n",
    "        ),\n",
    "    ),\n",
    "    create_trace(\n",
    "        inputs=\"How do I cancel my subscription?\",\n",
    "        outputs=\"Why would you want to do that? That's stupid.\",\n",
    "        feedback=mlflow.entities.Feedback(\n",
    "            name=JUDGE_NAME,\n",
    "            value=False,\n",
    "            rationale=\"Insulting and unprofessional.\",\n",
    "            source=feedback_source,\n",
    "        ),\n",
    "    ),\n",
    "    create_trace(\n",
    "        inputs=\"Is this item in stock?\",\n",
    "        outputs=\"I don't care.\",\n",
    "        feedback=mlflow.entities.Feedback(\n",
    "            name=JUDGE_NAME,\n",
    "            value=False,\n",
    "            rationale=\"Rude and unhelpful.\",\n",
    "            source=feedback_source,\n",
    "        ),\n",
    "    ),\n",
    "    # Tricky: Factually correct but lacks empathy for frustrated user\n",
    "    create_trace(\n",
    "        inputs=\"I've been charged twice for my subscription this month. This is really frustrating!\",\n",
    "        outputs=(\n",
    "            \"We see two charges on your account because you updated your payment method. \"\n",
    "            \"One charge will be reversed automatically within 5-7 business days.\"\n",
    "        ),\n",
    "        feedback=mlflow.entities.Feedback(\n",
    "            name=JUDGE_NAME,\n",
    "            value=False,\n",
    "            rationale=(\n",
    "                \"Factually correct but too cold and transactional. \"\n",
    "                \"Should start with empathy (e.g., 'Sorry for the confusion') and end with \"\n",
    "                \"support-oriented language when responding to a frustrated customer.\"\n",
    "            ),\n",
    "            source=feedback_source,\n",
    "        ),\n",
    "    ),\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Evaluate Baseline Judge Performance\n",
    "Before alignment, let's see how the initial judge performs. We expect the judge to make mistakes on edge cases like the tricky empathy examples.\n",
    "\n",
    "But first, we will set some helper functions to help understand our Judge's performance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:08:16.230732Z",
     "start_time": "2026-02-06T06:08:16.227349Z"
    }
   },
   "source": [
    "def get_human_label(trace, judge_name):\n",
    "    for assessment in trace.info.assessments:\n",
    "        if (assessment.name == judge_name and\n",
    "            assessment.source.source_type == \"HUMAN\"):\n",
    "            return assessment.value\n",
    "    return None\n",
    "\n",
    "\n",
    "def compute_accuracy(traces, judge_to_test):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for trace in traces:\n",
    "        human_label = get_human_label(trace, judge_to_test.name)\n",
    "        if human_label is None:\n",
    "            continue\n",
    "        result = judge_to_test(trace=trace)\n",
    "        if result.value == human_label:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def evaluate_and_print(traces, judge, label):\n",
    "    accuracy = compute_accuracy(traces, judge)\n",
    "    print(f\"  {label}: {accuracy:.0%}\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def display_comparison(baseline_align, baseline_test, aligned_align, aligned_test):\n",
    "    print(\n",
    "    \"\\n\" + \"=\" * 60 + \"\\n\"\n",
    "    \"PERFORMANCE COMPARISON\\n\"\n",
    "    + \"=\" * 60 + \"\\n\"\n",
    "    f\"\\n{'Dataset':<25} {'Baseline':<15} {'Aligned':<15} {'Change':<15}\\n\"\n",
    "    + \"-\" * 60 + \"\\n\"\n",
    "    f\"{'Alignment Set':<25} {baseline_align:<15.0%} {aligned_align:<15.0%} {(aligned_align - baseline_align):+.0%}\\n\"\n",
    "    f\"{'Test Set':<25} {baseline_test:<15.0%} {aligned_test:<15.0%} {(aligned_test - baseline_test):+.0%}\\n\"\n",
    "    + \"-\" * 60\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:08:49.403600Z",
     "start_time": "2026-02-06T06:08:17.520615Z"
    }
   },
   "source": [
    "baseline_align_accuracy = evaluate_and_print(alignment_traces, initial_judge, \"Alignment traces\")\n",
    "baseline_test_accuracy = evaluate_and_print(test_traces, initial_judge, \"Test traces\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Alignment traces: 100%\n",
      "  Test traces: 80%\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Align the Judge with MemAlign\n",
    "Now we'll use MemAlign to align the judge with our human feedback.\n",
    "\n",
    "MemAlign will:\n",
    "\n",
    "1. **Distill guidelines** from the feedback rationales (semantic memory)\n",
    "2. **Store examples** for few-shot retrieval (episodic memory)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:08:53.281769Z",
     "start_time": "2026-02-06T06:08:53.280079Z"
    }
   },
   "source": [
    "optimizer = MemAlignOptimizer(\n",
    "    reflection_lm=\"openai:/gpt-5.2\",\n",
    "    embedding_model=\"openai:/text-embedding-3-large\",\n",
    "    retrieval_k=3,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:08:58.693696Z",
     "start_time": "2026-02-06T06:08:53.973717Z"
    }
   },
   "source": [
    "aligned_judge = initial_judge.align(\n",
    "    traces=alignment_traces,\n",
    "    optimizer=optimizer\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distilling guidelines: 100%|██████████| 1/1 [00:03<00:00,  3.51s/it]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Inspect Learned Guidelines (Semantic Memory)\n",
    "Let's see what guidelines MemAlign distilled from our feedback."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:09:02.967422Z",
     "start_time": "2026-02-06T06:09:02.965276Z"
    }
   },
   "source": [
    "print(aligned_judge.instructions)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate whether the customer support bot's response is helpful given the user query.\n",
      "\n",
      "User query: {{ inputs }}\n",
      "Assistant response: {{ outputs }}\n",
      "\n",
      "\n",
      "Distilled Guidelines (4):\n",
      "  - Maintain a polite, professional tone; never be rude, dismissive, or curt when customers ask for help.\n",
      "  - For complaints or dissatisfaction, explicitly acknowledge and empathize (e.g., apologize) before giving factual explanations or next-step solutions.\n",
      "  - For straightforward informational questions, give a direct and accurate answer without unnecessary extra content.\n",
      "  - When users express gratitude, respond with a warm, friendly acknowledgment and optionally offer further help.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Evaluate Aligned Judge Performance\n",
    "Let's see how the aligned judge performs compared to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:09:37.298334Z",
     "start_time": "2026-02-06T06:09:05.811087Z"
    }
   },
   "source": [
    "aligned_align_accuracy = evaluate_and_print(alignment_traces, aligned_judge, \"Alignment traces\")\n",
    "aligned_test_accuracy = evaluate_and_print(test_traces, aligned_judge, \"Test traces\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Alignment traces: 100%\n",
      "  Test traces: 100%\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:09:37.303790Z",
     "start_time": "2026-02-06T06:09:37.301983Z"
    }
   },
   "source": [
    "display_comparison(baseline_align_accuracy, baseline_test_accuracy,\n",
    "                  aligned_align_accuracy, aligned_test_accuracy)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PERFORMANCE COMPARISON\n",
      "============================================================\n",
      "\n",
      "Dataset                   Baseline        Aligned         Change         \n",
      "------------------------------------------------------------\n",
      "Alignment Set             100%            100%            +0%\n",
      "Test Set                  80%             100%            +20%\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step 7: Unalign - Remove Specific Feedback\n",
    "Sometimes you may want to remove specific examples from the judge's memory. For instance, if some feedback was incorrect or is no longer relevant.\n",
    "\n",
    "Let's remove one of the alignment traces (say, the last one where the judge fails initially) and see how it affects the performance."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:09:45.691590Z",
     "start_time": "2026-02-06T06:09:45.689631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Before unalignment:\")\n",
    "print(f\"  Semantic memory: {len(aligned_judge._semantic_memory)} guidelines\")\n",
    "print(f\"  Episodic memory: {len(aligned_judge._episodic_memory)} examples\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before unalignment:\n",
      "  Semantic memory: 4 guidelines\n",
      "  Episodic memory: 5 examples\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:09:47.529950Z",
     "start_time": "2026-02-06T06:09:47.203840Z"
    }
   },
   "source": [
    "traces_to_remove = [alignment_traces[-1]]\n",
    "updated_judge = aligned_judge.unalign(traces=traces_to_remove)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:09:48.404859Z",
     "start_time": "2026-02-06T06:09:48.402979Z"
    }
   },
   "source": [
    "print(updated_judge.instructions)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate whether the customer support bot's response is helpful given the user query.\n",
      "\n",
      "User query: {{ inputs }}\n",
      "Assistant response: {{ outputs }}\n",
      "\n",
      "\n",
      "Distilled Guidelines (3):\n",
      "  - Maintain a polite, professional tone; never be rude, dismissive, or curt when customers ask for help.\n",
      "  - For straightforward informational questions, give a direct and accurate answer without unnecessary extra content.\n",
      "  - When users express gratitude, respond with a warm, friendly acknowledgment and optionally offer further help.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:10:01.071117Z",
     "start_time": "2026-02-06T06:09:49.449548Z"
    }
   },
   "source": [
    "updated_test_accuracy = evaluate_and_print(test_traces, updated_judge, \"Test traces\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Test traces: 80%\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After unalignment, we see the guideline on response empathy is removed from the instructions, and the judge's prediction on the relevant test example also degrades back to incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Register the Judge as a Scorer\n",
    "Finally, let's register the aligned judge so it can be used in future MLflow experiments. This allows you to:\n",
    "\n",
    "- Use the judge consistently across experiments\n",
    "- Share the judge with team members\n",
    "- Track judge versions over time"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:10:05.403831Z",
     "start_time": "2026-02-06T06:10:05.319477Z"
    }
   },
   "source": [
    "registered_judge = aligned_judge.register()"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:10:05.625803Z",
     "start_time": "2026-02-06T06:10:05.609872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mlflow.genai import list_scorers\n",
    "\n",
    "scorers = list_scorers(experiment_id=experiment_id)\n",
    "print(f\"\\nRegistered scorers in experiment:\")\n",
    "for scorer in scorers:\n",
    "    print(f\"  - {scorer.name} (model: {scorer.model})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Registered scorers in experiment:\n",
      "  - helpfulness (model: openai:/gpt-5.2)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:10:10.667557Z",
     "start_time": "2026-02-06T06:10:10.645945Z"
    }
   },
   "source": [
    "from mlflow.genai import get_scorer\n",
    "\n",
    "retrieved_judge = get_scorer(name=\"helpfulness\", experiment_id=experiment_id)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T06:10:13.450254Z",
     "start_time": "2026-02-06T06:10:10.940925Z"
    }
   },
   "source": [
    "test_result = retrieved_judge(\n",
    "    inputs=\"I'm having trouble with my order and feeling frustrated.\",\n",
    "    outputs=\"I understand this is frustrating. Let me look into your order right away and help resolve this.\"\n",
    ")\n",
    "print(f\"Helpful: {test_result.value}\\n\\nRationale: {test_result.rationale}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpful: True\n",
      "Rationale: The response is polite and professional, acknowledges the customer’s frustration with empathetic language, and offers immediate help to investigate and resolve the order issue. This aligns well with the need to validate feelings before moving to next steps. While it could be even more helpful by asking for an order number or specific issue details, it is still a supportive and appropriate first reply.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Summary\n",
    "In this notebook, we demonstrated the complete MemAlign workflow:\n",
    "\n",
    "1. Created an LLM judge for evaluating response helpfulness\n",
    "2. Created traces with human feedback, including a tricky case: factually correct but emotionally cold responses\n",
    "3. Evaluated baseline performance - the judge incorrectly rated cold responses as helpful\n",
    "4. Aligned the judge using human feedback with MemAlign\n",
    "5. Inspected learned guidelines - MemAlign learned that empathy matters\n",
    "6. Evaluated improved performance - the aligned judge now considers emotional tone\n",
    "7. Unaligned specific traces - removed feedback from the judge's memory\n",
    "8. Registered the judge for use in future experiments\n",
    "# Key takeaways:\n",
    "- MemAlign captures nuance: It learned that factual correctness alone isn't enough\n",
    "- Dual memory system: Guidelines (semantic) + examples (episodic) provide robust alignment\n",
    "- Incremental updates: Use .align() to add feedback and .unalign() to remove it\n",
    "- Persistence: Register judges to share and reuse across experiments"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cleanup (optional) - delete the registered scorer"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T07:33:03.968771Z",
     "start_time": "2026-01-29T07:33:03.931602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mlflow.genai.scorers import delete_scorer\n",
    "\n",
    "delete_scorer(name=\"helpfulness\", experiment_id=experiment_id, version=\"all\")"
   ],
   "outputs": [],
   "execution_count": 36
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "MemAlign Tutorial (1)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

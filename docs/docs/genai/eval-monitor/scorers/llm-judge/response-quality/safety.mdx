import TileCard from '@site/src/components/TileCard';
import TilesGrid from '@site/src/components/TilesGrid';
import { Bot, Shield, Hammer } from "lucide-react";
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import TabsWrapper from '@site/src/components/TabsWrapper';
import JudgePrerequisites from '@site/src/content/judge_prerequisites.mdx';
import SelectJudgeModel from '@site/src/content/select_judge_model.mdx';

# Safety Judge

The `Safety` judge assesses the safety of given content (whether generated by the application or provided by a user), checking for harmful, unethical, or inappropriate material.

The Safety judge evaluates text content to identify potentially harmful, offensive, or inappropriate material. It returns a pass/fail assessment along with a detailed rationale explaining the safety concerns (if any).

<JudgePrerequisites/>

## Usage examples

The `Safety` judge can be invoked directly for single assessment or used with MLflow's evaluation framework for batch evaluation.

<TabsWrapper>
<Tabs groupId="invocation-method">
  <TabItem value="direct" label="Invoke directly" default>

```python
from mlflow.genai.scorers import Safety

# Assess the safety of a single output
assessment = Safety()(
    outputs="MLflow is an open-source platform for managing the ML lifecycle, including experimentation, reproducibility, and deployment."
)
print(assessment)
```

  </TabItem>
  <TabItem value="evaluate" label="Invoke with evaluate()">

```python
import mlflow
from mlflow.genai.scorers import Safety

# Create evaluation dataset with various safety scenarios
eval_dataset = [
    {
        "inputs": {"query": "Tell me about MLflow"},
        "outputs": {
            "response": "MLflow is an open-source platform for managing the ML lifecycle, including experimentation, reproducibility, and deployment."
        },
    },
]

# Run evaluation with Safety judge
eval_results = mlflow.genai.evaluate(
    data=eval_dataset,
    scorers=[
        Safety(
            model="openai:/gpt-4o-mini",  # Optional.
        ),
    ],
)
```

  </TabItem>
</Tabs>
</TabsWrapper>

<SelectJudgeModel/>

## Next steps

<TilesGrid>
  <TileCard
    icon={Shield}
    title="Explore other built-in judges"
    description="Learn about relevance, groundedness, and correctness judges"
    href="/genai/eval-monitor/scorers/llm-judge/predefined/#available-judges"
  />
  <TileCard
    icon={Scroll}
    title="Create custom safety guidelines"
    description="Define specific safety criteria for your use case with Guidelines judge"
    href="/genai/eval-monitor/scorers/llm-judge/guidelines"
  />
  <TileCard
    icon={Bot}
    title="Evaluate Agents"
    description="Learn how to evaluate AI agents with specialized techniques and scorers"
    href="/genai/eval-monitor/running-evaluation/agents"
  />
</TilesGrid>

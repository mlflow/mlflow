---
sidebar_position: 15
sidebar_label: OpenTelemetry
---

import StepHeader from "@site/src/components/StepHeader";
import ServerSetup from "@site/src/content/setup_server_slim.mdx";

# Tracing Any OpenTelemetry Application

`mlflow.otel.autolog()` provides a generic bridge between [OpenTelemetry](https://opentelemetry.io/) and MLflow. When enabled, every span produced by any OTEL-instrumented library is automatically forwarded to the MLflow backend as a fully populated MLflow trace. Your existing OTEL tracing is completely unaffected; this is purely additive.

```python
import mlflow

mlflow.otel.autolog()
```

This works with any library that emits spans through the global OTEL `TracerProvider` — including libraries with dedicated MLflow integration pages (Langfuse, Arize Phoenix) and any other OTEL-instrumented code.

MLflow automatically captures the following information from every OTEL span:

- Span inputs and outputs (when present as OTEL attributes)
- Latencies
- Span name
- Parent-child span nesting
- Any exception if raised

When the spans originate from a known framework (e.g. Langfuse, OpenInference), the MLflow backend automatically translates framework-specific attributes to MLflow semantics — span types, structured inputs/outputs, token usage, and model name — with no additional configuration.

## Getting Started

<StepHeader number={1} title="Install Dependencies" />

```bash
pip install mlflow opentelemetry-sdk
```

<StepHeader number={2} title="Start MLflow Server" />

<ServerSetup />

<StepHeader number={3} title="Enable Tracing and Run Your Application" />

The example below uses the OTEL SDK directly to create spans. In practice, you would typically use an instrumented library that produces OTEL spans automatically.

```python
import mlflow
from opentelemetry import trace

# Register the MLflow span processor on the global OTEL TracerProvider
mlflow.otel.autolog()

mlflow.set_tracking_uri("http://localhost:5000")
mlflow.set_experiment("OTEL")

# Create spans using the standard OTEL API
tracer = trace.get_tracer("my-app")

with tracer.start_as_current_span("agent") as parent:
    parent.set_attribute("input.value", '{"query": "What is MLflow?"}')

    with tracer.start_as_current_span("llm_call") as child:
        child.set_attribute("input.value", '{"prompt": "What is MLflow?"}')
        child.set_attribute("output.value", '{"response": "MLflow is an open-source platform."}')

    parent.set_attribute("output.value", '{"answer": "MLflow is an open-source platform."}')
```

:::note
`mlflow.otel.autolog()` can be called before or after other OTEL setup. It creates an `SdkTracerProvider` if one does not already exist, or adds its processor to an existing one, so initialization order does not matter.
:::

<StepHeader number={4} title="View Traces in MLflow UI" />

Browse to the MLflow UI at http://localhost:5000 (or your MLflow server URL) and you should see the traces for your OTEL-instrumented application. Nested spans will appear as parent-child relationships in the trace view.

## Dual Tracing with Other Backends

Because `mlflow.otel.autolog()` adds a span processor to the shared `TracerProvider`, you can send spans to MLflow and another backend simultaneously. For example, to also export to an OTLP-compatible collector:

```python
import mlflow
from opentelemetry import trace
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace.export import SimpleSpanProcessor

# Register MLflow span processor
mlflow.otel.autolog()

# Also send spans to an OTLP collector
provider = trace.get_tracer_provider()
provider.add_span_processor(
    SimpleSpanProcessor(OTLPSpanExporter("http://localhost:4318/v1/traces"))
)
```

Every span is dispatched to all registered processors, so both MLflow and the other backend receive the same data.

## Disable auto-tracing

Auto tracing can be disabled globally by calling `mlflow.otel.autolog(disable=True)`.

```python
mlflow.otel.autolog(disable=True)
```

After disabling, new OTEL spans will no longer be forwarded to MLflow.

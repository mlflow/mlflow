import Tabs from "@theme/Tabs"
import TabItem from "@theme/TabItem"
import TabsWrapper from "@site/src/components/TabsWrapper";
import TilesGrid from "@site/src/components/TilesGrid";
import TileCard from "@site/src/components/TileCard";

# Instrument Your App with MLflow Tracing

:::tip
New to MLflow Tracing? Checkout the <ins>[Quick Start Guide](/genai/tracing/quickstart)</ins> to get started.
:::

## Three Steps to Trace Your App/Agents

### 1. Installation

<TabsWrapper>
<Tabs>
  <TabItem value="python" label="Python" default>
    Add [`mlflow`](https://pypistats.org/packages/mlflow) to your Python environment.

    ```bash
    pip install mlflow
    ```

  </TabItem>
  <TabItem value="js" label="JS/TS">
    Install the [mlflow-tracing](https://www.npmjs.com/package/mlflow-tracing) package and other auto-tracing integrations (e.g., [mlflow-openai](https://www.npmjs.com/package/mlflow-tracing-openai)).

    ```bash
    npm install mlflow-tracing
    ```

  </TabItem>
</Tabs>
</TabsWrapper>

### 2. Instrumenting Your Application Logic

MLflow offers different ways to instrument your application logic. Follow the links below to learn more about each approach to instrument your application:

<TilesGrid cols={2}>
  <TileCard
    image="/images/llms/tracing/app-instrumentation/autolog-logos.png"
    title="Automatic Tracing"
    description="Instrument your application with a single line of code. We recommend starting from here."
    href="/genai/tracing/app-instrumentation/automatic"
    containerHeight={96}
  />
  <TileCard
    image="/images/llms/tracing/app-instrumentation/manual-tracing2.png"
    title="Manual Tracing"
    description="Instrument any Python code with a few lines of code, with full control and flexibility."
    href="/genai/tracing/app-instrumentation/manual-tracing"
    containerHeight={96}
  />
  <TileCard
    image="/images/logos/javascript-typescript-logo.png"
    title="Typescript SDK"
    description="Instrument your Node.js applications with MLflow Tracing Typescript SDK."
    href="/genai/tracing/app-instrumentation/typescript-sdk"
    containerHeight={96}
  />
  <TileCard
    image="/images/logos/opentelemetry-logo.svg"
    title="OpenTelemetry"
    description="When you are using OpenTelemetry as your observability platform, you can export traces to MLflow directly."
    href="/genai/tracing/app-instrumentation/opentelemetry"
    containerHeight={96}
  />
</TilesGrid>

### 3. Choose Destination for Your Traces

MLflow Tracing supports exporting traces to various destinations.

<TilesGrid cols={3}>
  <TileCard
    image="/images/logos/mlflow-logo.svg"
    title="MLflow Experiment"
    description="Export traces to MLflow Tracking Server hosted on your machine."
    href="/self-hosting"
    containerHeight={96}
    linkText="Self-hosting guide →"
  />
  <TileCard
    image="/images/logos/databricks-logo.png"
    title="Databricks"
    description="Export traces to Databricks for centralized monitoring and governance."
    href="https://docs.databricks.com/aws/en/mlflow3/genai/tracing/"
    containerHeight={96}
    linkText="View documentation →"
  />
  <TileCard
    image="/images/logos/opentelemetry-logo.svg"
    title="OpenTelemetry"
    description="Export traces to any observability platform that supports OpenTelemetry protocol."
    href="/genai/tracing/opentelemetry/export"
    containerHeight={96}
  />
</TilesGrid>

## Common System Patterns

### Production Considerations

MLflow Tracing is production ready, but in order to ensure the scalability and reliability of the tracing system, we recommend the following best practices:

1. Enable [Async Logging](/genai/tracing/prod-tracing#asynchronous-trace-logging) and set up appropriate queue size and timeout.
2. Use the lightweight [`mlflow-tracing`](https://pypistats.org/packages/mlflow-tracing) package for minimizing the package footprint and dependencies.
3. Use [managed MLflow services](/genai/tracing/prod-tracing#managed-monitoring-with-databricks) for reducing the operational overhead and ensure the scalability of the tracing system.
4. When using self-hosted MLflow, make sure to use the **SQL Backend** with a scalable database like PostgreSQL. The default file-based backend has scalability limitations and is not recommended for production use.

### Async Applications

Async programming is an effective tool for improving the throughput of your application, particularly for LLM-based applications that are typically I/O bound. MLflow Tracing natively [supports instrumenting async applications](/genai/tracing/app-instrumentation/manual-tracing#async-support).

### Multi-Threaded Applications

Multi-threading is a common strategy for parallelizing IO-bound operations in applications. MLflow Tracing supports [multi-threaded applications](/genai/tracing/app-instrumentation/manual-tracing#multi-threading) using context propagation.

### Managing User sessions

Many LLM-based applications are deployed as chat-based applications, where each user session is a separate thread. Grouping traces by user session is a common practice. MLflow Tracing supports [managing user sessions](/genai/tracing/track-users-sessions).

### Redacting PII Data

Traces can contain sensitive data such as raw user inputs, internal document contents, etc. MLflow Tracing supports [redacting PII data](/genai/tracing/observe-with-traces/masking) using flexible masking rules, custom functions, and integration with external PII masking libraries.

### Collecting User Feedbacks

User feedback is a valuable source of information for improving the user experience of your application. MLflow Tracing supports [collecting user feedback on traces](/genai/tracing/collect-user-feedback) to track and analyze the feedbacks effectively.

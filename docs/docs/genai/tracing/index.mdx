import Tabs from "@theme/Tabs"
import TabItem from "@theme/TabItem"
import { APILink } from "@site/src/components/APILink";
import TabsWrapper from "@site/src/components/TabsWrapper";
import TilesGrid from "@site/src/components/TilesGrid";
import TileCard from "@site/src/components/TileCard";
import FeatureHighlights from "@site/src/components/FeatureHighlights";
import { GitMerge, Heart, Zap, Puzzle, LifeBuoy, Users } from "lucide-react";

# MLflow Tracing for LLM Observability

<<<<<<< HEAD
**MLflow Tracing** is a feature that enhances LLM observability in your Generative AI (GenAI) applications by capturing detailed information about the execution of your application's services. Tracing provides a way to record the inputs, outputs, and metadata associated with each intermediate step of a request, enabling you to easily pinpoint the source of bugs and unexpected behaviors.

MLflow Tracing offers [**automatic, no-code-added integrations**](/genai/tracing/app-instrumentation/automatic) with **over 20 popular GenAI libraries**, providing immediate observability with just a single line of code. For any other Python-based GenAI code or custom components, MLflow's [**flexible instrumentation APIs**](/genai/tracing/app-instrumentation/manual-tracing) can be used to capture detailed traces, regardless of the specific frameworks in use.

**Ready to get started? See how to [Instrument your app](/genai/tracing/app-instrumentation).**

![Tracing Gateway Video](/images/llms/tracing/tracing-top.gif)

## Why Choose MLflow Tracing?

<details>
  <summary>Why Choose MLflow?</summary>

**ü™Ω Free and Open** - MLflow is open source and 100% FREE. You don't need to pay additional SaaS costs to add observability to your GenAI stack. Your trace data is hosted on your own infrastructure.

**ü•á Standard** - MLflow Tracing is compatible with **OpenTelemetry**, an industry-standard observability spec. You can export your trace data to various services in your existing observability stack, such as Grafana, Prometheus, Datadog, New Relic, and more.

**ü§ù Framework Support** - MLflow Tracing integrates with 20+ GenAI libraries, including OpenAI, LangChain, LlamaIndex, DSPy, and others. See the [Automatic Tracing](#automatic-tracing) section for the full list of supported libraries.

**üîÑ End-to-End** - MLflow is designed for managing the end-to-end machine learning lifecycle. With its model tracking and evaluation capabilities, MLflow empowers you to leverage your trace data fully.

**üë• Community** - MLflow boasts a vibrant Open Source community as a part of the Linux Foundation. With 19,000+ GitHub Stars and 15MM+ monthly downloads, MLflow is a trusted standard in the MLOps/LLMOps ecosystem.

</details>

=======
MLflow Tracing enhances LLM observability in your applications by capturing the inputs, outputs, and metadata associated with each intermediate step of a request, enabling you to easily pinpoint the source of bugs and unexpected behaviors.

![Tracing Gateway Video](/images/llms/tracing/tracing-top.gif)

>>>>>>> v3.1.4
## Use Cases Throughout the ML Lifecycle

MLflow Tracing empowers you throughout the end-to-end lifecycle of a machine learning project. Here's how it helps you at each step of the workflow, click on the tabs below to learn more:

<<<<<<< HEAD
<Tabs>
  <TabItem value="debugging" label="Debugging" default>
=======
<TabsWrapper>
  <Tabs>
    <TabItem value="debugging" label="Build & Debug" default>
>>>>>>> v3.1.4
    <div class="flex-column">

      <div class="flex-row">
        <div class="flex-item">

          #### Debug Issues in Your IDE or Notebook

          Traces provide deep insights into what happens beneath the abstractions of GenAI libraries, helping you precisely identify where issues occur.

          You can navigate traces seamlessly within your preferred IDE, notebook, or the MLflow UI, eliminating the hassle of switching between multiple tabs or searching through an overwhelming list of traces.

          [Learn more ‚Üí](/genai/tracing/observe-with-traces)

        </div>

        <div class="flex-item padding-md">
          ![Trace Debugging](/images/llms/tracing/genai-trace-debug.png)
        </div>
      </div>
    </div>

  </TabItem>
  <TabItem value="feedback" label="Human Feedback">
    <div class="flex-column">
      <div class="flex-row">
        <div class="flex-item">

        #### Track Annotation and Human Feedbacks

        Human feedback is essential for building high-quality GenAI applications that meet user expectations. MLflow supports collecting, managing, and utilizing feedback from end-users and domain experts.

        Feedbacks are attached to traces and recorded with metadata, including user, timestamp, revisions, etc.

        [Learn more ‚Üí](/genai/tracing/collect-user-feedback)

        </div>

        <div class="flex-item padding-md">
          ![Trace Feedback](/images/llms/tracing/genai-human-feedback.png)
        </div>
      </div>
    </div>

  </TabItem>
  <TabItem value="evaluation" label="Evaluation">
    <div class="flex-column">
      <div class="flex-row">
        <div class="flex-item">

        #### Evaluate and Enhance Quality

        Systematically assessing and improving the quality of GenAI applications is a challenge. Combined with [MLflow GenAI Evaluation](/genai/eval-monitor), MLflow offers a seamless experience for evaluating your applications.

        Tracing helps by allowing you to track quality assessment and inspect the evaluation results with visibility into the internals of the system.

        [Learn more ‚Üí](/genai/eval-monitor)

        </div>

        <div class="flex-item padding-md">
          ![Trace Evaluation](/images/llms/tracing/genai-trace-evaluation.png)
        </div>
      </div>
    </div>

  </TabItem>
  <TabItem value="production-monitoring" label="Production Monitoring">
    <div class="flex-column">
      <div class="flex-row">
        <div class="flex-item">

        #### Monitor Applications in Production

        Understanding and optimizing GenAI application performance is crucial for efficient operations. MLflow Tracing captures key metrics like latency and token usage at each step, as well as various quality metrics, helping you identify bottlenecks, monitor efficiency, and find optimization opportunities.

        [Learn more ‚Üí](/genai/tracing/prod-tracing)

        </div>

        <div class="flex-item padding-md">
          ![Monitoring](/images/llms/tracing/genai-monitoring.png)
        </div>
      </div>
    </div>

  </TabItem>
  <TabItem value="dataset" label="Dataset Collection">
    <div class="flex-column">
      <div class="flex-row">
        <div class="flex-item">

        #### Create a High-Quality Dataset from Real World Traffic

        Evaluating the performance of your GenAI application is crucial, but creating a reliable evaluation dataset is challenging.

        Traces from production systems capture perfect data for building high-quality datasets with precise details for internal components like retrievers and tools.

        [Learn more ‚Üí](/genai/tracing/search-traces/#creating-evaluation-datasets)

        </div>

        <div class="flex-item padding-md">
          ![Trace Dataset](/images/llms/tracing/genai-trace-dataset.png)
        </div>
      </div>
    </div>

  </TabItem>
  </Tabs>
</TabsWrapper>

## What Makes MLflow Tracing Unique?

<<<<<<< HEAD
Moreover, traces are invaluable for **building high-quality evaluation datasets**. By capturing real user interactions and their outcomes, you can curate representative test cases based on actual usage patterns, build comprehensive evaluation sets that cover diverse scenarios, and use this data to fine-tune models or improve retrieval mechanisms.

When combined with [MLflow GenAI Evaluation](/genai/eval-monitor), MLflow offers a seamless experience for assessing and improving your application's quality.

## Industry-Standard Observability with OpenTelemetry

MLflow Tracing is built on **OpenTelemetry**, the industry-standard open source specification for observability. This foundation ensures that your tracing implementation follows widely accepted standards and provides interoperability with the broader observability ecosystem.

The OpenTelemetry compatibility means you can export your MLflow trace data to various monitoring and observability services in your existing infrastructure stack, including Grafana, Prometheus, Datadog, New Relic, and other OpenTelemetry-compatible systems. This standardization gives you the flexibility to integrate MLflow Tracing into your current monitoring workflows without vendor lock-in.

By conforming to OpenTelemetry standards, MLflow Tracing ensures that your observability investment is portable and future-proof, allowing you to leverage the growing ecosystem of OpenTelemetry-compatible tools and services. See [Export Traces to Other Services](/genai/tracing/prod-tracing#opentelemetry-integration) for detailed integration instructions.

## Automatic Tracing

MLflow Tracing is integrated with various GenAI libraries and provides **one-line automatic tracing** experience for each library (and combinations of them!). Here are some of the 20+ supported frameworks:

**Popular Frameworks**: [OpenAI](/genai/tracing/integrations/listing/openai), [LangChain](/genai/tracing/integrations/listing/langchain), [LangGraph](/genai/tracing/integrations/listing/langgraph), [LlamaIndex](/genai/tracing/integrations/listing/llama_index), [DSPy](/genai/tracing/integrations/listing/dspy), [Anthropic](/genai/tracing/integrations/listing/anthropic), [AutoGen](/genai/tracing/integrations/listing/autogen), [AG2](/genai/tracing/integrations/listing/ag2), [CrewAI](/genai/tracing/integrations/listing/crewai), [OpenAI Swarm](/genai/tracing/integrations/listing/swarm)

**Model Providers**: [Bedrock](/genai/tracing/integrations/listing/bedrock), [Gemini](/genai/tracing/integrations/listing/gemini), [LiteLLM](/genai/tracing/integrations/listing/litellm), [Ollama](/genai/tracing/integrations/listing/ollama), [Groq](/genai/tracing/integrations/listing/groq), [Mistral](/genai/tracing/integrations/listing/mistral), [DeepSeek](/genai/tracing/integrations/listing/deepseek)

**Specialized Tools**: [Instructor](/genai/tracing/integrations/listing/instructor), [txtai](/genai/tracing/integrations/listing/txtai), [Smolagents](/genai/tracing/integrations/listing/smolagents), [PydanticAI](/genai/tracing/integrations/listing/pydantic_ai)

For the complete list and detailed integration examples, see the [Automatic Tracing](/genai/tracing/app-instrumentation/automatic) documentation and [Integrations page](/genai/tracing/integrations).

This broad support means you can gain observability without significant code changes, leveraging the tools you already use. For custom components or unsupported libraries, MLflow also provides powerful [manual tracing APIs](/genai/tracing/app-instrumentation/manual-tracing).

## Manual Tracing

In addition to the one-line auto tracing experience, MLflow offers Python SDK for manually instrumenting your code and manipulating traces:

- [Instrument a function with `@mlflow.trace` decorator](/genai/tracing/app-instrumentation/manual-tracing/fluent-apis#decorator)
- [Instrument any block of code using `mlflow.start_span` context manager](/genai/tracing/app-instrumentation/manual-tracing/fluent-apis#context-manager)
- [Group or annotate traces using tags](/genai/tracing/attach-tags)
- [Disable tracing globally](/genai/tracing/app-instrumentation/automatic#disabling-tracing)

Refer to the [Manual Tracing Guide](/genai/tracing/app-instrumentation/manual-tracing) for complete details about the SDK.

## Reviewing and Querying Traces

MLflow Traces can be reviewed and analyzed in several ways:

**MLflow UI**: The MLflow UI provides a rich interface for exploring traces. You can view traces for a specific experiment, run, and [search and filter traces](/genai/tracing/search-traces) based on various criteria. Start the UI by running `mlflow ui` in your terminal and navigating to `http://localhost:5000`.

**Jupyter Notebook**: The trace UI is also available within Jupyter notebooks! The trace UI will automatically be displayed when a cell generates a trace, eliminating the need to switch between the notebook and web browser.

**Programmatic Access**: Query and analyze traces with Python APIs to search traces with filters and conditions using <APILink fn="mlflow.search_traces" />, retrieve specific traces for detailed analysis, export data for custom analysis or integration with other tools, and build custom dashboards and monitoring solutions.

Trace data is useful for various downstream tasks, such as creating evaluation datasets for offline evaluation and production monitoring. MLflow provides several APIs to search and retrieve recorded traces programmatically. See [Searching and Retrieving Traces](/genai/tracing/search-traces) for more details.

## Production Monitoring

MLflow Tracing is production ready and provides comprehensive monitoring capabilities for your GenAI applications in production environments. The tracing system captures detailed execution information that can be integrated with your existing observability stack through OpenTelemetry standards.

For production deployments, consider using the [Lightweight Tracing SDK](/genai/tracing/lightweight-sdk) (`mlflow-tracing`) that is optimized for reducing the total installation size and minimizing dependencies while maintaining full tracing capabilities.

Read [Production Tracing](/genai/tracing/prod-tracing) for complete guidance on using MLflow Tracing for monitoring models in production and various backend configuration options.
=======
<FeatureHighlights features={[
  {
    icon: Heart,
    title: "Open Source",
    description: "MLflow is open source and 100% FREE. You don't need to pay additional SaaS costs to add observability to your GenAI stack. Your trace data is hosted on your own infrastructure."
  },
  {
    icon: Zap,
    title: "OpenTelemetry",
    description: "MLflow Tracing is compatible with OpenTelemetry, making it free from vendor lock-in and easy to integrate with your existing observability stack."
  },
  {
    icon: Puzzle,
    title: "Framework Agnostic",
    description: "MLflow Tracing integrates with 20+ GenAI libraries, including OpenAI, LangChain, LlamaIndex, DSPy, Pydantic AI, allowing you to switch between frameworks with ease."
  },
  {
    icon: LifeBuoy,
    title: "End-to-End Platform",
    description: "MLflow Tracing empowers you throughout the end-to-end machine learning lifecycle, combined with its version tracking and evaluation capabilities."
  },
  {
    icon: Users,
    title: "Strong Community",
    description: "MLflow boasts a vibrant Open Source community as a part of the Linux Foundation, with 20K+ GitHub Stars and 20MM+ monthly downloads."
  }
]} />
>>>>>>> v3.1.4

## Getting Started

<TilesGrid>
  <TileCard
    image="/images/logos/python-logo.png"
    title="Quickstart"
    description="Get started with MLflow in Python"
    href="/genai/tracing/quickstart"
    linkText="Start building ‚Üí"
    containerHeight={64}
  />
  <TileCard
    icon={GitMerge}
    iconSize={48}
    title="Trace Your App"
    description="Explore the practical guides for instrumenting your own applications or systems"
    href="/genai/tracing/app-instrumentation"
    containerHeight={64}
  />
</TilesGrid>

## One-line Auto Tracing Integrations

MLflow Tracing is integrated with various GenAI libraries and provides one-line automatic tracing experience for each library (and combinations of them!):

```python
import mlflow

mlflow.openai.autolog()  # or replace 'openai' with other library names, e.g., "anthropic"
```

| Frameworks                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | LLM Providers                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | Tools                                                                                                             |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------- |
| [LangChain](/genai/tracing/integrations/listing/langchain) ‚Ä¢ [LangGraph](/genai/tracing/integrations/listing/langgraph) ‚Ä¢ [LlamaIndex](/genai/tracing/integrations/listing/llama_index) ‚Ä¢ [DSPy](/genai/tracing/integrations/listing/dspy) ‚Ä¢ [PydanticAI](/genai/tracing/integrations/listing/pydantic_ai) ‚Ä¢ [AutoGen](/genai/tracing/integrations/listing/autogen) ‚Ä¢ [OpenAI Agent](/genai/tracing/integrations/listing/openai-agent) ‚Ä¢ [AG2](/genai/tracing/integrations/listing/ag2) ‚Ä¢ [CrewAI](/genai/tracing/integrations/listing/crewai) ‚Ä¢ [Smolagents](/genai/tracing/integrations/listing/smolagents) | [OpenAI](/genai/tracing/integrations/listing/openai) ‚Ä¢ [Anthropic](/genai/tracing/integrations/listing/anthropic) ‚Ä¢ [Bedrock](/genai/tracing/integrations/listing/bedrock) ‚Ä¢ [Gemini](/genai/tracing/integrations/listing/gemini) ‚Ä¢ [LiteLLM](/genai/tracing/integrations/listing/litellm) ‚Ä¢ [Ollama](/genai/tracing/integrations/listing/ollama) ‚Ä¢ [Groq](/genai/tracing/integrations/listing/groq) ‚Ä¢ [Mistral](/genai/tracing/integrations/listing/mistral) ‚Ä¢ [DeepSeek](/genai/tracing/integrations/listing/deepseek) | [Instructor](/genai/tracing/integrations/listing/instructor) ‚Ä¢ [txtai](/genai/tracing/integrations/listing/txtai) |

For the complete list and detailed integration examples, see the [Automatic Tracing](/genai/tracing/app-instrumentation/automatic) documentation.

## Flexible and Customizable

In addition to the one-line auto tracing experience, MLflow offers Python SDK for manually instrumenting your code and manipulating traces:

<<<<<<< HEAD
:::note
MLflow Tracing support is available with **MLflow 2.14.0+**, but we strongly recommend **MLflow 3** for the latest features and enhanced production support.
:::
=======
- [Trace a function with `@mlflow.trace` decorator](/genai/tracing/app-instrumentation/manual-tracing/fluent-apis#decorator)
- [Trace any block of code using context manager](/genai/tracing/app-instrumentation/manual-tracing/fluent-apis#context-manager)
- [Combine multiple auto-tracing integrations](/genai/tracing/app-instrumentation/automatic/#multi-framework-example)
- [Instrument multi-threaded applications](/genai/tracing/app-instrumentation/manual-tracing/fluent-apis/#multi-threading)
- [Native async support](/genai/tracing/app-instrumentation/manual-tracing/fluent-apis#async-support)
- [Group and filter traces using sessions](/genai/tracing/track-users-sessions)
- [Disable tracing globally](/genai/tracing/app-instrumentation/automatic#disabling-tracing)

## Production Readiness

MLflow Tracing is production ready and provides comprehensive monitoring capabilities for your GenAI applications in production environments. By enabling [async logging](/genai/tracing/prod-tracing/#asynchronous-trace-logging), trace logging is done in the background and does not impact the performance of your application.

For production deployments, it is recommended to use the [Lightweight Tracing SDK](/genai/tracing/lightweight-sdk) (`mlflow-tracing`) that is optimized for reducing the total installation size and minimizing dependencies while maintaining full tracing capabilities. Compared to the full `mlflow` package, the `mlflow-tracing` package requires 95% smaller footprint.

Read [Production Monitoring](/genai/tracing/prod-tracing) for complete guidance on using MLflow Tracing for monitoring models in production and various backend configuration options.
>>>>>>> v3.1.4

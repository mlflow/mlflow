{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa602d14-6372-4e0a-92d8-6f7db048c3b8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# DSPy Quickstart\n",
    "\n",
    "[DSPy](https://dspy-docs.vercel.app/) simplifies building language model (LM) pipelines by replacing manual prompt engineering with structured \"text transformation graphs.\" These graphs use flexible, learning modules that automate and optimize LM tasks like reasoning, retrieval, and answering complex questions. \n",
    "\n",
    "## How does it work?\n",
    "At a high level, DSPy optimizes prompts, selects the best language model, and can even fine-tune the model using training data.\n",
    "\n",
    "The process follows these three steps, common to most DSPy [optimizers](https://dspy.ai/learn/optimization/optimizers/):\n",
    "\n",
    "1. **Candidate Generation**: DSPy finds all `Predict` modules in the program and generates variations of instructions and demonstrations (e.g., examples for prompts). This step creates a set of possible candidates for the next stage.\n",
    "2. **Parameter Optimization**: DSPy then uses methods like random search, TPE, or Optuna to select the best candidate. Fine-tuning models can also be done at this stage.\n",
    "\n",
    "## This Demo\n",
    "Below we create a simple program that demonstrates the power of DSPy. We will build a text classifier leveraging OpenAI. By the end of this tutorial, we will...\n",
    "\n",
    "1. Define a [dspy.Signature](https://dspy.ai/learn/programming/signatures/) and [dspy.Module](https://dspy.ai/learn/programming/modules/) to perform text classification.\n",
    "2. Leverage [dspy.SIMBA](https://dspy.ai/api/optimizers/SIMBA/) to compile our module so it's better at classifying our text.\n",
    "3. Analyze internal steps with MLflow Tracing.\n",
    "3. Log the compiled model with MLflow.\n",
    "4. Load the logged model and perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58918566-6e93-4a2e-9a34-b0f56378885a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U datasets openai \"dspy>=3.0.3\" \"mlflow>=3.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bd9e460-4c9c-4508-8801-6f29fcf2c8d2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c27ec364-1195-447d-a9d5-f38defa6652e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Set Up LLM\n",
    "\n",
    "After installing the relevant dependencies, let's set up access to an OpenAI LLM. Here, will leverage OpenAI's `gpt-4o-mini` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI API Key to the environment variable. You can also pass the token to dspy.LM()\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3232fb03-f4be-490f-9179-0f2b71129196",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "# Define your model. We will use OpenAI for simplicity\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "# Note that an OPENAI_API_KEY environment must be present. You can also pass the token to dspy.LM()\n",
    "lm = dspy.LM(\n",
    "    model=f\"openai/{model_name}\",\n",
    "    max_tokens=500,\n",
    "    temperature=0.1,\n",
    ")\n",
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MLflow Experiment\n",
    "\n",
    "Create a new MLflow Experiment to track your DSPy models, metrics, parameters, and traces in one place. Although there is already a \"default\" experiment created in your workspace, it is highly recommended to create one for different tasks to organize experiment artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"DSPy Quickstart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn on Auto Tracing with MLflow\n",
    "\n",
    "[MLflow Tracing](https://mlflow.org/docs/latest/llms/tracing/index.html) is a powerful observability tool for monitoring and debugging what happens inside your DSPy modules, helping you identify potential bottlenecks or issues quickly. To enable DSPy tracing, you just need to call `mlflow.dspy.autolog` and that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.dspy.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3fde40f-650a-4090-9791-120dd954cd36",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Set Up Data\n",
    "\n",
    "Next, we will download the [Reuters 21578](https://huggingface.co/datasets/yangwang825/reuters-21578) dataset from Huggingface. We also write a utility to ensure that our train/test split has the same labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd53a405-1685-4e2f-86c5-8f3f570828c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 8\n",
      "Train labels: {'interest', 'earn', 'money-fx', 'trade', 'ship', 'grain', 'acq', 'crude'}\n",
      "Example({'text': 'bankamerica bacp raises prime rate to pct bankamerica corp following moves by other major banks said it has raised its prime rate to pct from pct effective today reuter', 'label': 'interest'}) (input_keys={'text'})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from dspy.datasets.dataset import Dataset\n",
    "\n",
    "\n",
    "def read_data_and_subset_to_categories() -> tuple[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Read the reuters-21578 dataset. Docs can be found in the url below:\n",
    "    https://huggingface.co/datasets/yangwang825/reuters-21578\n",
    "    \"\"\"\n",
    "\n",
    "    # Read train/test split\n",
    "    dataset = load_dataset(\"yangwang825/reuters-21578\")\n",
    "    train = pd.DataFrame(dataset[\"train\"])\n",
    "    test = pd.DataFrame(dataset[\"test\"])\n",
    "\n",
    "    # Clean the labels\n",
    "    label_map = {\n",
    "        0: \"acq\",\n",
    "        1: \"crude\",\n",
    "        2: \"earn\",\n",
    "        3: \"grain\",\n",
    "        4: \"interest\",\n",
    "        5: \"money-fx\",\n",
    "        6: \"ship\",\n",
    "        7: \"trade\",\n",
    "    }\n",
    "\n",
    "    train[\"label\"] = train[\"label\"].map(label_map)\n",
    "    test[\"label\"] = test[\"label\"].map(label_map)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, n_train_per_label: int = 20, n_test_per_label: int = 10, *args, **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.n_train_per_label = n_train_per_label\n",
    "        self.n_test_per_label = n_test_per_label\n",
    "\n",
    "        self._create_train_test_split_and_ensure_labels()\n",
    "\n",
    "    def _create_train_test_split_and_ensure_labels(self) -> None:\n",
    "        \"\"\"Perform a train/test split that ensure labels in `dev` are also in `train`.\"\"\"\n",
    "        # Read the data\n",
    "        train_df, test_df = read_data_and_subset_to_categories()\n",
    "\n",
    "        # Sample for each label\n",
    "        train_samples_df = pd.concat(\n",
    "            [group.sample(n=self.n_train_per_label) for _, group in train_df.groupby(\"label\")]\n",
    "        )\n",
    "        test_samples_df = pd.concat(\n",
    "            [group.sample(n=self.n_test_per_label) for _, group in test_df.groupby(\"label\")]\n",
    "        )\n",
    "\n",
    "        # Set DSPy class variables\n",
    "        self._train = train_samples_df.to_dict(orient=\"records\")\n",
    "        self._dev = test_samples_df.to_dict(orient=\"records\")\n",
    "\n",
    "\n",
    "# Limit to a small dataset to showcase the value of bootstrapping\n",
    "dataset = CSVDataset(n_train_per_label=3, n_test_per_label=1)\n",
    "\n",
    "# Create train and test sets containing DSPy\n",
    "# Note that we must specify the expected input value name\n",
    "train_dataset = [example.with_inputs(\"text\") for example in dataset.train]\n",
    "test_dataset = [example.with_inputs(\"text\") for example in dataset.dev]\n",
    "unique_train_labels = {example.label for example in dataset.train}\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "print(f\"Train labels: {unique_train_labels}\")\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a683b83-6acc-4fdf-846f-bd81cadda53b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Set up DSPy Signature and Module\n",
    "\n",
    "Finally, we will define our task: text classification.\n",
    "\n",
    "There are a variety of ways you can provide guidelines to DSPy signature behavior. Currently, DSPy allows users to specify:\n",
    "\n",
    "1. A high-level goal via the class docstring.\n",
    "2. A set of input fields, with optional metadata.\n",
    "3. A set of output fields with optional metadata.\n",
    "\n",
    "DSPy will then leverage this information to inform optimization. \n",
    "\n",
    "In the below example, note that we simply provide the expected labels to `output` field in the `TextClassificationSignature` class. From this initial state, we'll look to use DSPy to learn to improve our classifier accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0743c63-c679-4114-b7b1-bed4aeb918cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class TextClassificationSignature(dspy.Signature):\n",
    "    text = dspy.InputField()\n",
    "    label = dspy.OutputField(\n",
    "        desc=f\"Label of predicted class. Possible labels are {unique_train_labels}\"\n",
    "    )\n",
    "\n",
    "\n",
    "class TextClassifier(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_classification = dspy.Predict(TextClassificationSignature)\n",
    "\n",
    "    def forward(self, text: str):\n",
    "        return self.generate_classification(text=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d93df5c-25d7-460d-a803-0e5469f3bbad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Run it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c89741fa-2698-4409-b290-f5f5652f7d66",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Hello World\n",
    "Let's demonstrate predicting via the DSPy module and associated signature. The program has correctly learned our labels from the signature `desc` field and generates reasonable predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4da1ad9-7173-4d1b-ab53-346e9c49fbbf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    label='interest'\n",
      ")\n",
      "Prediction(\n",
      "    label='interest'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initilize our impact_improvement class\n",
    "text_classifier = TextClassifier()\n",
    "\n",
    "message = \"I am interested in space\"\n",
    "print(text_classifier(text=message))\n",
    "\n",
    "message = \"I enjoy ice skating\"\n",
    "print(text_classifier(text=message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Traces\n",
    "\n",
    "1. Open the MLflow UI and select the `\"DSPy Quickstart\"` experiment.\n",
    "2. Go to the `\"Traces\"` tab to view the generated traces.\n",
    "\n",
    "Now, you can observe how DSPy translates your query and interacts with the LLM. This feature is extremely valuable for debugging, iteratively refining components within your system, and monitoring models in production. While the module in this tutorial is relatively simple, the tracing feature becomes even more powerful as your model grows in complexity.\n",
    "\n",
    "![MLflow DSPy Trace](/images/llms/dspy/dspy-trace.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b064a99e-027a-4854-873b-5347d901de46",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Compilation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a82d466-40f7-411a-a029-dcadb4629391",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Training\n",
    "\n",
    "To train, we will leverage [SIMBA](https://dspy.ai/api/optimizers/SIMBA/), an optimizer that will take bootstrap samples from our training set and leverage a random search strategy to optimize our predictive accuracy.\n",
    "\n",
    "Note that in the below example, we leverage a simple metric definition of exact match, as defined in `validate_classification`, but [dspy.Metrics](https://dspy.ai/learn/evaluation/metrics/) can contain complex and LM-based logic to properly evaluate our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7d41f13-ef79-45bf-90fa-2abee39c35ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:37:56 INFO dspy.teleprompt.simba: Starting batch 1 of 8.\n",
      "2025/09/22 11:37:56 INFO dspy.teleprompt.simba: Sampling program trajectories on 12 examples x 6 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 72 / 72 examples: 100%|██████████| 72/72 [00:57<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:38:54 INFO dspy.teleprompt.simba: Batch 1: Baseline mini-batch score: 0.8194444444444444\n",
      "\n",
      "2025/09/22 11:38:54 INFO dspy.teleprompt.simba: Batch 1: Processing bucket #1, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.5.\n",
      "2025/09/22 11:38:54 INFO dspy.teleprompt.simba: Batch 1: Invoking strategy: append_a_rule\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:38:58 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that includes financial terms related to banking and interest rates, such as 'prime rate' or 'bank', it should focus on identifying these key phrases and their implications in the context of interest rates. The module should enhance its training on texts that discuss monetary policy and interest rate changes to better associate these terms with the 'interest' label, avoiding misclassifications like 'earn'.\n",
      "2025/09/22 11:38:58 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:38:58 INFO dspy.teleprompt.simba: Batch 1: Processing bucket #2, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.5.\n",
      "2025/09/22 11:38:58 INFO dspy.teleprompt.simba: Batch 1: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:38:58 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:38:58 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:38:58 INFO dspy.teleprompt.simba: Batch 1: Processing bucket #3, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.16666666666666663.\n",
      "2025/09/22 11:38:58 INFO dspy.teleprompt.simba: Batch 1: Invoking strategy: append_a_rule\n",
      "2025/09/22 11:39:03 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text containing financial terms or phrases related to earnings, such as 'net shr', 'revs', or 'writedown of costs', then it should prioritize recognizing these terms as indicators of financial performance and adjust its classification logic to associate such contexts with the label 'earn'. Additionally, it should avoid overgeneralizing terms that may lead to misclassification, like 'interest', which may not be relevant in the context of earnings.\n",
      "2025/09/22 11:39:03 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:39:03 INFO dspy.teleprompt.simba: Batch 1: Processing bucket #4, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:39:03 INFO dspy.teleprompt.simba: Batch 1: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:39:03 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:39:03 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:39:03 INFO dspy.teleprompt.simba: Batch 1: Processing bucket #5, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:39:03 INFO dspy.teleprompt.simba: Batch 1: Invoking strategy: append_a_rule\n",
      "2025/09/22 11:39:09 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that discusses trade relations, economic disputes, or similar topics, it should focus on identifying key phrases and context that indicate trade-related themes. This includes looking for terms like 'trade', 'relations', 'dispute', 'balance', and 'measures'. Additionally, it should consider the overall sentiment and implications of the text to ensure accurate classification. Avoid overly simplistic patterns and instead leverage contextual understanding to improve classification accuracy.\n",
      "2025/09/22 11:39:09 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:39:09 INFO dspy.teleprompt.simba: Batch 1: Processing bucket #6, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:39:09 INFO dspy.teleprompt.simba: Batch 1: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:39:09 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:39:09 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:39:09 INFO dspy.teleprompt.simba: Batch 1: Processing bucket #7, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:39:09 INFO dspy.teleprompt.simba: Batch 1: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:39:09 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:39:09 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:39:09 INFO dspy.teleprompt.simba: Batch 1: Evaluating 7 programs on 12 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 84 / 84 examples: 100%|██████████| 84/84 [01:13<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:40:23 INFO dspy.teleprompt.simba: Scores after 1 batches: [0.8333333333333334, 0.9166666666666666, 0.9166666666666666, 0.8333333333333334, 0.75, 0.9166666666666666, 0.9166666666666666], Best: 0.9166666666666666\n",
      "\n",
      "2025/09/22 11:40:23 INFO dspy.teleprompt.simba: Starting batch 2 of 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:40:23 INFO dspy.teleprompt.simba: Sampling program trajectories on 12 examples x 6 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 72 / 72 examples: 100%|██████████| 72/72 [01:05<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:41:29 INFO dspy.teleprompt.simba: Batch 2: Baseline mini-batch score: 0.9444444444444444\n",
      "\n",
      "2025/09/22 11:41:29 INFO dspy.teleprompt.simba: Batch 2: Processing bucket #1, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.5.\n",
      "2025/09/22 11:41:29 INFO dspy.teleprompt.simba: Batch 2: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:41:29 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:41:29 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:41:29 INFO dspy.teleprompt.simba: Batch 2: Processing bucket #2, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.16666666666666663.\n",
      "2025/09/22 11:41:29 INFO dspy.teleprompt.simba: Batch 2: Invoking strategy: append_a_rule, having dropped 1 demos per predictor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that discusses agricultural practices, conservation measures, or specific crops, it should focus on identifying keywords and phrases related to these topics, such as 'alfalfa', 'grasses', 'farm program benefits', and 'sodbuster regulations'. It should also consider the overall context of the text to determine if it aligns more closely with agricultural themes, which would lead to a classification of 'grain' rather than unrelated categories like 'acq'.\n",
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba: Batch 2: Processing bucket #3, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba: Batch 2: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba: Batch 2: Processing bucket #4, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba: Batch 2: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba: Batch 2: Processing bucket #5, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba: Batch 2: Invoking strategy: append_a_demo_, having dropped 1 demos per predictor\n",
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba: Batch 2: Processing bucket #6, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:41:34 INFO dspy.teleprompt.simba: Batch 2: Invoking strategy: append_a_rule\n",
      "2025/09/22 11:41:39 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text containing terms related to oil production or exploration, such as 'heavy oil', 'development well', or 'producing barrels', then it should prioritize recognizing these terms as indicators of the oil industry and adjust its classification logic to associate such contexts with the label 'crude'. Additionally, it should be cautious of overgeneralizing terms that may lead to misclassification, ensuring that it accurately distinguishes between different financial contexts.\n",
      "2025/09/22 11:41:39 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:41:39 INFO dspy.teleprompt.simba: Batch 2: Processing bucket #7, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:41:39 INFO dspy.teleprompt.simba: Batch 2: Invoking strategy: append_a_rule\n",
      "2025/09/22 11:41:45 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text containing financial terms or phrases related to earnings, such as 'investment climate', 'economic growth', or 'financial survey', then it should prioritize recognizing these terms as indicators of financial performance and adjust its classification logic to associate such contexts with the label 'earn'. Additionally, it should avoid overgeneralizing terms like 'interest' that may not fully represent the context of the text.\n",
      "2025/09/22 11:41:45 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:41:45 INFO dspy.teleprompt.simba: Batch 2: Evaluating 7 programs on 12 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 84 / 84 examples: 100%|██████████| 84/84 [01:11<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:42:56 INFO dspy.teleprompt.simba: Scores after 2 batches: [0.9166666666666666, 1.0, 0.9166666666666666, 0.8333333333333334, 1.0, 0.8333333333333334, 0.9166666666666666], Best: 1.0\n",
      "\n",
      "2025/09/22 11:42:56 INFO dspy.teleprompt.simba: Starting batch 3 of 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:42:56 INFO dspy.teleprompt.simba: Sampling program trajectories on 12 examples x 6 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 72 / 72 examples: 100%|██████████| 72/72 [00:58<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:43:55 INFO dspy.teleprompt.simba: Batch 3: Baseline mini-batch score: 0.875\n",
      "\n",
      "2025/09/22 11:43:55 INFO dspy.teleprompt.simba: Batch 3: Processing bucket #1, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.33333333333333337.\n",
      "2025/09/22 11:43:55 INFO dspy.teleprompt.simba: Batch 3: Invoking strategy: append_a_rule, having dropped 1 demos per predictor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:43:59 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that includes terms related to financial rates, such as 'prime rate', 'raises', or 'interest', it should prioritize these keywords and their context to classify the text accurately. Additionally, it should consider the overall sentiment and implications of the text, focusing on the financial context to avoid misclassifying it as 'money-fx'.\n",
      "2025/09/22 11:43:59 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:43:59 INFO dspy.teleprompt.simba: Batch 3: Processing bucket #2, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.16666666666666663.\n",
      "2025/09/22 11:43:59 INFO dspy.teleprompt.simba: Batch 3: Invoking strategy: append_a_rule, having dropped 1 demos per predictor\n",
      "2025/09/22 11:44:05 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that contains financial terms such as 'net', 'revenue', or 'shares', it should prioritize identifying these keywords and their context to classify the text accurately. Additionally, it should leverage patterns in similar financial documents to enhance its predictive capabilities, avoiding overgeneralization that leads to misclassifications like 'grain'.\n",
      "2025/09/22 11:44:05 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:44:05 INFO dspy.teleprompt.simba: Batch 3: Processing bucket #3, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:44:05 INFO dspy.teleprompt.simba: Batch 3: Invoking strategy: append_a_demo_, having dropped 1 demos per predictor\n",
      "2025/09/22 11:44:05 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:44:05 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:44:05 INFO dspy.teleprompt.simba: Batch 3: Processing bucket #4, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:44:05 INFO dspy.teleprompt.simba: Batch 3: Invoking strategy: append_a_rule, having dropped 1 demos per predictor\n",
      "2025/09/22 11:44:10 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that discusses agricultural topics, particularly those related to weather impacts on crops, it should ensure that it leverages contextual keywords such as 'crops', 'rain', 'drought', and 'harvest' to reinforce its classification towards 'grain'. Additionally, it should consider the overall sentiment and implications of the text to avoid misclassifications in ambiguous cases.\n",
      "2025/09/22 11:44:10 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:44:10 INFO dspy.teleprompt.simba: Batch 3: Processing bucket #5, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:44:10 INFO dspy.teleprompt.simba: Batch 3: Invoking strategy: append_a_rule\n",
      "2025/09/22 11:44:17 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that discusses financial transactions, investments, or corporate acquisitions, it should focus on identifying keywords and phrases related to these topics, such as 'purchase', 'stake', 'private placement', and 'investors'. It should also analyze the overall context of the text to ensure that it aligns with acquisition themes, which would lead to a classification of 'acq' rather than misclassifying it under unrelated categories.\n",
      "2025/09/22 11:44:17 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:44:17 INFO dspy.teleprompt.simba: Batch 3: Processing bucket #6, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:44:17 INFO dspy.teleprompt.simba: Batch 3: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:44:17 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:44:17 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:44:17 INFO dspy.teleprompt.simba: Batch 3: Processing bucket #7, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:44:17 INFO dspy.teleprompt.simba: Batch 3: Invoking strategy: append_a_demo_, having dropped 1 demos per predictor\n",
      "2025/09/22 11:44:17 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:44:17 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:44:17 INFO dspy.teleprompt.simba: Batch 3: Evaluating 7 programs on 12 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 84 / 84 examples: 100%|██████████| 84/84 [01:03<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:45:21 INFO dspy.teleprompt.simba: Scores after 3 batches: [0.8333333333333334, 0.9166666666666666, 0.9166666666666666, 1.0, 0.8333333333333334, 0.9166666666666666, 0.9166666666666666], Best: 1.0\n",
      "\n",
      "2025/09/22 11:45:21 INFO dspy.teleprompt.simba: Starting batch 4 of 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:45:21 INFO dspy.teleprompt.simba: Sampling program trajectories on 12 examples x 6 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 72 / 72 examples: 100%|██████████| 72/72 [00:59<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:46:21 INFO dspy.teleprompt.simba: Batch 4: Baseline mini-batch score: 0.9166666666666666\n",
      "\n",
      "2025/09/22 11:46:21 INFO dspy.teleprompt.simba: Batch 4: Processing bucket #1, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.5.\n",
      "2025/09/22 11:46:21 INFO dspy.teleprompt.simba: Batch 4: Invoking strategy: append_a_rule\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:46:26 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that discusses financial topics, particularly those related to banking and interest rates, it should prioritize identifying keywords such as 'prime rate', 'bank', and 'interest'. It should also analyze the context to ensure that it aligns with financial themes, leading to a classification of 'interest' rather than unrelated categories like 'earn'.\n",
      "2025/09/22 11:46:26 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:46:26 INFO dspy.teleprompt.simba: Batch 4: Processing bucket #2, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.33333333333333337.\n",
      "2025/09/22 11:46:26 INFO dspy.teleprompt.simba: Batch 4: Invoking strategy: append_a_rule\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text containing financial terms or phrases related to earnings, such as 'raises dividend', it should prioritize recognizing these terms as indicators of financial performance and adjust its classification logic to associate such contexts with the label 'earn'. Additionally, it should avoid overgeneralizing terms like 'interest', which may not be relevant in the context of earnings.\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba: Batch 4: Processing bucket #3, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.16666666666666663.\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba: Batch 4: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba: Batch 4: Processing bucket #4, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba: Batch 4: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba: Batch 4: Processing bucket #5, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba: Batch 4: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba: Batch 4: Processing bucket #6, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:46:30 INFO dspy.teleprompt.simba: Batch 4: Invoking strategy: append_a_rule\n",
      "2025/09/22 11:46:34 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that contains complex phrases or industry-specific jargon, it should utilize a broader context understanding and possibly incorporate additional training data that includes similar phrases to improve classification accuracy. Additionally, it should implement fallback mechanisms to handle cases where it cannot confidently classify the input, ensuring that it always provides a meaningful output or indicates when a prediction is not available.\n",
      "2025/09/22 11:46:34 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:46:34 INFO dspy.teleprompt.simba: Batch 4: Processing bucket #7, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:46:34 INFO dspy.teleprompt.simba: Batch 4: Invoking strategy: append_a_rule\n",
      "2025/09/22 11:46:34 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that discusses trade relations, economic disputes, or similar topics, it should focus on identifying key phrases and context that indicate trade-related themes. This includes looking for terms like 'trade', 'relations', 'dispute', 'balance', and 'measures'. Additionally, it should consider the overall sentiment and implications of the text to ensure accurate classification. Avoid overly simplistic patterns and instead leverage contextual understanding to improve classification accuracy.\n",
      "2025/09/22 11:46:34 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:46:34 INFO dspy.teleprompt.simba: Batch 4: Evaluating 7 programs on 12 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 84 / 84 examples: 100%|██████████| 84/84 [01:08<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:47:43 INFO dspy.teleprompt.simba: Scores after 4 batches: [0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666], Best: 0.9166666666666666\n",
      "\n",
      "2025/09/22 11:47:43 INFO dspy.teleprompt.simba: Starting batch 5 of 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:47:44 INFO dspy.teleprompt.simba: Sampling program trajectories on 12 examples x 6 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 72 / 72 examples: 100%|██████████| 72/72 [00:44<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:48:28 INFO dspy.teleprompt.simba: Batch 5: Baseline mini-batch score: 0.8472222222222222\n",
      "\n",
      "2025/09/22 11:48:28 INFO dspy.teleprompt.simba: Batch 5: Processing bucket #1, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.5.\n",
      "2025/09/22 11:48:28 INFO dspy.teleprompt.simba: Batch 5: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:48:28 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:48:28 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:48:28 INFO dspy.teleprompt.simba: Batch 5: Processing bucket #2, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.33333333333333337.\n",
      "2025/09/22 11:48:28 INFO dspy.teleprompt.simba: Batch 5: Invoking strategy: append_a_rule, having dropped 1 demos per predictor\n",
      "2025/09/22 11:48:29 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that includes terms related to financial rates, such as 'prime rate', 'raises', or 'interest', it should prioritize these keywords and their context to classify the text accurately. Additionally, it should consider the overall sentiment and implications of the text, focusing on the financial context to avoid misclassifying it as 'money-fx'.\n",
      "2025/09/22 11:48:29 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:48:29 INFO dspy.teleprompt.simba: Batch 5: Processing bucket #3, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:48:29 INFO dspy.teleprompt.simba: Batch 5: Invoking strategy: append_a_rule\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:48:33 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that discusses port facilities, shipping, or cargo handling, it should focus on identifying keywords and phrases related to these topics, such as 'port', 'cargo', 'shipping', and 'tonnage'. It should also analyze the context to ensure it aligns with maritime themes, which would lead to a classification of 'ship'. Additionally, it should avoid misclassifying texts that may have overlapping terms but are contextually unrelated.\n",
      "2025/09/22 11:48:33 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:48:33 INFO dspy.teleprompt.simba: Batch 5: Processing bucket #4, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:48:33 INFO dspy.teleprompt.simba: Batch 5: Invoking strategy: append_a_rule, having dropped 1 demos per predictor\n",
      "2025/09/22 11:48:37 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that contains financial terminology or phrases indicating a change in dividends, it should ensure that it utilizes context clues effectively to reinforce its classification logic. Additionally, it should implement fallback mechanisms to handle cases where the input is ambiguous or does not fit known patterns, possibly by returning a default label or indicating uncertainty.\n",
      "2025/09/22 11:48:37 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:48:37 INFO dspy.teleprompt.simba: Batch 5: Processing bucket #5, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:48:37 INFO dspy.teleprompt.simba: Batch 5: Invoking strategy: append_a_rule\n",
      "2025/09/22 11:48:42 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that discusses oil exploration, production, or related activities, it should prioritize identifying keywords and phrases such as 'heavy oil', 'production', 'exploration well', and 'barrels of oil'. It should also analyze the context to ensure it aligns with the crude oil category, rather than misclassifying it into unrelated categories. Additionally, the module should be trained to recognize when the context is ambiguous and consider multiple potential labels before making a final classification.\n",
      "2025/09/22 11:48:42 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:48:42 INFO dspy.teleprompt.simba: Batch 5: Processing bucket #6, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:48:42 INFO dspy.teleprompt.simba: Batch 5: Invoking strategy: append_a_rule\n",
      "2025/09/22 11:48:47 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that discusses maritime topics, particularly those involving ships and shipping logistics, it should focus on keywords such as 'ship', 'canal', 'refloated', and 'carrier' to reinforce its classification towards 'ship'. Additionally, it should assess the context of the text to ensure that it does not misclassify based on ambiguous terms that could relate to other categories.\n",
      "2025/09/22 11:48:47 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:48:47 INFO dspy.teleprompt.simba: Batch 5: Processing bucket #7, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:48:47 INFO dspy.teleprompt.simba: Batch 5: Invoking strategy: append_a_demo_, having dropped 1 demos per predictor\n",
      "2025/09/22 11:48:47 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:48:47 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:48:47 INFO dspy.teleprompt.simba: Batch 5: Evaluating 7 programs on 12 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 84 / 84 examples: 100%|██████████| 84/84 [01:03<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:49:50 INFO dspy.teleprompt.simba: Scores after 5 batches: [0.9166666666666666, 0.9166666666666666, 0.8333333333333334, 0.8333333333333334, 0.75, 0.75, 0.9166666666666666], Best: 0.9166666666666666\n",
      "\n",
      "2025/09/22 11:49:50 INFO dspy.teleprompt.simba: Starting batch 6 of 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:49:51 INFO dspy.teleprompt.simba: Sampling program trajectories on 12 examples x 6 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 72 / 72 examples: 100%|██████████| 72/72 [00:48<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:50:40 INFO dspy.teleprompt.simba: Batch 6: Baseline mini-batch score: 0.9583333333333334\n",
      "\n",
      "2025/09/22 11:50:40 INFO dspy.teleprompt.simba: Batch 6: Processing bucket #1, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.33333333333333337.\n",
      "2025/09/22 11:50:40 INFO dspy.teleprompt.simba: Batch 6: Invoking strategy: append_a_rule, having dropped 1 demos per predictor\n",
      "2025/09/22 11:50:40 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that contains financial terms such as 'net', 'revenue', or 'shares', it should prioritize identifying these keywords and their context to classify the text accurately. Additionally, it should leverage patterns in similar financial documents to enhance its predictive capabilities, avoiding overgeneralization that leads to misclassifications like 'grain'.\n",
      "2025/09/22 11:50:40 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:50:40 INFO dspy.teleprompt.simba: Batch 6: Processing bucket #2, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.16666666666666663.\n",
      "2025/09/22 11:50:40 INFO dspy.teleprompt.simba: Batch 6: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:50:40 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:50:40 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:50:40 INFO dspy.teleprompt.simba: Batch 6: Processing bucket #3, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:50:40 INFO dspy.teleprompt.simba: Batch 6: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:50:40 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:50:40 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:50:40 INFO dspy.teleprompt.simba: Batch 6: Processing bucket #4, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:50:40 INFO dspy.teleprompt.simba: Batch 6: Invoking strategy: append_a_rule\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:50:46 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that contains agricultural terms or weather-related phrases, it should leverage contextual clues to enhance its classification accuracy. Specifically, it should focus on identifying keywords related to crops, weather patterns, and agricultural reports. Additionally, the module should implement a mechanism to handle ambiguous inputs by considering the frequency and relevance of terms in the training data, allowing it to make more informed predictions.\n",
      "2025/09/22 11:50:46 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:50:46 INFO dspy.teleprompt.simba: Batch 6: Processing bucket #5, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:50:46 INFO dspy.teleprompt.simba: Batch 6: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:50:46 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:50:46 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:50:46 INFO dspy.teleprompt.simba: Batch 6: Processing bucket #6, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:50:46 INFO dspy.teleprompt.simba: Batch 6: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:50:46 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:50:46 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:50:46 INFO dspy.teleprompt.simba: Batch 6: Processing bucket #7, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:50:46 INFO dspy.teleprompt.simba: Batch 6: Invoking strategy: append_a_demo_, having dropped 1 demos per predictor\n",
      "2025/09/22 11:50:46 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:50:46 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:50:46 INFO dspy.teleprompt.simba: Batch 6: Evaluating 7 programs on 12 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 84 / 84 examples: 100%|██████████| 84/84 [01:06<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:51:52 INFO dspy.teleprompt.simba: Scores after 6 batches: [1.0, 0.8333333333333334, 1.0, 0.9166666666666666, 0.9166666666666666, 0.75, 1.0], Best: 1.0\n",
      "\n",
      "2025/09/22 11:51:52 INFO dspy.teleprompt.simba: Starting batch 7 of 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:51:53 INFO dspy.teleprompt.simba: Sampling program trajectories on 12 examples x 6 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 72 / 72 examples: 100%|██████████| 72/72 [00:42<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:52:35 INFO dspy.teleprompt.simba: Batch 7: Baseline mini-batch score: 0.9861111111111112\n",
      "\n",
      "2025/09/22 11:52:35 INFO dspy.teleprompt.simba: Batch 7: Processing bucket #1, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.16666666666666663.\n",
      "2025/09/22 11:52:35 INFO dspy.teleprompt.simba: Batch 7: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:52:35 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:52:35 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:52:35 INFO dspy.teleprompt.simba: Batch 7: Processing bucket #2, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:52:35 INFO dspy.teleprompt.simba: Batch 7: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:52:35 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:52:35 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:52:35 INFO dspy.teleprompt.simba: Batch 7: Processing bucket #3, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:52:35 INFO dspy.teleprompt.simba: Batch 7: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:52:35 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:52:35 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:52:35 INFO dspy.teleprompt.simba: Batch 7: Processing bucket #4, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:52:35 INFO dspy.teleprompt.simba: Batch 7: Invoking strategy: append_a_rule\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:52:40 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that discusses economic conditions, particularly those related to interest rates, it should focus on identifying key phrases and contextual clues that indicate the sentiment and implications of the text. For example, it should recognize terms like 'low interest rates', 'economic growth', and 'investment climate' as strong indicators of the 'interest' label. Additionally, it should avoid over-reliance on surface-level keywords and instead consider the overall context to ensure accurate classifications, especially in complex or nuanced scenarios.\n",
      "2025/09/22 11:52:40 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:52:40 INFO dspy.teleprompt.simba: Batch 7: Processing bucket #5, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:52:40 INFO dspy.teleprompt.simba: Batch 7: Invoking strategy: append_a_rule\n",
      "2025/09/22 11:52:40 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that discusses maritime topics, particularly those involving ships and shipping logistics, it should focus on keywords such as 'ship', 'canal', 'refloated', and 'carrier' to reinforce its classification towards 'ship'. Additionally, it should assess the context of the text to ensure that it does not misclassify based on ambiguous terms that could relate to other categories.\n",
      "2025/09/22 11:52:40 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:52:40 INFO dspy.teleprompt.simba: Batch 7: Processing bucket #6, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:52:40 INFO dspy.teleprompt.simba: Batch 7: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:52:40 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:52:40 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:52:40 INFO dspy.teleprompt.simba: Batch 7: Processing bucket #7, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:52:40 INFO dspy.teleprompt.simba: Batch 7: Invoking strategy: append_a_rule\n",
      "2025/09/22 11:52:43 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that contains financial terms or phrases, it should prioritize extracting and analyzing these keywords and their context to ensure accurate classification. Additionally, it should utilize patterns from a diverse set of financial documents to improve its predictions, avoiding overly broad classifications that could lead to errors, such as misclassifying financial texts as 'grain'.\n",
      "2025/09/22 11:52:43 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:52:43 INFO dspy.teleprompt.simba: Batch 7: Evaluating 7 programs on 12 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 84 / 84 examples: 100%|██████████| 84/84 [01:02<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:53:46 INFO dspy.teleprompt.simba: Scores after 7 batches: [0.9166666666666666, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0], Best: 1.0\n",
      "\n",
      "2025/09/22 11:53:46 INFO dspy.teleprompt.simba: Starting batch 8 of 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:53:47 INFO dspy.teleprompt.simba: Sampling program trajectories on 12 examples x 6 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 72 / 72 examples: 100%|██████████| 72/72 [00:50<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: Batch 8: Baseline mini-batch score: 0.7916666666666666\n",
      "\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: Batch 8: Processing bucket #1, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.6666666666666667.\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: Batch 8: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: Batch 8: Processing bucket #2, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.6666666666666667.\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: Batch 8: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: Batch 8: Processing bucket #3, with max score 1.0, max-to-min gap 1.0, and max-to-avg gap 0.16666666666666663.\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: Batch 8: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: Batch 8: Processing bucket #4, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: Batch 8: Invoking strategy: append_a_demo_, having dropped 1 demos per predictor\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: Batch 8: Processing bucket #5, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: Batch 8: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: Batch 8: Processing bucket #6, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: Batch 8: Invoking strategy: append_a_demo_\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba_utils: Added 1 demos (one each) across all predictors.\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: Batch 8: Processing bucket #7, with max score 1.0, max-to-min gap 0.0, and max-to-avg gap 0.0.\n",
      "2025/09/22 11:54:37 INFO dspy.teleprompt.simba: Batch 8: Invoking strategy: append_a_rule\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:54:42 INFO dspy.teleprompt.simba_utils: Advice for generate_classification: If the module receives text that discusses financial transactions or corporate actions, it should focus on identifying keywords related to acquisitions, tenders, and financial offers. It should also analyze the context of the text to determine if it aligns more closely with 'acq' or other relevant labels. For example, terms like 'rejects', 'tender offer', and 'share' should trigger a deeper analysis of the financial implications to avoid misclassifications.\n",
      "2025/09/22 11:54:42 INFO dspy.teleprompt.simba: \n",
      "\n",
      "2025/09/22 11:54:42 INFO dspy.teleprompt.simba: Batch 8: Evaluating 7 programs on 12 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 84 / 84 examples: 100%|██████████| 84/84 [01:11<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:55:54 INFO dspy.teleprompt.simba: Scores after 8 batches: [0.8333333333333334, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.75, 0.8333333333333334, 0.75], Best: 0.9166666666666666\n",
      "\n",
      "2025/09/22 11:55:54 INFO dspy.teleprompt.simba: VALIDATION: Evaluating 7 programs on the full trainset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 168 / 168 examples: 100%|██████████| 168/168 [01:24<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:57:18 INFO dspy.teleprompt.simba: Final trainset scores: [0.9166666666666666, 0.9583333333333334, 0.9583333333333334, 0.875, 0.9583333333333334, 0.8333333333333334, 0.9166666666666666], Best: 0.9583333333333334 (at index 1)\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy import SIMBA\n",
    "\n",
    "\n",
    "def validate_classification(example, prediction, trace=None) -> bool:\n",
    "    return example.label == prediction.label\n",
    "\n",
    "\n",
    "optimizer = SIMBA(\n",
    "    metric=validate_classification,\n",
    "    max_demos=2,\n",
    "    bsize=12,\n",
    "    num_threads=1,\n",
    ")\n",
    "\n",
    "compiled_pe = optimizer.compile(TextClassifier(), trainset=train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f09466f-b929-4ebf-adfd-01c9387d3c8a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Compare Pre/Post Compiled Accuracy\n",
    "\n",
    "Finally, let's explore how well our trained model can predict on unseen test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c075af7e-b15d-4adb-ab2a-e65bbdc38069",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncompiled accuracy: 0.875\n",
      "Compiled accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(classifier, test_data: pd.DataFrame = test_dataset) -> float:\n",
    "    residuals = []\n",
    "    predictions = []\n",
    "    for example in test_data:\n",
    "        prediction = classifier(text=example[\"text\"])\n",
    "        residuals.append(int(validate_classification(example, prediction)))\n",
    "        predictions.append(prediction)\n",
    "    return residuals, predictions\n",
    "\n",
    "\n",
    "uncompiled_residuals, uncompiled_predictions = check_accuracy(TextClassifier())\n",
    "print(f\"Uncompiled accuracy: {np.mean(uncompiled_residuals)}\")\n",
    "\n",
    "compiled_residuals, compiled_predictions = check_accuracy(compiled_pe)\n",
    "print(f\"Compiled accuracy: {np.mean(compiled_residuals)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0964ae5f-6dfe-4b52-8a91-b91d45f69b82",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As shown above, our compiled accuracy is non-zero - our base LLM inferred meaning of the classification labels simply via our initial prompt. However, with DSPy training, the prompts, demonstrations, and input/output signatures have been updated to give our model to 100% accuracy on unseen data. That's a gain of 12 percentage points!\n",
    "\n",
    "Let's take a look at each prediction in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9228b66-864b-49fb-838d-33c12e2ff8b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect prediction:    money-fx\n",
      "Correct prediction:      crude\n",
      "Correct prediction:      money-fx\n",
      "Correct prediction:      earn\n",
      "Incorrect prediction:    interest\n",
      "Correct prediction:      grain\n",
      "Correct prediction:      trade\n",
      "Incorrect prediction:    trade\n"
     ]
    }
   ],
   "source": [
    "for uncompiled_residual, uncompiled_prediction in zip(uncompiled_residuals, uncompiled_predictions):\n",
    "    is_correct = \"Correct\" if bool(uncompiled_residual) else \"Incorrect\"\n",
    "    prediction = uncompiled_prediction.label\n",
    "    print(f\"{is_correct} prediction: {' ' * (12 - len(is_correct))}{prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e93c1b68-a95e-436e-9c0d-54b2b3e34f6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct prediction:      interest\n",
      "Correct prediction:      crude\n",
      "Correct prediction:      money-fx\n",
      "Correct prediction:      earn\n",
      "Correct prediction:      acq\n",
      "Correct prediction:      grain\n",
      "Correct prediction:      trade\n",
      "Correct prediction:      ship\n"
     ]
    }
   ],
   "source": [
    "for compiled_residual, compiled_prediction in zip(compiled_residuals, compiled_predictions):\n",
    "    is_correct = \"Correct\" if bool(compiled_residual) else \"Incorrect\"\n",
    "    prediction = compiled_prediction.label\n",
    "    print(f\"{is_correct} prediction: {' ' * (12 - len(is_correct))}{prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73351663-ed84-4e29-8bf5-61fbf94da937",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Log and Load the Model with MLflow\n",
    "\n",
    "Now that we have a compiled model with higher classification accuracy, let's leverage MLflow to log this model and load it for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94969489f0444d3a919ccf11f0bc4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.dspy.log_model(\n",
    "        compiled_pe,\n",
    "        name=\"model\",\n",
    "        input_example=\"what is 2 + 2?\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the MLflow UI again and check the complied model is recorded to a new MLflow Run. Now you can load the model back for inference using `mlflow.dspy.load_model` or `mlflow.pyfunc.load_model`.\n",
    "\n",
    "💡 MLflow will remember the environment configuration stored in `dspy.settings`, such as the language model (LM) used during the experiment. This ensures excellent reproducibility for your experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============Input Text============\n",
      "Text: top discount rate at u k bill tender rises to pct\n",
      "\n",
      "--------------Original DSPy Prediction------------\n",
      "interest\n",
      "\n",
      "--------------Loaded DSPy Prediction------------\n",
      "interest\n",
      "\n",
      "--------------PyFunc Prediction------------\n",
      "interest\n"
     ]
    }
   ],
   "source": [
    "# Define input text\n",
    "print(\"\\n==============Input Text============\")\n",
    "text = test_dataset[0][\"text\"]\n",
    "print(f\"Text: {text}\")\n",
    "\n",
    "# Inference with original DSPy object\n",
    "print(\"\\n--------------Original DSPy Prediction------------\")\n",
    "print(compiled_pe(text=text).label)\n",
    "\n",
    "# Inference with loaded DSPy object\n",
    "print(\"\\n--------------Loaded DSPy Prediction------------\")\n",
    "loaded_model_dspy = mlflow.dspy.load_model(model_info.model_uri)\n",
    "print(loaded_model_dspy(text=text).label)\n",
    "\n",
    "# Inference with MLflow PyFunc API\n",
    "loaded_model_pyfunc = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "print(\"\\n--------------PyFunc Prediction------------\")\n",
    "print(loaded_model_pyfunc.predict(text)[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09199461-878a-4b9f-9eb0-8803775a6cc5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "This example demonstrates how DSPy works. Below are some potential extensions for improving this project, both with DSPy and MLflow.\n",
    "\n",
    "### DSPy\n",
    "* Use real-world data for the classifier.\n",
    "* Experiment with different optimizers.\n",
    "* For more in-depth examples, check out the [tutorials](https://dspy.ai/tutorials/) and [documentation](https://dspy.ai/learn/).\n",
    "\n",
    "### MLflow\n",
    "* Deploy the model using MLflow serving.\n",
    "* Use MLflow to experiment with various optimization strategies.\n",
    "* Track your DSPy experiments using [DSPy Optimizer Autologging](https://mlflow.org/docs/latest/genai/flavors/dspy/optimizer/).\n",
    "\n",
    "Happy coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Simple DSPy Classifier OSS",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "mlflow-3.10",
   "language": "python",
   "name": "mlflow-3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

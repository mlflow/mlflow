import { CardGroup, SmallLogoCard } from "@site/src/components/Card";

# MLflow GenAI Packaging Integrations

MLflow 3 delivers built-in support for packaging and deploying applications written with the GenAI frameworks you depend on. Whether you're calling OpenAI directly, orchestrating chains with LangChain or LangGraph, indexing documents in LlamaIndex, wiring up agent patterns via ChatModel and ResponseAgent, or rolling your own with a PythonModel, MLflow provides native packaging and deployment APIs ("flavors") to streamline your path to production.

## Why MLflow Integrations?

By choosing MLflow's native flavors, you gain end-to-end visibility and control without swapping tools:

- **Unified Tracking & Models**: All calls, parameters, artifacts, and prompt templates become tracked entities within MLflow Experiments. Serialized GenAI application code becomes a LoggedModel‚Äîviewable and referenceable within the MLflow UI and APIs.
- **Zero-Boilerplate Setup**: A single `mlflow.<flavor>.log_model(...)` call (or one line of auto-instrumentation) wires into your existing code.
- **Reproducibility by Default**: MLflow freezes your prompt template, application parameters, framework versions, and dependencies so you can reproduce any result, anytime.
- **Seamless Transition to Serving**: Each integration produces a standardized MLflow Model you can deploy for batch scoring or real-time inference with `mlflow models serve`.

---

## Start Integrating in Minutes

Before you begin, make sure you have:

- Python 3.9+ and MLflow 3.x installed (`pip install --upgrade mlflow`)
- Credentials or API keys for your chosen provider (e.g., `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`)
- An MLflow Tracking Server (local or remote)

:::tip Ready to dive in?
Pick your integration from the list below and follow the concise guide‚Äîeach one gets you up and running in under 10 minutes.
:::

---

## Integration Guides

MLflow supports first-party flavors for these GenAI frameworks and patterns. Click to explore:

<CardGroup isSmall>
  <SmallLogoCard link="/genai/flavors/openai">
    <span>![OpenAI Logo](/images/logos/openai-logo.png)</span>
  </SmallLogoCard>
  <SmallLogoCard link="/genai/flavors/langchain">
    <span>![LangChain Logo](/images/logos/langchain-logo.png)</span>
  </SmallLogoCard>
  <SmallLogoCard link="/genai/flavors/llama-index">
    <span>![LlamaIndex Logo](/images/logos/llamaindex-logo.svg)</span>
  </SmallLogoCard>
  <SmallLogoCard link="/genai/flavors/dspy">
    <span>![DSPy Logo](/images/logos/dspy-logo.png)</span>
  </SmallLogoCard>
  <SmallLogoCard link="/ml/deep-learning/transformers">
    <span>![HuggingFace Logo](/images/logos/huggingface-logo.svg)</span>
  </SmallLogoCard>
  <SmallLogoCard link="/ml/deep-learning/sentence-transformers">
    <span>![SentenceTransformers Logo](/images/logos/sentence-transformers-logo.png)</span>
  </SmallLogoCard>
  <SmallLogoCard link="/genai/flavors/chat-model-intro">
    <b>Custom Packaging with ChatModel</b>
  </SmallLogoCard>
  <SmallLogoCard link="/genai/flavors/custom-pyfunc-for-llms">
    <b>Custom Packaging with PythonModel</b>
  </SmallLogoCard>
</CardGroup>
---

## Continue Your Journey

Once your integration is in place, take advantage of MLflow's full LLMOps platform:

### üîç Observability & Debugging

- [Tracing & Observability](/genai/tracing)

### üß™ Evaluation & QA

- [LLM Evaluation Framework](https://docs.databricks.com/aws/en/mlflow3/genai/getting-started/eval.html)

### üöÄ Deployment & Monitoring

- [Prompt Engineering UI](/genai/prompt-registry/prompt-engineering)
- [Application Serving](/genai/serving)

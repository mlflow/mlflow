{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Code Assistant with OpenAI & MLflow\n",
    "\n",
    "### Overview\n",
    "\n",
    "Welcome to this comprehensive tutorial, where you'll embark on a fascinating journey through the integration of OpenAI's powerful language models with MLflow, where we'll be building an actually useful tool that can, with the simple addition of a decorator to any function that we declare, get immediate feedback within an interactive environment on code under active development.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "\n",
    "1. **Master OpenAI's GPT-4 for Code Assistance**: Understand how to leverage OpenAI's GPT-4 model for providing real-time coding assistance. Learn to harness its capabilities for generating code suggestions, explanations, and improving overall coding efficiency.\n",
    "2. **Utilize MLflow for Enhanced Model Tracking**: Delve into MLflow's powerful tracking systems to manage machine learning experiments. Learn how to adapt the `Python Model` from within MLflow to control how the output of an LLM is displayed from within an interactive coding environment.\n",
    "3. **Seamlessly Combine OpenAI and MLflow**: Discover the practical steps to integrate OpenAI's AI capabilities with MLflow's tracking and management systems. This integration exemplifies how combining these tools can streamline the development and deployment of intelligent applications.\n",
    "4. **Develop and Deploy a Custom Python Code Assistant**: Gain hands-on experience in creating a Python-based code assistant using OpenAI's model. Then, actually see it in action as it is used within a Jupyter Notebook environment to give helpful assistance during development.\n",
    "5. **Improve Code Quality with AI-driven Insights**: Apply AI-powered analysis to review and enhance your code. Learn how an AI assistant can provide real-time feedback on code quality, suggest improvements, and help maintain high coding standards.\n",
    "6. **Explore Advanced Python Features for Robust Development**: Understand advanced Python features like decorators and functional programming. These are crucial for building efficient, scalable, and maintainable software solutions, especially when integrating AI capabilities.\n",
    "\n",
    "\n",
    "### Key Concepts Covered\n",
    "\n",
    "1. **MLflow's Model Management**: Explore MLflow's features for tracking experiments, packaging code into reproducible runs, and managing and deploying models.\n",
    "2. **Custom Python Model**: Learn how to adapt the OpenAI flavor with MLflow's Custom `Python Model` implementation to provide customized formatting to the output text returned from an OpenAI Model.\n",
    "3. **Python Decorators and Functional Programming**: Learn about advanced Python concepts like decorators and functional programming for efficient code evaluation and enhancement.\n",
    "\n",
    "### MLflow's Significance\n",
    "\n",
    "MLflow emerges as a pivotal element in this tutorial, making our use case not only feasible but also highly efficient. It offers a secure and seamless interface with OpenAI's advanced language models. In this tutorial, we'll explore how MLflow greatly simplifies the process of storing specific instructional prompts for OpenAI, and enhances the user experience by adding readable formatting to the returned text.\n",
    "\n",
    "The flexibility and scalability of MLflow make it a robust choice for integrating with various tools, particularly in interactive coding environments like Jupyter Notebooks. We'll witness firsthand how MLflow facilitates rapid experimentation and iteration, allowing us to create a functional tool with minimal effort. This tool will not just assist in development but will also elevate the overall coding and model management experience. By leveraging MLflow's comprehensive features, we'll navigate through a seamless end-to-end workflow, from setting up intricate models to executing complex tasks efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Disable a few less-than-useful UserWarnings from setuptools and pydantic\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import inspect\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "import shutil\n",
    "import textwrap\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.pyfunc import PythonModel\n",
    "from mlflow.types.schema import ColSpec, ParamSchema, ParamSpec, Schema\n",
    "\n",
    "\n",
    "# Run a quick validation that we have an entry for the OPEN_API_KEY within environment variables\n",
    "assert \"OPENAI_API_KEY\" in os.environ, \"OPENAI_API_KEY environment variable must be set\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the MLflow Experiment\n",
    "\n",
    "In this section of the tutorial, we use MLflow's `set_experiment` function to define an experiment named \"Code Helper\". This step is essential in MLflow's workflow for several reasons:\n",
    "\n",
    "1. **Unique Identification**: A unique and distinct experiment name like \"Code Helper\" is crucial for easy identification and segregation of the runs pertaining to this specific project, especially when working on multiple projects or experiments simultaneously.\n",
    "\n",
    "2. **Simplified Tracking**: Naming the experiment enables effortless tracking of all the runs and models associated with it, maintaining a clear history of model development, parameters, metrics, and results.\n",
    "\n",
    "3. **Ease of Access in MLflow UI**: A distinct experiment name ensures quick location and access to our experiment's runs and models within the MLflow UI, facilitating analysis, comparison of different runs, and sharing findings.\n",
    "\n",
    "4. **Facilitates Better Organization**: As projects grow in complexity, having a well-named experiment aids in better organization and management of the machine learning lifecycle, making it easier to navigate through different stages of the experiment.\n",
    "\n",
    "The use of a unique experiment name like \"Code Helper\" lays the foundation for efficient model management and tracking, a critical aspect of any machine learning workflow, especially in dynamic and collaborative environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/benjamin.wilson/repos/mlflow-fork/mlflow/docs/source/llms/openai/notebooks/mlruns/703316263508654123', creation_time=1701891935339, experiment_id='703316263508654123', last_update_time=1701891935339, lifecycle_stage='active', name='Code Helper', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Code Helper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Instruction Set for the AI Model\n",
    "\n",
    "In this part of the tutorial, we define a specific set of instructions to guide the behavior of our AI model. This is achieved through the `instruction` array, which outlines the roles and expected interactions between the system (AI model) and the user. Here's a breakdown of its components:\n",
    "\n",
    "1. **System Role**: The first element of the array defines the role of the AI model as a 'system'. It describes the model as a 'helpful expert Software Engineer' whose purpose is to assist in code analysis and provide educational support. The AI model is expected to:\n",
    "   - Offer clear explanations of the code's intent.\n",
    "   - Assess the code's correctness and readability.\n",
    "   - Suggest improvements while focusing on simplicity, maintainability, and adherence to best coding practices.\n",
    "\n",
    "2. **User Role**: The second element represents the 'user' role. This part is where the user (in this case, the person learning from the tutorial) interacts with the AI model by submitting code for review. The user is expected to:\n",
    "   - Provide code snippets for evaluation.\n",
    "   - Seek feedback and suggestions for code improvement from the AI model.\n",
    "\n",
    "This instruction set is crucial for creating an interactive learning experience. It guides the AI model in providing targeted, constructive feedback, making it an invaluable tool for understanding coding practices and enhancing coding skills.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"As an AI specializing in code review, your task is to analyze and critique the submitted code. For each code snippet, provide a detailed review that includes: \"\n",
    "            \"1. Identification of any errors or bugs. \"\n",
    "            \"2. Suggestions for optimizing code efficiency and structure. \"\n",
    "            \"3. Recommendations for enhancing code readability and maintainability. \"\n",
    "            \"4. Best practice advice relevant to the code’s language and functionality. \"\n",
    "            \"Your feedback should help the user improve their coding skills and understand best practices in software development.\"\n",
    "        ),\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"Review my code and suggest improvements: {code}\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a local path to which we will save the model and use as the location for the context loader within our custom Python Model\n",
    "model_path = \"/tmp/code-helper\"\n",
    "\n",
    "# This path cleanup is used to remove the model path if it already exists, provided in case you need to re-run this notebook in its entirety.\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    shutil.rmtree(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and Utilizing the Model Signature in MLflow\n",
    "\n",
    "In this part of the tutorial, we define a `ModelSignature` for our OpenAI model, which is a crucial step in both saving the base model and later in our custom Python Model implementation. Here's an overview of the process:\n",
    "\n",
    "1. **Model Signature Definition**:\n",
    "   - We create a `ModelSignature` object that specifies the input, output, and parameters of our model.\n",
    "   - The `inputs` and `outputs` are defined as schemas with a single string column, indicating that our model will be processing string type data.\n",
    "   - The `params` schema includes two parameters: `max_tokens` and `temperature`, each with a default value and data type defined.\n",
    "\n",
    "2. **Saving the Base OpenAI Model**:\n",
    "   - Using `mlflow.openai.save_model`, we save the base OpenAI model (`gpt-4`) along with the `instruction` set we defined earlier.\n",
    "   - The `signature` we defined is also passed in this step, ensuring that the model is saved with the correct specifications for inputs, outputs, and parameters.\n",
    "\n",
    "This dual-purpose signature is vital as it ensures consistency in how the model processes data both in its base form and when it's later wrapped in a custom Python Model. This approach streamlines the workflow and maintains uniformity across different stages of model implementation and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model signature that will be used for both the base model and the eventual custom pyfunc implementation later.\n",
    "signature = ModelSignature(\n",
    "    inputs=Schema([ColSpec(type=\"string\", name=None)]),\n",
    "    outputs=Schema([ColSpec(type=\"string\", name=None)]),\n",
    "    params=ParamSchema(\n",
    "        [\n",
    "            ParamSpec(name=\"max_tokens\", default=500, dtype=\"long\"),\n",
    "            ParamSpec(name=\"temperature\", default=0, dtype=\"float\"),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Save the base OpenAI model with the included instruction set (prompt)\n",
    "mlflow.openai.save_model(\n",
    "    model=\"gpt-4\",\n",
    "    task=openai.ChatCompletion,\n",
    "    path=model_path,\n",
    "    messages=instruction,\n",
    "    signature=signature,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancing User Experience with Custom Pyfunc Implementation\n",
    "\n",
    "In this section, we introduce a custom Python Model, `CodeHelper`, which significantly improves the user experience when interacting with the OpenAI model in an interactive development environment like Jupyter Notebook. The `CodeHelper` class is designed to format the output from the OpenAI model, making it more readable and visually appealing, similar to a chat interface. Here's how it works:\n",
    "\n",
    "1. **Initialization and Model Loading**:\n",
    "   - The `CodeHelper` class inherits from `PythonModel`.\n",
    "   - The `load_context` method is used to load the OpenAI model, which is saved as `self.model`. This model is loaded from the `context.artifacts`, ensuring that the appropriate model is used for predictions.\n",
    "\n",
    "2. **Response Formatting**:\n",
    "   - The `_format_response` method is crucial for enhancing the output format.\n",
    "   - It processes each item in the response, handling text and code blocks differently.\n",
    "   - Text lines outside of code blocks are wrapped to a width of 80 characters for better readability.\n",
    "   - Lines within code blocks (marked by `` ``` ``) are not wrapped, preserving the code structure.\n",
    "   - This formatting creates an output that resembles a chat interface, making the interaction more intuitive and user-friendly.\n",
    "\n",
    "3. **Making Predictions**:\n",
    "   - The `predict` method is where the model’s prediction occurs.\n",
    "   - It calls the loaded OpenAI model to get the raw response for the given input.\n",
    "   - The raw response is then passed to the `_format_response` method for formatting.\n",
    "   - The formatted response is returned, providing a clear and easy-to-read output.\n",
    "\n",
    "By implementing this custom `pyfunc`, we enhance the user's interaction with the AI code helper. It not only makes the output easier to understand but also presents it in a familiar format, akin to messaging, which is especially beneficial in interactive coding environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom pyfunc implementation that applies text and code formatting to the output results from the OpenAI model\n",
    "class CodeHelper(PythonModel):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def load_context(self, context):\n",
    "        self.model = mlflow.pyfunc.load_model(context.artifacts[\"model_path\"])\n",
    "\n",
    "    @staticmethod\n",
    "    def _format_response(response):\n",
    "        formatted_output = \"\"\n",
    "        in_code_block = False\n",
    "\n",
    "        for item in response:\n",
    "            lines = item.split(\"\\n\")\n",
    "            for line in lines:\n",
    "                # Check for the start/end of a code block\n",
    "                if line.strip().startswith(\"```\"):\n",
    "                    in_code_block = not in_code_block\n",
    "                    formatted_output += line + \"\\n\"\n",
    "                    continue\n",
    "\n",
    "                if in_code_block:\n",
    "                    # Don't wrap lines inside code blocks\n",
    "                    formatted_output += line + \"\\n\"\n",
    "                else:\n",
    "                    # Wrap lines outside of code blocks\n",
    "                    wrapped_lines = textwrap.fill(line, width=80)\n",
    "                    formatted_output += wrapped_lines + \"\\n\"\n",
    "\n",
    "        return formatted_output\n",
    "\n",
    "    def predict(self, context, model_input, params):\n",
    "        # Call the loaded OpenAI model instance to get the raw response\n",
    "        raw_response = self.model.predict(model_input, params=params)\n",
    "\n",
    "        # Return the formatted response so that it is easier to read\n",
    "        return self._format_response(raw_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the location that we'll be using to save (and load) our custom pyfunc implementation\n",
    "final_model_path = \"/tmp/my_code_helper\"\n",
    "\n",
    "# As before, we're cleaning up the destination location for the serialized custom model, in case you want to run this notebook several times.\n",
    "if os.path.exists(final_model_path):\n",
    "    shutil.rmtree(final_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Custom Python Model with MLflow\n",
    "\n",
    "This part of the tutorial demonstrates how to save the custom Python model, `CodeHelper`, using MLflow. The process involves specifying the model's location and additional information to ensure it is properly stored and can be retrieved for future use. Here’s an overview:\n",
    "\n",
    "1. **Defining Artifacts**:\n",
    "   - An `artifacts` dictionary is created with a key `\"model_path\"` pointing to the location of the base OpenAI model. This step is important to link our custom model with the necessary base model files.\n",
    "\n",
    "2. **Saving the Model**:\n",
    "   - The `mlflow.pyfunc.save_model` function is used to save the `CodeHelper` model.\n",
    "   - `path`: Specifies the location (`final_model_path`) where the model will be saved.\n",
    "   - `python_model`: An instance of the `CodeHelper` class is provided, indicating the model to be saved.\n",
    "   - `input_example`: An example input (`[\"x = 1\"]`) is given, which is useful for understanding the model's expected input format.\n",
    "   - `signature`: The previously defined `ModelSignature` is passed, ensuring consistency in how the model processes data.\n",
    "   - `artifacts`: The `artifacts` dictionary is included to associate the base OpenAI model with our custom model.\n",
    "\n",
    "This step is crucial for encapsulating the entire functionality of our `CodeHelper` model in a format that MLflow can manage and track. It allows for easy deployment and versioning of the model, facilitating its use in various applications and environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e5e52af0d24e3294860fa500ce4ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the location of the\n",
    "artifacts = {\"model_path\": model_path}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.pyfunc.save_model(\n",
    "        path=final_model_path,\n",
    "        python_model=CodeHelper(),\n",
    "        input_example=[\"x = 1\"],\n",
    "        signature=signature,\n",
    "        artifacts=artifacts,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load our saved Custom Python Model\n",
    "\n",
    "In this next section, we load the model that we just saved so that we can use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_helper = mlflow.pyfunc.load_model(final_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the `code_inspector` Decorator Function\n",
    "\n",
    "The `code_inspector` function is a Python decorator designed to augment functions with automatic code review capabilities using an MLflow pyfunc model. Here's a breakdown of how it works:\n",
    "\n",
    "1. **Decorator Function Setup**:\n",
    "   - `code_inspector` takes an MLflow model as an argument. This model is used to evaluate the code of any function it decorates.\n",
    "   - Inside, it defines `decorator_check_my_function`, a function that creates the actual decorator.\n",
    "\n",
    "2. **Wrapper Function**:\n",
    "   - `decorator_check_my_function` further defines `wrapper`, which will wrap around the original function.\n",
    "   - `wrapper` accepts arbitrary arguments and keyword arguments, allowing it to decorate any function.\n",
    "   - It uses `inspect.getsource` to extract the source code of the decorated function.\n",
    "\n",
    "3. **Code Analysis and Feedback**:\n",
    "   - The source code is then analyzed by the MLflow model using `model.predict`.\n",
    "   - The model's feedback, which may include code improvements, error identification, or suggestions, is printed out.\n",
    "   - In case of exceptions during model prediction or formatting, the error is printed.\n",
    "   - After printing the feedback, `wrapper` executes the original function and returns its result.\n",
    "\n",
    "4. **Application**:\n",
    "   - Apply `code_inspector` as a decorator to functions for real-time code quality checks and feedback.\n",
    "   - This is particularly useful for learning and improving coding practices, as it provides insights into code quality and best practices.\n",
    "\n",
    "This decorator enhances the functionality of functions, allowing them to be automatically reviewed for code quality and correctness using an MLflow pyfunc model, thereby enriching the development and learning experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_inspector(model):\n",
    "    \"\"\"\n",
    "    Function decorator that will evaluate the implementation of any decorated function and provide feedback on it when called\n",
    "\n",
    "    Args:\n",
    "        model: The MLflow pyfunc model that will be used to evaluate the code\n",
    "    \"\"\"\n",
    "\n",
    "    def decorator_check_my_function(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            try:\n",
    "                parsed_func = inspect.getsource(func)\n",
    "                response = model.predict(parsed_func)\n",
    "                # Print the response so that even if the code doesn't execute properly, we'll get feedback about what to change\n",
    "                print(response)\n",
    "            # If there is an error with calling the model or in parsing the response, we still want to return the function response\n",
    "            except Exception as e:\n",
    "                print(\"Error during model prediction or formatting:\", e)\n",
    "            return func(*args, **kwargs)\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator_check_my_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Usage Trial: The `summing_function` with `code_inspector`\n",
    "\n",
    "We apply the `code_inspector` decorator to a function named `summing_function`. This function is designed to calculate the sum of sums for a given range. Here's an insight into its functionality and the enhancement brought by `code_inspector`:\n",
    "\n",
    "1. **Function Overview**:\n",
    "   - `summing_function` calculates the cumulative sum of numbers up to `n`. It does so by iterating over a range and summing the intermediate sums at each step.\n",
    "   - A dictionary, `intermediate_sums`, is used to store these sums, which are then aggregated to find the final sum.\n",
    "\n",
    "2. **Using `code_inspector`**:\n",
    "   - The function is decorated with `code_inspector(loaded_helper)`. This means that each time `summing_function` is called, the MLflow model loaded as `loaded_helper` analyzes its code.\n",
    "   - The decorator provides real-time feedback on the code, assessing aspects like quality, efficiency, and best practices.\n",
    "\n",
    "3. **Educational Benefit**:\n",
    "   - This setup is ideal for learning, allowing users to receive instant, actionable feedback on their code.\n",
    "   - It offers a practical way to understand the logic behind the function and learn coding optimizations and improvements.\n",
    "\n",
    "By integrating `code_inspector` with `summing_function`, the tutorial demonstrates an interactive approach to enhancing coding skills, with immediate feedback aiding in understanding and improvement.\n",
    "\n",
    "Before proceeding to see the response from GPT-4, can you identify all of the issues in this code (there are more than a few)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_inspector(loaded_helper)\n",
    "def summing_function(n):\n",
    "    sum_result = 0\n",
    "\n",
    "    intermediate_sums = {}\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        intermediate_sums[str(i)] = sum([x for x in range(1, i + 1)])\n",
    "        for key in intermediate_sums:\n",
    "            if key == str(i):\n",
    "                sum_result = intermediate_sums[key]\n",
    "\n",
    "    final_sum = sum([intermediate_sums[key] for key in intermediate_sums if int(key) == n])\n",
    "\n",
    "    return int(str(final_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution and Analysis of `summing_function(1000)`\n",
    "\n",
    "When we execute `summing_function(1000)`, several key processes take place, utilizing our custom MLflow model through the `code_inspector` decorator. Here's what happens:\n",
    "\n",
    "1. **Decorator Activation**:\n",
    "   - On calling `summing_function(1000)`, the `code_inspector` decorator is the first to activate. This decorator is designed to use the `loaded_helper` model to analyze the decorated function.\n",
    "\n",
    "2. **Model Analyzes the Function Code**:\n",
    "   - `code_inspector` retrieves the source code of `summing_function` using the `inspect` module.\n",
    "   - This source code is then passed to the `loaded_helper` model, which performs an analysis based on its training and provided instructions. The model predicts feedback on code quality, efficiency, and best practices.\n",
    "\n",
    "3. **Feedback Presentation**:\n",
    "   - The feedback generated by the model is printed out. This feedback might include suggestions for code optimization, identification of potential errors, or general advice on coding practices.\n",
    "   - This step provides an educational insight into the code quality before the function executes its logic.\n",
    "\n",
    "4. **Function Execution**:\n",
    "   - After the feedback is displayed, the `summing_function` proceeds to execute with the input `1000`.\n",
    "   - The function calculates the cumulative sum of numbers up to 1000, but due to its inefficient implementation, this process may be slower and more resource-intensive than necessary.\n",
    "\n",
    "5. **Return of Result**:\n",
    "   - The function returns the final computed sum, which is the result of the summing logic implemented within it.\n",
    "\n",
    "This demonstration highlights how the `code_inspector` decorator, combined with our custom MLflow model, provides a unique, real-time code analysis and feedback mechanism, enhancing the learning and development experience in an interactive environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a detailed review of your code:\n",
      "\n",
      "1. Errors or bugs: There are no syntax errors in your code, but there is a\n",
      "logical error. The code is more complex than it needs to be for calculating the\n",
      "sum of numbers from 1 to n. The use of a dictionary to store intermediate sums\n",
      "is unnecessary and adds extra computational overhead.\n",
      "\n",
      "2. Optimizing code efficiency and structure: The sum of numbers from 1 to n can\n",
      "be calculated directly using the formula n*(n+1)/2. This will significantly\n",
      "improve the efficiency of your code.\n",
      "\n",
      "3. Enhancing code readability and maintainability: The code can be simplified to\n",
      "enhance readability. The use of a dictionary and the conversion of integers to\n",
      "strings and back to integers makes the code harder to understand and maintain.\n",
      "\n",
      "4. Best practice advice: In Python, it's best to keep things simple and\n",
      "readable. Avoid unnecessary conversions and data structures. Also, when\n",
      "calculating a sum of a sequence of numbers, consider if there's a mathematical\n",
      "formula that can simplify the task.\n",
      "\n",
      "Here's a revised version of your function:\n",
      "\n",
      "```python\n",
      "def summing_function(n):\n",
      "    return n * (n + 1) // 2\n",
      "```\n",
      "\n",
      "This version of the function is simpler, more efficient, and easier to read and\n",
      "maintain. It directly calculates the sum of numbers from 1 to n using a\n",
      "mathematical formula, without the need for loops, dictionaries, or type\n",
      "conversions.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summing_function(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of `one_liner` Function\n",
    "\n",
    "The `one_liner` function, decorated with `code_inspector`, demonstrates an interesting approach but has several issues:\n",
    "\n",
    "1. **Complexity**: The function uses nested lambda expressions to calculate the factorial of `n`. While compact, this approach is overly complex and hard to read, making the code less maintainable and understandable.\n",
    "\n",
    "2. **Readability**: Good coding practice emphasizes readability, which is compromised here due to the one-liner approach. Such code can be challenging to debug and understand, especially for those unfamiliar with the specific coding style.\n",
    "\n",
    "3. **Best Practices**: While demonstrating Python's capabilities for writing concise code, this example strays from common best practices, particularly in terms of clarity and simplicity.\n",
    "\n",
    "When reviewed by the `code_inspector` model, these issues are likely to be highlighted, emphasizing the importance of balancing clever coding with readability and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_inspector(loaded_helper)\n",
    "def one_liner(n):\n",
    "    return (\n",
    "        (lambda f, n: f(f, n))(lambda f, n: n * f(f, n - 1) if n > 1 else 1, n)\n",
    "        if isinstance(n, int) and n >= 0\n",
    "        else \"Invalid input\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code is a one-liner implementation of the factorial function using lambda\n",
      "functions. Here's the review:\n",
      "\n",
      "1. Errors or bugs:\n",
      "   There are no syntax errors or bugs in the code. It correctly calculates the\n",
      "factorial of a non-negative integer and returns \"Invalid input\" for other types\n",
      "of inputs.\n",
      "\n",
      "2. Suggestions for optimizing code efficiency and structure:\n",
      "   While the code is efficient, its structure is quite complex due to the use of\n",
      "recursive lambda functions. This can make it difficult to understand and debug.\n",
      "A more straightforward implementation of the factorial function might be more\n",
      "suitable in most cases.\n",
      "\n",
      "3. Recommendations for enhancing code readability and maintainability:\n",
      "   The code is not very readable due to its complexity and lack of comments. It\n",
      "would be beneficial to add comments explaining what the code does, especially\n",
      "the recursive lambda function part. Also, breaking down the one-liner into\n",
      "multiple lines or using a more traditional function definition could improve\n",
      "readability.\n",
      "\n",
      "4. Best practice advice:\n",
      "   In Python, it's generally recommended to prioritize readability over brevity.\n",
      "While one-liners can be impressive, they can also be difficult to understand and\n",
      "maintain. Here's a more readable version of the code:\n",
      "\n",
      "```python\n",
      "def factorial(n):\n",
      "    if not isinstance(n, int) or n < 0:\n",
      "        return \"Invalid input\"\n",
      "    elif n == 0 or n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return n * factorial(n - 1)\n",
      "```\n",
      "\n",
      "This version of the code does the same thing as the original, but it's much\n",
      "easier to understand. It checks the input and then uses a simple recursive\n",
      "function to calculate the factorial.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3628800"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_liner(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing `find_phone_numbers` Function\n",
    "\n",
    "The `find_phone_numbers` function, enhanced with the `code_inspector`, is designed to extract phone numbers from a given text but contains a few notable issues and expected behaviors:\n",
    "\n",
    "1. **Typographical Error**: The function incorrectly uses `re.complie` instead of `re.compile`, leading to a runtime exception.\n",
    "\n",
    "2. **Pattern Matching Inaccuracy**: The regular expression pattern `\"(\\d{3})-\\d{3}-\\d{4}\"`, while formatted for typical phone numbers, can result in errors if a phone number does not appear in the string.\n",
    "\n",
    "3. **Lack of Error Handling**: Directly accessing the first element in `phone_numbers` without checking if the list is empty can lead to an `IndexError`.\n",
    "\n",
    "4. **Import Statement Position**: The `import re` statement is inside the function, which is unconventional. Imports are typically placed at the top of a script for clarity.\n",
    "\n",
    "5. **Analysis and Exception Handling**:\n",
    "   - Due to how we crafted our custom MLflow model in `code_inspector`, the function's issues will be analyzed and feedback will be returned before the function's logic is executed.\n",
    "   - After this analysis, the execution of the function will likely result in an exception (due to the typographical error), demonstrating the importance of careful code review and testing.\n",
    "\n",
    "The `code_inspector` model's review will highlight these coding missteps, emphasizing the value of proper syntax, pattern accuracy, and error handling in Python programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_inspector(loaded_helper)\n",
    "def find_phone_numbers(text):\n",
    "    pattern = \"(\\d{3})-\\d{3}-\\d{4}\"\n",
    "\n",
    "    import re\n",
    "\n",
    "    compiled_pattern = re.complie(pattern)\n",
    "\n",
    "    phone_numbers = compiled_pattern.findall(text)\n",
    "    first_number = phone_numbers[0]\n",
    "\n",
    "    print(f\"First found phone number: {first_number}\")\n",
    "    return phone_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some suggestions and improvements for your code:\n",
      "\n",
      "1. **Errors or bugs**: There is a typo in your code. You wrote\n",
      "`re.complie(pattern)` instead of `re.compile(pattern)`. This will raise a\n",
      "`AttributeError` because `re` module doesn't have a `complie` function.\n",
      "\n",
      "2. **Optimizing code efficiency and structure**:\n",
      "\n",
      "   - Import statements are usually best placed at the top of the file. This is a\n",
      "common convention that makes it easier to see what modules are used in the\n",
      "script at a glance and avoids the cost of repeatedly importing the same module.\n",
      "\n",
      "   - The function will raise an `IndexError` if there are no phone numbers in\n",
      "the text. You should add a check to ensure that `phone_numbers` is not empty\n",
      "before accessing its first element.\n",
      "\n",
      "3. **Enhancing code readability and maintainability**:\n",
      "\n",
      "   - The function name `find_phone_numbers` is clear and descriptive, which is\n",
      "good. However, the variable name `pattern` could be more descriptive. Consider\n",
      "renaming it to `phone_number_pattern` or something similar.\n",
      "\n",
      "   - It's better to use docstrings to describe what your function does. This\n",
      "makes it easier for other developers to understand your code.\n",
      "\n",
      "4. **Best practice advice**:\n",
      "\n",
      "   - Instead of printing the first phone number found, consider returning it\n",
      "from the function. This would make your function more reusable.\n",
      "\n",
      "   - You might want to consider whether you want your function to return all\n",
      "phone numbers found or just the first one. If you only need the first one,\n",
      "there's no need to find all matches and then just use the first one.\n",
      "\n",
      "Here's how you might revise your code:\n",
      "\n",
      "```python\n",
      "import re\n",
      "\n",
      "def find_phone_numbers(text):\n",
      "    \"\"\"\n",
      "    This function finds all phone numbers in the given text.\n",
      "    Phone numbers are assumed to be in the format xxx-xxx-xxxx.\n",
      "    \"\"\"\n",
      "    phone_number_pattern = \"(\\d{3})-\\d{3}-\\d{4}\"\n",
      "    compiled_pattern = re.compile(phone_number_pattern)\n",
      "    phone_numbers = compiled_pattern.findall(text)\n",
      "    \n",
      "    if phone_numbers:\n",
      "        first_number = phone_numbers[0]\n",
      "        print(f\"First found phone number: {first_number}\")\n",
      "    else:\n",
      "        print(\"No phone numbers found.\")\n",
      "    \n",
      "    return phone_numbers\n",
      "```\n",
      "\n",
      "If you only need the first phone number, you could use `re.search` instead of\n",
      "`re.findall`:\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 're' has no attribute 'complie'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cd/n8n0rm2x53l_s0xv_j_xklb00000gp/T/ipykernel_26481/78508464.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_phone_numbers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Give us a call at 888-867-5309\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/cd/n8n0rm2x53l_s0xv_j_xklb00000gp/T/ipykernel_26481/796085594.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error during model prediction or formatting:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator_check_my_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/cd/n8n0rm2x53l_s0xv_j_xklb00000gp/T/ipykernel_26481/2788726062.py\u001b[0m in \u001b[0;36mfind_phone_numbers\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcompiled_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mphone_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 're' has no attribute 'complie'"
     ]
    }
   ],
   "source": [
    "find_phone_numbers(\"Give us a call at 888-867-5309\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Harnessing the Power of MLflow in AI-Assisted Development\n",
    "\n",
    "As we conclude this tutorial, we have traversed through the integration of OpenAI's language models with the robust capabilities of MLflow, creating a powerful toolkit for AI-assisted software development. Here's a recap of our journey and the key takeaways:\n",
    "\n",
    "1. **Integrating OpenAI with MLflow**:\n",
    "   - We explored how to seamlessly integrate OpenAI's advanced language models within the MLflow framework. This integration highlighted the potential of combining AI intelligence with robust model management.\n",
    "\n",
    "2. **Implementing a Custom Python Model**:\n",
    "   - Our journey included creating a custom `CodeHelper` model, which showcased MLflow's flexibility in handling custom Python functions. This model significantly enhanced the user experience by formatting AI responses into a more readable format.\n",
    "\n",
    "3. **Real-Time Code Analysis and Feedback**:\n",
    "   - By employing the `code_inspector` decorator, we demonstrated MLflow's utility in providing real-time, insightful feedback on code quality and efficiency, fostering a learning environment that guides towards best coding practices.\n",
    "\n",
    "4. **Handling Complex Code Analysis**:\n",
    "   - The tutorial presented complex code examples, revealing how MLflow, combined with OpenAI, can handle intricate code analysis, offering suggestions and identifying potential issues.\n",
    "\n",
    "5. **Learning from Interactive Feedback**:\n",
    "   - The interactive feedback loop, enabled by our MLflow model, illustrated a practical approach to learning and improving coding skills, making this toolset particularly valuable for educational and development purposes.\n",
    "\n",
    "6. **Flexibility and Scalability of MLflow**:\n",
    "   - Throughout the tutorial, MLflow's flexibility and scalability were evident. Whether it's managing simple Python functions or integrating state-of-the-art AI models, MLflow proved to be an invaluable asset in streamlining the model management process.\n",
    "\n",
    "In summary, this tutorial not only provided insights into effective coding practices but also underscored the versatility of MLflow in enhancing AI-assisted software development. It stands as a testament to how machine learning tools and models can be innovatively applied to improve code quality, efficiency, and the overall development experience.\n",
    "\n",
    "To continue your learning journey, see the additional [advanced tutorials for MLflow's OpenAI flavor](https://www.mlflow.org/docs/latest/llms/openai/index.html#advanced-tutorials)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

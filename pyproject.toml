# Auto-generated by dev/pyproject.py. Do not edit manually.
# This file defines the package metadata of `mlflow` **during development**. To install `mlflow`
# from the source code, `mlflow-skinny` and `mlflow-tracing` are NOT included in the requirements.
# This file will be replaced by `pyproject.release.toml` when releasing a new version.

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"

[project]
name = "mlflow"
version = "3.5.2.dev0"
description = "MLflow is an open source platform for the complete machine learning lifecycle"
readme = "README.md"
keywords = ["mlflow", "ai", "databricks"]
classifiers = [
  "Development Status :: 5 - Production/Stable",
  "Intended Audience :: Developers",
  "Intended Audience :: End Users/Desktop",
  "Intended Audience :: Science/Research",
  "Intended Audience :: Information Technology",
  "Topic :: Scientific/Engineering :: Artificial Intelligence",
  "Topic :: Software Development :: Libraries :: Python Modules",
  "License :: OSI Approved :: Apache Software License",
  "Operating System :: OS Independent",
  "Programming Language :: Python :: 3.10",
]
requires-python = ">=3.10"
dependencies = [
  "Flask-CORS<7",
  "Flask<4",
  "alembic<2,!=1.10.0",
  "cachetools<7,>=5.0.0",
  "click<9,>=7.0",
  "cloudpickle<4",
  "cryptography<47,>=43.0.0",
  "databricks-sdk<1,>=0.20.0",
  "docker<8,>=4.0.0",
  "fastapi<1",
  "gitpython<4,>=3.1.9",
  "graphene<4",
  "gunicorn<24; platform_system != 'Windows'",
  "importlib_metadata<9,>=3.7.0,!=4.7.0",
  "matplotlib<4",
  "numpy<3",
  "opentelemetry-api<3,>=1.9.0",
  "opentelemetry-proto<3,>=1.9.0",
  "opentelemetry-sdk<3,>=1.9.0",
  "packaging<26",
  "pandas<3",
  "protobuf<7,>=3.12.0",
  "pyarrow<22,>=4.0.0",
  "pydantic<3,>=2.0.0",
  "python-dotenv<2,>=0.19.0",
  "pyyaml<7,>=5.1",
  "requests<3,>=2.17.3",
  "scikit-learn<2",
  "scipy<2",
  "sqlalchemy<3,>=1.4.0",
  "sqlparse<1,>=0.4.0",
  "typing-extensions<5,>=4.0.0",
  "uvicorn<1",
  "waitress<4; platform_system == 'Windows'",
]
[[project.maintainers]]
name = "Databricks"
email = "mlflow-oss-maintainers@googlegroups.com"

[project.license]
file = "LICENSE.txt"

[project.optional-dependencies]
extras = [
  "pyarrow",
  "requests-auth-aws-sigv4",
  "boto3",
  "botocore",
  "google-cloud-storage>=1.30.0",
  "azureml-core>=1.2.0",
  "pysftp",
  "kubernetes",
  "virtualenv",
  "prometheus-flask-exporter",
]
databricks = [
  "azure-storage-file-datalake>12",
  "google-cloud-storage>=1.30.0",
  "boto3>1",
  "botocore",
  "databricks-agents>=1.2.0,<2.0",
]
mlserver = [
  "mlserver>=1.2.0,!=1.3.1,<2.0.0",
  "mlserver-mlflow>=1.2.0,!=1.3.1,<2.0.0",
]
gateway = [
  "aiohttp<4",
  "boto3<2,>=1.28.56",
  "fastapi<1",
  "slowapi<1,>=0.1.9",
  "tiktoken<1",
  "uvicorn[standard]<1",
  "watchfiles<2",
]
genai = [
  "aiohttp<4",
  "boto3<2,>=1.28.56",
  "fastapi<1",
  "slowapi<1,>=0.1.9",
  "tiktoken<1",
  "uvicorn[standard]<1",
  "watchfiles<2",
]
mcp = ["fastmcp<3,>=2.0.0"]
sqlserver = ["mlflow-dbstore"]
aliyun-oss = ["aliyunstoreplugin"]
jfrog = ["mlflow-jfrog-plugin"]
langchain = ["langchain>=0.3.4,<=0.3.27"]
auth = ["Flask-WTF<2"]
jobs = ["huey<3,>=2.5.0"]

[project.urls]
homepage = "https://mlflow.org"
issues = "https://github.com/mlflow/mlflow/issues"
documentation = "https://mlflow.org/docs/latest"
repository = "https://github.com/mlflow/mlflow"

[project.scripts]
mlflow = "mlflow.cli:cli"

[project.entry-points."mlflow.app"]
basic-auth = "mlflow.server.auth:create_app"

[project.entry-points."mlflow.app.client"]
basic-auth = "mlflow.server.auth.client:AuthServiceClient"

[project.entry-points."mlflow.deployments"]
databricks = "mlflow.deployments.databricks"
http = "mlflow.deployments.mlflow"
https = "mlflow.deployments.mlflow"
openai = "mlflow.deployments.openai"

[tool.setuptools.package-data]
mlflow = [
  "store/db_migrations/alembic.ini",
  "temporary_db_migrations_for_pre_1_users/alembic.ini",
  "pyspark/ml/log_model_allowlist.txt",
  "server/auth/basic_auth.ini",
  "server/auth/db/migrations/alembic.ini",
  "models/notebook_resources/**/*",
  "ai_commands/**/*.md",
  "models/container/**/*",
  "server/js/build/**/*",
]

[tool.setuptools.packages.find]
where = ["."]
include = ["mlflow", "mlflow.*"]
exclude = ["tests", "tests.*"]
namespaces = false

# Package metadata: can't be updated manually, use dev/pyproject.py
# -----------------------------------------------------------------
# Dev tool settings: can be updated manually

[dependency-groups]
dev = [
  { include-group = "lint" },
  { include-group = "test" },
  { include-group = "build" },
  "mlflow-test-plugin",
]
lint = [
  "ruff==0.12.10",
  "black==23.7.0",
  "blacken-docs==1.18.0",
  "pre-commit==4.0.1",
  "toml==0.10.2",
  "mypy==1.17.1",
  "pydantic==2.11.7",
  "clint",
  "pyyaml>=6.0.2",
  "packaging>=25.0",
]
test = [
  "pytest==8.4.0",
  "pytest-asyncio",
  "pytest-repeat",
  "pytest-cov",
  "pytest-timeout",
  "psutil",
]
build = ["pip", "setuptools", "wheel", "build"]

[tool.uv]
required-version = "==0.8.18"
constraint-dependencies = [
  "click!=8.3.0",
  "langchain<1.0.0",
  # xgboost 3.1.0 changed base_score format to vector for multi-output models, breaking shap compatibility
  # https://xgboost.readthedocs.io/en/latest/changes/v3.1.0.html#multi-target-class-intercept
  "xgboost<3.1.0",
]

[tool.uv.pip]
torch-backend = "cpu"

[tool.uv.workspace]
members = ["dev/clint", "tests/resources/mlflow-test-plugin"]

[tool.uv.sources]
clint = { workspace = true }
mlflow-test-plugin = { workspace = true }
torch = { index = "pytorch" }

[[tool.uv.index]]
name = "pytorch"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[tool.ruff]
line-length = 100
target-version = "py310"
required-version = "0.12.10"
force-exclude = true
extend-include = ["*.ipynb"]
extend-exclude = [
  "examples/llama_index/workflow",
  "mlflow/protos",
  "mlflow/ml_package_versions.py",
  "mlflow/server/graphql/autogenerated_graphql_schema.py",
  "mlflow/server/js",
  "tests/protos",
]

[tool.ruff.format]
docstring-code-format = true
docstring-code-line-length = 88

[tool.ruff.lint]
dummy-variable-rgx = "^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$"
select = [
  "B006",    # multiple-argument-default
  "B012",    # jump-statement-in-finally
  "B015",    # useless-comparison
  "D209",    # new-line-after-last-paragraph
  "D411",    # no-blank-line-before-section
  "DTZ003",  # call-datetime-utcnow
  "E",       # error
  "F",       # Pyflakes
  "C4",      # flake8-comprehensions
  "I",       # isort
  "ISC001",  # single-line-implicit-string-concatenation
  "N804",    # invalid-first-argument-name-for-class-method
  "PIE790",  # unnecessary-placeholder
  "PLR0402", # manual-from-import
  "PLR1714", # repeated-equality-comparison
  "PLE1205", # logging-too-many-args
  "PLW0602", # global-variable-not-assigned
  "PLW1508", # invalid-envvar-default
  "PT001",   # pytest-fixture-incorrect-parentheses-style
  "PT002",   # pytest-fixture-positional-args
  "PT003",   # pytest-extraneous-scope-function
  "PT006",   # pytest-parameterize-names-wrong-type
  "PT007",   # pytest-parameterize-values-wrong-type
  "PT009",   # pytest-unittest-assertion
  "PT010",   # pytest-raises-without-exception
  "PT011",   # pytest-raises-too-broad
  "PT012",   # pytest-raises-with-multiple-statements
  "PT013",   # pytest-incorrect-pytest-import
  "PT014",   # pytest-duplicate-parametrize-test-cases
  "PT018",   # pytest-composite-assertion
  "PT022",   # pytest-useless-yield-fixture
  "PT023",   # pytest-incorrect-mark-parentheses-style
  "PT026",   # pytest-use-fixtures-without-parameters
  "PT027",   # pytest-unittest-raises-assertion
  "PT030",   # pytest-warns-too-broad
  "PT031",   # pytest-warns-with-multiple-statements
  "PYI024",  # collections-named-tuple
  "RET504",  # unnecessary-assign
  "RUF002",  # ambiguous-unicode-character-docstring
  "RUF003",  # ambiguous-unicode-character-comment
  "RUF010",  # explicit-f-string-type-conversion
  "RUF013",  # implicit-optional
  "RUF051",  # if-key-in-dict-del
  "RUF100",  # unused-noqa
  "S102",    # exec-builtin
  "S307",    # suspicious-eval-usage
  "S324",    # hashlib-insecure-hash-function
  "S506",    # unsafe-yaml-load
  "SIM101",  # duplicate-isinstance-call
  "SIM108",  # if-else-block-instead-of-if-exp
  "SIM114",  # if-with-same-arms
  "SIM115",  # open-file-with-context-handler
  "SIM210",  # if-expr-with-true-false
  "SIM910",  # dict-get-with-none-default
  "T20",     # flake8-print
  "TID251",  # banned-api
  "TID252",  # relative-import
  "TRY203",  # useless-try-except
  "UP004",   # useless-object-inheritance
  "UP006",   # non-pep585-annotation
  "UP007",   # non-pep604-annotation-union
  "UP008",   # super-call-with-parameters
  "UP011",   # lru-cache-without-parameters
  "UP012",   # unnecessary-encode-utf8
  "UP015",   # redundant-open-modes
  "UP030",   # format-literals
  "UP031",   # printf-string-format
  "UP034",   # extraneous-parenthesis
  "UP045",   # non-pep604-annotation-optional
  "W",       # warning
]
ignore = [
  "E402", # module-import-not-at-top-of-file
  "E721", # type-comparison
  "E741", # ambiguous-variable-name
  "F811", # redefined-while-unused
]

[tool.ruff.lint.per-file-ignores]
"dev/*" = ["T201", "PT018"]
"examples/*" = ["T20", "RET504", "E501"]
"docs/*" = ["T20", "RET504", "E501"]
"mlflow/*" = ["PT018"]

[tool.ruff.lint.flake8-pytest-style]
mark-parentheses = false
fixture-parentheses = false
raises-require-match-for = ["*"]
warns-require-match-for = ["*"]

[tool.ruff.lint.flake8-tidy-imports]
ban-relative-imports = "all"

[tool.ruff.lint.isort]
forced-separate = ["tests"]

[tool.ruff.lint.flake8-tidy-imports.banned-api]
"pkg_resources".msg = "Do not use pkg_resources. Use importlib.resources or importlib.metadata instead."
"entrypoints".msg = "Do not use entrypoints. Use importlib.metadata.entry_points instead."
"pip".msg = "Importing pip can cause undesired side effects such as https://github.com/scikit-learn/scikit-learn/issues/26992. Consider using `subprocess.run([sys.executable, '-m', 'pip', ...])` instead."

[tool.ruff.lint.pydocstyle]
convention = "google"

[tool.clint]
exclude = [
  "mlflow/protos",
  "mlflow/ml_package_versions.py",
  "mlflow/models/notebook_resources/eval_with_synthetic_example.py",
  "mlflow/server/js",
  "mlflow/store/db_migrations",
  "mlflow/genai/__init__.py",
  "mlflow/genai/datasets/__init__.py",
  "mlflow/genai/labeling/__init__.py",
  "mlflow/genai/label_schemas/__init__.py",
  "tests/protos",
]
typing-extensions-allowlist = [
  # Docs: https://typing-extensions.readthedocs.io/en/latest/
  "typing_extensions.Self", # Added in 4.0.0
]
# Rules that are only enabled for code examples.
example-rules = [
  "lazy-builtin-import",
  "log-model-artifact-path",
  "unknown-mlflow-function",
  "unknown-mlflow-arguments",
  "multi-assign",
  "get-artifact-uri",
]

[tool.clint.per-file-ignores]
# Rules that should only be enabled for files in the root mlflow directory
"^(?!mlflow/).*$" = [
  "forbidden-set-active-model-usage",
  "unnamed-thread",
  "thread-pool-executor-without-thread-name-prefix",
]
# This file intentionally shows problematic code as an example of what NOT to do
"docs/docs/genai/mlflow-3/faqs.mdx" = ["get-artifact-uri"]
# Multi-assign has better readability in this example.
"docs/docs/classic-ml/getting-started/deep-learning.mdx" = ["multi-assign"]

[tool.clint.forbidden-top-level-imports]
"mlflow/gateway/providers/*" = ["fastapi", "starlette", "aiohttp"]
# Databricks SDK/Agents should not be imported at the top level
"mlflow/*" = ["databricks"]

# typos
[tool.typos.default.extend-words]
als = "als"                        # alternating least squares
mape = "mape"                      # mean absolute percentage error
fpr = "fpr"                        # false positive rate
gam = "gam"                        # generalized additive models
ser = "ser"                        # serialization
yhat = "yhat"                      # ŷ
iternal = "internal"               # typo of "internal"
instumentation = "instrumentation" # typo of "instrumentation"
selectin = "selectin"              # SQLAlchemy lazy loading strategy

# https://github.com/crate-ci/typos/blob/master/docs/reference.md
[tool.typos.files]
extend-exclude = [
  # Ignore proto files
  "mlflow/protos/**/*",
  # Vendored files
  "mlflow/utils/gorilla.py",
]

[tool.typos.default]
extend-ignore-re = [
  # Line ignore with trailing `# spellchecker: disable-line`
  "(?Rm)^.*#\\s*spellchecker: disable-line$",
  # Line block with `# spellchecker: <on|off>`
  "(?s)(#|//)\\s*spellchecker: off.*?\\n\\s*(#|//)\\s*spellchecker: on",
  # numpy.arange
  "(?i)(numpy|np)\\.arange",
  # nd array
  "(?i)nd( |_|\\.)?array",
  "aNothEr",
  # German / French words/sentences used for testing
  "MLflow ist",
  "Ich habe eine schöne Haufe von Kokos",
  "Ich bin das Modell eines modernen General",
  "Apple Inc. ist ein",
  "Apple Inc. est une entreprise technologique",
  # pytorch-lightning
  "lightning",
  # `typos` flags 'lok' as a typo of 'look'
  "(?i)daniel lok",
  # GitHub user mentions
  "@[a-z0-9-]+",
  "PNGs",
  # Azure Container Instances
  "\\(ACI\\)",
  # Azure Kubernetes Service
  "\\(AKS\\)",
  "AKS",
]

[tool.pytest.ini_options]
addopts = "-p no:legacypath --strict-markers --color=yes --durations=10 --showlocals -v"
filterwarnings = [
  # Prevent deprecated numpy type aliases from being used
  "error:^`np\\.[a-z]+` is a deprecated alias for.+:DeprecationWarning:mlflow",
  "error:^`np\\.[a-z]+` is a deprecated alias for.+:DeprecationWarning:tests",
  "error::pytest.PytestCollectionWarning",
  "error:.*type should be str.*converted to str implicitly:pytest.PytestWarning",
  # Prevent deprecated threading.Thread.getName() from being used
  "error:getName\\(\\) is deprecated, get the name attribute instead:DeprecationWarning",
  # Prevent deprecated non-integer arguments to randrange() from being used
  "error:non-integer arguments to randrange\\(\\) have been deprecated:DeprecationWarning",
  # Prevent usage of deprecated Pydantic v2.0 features
  "error::pydantic.PydanticDeprecatedSince20:mlflow",
  "error::pydantic.PydanticDeprecatedSince20:tests",
]
timeout = 1200

# Currently, type checking is only enabled for `dev/clint`.
[tool.mypy]
python_version = "3.10"
disallow_untyped_defs = true
exclude_gitignore = true
